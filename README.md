# BuzzScope - Keyword Tracking Across Tech Communities

BuzzScope is a comprehensive keyword tracking application that monitors keyword popularity across multiple tech communities including Hacker News, Reddit, Discord, and YouTube. It provides detailed analytics, trend analysis, and cross-platform insights.

## Current Status

âœ… **Fully Functional** - The application is ready for use with:
- Pre-processed historical data for 4 keywords (ai, iot, mqtt, unified_namespace)
- Optimized Streamlit frontend with cached results
- Discord special display with channel distribution charts
- Cross-platform comparison and trend analysis
- All major features working and tested

## âœ¨ Features

### ğŸ“Š Analytics & Metrics
- **Volume Metrics**: Mention count, unique users, interaction count
- **Trend Analysis**: Time series analysis with moving averages
- **Cross-Platform Comparison**: Side-by-side keyword comparison
- **User Insights**: Top contributors and cross-platform user identification

### ğŸŒ Platform Support
- **Hacker News**: Stories and comments via official API
- **Reddit**: Posts and comments via PRAW
- **YouTube**: Videos via YouTube Data API v3
- **Discord**: Messages from local JSON archives

### ğŸ¯ Key Capabilities
- Real-time data collection and analysis
- Modular, extensible architecture
- Efficient Parquet-based storage
- Beautiful Streamlit web interface
- Command-line tools for automation
- Keyword management system

## ğŸš€ Quick Start

### Option 1: Use Pre-processed Data (Recommended)

The application comes with pre-processed data for 4 keywords. Simply run:

```bash
streamlit run app_simple_historical.py --server.port 8501
```

Then visit http://localhost:8501 to see the analysis results.

### Option 2: Full Installation

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd BuzzScope

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Copy the environment template and configure your API keys:

```bash
cp env.example .env
```

Edit `.env` with your API credentials:

```env
# YouTube Data API v3
YOUTUBE_API_KEY=your_youtube_api_key_here

# Reddit API (via PRAW)
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USER_AGENT=your_app_name/1.0

# Optional: Discord Bot Token
DISCORD_BOT_TOKEN=your_discord_bot_token
```

### 3. Launch the Application

```bash
# Launch Streamlit web interface
python run.py app

# Or directly with Streamlit
streamlit run app.py
```

## ğŸ› ï¸ Usage

### Web Interface

The Streamlit application provides an intuitive web interface with:

- **Keyword Input**: Enter keywords to track
- **Platform Selection**: Choose which platforms to monitor
- **Analysis Types**: Single keyword, comparison, or cross-platform insights
- **Data Collection**: Collect fresh data with one click
- **Visualizations**: Interactive charts and graphs

### Command Line Interface

```bash
# Collect data for a keyword
python run.py collect "UNS" --platforms hackernews reddit --days 30

# Analyze a keyword
python run.py analyze "UNS" --days 30

# Manage keywords
python run.py keywords

# Show storage statistics
python run.py stats
```

### Keyword Management

```bash
python run.py keywords
```

Interactive keyword management allows you to:
- Add/remove keywords
- Configure platforms per keyword
- Set analysis frequency
- Export/import keyword configurations

## ğŸ“ Project Structure

```
BuzzScope/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ models.py              # Data models and schemas
â”‚   â”œâ”€â”€ storage.py             # Parquet-based storage system
â”‚   â”œâ”€â”€ analysis.py            # Analysis engine
â”‚   â”œâ”€â”€ keyword_manager.py     # Keyword management
â”‚   â””â”€â”€ collectors/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_collector.py  # Base collector class
â”‚       â”œâ”€â”€ hackernews_collector.py
â”‚       â”œâ”€â”€ reddit_collector.py
â”‚       â”œâ”€â”€ youtube_collector.py
â”‚       â””â”€â”€ discord_collector.py
â”œâ”€â”€ data/                      # Data storage directory
â”‚   â”œâ”€â”€ hackernews/           # Hacker News data
â”‚   â”œâ”€â”€ reddit/               # Reddit data
â”‚   â”œâ”€â”€ youtube/              # YouTube data
â”‚   â”œâ”€â”€ discord/              # Discord data
â”‚   â””â”€â”€ analysis/             # Analysis results
â”œâ”€â”€ app.py                    # Streamlit application
â”œâ”€â”€ run.py                    # Command-line interface
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ env.template             # Environment template
â””â”€â”€ README.md               # This file
```

## ğŸ”§ API Setup

### YouTube Data API v3
1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing one
3. Enable YouTube Data API v3
4. Create credentials (API Key)
5. Add the API key to your `.env` file

### Reddit API
1. Go to [Reddit App Preferences](https://www.reddit.com/prefs/apps)
2. Create a new app (script type)
3. Note the client ID and secret
4. Add credentials to your `.env` file

### Discord Data
1. Use [DiscordChatExporter](https://github.com/Tyrrrz/DiscordChatExporter) to export chat data
2. Place JSON files in `./data/discord_archives/`
3. The system will automatically process the archives

## ğŸ“Š Data Storage

BuzzScope uses Parquet format for efficient data storage:

- **Partitioned by platform and date**
- **Compressed with Snappy compression**
- **Schema evolution support**
- **Fast query performance**

Data is organized as:
```
data/
â”œâ”€â”€ hackernews/
â”‚   â”œâ”€â”€ hackernews_20240101.parquet
â”‚   â””â”€â”€ hackernews_20240102.parquet
â”œâ”€â”€ reddit/
â”‚   â”œâ”€â”€ reddit_20240101.parquet
â”‚   â””â”€â”€ reddit_20240102.parquet
â””â”€â”€ ...
```

## ğŸ” Analysis Features

### Volume Metrics
- Total mentions across platforms
- Unique author count
- Interaction metrics (likes, upvotes, comments, views)

### Trend Analysis
- Daily mention trends
- Moving averages
- Growth rate calculations
- Peak activity identification

### Cross-Platform Insights
- Platform comparison
- Common users across platforms
- Platform-specific behavior patterns

### Keyword Comparison
- Side-by-side keyword performance
- Relative popularity metrics
- Trend comparisons

## ğŸ¨ Customization

### Adding New Platforms

1. Create a new collector class inheriting from `BaseCollector`
2. Implement required methods: `search_keyword()` and `get_recent_posts()`
3. Add platform configuration to `Config.PLATFORMS`
4. Update the platform registry in `models.py`

### Custom Analysis

Extend the `BuzzScopeAnalyzer` class to add custom analysis methods:

```python
def custom_analysis(self, keyword: str, **kwargs):
    # Your custom analysis logic
    pass
```

### UI Customization

The Streamlit app can be customized by modifying `app.py`:
- Add new analysis types
- Create custom visualizations
- Implement new data collection workflows

## ğŸš€ Advanced Usage

### Automated Data Collection

Set up a cron job for automated data collection:

```bash
# Collect data every 6 hours
0 */6 * * * cd /path/to/BuzzScope && python run.py collect "UNS" --days 7
```

### Batch Analysis

Analyze multiple keywords:

```python
from src.analysis import BuzzScopeAnalyzer

analyzer = BuzzScopeAnalyzer()
keywords = ["UNS", "IoT", "MQTT", "Arduino"]

for keyword in keywords:
    results = analyzer.analyze_keyword(keyword)
    # Process results
```

### Data Export

Export analysis results:

```python
from src.storage import BuzzScopeStorage

storage = BuzzScopeStorage()
results = storage.search_posts("UNS", days_back=30)

# Export to CSV
results['hackernews'].to_csv('hackernews_uns.csv', index=False)
```

## ğŸ› Troubleshooting

### Common Issues

1. **API Rate Limits**: Reduce collection frequency or implement delays
2. **Missing Data**: Check API credentials and platform availability
3. **Storage Issues**: Ensure sufficient disk space for Parquet files
4. **Memory Issues**: Process data in smaller batches

### Logging

Enable debug logging:

```bash
python run.py --log-level DEBUG collect "UNS"
```

Logs are written to `buzzscope.log` and console output.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Hacker News API
- Reddit API (PRAW)
- YouTube Data API v3
- DiscordChatExporter
- Streamlit
- Pandas and PyArrow

## ğŸ“ Support

For questions, issues, or contributions:
- Create an issue on GitHub
- Check the documentation
- Review the troubleshooting section

---

**Happy keyword tracking! ğŸ”ğŸ“Š**

