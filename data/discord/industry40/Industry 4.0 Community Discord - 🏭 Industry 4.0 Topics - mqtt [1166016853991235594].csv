AuthorID,Author,Date,Content,Attachments,Reactions
"751492163233382430","andyott33","2023-10-23T22:28:58.3290000+08:00","https://tenor.com/view/olddance-gif-23074315","",""
"829502128191045652","joshuastover","2023-10-24T22:04:01.3320000+08:00","First message ‚òùÔ∏è","",""
"829502128191045652","joshuastover","2023-10-24T22:08:07.4240000+08:00","Is MQTT lighter than OPC-UA? If yes or no, explain.","",""
"1073312001788477471","sparkylarks","2023-10-25T03:57:56.0440000+08:00","If you have 100lbs of MQTT and 100lbs of OPC-UA then neither is lighter.
dry MQTT is heavier ,but asorbs water and at about 8% water tends to become densere than OPC-UA is impermeable to water 

If your talking about colour, MQTT is octarine so can only be seen by wizards and cats, but I think it's a light shade of that.","","ü§£ (2)"
"794020366536146977","mparris","2023-10-25T05:40:16.1460000+08:00","Not enough information to answer definitely.

When it comes to interoperability, both are undefined terms.","",""
"1073312001788477471","sparkylarks","2023-10-25T08:05:54.9520000+08:00","Taking on the last MQTT related questions and Looking at the Parris method first, am on the right track to say
With the Parris Method. I publish from the Edge with my subtopics nicely delimited into the Name Metric like Greeks in a Trojan horse. 
I then run some scripts in my IIoT Platform, and create a Flat MQTT namespace.
 have I now created two single sources of truth for my organisation??
Regardless , lets say I used Node red to publish my data from a Line, into my Hive MQTT broker and then I want to create some Dashboards in my IIoT platform lets say Ignition do I
1. Read in the Sparkplug topics from the Broker( e.g Status, Count ....)
2. Parse the data I read in and publish it back to the Broker as Flat MQTT
3. Create my UDT, screen etc to calculate and visualise OEE.
4. Publish my A, Q, P and OEE into the  Broker using Sparkplug B
5. Create a script back in Ignition to read the A,S,P and OEE and publish back to the Flat ?

Assuming I do go and do that everything working great and I want to connect to my ERP and add some Business intelligence, and maybe a Canary historian. Is there any rule about whether other systems should consume the data as SPB or Flat, or is it Just case by case, and I could be consuming the Sparkplug B in Canary while the BI analysists, are using the flat structure a bit more as they look to understand the available data, even if they go back to SpB later when pulling datat through scripts.","",""
"867075936054149191","rickbullotta","2023-10-25T09:33:18.2620000+08:00","First rule: there are no rules.","",""
"794020366536146977","mparris","2023-10-25T10:25:37.6460000+08:00","""have I now created two single sources of truth for my organisation??""

It depends what you consider the single source of truth.

Sparkplug in its current form is nowhere near ready to serve an enterprise full of application trying to read that data.  In fact, I doubt many enterprise application support ingesting protobufs (encoding of sparkplug).

So, you have to determine, what will be the most popular way of consuming data for the UNS, and try to bring all data into that format/accessMethod.

Having some process unpack SparkplugB to make it more friendly for the enterprise applications sounds like a very reasonable approach.  And, in fact, you can have both namespaces live on the same MQTT broker: spBv1.0/# and also json/# (just to make up a root topic)

I think you are right in your instinct to push down to the lowest level the native protocol/informationFormat that will comprise the UNS.  Not all devices will support that, however, so Device Gateways will be required within a scalable architecture.","https://cdn.discordapp.com/attachments/1166016853991235594/1166563187492139108/Fig8.png?ex=68df3421&is=68dde2a1&hm=3028b0d7cf9108bad38ff504db84964a0e24bab1f675ba8ed3268ce512f024b1&",""
"794020366536146977","mparris","2023-10-25T10:27:14.0820000+08:00","Truth.","",""
"1073312001788477471","sparkylarks","2023-10-25T17:43:51.6660000+08:00","So I want to use Sparkplug for the additional features( Compression, State monitoring, Store and forward etc), but then map int into Flat MQTT for accessibility. That makes a lot of sense

If I have multiple brokers, e.g.4 x  Site and 1 Corporate, I focus on spB at the OT, but have my two single sources of truth which is managed by my IIOT, Devices that are Flat, are scripted to publish to spB and Devices that are spB are scripted to the  Flat.

Is that overkill?

When I get to the Corporate, do I keep the dual structure , or just go with a Flat. I think though I want to keep the connection between the brokers as spV and then convert to the flat If I use the Parris method for my data a Site level, can I then use the Schultz method at the corporate level to att the Site and Corporate topics, based on the site broker that the data originates on 

Though I'm thinking about going rogue and using AMQP for the corporate broker.","",""
"867075936054149191","rickbullotta","2023-10-25T20:58:01.9790000+08:00","Zero value keeping sparkplug topics and formats at the enterprise level.  Actually, negative value.","",""
"794542235676180500","akoscs","2023-10-26T15:35:58.7150000+08:00","I thiknk the rigth phrasing would be under what conditions is OPC UA lighter and under what conditions is MQTT lighter. As they are two very different protocols, there is not definet answer. Furthermore, as they are not even defined at the same OSI levels (plural), basicaly it is dependent on the layer above MQTT, which I implement for my applcations, how light it is. I can choose to pad every message I send with redundant data or zeros, then it will not be lighter, I can choose to implement a  custom UTF-4194304 encoding instead of UTF-8 and then it will definetly not be lighter. If we consider OPC over MQTT then your question word for word becomes equivalent to is TCP lighter then HTTP. There is not much sense in answering that. It can be lighter it can be heavier. I can choose to implement the exact same HTTP protocol over TCP just abreviate GET/POST/PUT/DELETE/others with their first two letters and ... there you have it, MY PROTOCOL is always lighter then HTTP, therefore everyone should use MY PROTOCOL. Nonsense.","",""
"767678812699361310","henning8936","2023-10-27T17:43:56.9290000+08:00","I am currently looking for a suitable MQTT Broker with clustering capabilities and found that cedalo offers a pro variant of mosquitto that allows for high availability setups. Anyone here got experience with mosquitto as an enterprise broker? Would be great to also hear your opinions and experiences on the other better known options for enterprise brokers HiveMQ, EMQX and VerneMQ? I am not looking for ne next comparision on which broker can handle how many messages. It would be more interesting to hear about ease of use/implementation, quality of support etc. 
Thanks in advance!","",""
"817835202746253344","IIoT#4707","2023-10-27T17:43:57.3120000+08:00","GG @henning, you just advanced to level 9!","",""
"867075936054149191","rickbullotta","2023-10-28T05:31:48.4870000+08:00","Add Litmus‚Äôs new broker to your list.","","üëç (3)"
"766684226455207996","bright_hummingbird_31342","2023-10-28T05:51:22.5260000+08:00","Solace is another option.","","üëç (1)"
"855607029518434314","hiptopjones","2023-10-30T03:44:13.0430000+08:00","I am experimenting with data flows using MQTT, Telegraf, InfluxDB, Grafana.  I have a station providing event data to MQTT (processed this serial number, ran this operation), but am struggling with ambiguity.  For example, how to usefully structure the events being provided, how to usefully represent those events to influxdb, how to usefully query and show them in grafana.  Can anyone recommend resources for some best practices for event data like this?  My event data looks something like this log, but I have full control over it.
2023-09-22 07:02:59.4945 [Production/Line8/Assembly/Part] {""PartNumber"":""ABC-XYZ""}
2023-09-22 07:02:59.4945 [Production/Line8/Assembly/Serial] {""SerialNumber"":""23466116""}
2023-09-22 07:02:59.5373 [Production/Line8/Assembly/Step] {""StepName"":""Check LED GPIO and USB Soldering""}
2023-09-22 07:03:00.8357 [Production/Line8/Assembly/Step] {""StepName"":""""}
2023-09-22 07:03:00.8357 [Production/Line8/Assembly/Step] {""StepName"":""Link Core Board""}
2023-09-22 07:03:01.4878 [Production/Line8/Assembly/Operation] {""OperationName"":""LinkCoreBoardSerial""}
2023-09-22 07:03:03.7278 [Production/Line8/Assembly/Operation] {""OperationName"":""""}
2023-09-22 07:03:03.7278 [Production/Line8/Assembly/Step] {""StepName"":""""}
(Sorry if there's a better place for this question--let me know)","",""
"855607029518434314","hiptopjones","2023-10-30T03:46:18.2640000+08:00","At the end, with this data, I want to be able to show number of serial numbers processed, and maybe some state timelines showing utilization of the station.","",""
"855607029518434314","hiptopjones","2023-10-30T05:07:51.8490000+08:00","And, for the record, I do have this roughly working.  I am trying to learn how others structure, transform, query, display this type of data for better flexibility and expansion.  (I don't know what I don't know, and I also don't have the right words to ask Google or GPT the right questions.)","https://cdn.discordapp.com/attachments/1166016853991235594/1168295158815662160/image.png?ex=68dee9a7&is=68dd9827&hm=9dae328323a38a826eb13fafd07048ec34d2e6b435cb1427bc2527e2aa203a2d&",""
"740383178279354388","mriiot","2023-10-30T09:57:42.7830000+08:00","How do your payloads map to Influx LP?  https://docs.influxdata.com/influxdb/v2/reference/syntax/line-protocol/","",""
"740383178279354388","mriiot","2023-10-30T10:00:05.0470000+08:00","I find Streamsheets a good way to PoC the logic you want without the added technical constraints of all the pipeline pieces involved.
i can share a docker compose if you want to give it a try.","",""
"855607029518434314","hiptopjones","2023-10-30T12:11:11.7250000+08:00","Each message ends up going to MQTT like this
{""Timestamp"":""2023-09-19T07:14:40.3726"",""Data"":{""SerialNumber"":""12345678""}}
And then telegraf works its magic, and ends up sending influxdb this
mqtt_consumer,host=abe02311ea78,topic=Production/Line8/Assembly/Serial Data_SerialNumber=""12345678"" 1695107205398200000","",""
"855607029518434314","hiptopjones","2023-10-30T12:15:15.9880000+08:00","That looks really useful.  And you're right, a lot of time is spent just massaging the pipeline.  Streamsheets looks like it would shorten the feedback loop, and then I can worry about translating it to the pipeline once I have something I like.  Docker compose would be great!","",""
"740383178279354388","mriiot","2023-10-30T14:41:53.3120000+08:00","https://pastebin.com/raw/TJSQhzW4","","üôè (1)"
"794542235676180500","akoscs","2023-10-30T18:07:04.4810000+08:00","You really need something to tie all these messages together to make sure you know they refer to the sam part. Maybe add serial number to all of the messages realated to a certain part or add a UUId or something. Timestamps alone can help, but it would be much better if they come from the source, also then, the time stamp of your 3rd Step will not have much to do with the product serial number, so you would have to do some query gymnastics to find out which part it refers to. Use that as a TAG in influx to make querying easier. Addint a start of [operation/step/productio] and finished [operation/step/production] would make it more liek an event driven system then just passing states rather then events related to state changes.","",""
"855607029518434314","hiptopjones","2023-10-30T22:24:00.2400000+08:00","Great, this seems to validate how I've been thinking about it.  However, adding the context requires building and keeping track of some sort of metadata stack alongside the event radiator, and I was trying to keep it simple on that side.  But I guess this contextualization is going to be necessary somewhere, otherwise it will be very limiting to report on.  If I don't want to keep track of that metadata state in the source, I could probably have a step in the pipeline that consumes the MQTT events, augments them and then writes them back for downstream customers.  I get the feeling this is what data ops tools can do?  (Also when I think about starting to add 10-15 metadata tags to every event, then my SQL background wonders if that's going to have some negative outcome in influxdb related to data normalization and if there's a better way to manage it.)","",""
"867075936054149191","rickbullotta","2023-10-31T00:34:33.5790000+08:00","You're identifying one of the challenges of an MQTT-based UNS - where to store and attach persistent metadata.  It's a major flaw that could be easily addressed by the MQTT committee if they actually cared to do anything anymore.","","üëç (2)"
"855607029518434314","hiptopjones","2023-10-31T00:40:54.8470000+08:00","What's your opinion on how it should work?","",""
"817835202746253344","IIoT#4707","2023-10-31T00:40:55.1720000+08:00","GG @Indiecat, you just advanced to level 4!","",""
"740641359945531453","oliver.m.","2023-10-31T01:00:50.0010000+08:00","Is it just they can‚Äôt be bothered or they don‚Äôt see the need?","",""
"867075936054149191","rickbullotta","2023-10-31T01:04:16.3070000+08:00","They haven't done anything meaningful in years.","","üëç (1)"
"867075936054149191","rickbullotta","2023-10-31T01:06:54.2650000+08:00","Topics should support retained/persistent properties (name/value pairs) in addition to retained values.  There needs to be both an MQTT mechanism (as part of a publish or other message using user properties) and a REST or GraphQL API to get/set/query them.  The metadata properties should also be able to used as part of defining a subscription expression.   This would improve the utility of MQTT as a UNS foundation by easily 10-20X.  They also need to add a ""multi-publish"" message type so that multiple topics can be published in a single message (this is not currently supported by MQTT itself).","","üëç (2)"
"740641359945531453","oliver.m.","2023-10-31T01:22:13.9300000+08:00","Assuming the MQTT committee doesn't make these improvements, what other solutions are there?","",""
"867075936054149191","rickbullotta","2023-10-31T01:27:11.4040000+08:00","Broker vendors or UNS/IIoT platform vendors can implement similar functionality.  I already have a working version of it, except for the ability to use metadata in subscriptions.","","üëç (2)"
"855607029518434314","hiptopjones","2023-10-31T01:31:03.6220000+08:00","I've heard you talk about this project before.  Are you hoping to productize / commercialize it or is it something that's shareable, even privately?  Seeing how you're thinking about the problem space might drive some inspiration.","",""
"867075936054149191","rickbullotta","2023-10-31T01:33:20.6870000+08:00","My hope is that we find a common set of ""broker extensions"" and APIs/formats that all of the leading IIoT platform/broker vendors can implement. I don't have the time or desire anymore to do another startup, but I'm happy to contribute code and experience.","","üëç (3),üï∫ (1)"
"867075936054149191","rickbullotta","2023-10-31T01:48:05.9470000+08:00","I'm working on some visualization pieces for the POC I've built, and when that's ready I'll be happy to do a demo for the community to get some feedback","","ü§ò (2)"
"382941357699760129","walker.reynolds","2023-10-31T04:17:37.4290000+08:00","This will be a common option very soon ‚Äî Solace is impressive and has a lot of value add features which gives high ROI on licensing.","",""
"382941357699760129","walker.reynolds","2023-10-31T04:18:52.9380000+08:00","This is my primary goal of attending the Summit in Munich ‚Äî this and support for methods and/or GraphQL on topics at the broker layer.","","üëèüèº (1),üï∫ (1)"
"382941357699760129","walker.reynolds","2023-10-31T04:19:40.8040000+08:00","Cant wait to test drive this","","ü§òüèº (1)"
"740383178279354388","mriiot","2023-10-31T04:40:02.4370000+08:00","Metadata and data could be separate streams, it‚Äôs not rocket science.  There is a model representing the machine/process and then there is data against that model.","","üíØ (2)"
"740383178279354388","mriiot","2023-10-31T04:42:08.6000000+08:00","‚Ä¶. Here it comes üëπ","",""
"867075936054149191","rickbullotta","2023-10-31T04:42:29.4280000+08:00","Yup.  Agreed.  But if you're going to separate them out, you might still want ""hot"" validation of data on ingress to the broker.  And you'll need to keep them in sync.  And if you're doing granular ACL's (which you should), that's another point of overlap.","",""
"867075936054149191","rickbullotta","2023-10-31T04:42:50.7660000+08:00","I brought the love. ‚ù§Ô∏è","",""
"740383178279354388","mriiot","2023-10-31T04:43:08.2550000+08:00","üòÖ","",""
"740383178279354388","mriiot","2023-10-31T04:43:53.0580000+08:00","Broker plugins make sense","",""
"855607029518434314","hiptopjones","2023-10-31T04:44:40.7080000+08:00","That makes sense, but then how do you join those streams when comsuming?  When you're looking back at history, how do you know what metadata applied to what data?","",""
"740383178279354388","mriiot","2023-10-31T04:45:24.8860000+08:00","You have to store the model and reference back to it from the data‚Äôs ID","",""
"867075936054149191","rickbullotta","2023-10-31T04:45:50.2080000+08:00","""In Theory"" an intermediary GraphQL engine could enable heterogeneous joins, to a point.  ""In Theory"".","","üëç (2)"
"855607029518434314","hiptopjones","2023-10-31T04:47:49.8810000+08:00","That implies that you knew the metadata at the event source, so you could just pack it along for the ride in the first place.  I guess using a reference is a way to solve the ""normalization"" problem I was talking about before, so it doesn't need to come for the ride.  Or you need to augment and retrofit the reference downstream.","",""
"855607029518434314","hiptopjones","2023-10-31T04:49:56.2690000+08:00","My (admittedly limited) understanding of GraphQL is that it's a way to select out parts of a REST response that you're interested in, so basically customized APIs for everyone.  How would GraphQL enable the joining of streams?  (Never cross the streams.)","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-10-31T04:51:50.0710000+08:00","There are intermediary servers/platforms that allow you to do what amount to ""join"" GraphQL queries across federated data/APIs.  The ""join"" magic happens at the intermediate layer, and can obviously have scalabilty and performance issues depending on how the providers and the join engine is written.  And yes, NEVER CROSS THE STREAMS!","","üëç (1),ü§£ (1)"
"867075936054149191","rickbullotta","2023-10-31T04:57:34.7360000+08:00","Two to check out are Hasura and Apache Apollo.

https://www.apollographql.com/docs/federation/

https://hasura.io/blog/remote-joins-a-graphql-api-to-join-database-and-other-data-sources/","","üôå (1)"
"740383178279354388","mriiot","2023-10-31T05:00:09.0110000+08:00","I always thought PipelineDB had some goood points https://github.com/pipelinedb/docs/blob/master/streams.rst","",""
"855607029518434314","hiptopjones","2023-10-31T06:12:03.6150000+08:00","I guess more specifically, you're thinking this could be managed with federated GraphQL subscriptions, rather than GraphQL API calls.  Do you have experience with how GraphQL subscriptions scale if they were used to federate data and metadata from MQTT?","",""
"867075936054149191","rickbullotta","2023-10-31T06:17:00.8280000+08:00","I suspect it will scale terribly if there are layers and multiple conversions and serializations along the way.","",""
"867075936054149191","rickbullotta","2023-10-31T06:17:21.0380000+08:00","That‚Äôs not the approach I‚Äôm proposing BTW.","",""
"867075936054149191","rickbullotta","2023-10-31T06:17:33.7430000+08:00","But it‚Äôs certainly one option.","",""
"855607029518434314","hiptopjones","2023-10-31T07:26:18.1710000+08:00","I could see a broker that allows subscribers to request augments from other topics or other types of retained state being pretty interesting.  Probably a bunch of corner cases, but the 90% case would be awesome.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-10-31T07:46:03.8310000+08:00","That‚Äôs actually how it‚Äôs working now! Ha. Subtopic named _metadata","","üëç (1)"
"855607029518434314","hiptopjones","2023-10-31T23:28:07.6300000+08:00","Okay, so I created a little tool that listens to the simple events from MQTT I posted earlier.  It keeps track of the running set of metadata, and publishes back a more descriptive start/stop event to MQTT.  This new event is now the one that ends up in influxdb.  My raw topics are written as area/line/workstation/property, and my enriched topics are written as area/line/workstation/property/state, but I don't love that.  That structure will make it hard to do wildcard subscriptions for the raw events.  But changing something in the hierarchy above that seemed artificial and wrong, unless I maybe change the topic the raw events publish to to create some space.  I guess my question is whether there are guidelines or practices around topic namespace management, especially when writing back enriched events?
RAW: Production/Line8/Assembly/Operation --> {""Timestamp"":""2023-09-11T08:56:23.1487"",""Data"":{""OperationName"":""LinkCoreBoardSerial""}}
ENRICHED: Production/Line8/Assembly/Operation/State --> '{""Timestamp"":""2023-09-11T08:56:23.1487"",""SubjectName"":""OperationName"",""SubjectValue"":""LinkCoreBoardSerial"",""StateValue"":""Start"",""Metadata"":{""LocationName"":""Staging"",""PartNumber"":""ABC-XYZ"",""SerialNumber"":""23444171"",""StepName"":""Link Core Board"",""OperationName"":""LinkCoreBoardSerial""}}'","",""
"898217314741280828","hobbes1069","2023-11-01T00:25:09.2860000+08:00","It's arbitrary what term you use, but Walker uses `edge` to describe raw data and events. As an example let's say you're pulling 100 tags from a PLC, you can dump them in `ent/site/area/line/cell/[asset]/edge`. I'm in discrete manufacturing so I go down to the asset level, but do what works for you. Then you can consume data from the `edge` namespace and then republish the contextualized data to wherever is appropriate. This would allow generic wildercard subscriptions to whatever depth you want:
`ent/site/+/+/+/+/edge` or whatever for instance.","","üëç (1)"
"855607029518434314","hiptopjones","2023-11-01T01:08:29.3030000+08:00","Yeah, that makes a lot of sense.  Basically, be more judicious about locating the raw events in the namespace in the first place.  I'm currently changing the events from one form to another, but if I was just adding context, is there a naming convention for enriched events that people like?","",""
"898217314741280828","hobbes1069","2023-11-01T02:17:44.7890000+08:00","I don't have a document or anything, but since you're part of Mastermind, I know there are videos that cover this as well as some details in the shared OneNote.","",""
"855607029518434314","hiptopjones","2023-11-01T02:20:18.5040000+08:00","Thanks!  I am slowly working through that content.  Really good, but taking a while listening at 1.5x on my 30 min commutes üôÇ","",""
"898217314741280828","hobbes1069","2023-11-01T02:26:50.7790000+08:00","As just general advice:
1. Be obvious and don't overthink it. If something is obviously ERP data, then maybe an `.../erp/subtopic` path would be best.
2. Publish it where it makes sense. If the data describes the whole line, then it would be `.../line/subtopic`. There are things that you might publish for a whole site, etc. 

Currently I publish the weather using OpenWeatherMaps and historize it in TimescaleDB. That way a year from now if someone is running AI on the data, we can see, yeah, the weather really affects production. Hopefully we'll long term have access to the time keeping platform and know how many employees didn't showup.","","üíØ (1),üëç (2)"
"898217314741280828","hobbes1069","2023-11-01T02:40:21.0100000+08:00","Also as part of your naming scheme you need to document your UNS naming standards. I would recommened against using spaces in topic names, if you feel you need it use an underscore. I plan to use camel case since that's consistent with JSON and a lot of MQTT clients produce JSON payloads.","",""
"666121790610735110",".dmays","2023-11-03T01:14:14.5100000+08:00","I'm learning about Sparkplug B, and also seeing how it doesn't really play nice with the UNS.
It seems like having to convert each of the messages into another format to add them back into the UNS could negate some of the proposed speed benefits? 

One of the biggest benefits I see is the exception based reporting in Sparkplug B - but if Sparkplug is mostly a definition of the packet shape, couldn't regular MQTT also be exception based reporting?

And with MQTT being a poor fit for things running sub 50ms transactions, do other transactions need the speed improvement Sparkplug B offers over regular MQTT anyway?","",""
"1073312001788477471","sparkylarks","2023-11-03T23:41:36.4380000+08:00","Can anyone help me  with the Schultz Method.
 Basically reading the descriptions of the method I have found made me think I should not be using an IIoT platform doing scripting but should be using MQTT Bridging, but any way I try to use Bridging, I break the Sparkplug  payload format 

I have an Edge Broker(hiveMQEdge) with data being published to spBv1.0/Machine1/DDATA/Schultz/RiB

I have a python script on my Raspberry PI B simulating a Machine and it stored the following in a Modbus Array, Work Order, Status, Total Good and Bad Counts, Uptime and Downtime.

I have NodeRed then polling modbus and posting to MQTT. I have a Flow for doing FlatMQTT and one using the Parris Method. and then one where I am trying and failing to use the Schultz Method. That is why I use ""Schultz as my Node so I know where the data is coming from.

Am I supposed to use Broker Bridging to pass the data from the Machine1 Broker to the Line1 Broker .

Or do I need a platform to read the data from the ""Machine"" Broker and add the ""Machine1"" to the Name Metrics and publish to the Line Broker so my topic would become spBv1.0/Line1/DData/Machine1/RiB  and the metric name become ""machine 1 Total Count""","",""
"745796393855352953","thedavidschultz","2023-11-04T01:50:18.7240000+08:00","It‚Äôs not bridging per se. It means there is an area broker with devices publishing Area/Line for Group/Node. Then there is another plant or enterprise broker that consumes Enterprise/Site. For example Ignition Transmission publishes the Engine namespace. Or reference tags are created in another tag provider and that namespace is published.","",""
"745796393855352953","thedavidschultz","2023-11-04T01:51:27.1640000+08:00","I published some screen shots a while back. Might be easier to show you.","",""
"794020366536146977","mparris","2023-11-04T23:03:28.4860000+08:00","The limitation with SparkplugB is that you only have one variable ""groupID"" to represent where the node is located.

For simplicity sake, ignore devices, and let's just focus on nodes. And let's say we have a hierarchy of Enterprise/Site/Line/Cell

Your hiveMQedge is a sparkplug node, since it is the one publishing the data to the MQTT broker. So your topic path would be:

spBv1.0/<groupID>/NDATA/hiveMQedge

Rather than calling your node hiveMQedge, you could pick a name that better represents what it actual is doing:

spBv1.0/<groupID>/NDATA/cellA

So the question is, what should the groupID be? It depends on who the immediate consumer of this data is within this immediate MQTT broker.

You may have Ignition at the line level that is connected to that MQTT broker and subscribing to all the cells. So the topic path could become:
spBv1.0/line2/NDATA/cellA

Then, this ignition instance would have all the cell data in its local namespace.

So what to do if you want to aggregate the data up to the site level?

The ignition instance can become a node itself and publish to a site MQTT broker. You can pick the ignition nide name to be the line it represents So the topic path at the site broker can be:
spBv1.0/site5/NDATA/line2

All of the line2 data is bundled together as metrics under the line2 node.

You can then repeat this to aggregate to the Enterprise level:
Site ignition publishes to Enterprise broker with a node name of ""site5"" so the topic path at the enterprise level becomes:
spBv1.0/Enterprise/NDATA/site5","",""
"794020366536146977","mparris","2023-11-04T23:10:10.1120000+08:00","Sparkplug works well for setting up static pipes to applications that want all the data. It starts to break down if an application is at the enterprise level and wants only one piece of data, it will have to subscribe to the site5 node, and then receive all data from site5, sift through it for the one piece of data it wants, and throw away the rest of the data. Not very efficient for bandwidth on the wire or processing power on the application wanting the little data.

Ignition could at the enterprise level unpack all the Sparkplug data and republish to the enterprise broker as vanilla MQTT topic structures. Then, the enterprise application can subscribe to the specific data it wants:
vanillamqtt/enterprise/site5/line2/cellA/temperature","",""
"794020366536146977","mparris","2023-11-04T23:13:50.5850000+08:00","Rather than have to spin up ignition, just to handle packing/repacking of data, it would be nice to see The specification expanded to have a broker do the unpacking. The broker already has the Sparkplug data coming to it, and it could ""unpack"" on demand when a subscriber is requesting something specific via a vanilla MQTT topic. No additional bandwidth required, and no wasted processing at the client application needing the small data.

The specification also needs to be expanded to enable a browse function to see what data is available before subscribing to the data.  Again, this should be simple for the broker to do because it has all the data already and knows the topic structures that are available for subscription","",""
"1073312001788477471","sparkylarks","2023-11-04T23:31:41.3400000+08:00","My problem is if I follow the approach. and use spBv1.0/line2/NDATA/cellA and then forward that to the Site as spBv1.0/site5/NDATA/line2

I now do not know the cell that the data is comeing from.

So I am back using my IIot Platform to parse out the cell and put it back into the name metric, and I've no problem doing that, but I had thought the Schultz Method meant I didn;t need the scripting and I must be doing something wrong.

I get the limitation of Sparkplug, but a lot of the material out the suggests that you can leverage MQTT sparkplug B to structure you data to align with ISA95, but it's actually 100% incorrect, you can't make Sparkplug and ISA95 match. Vanilla MQTT yes absolutly.

So if I use Sparkplug to blast data from the edge into my broker great.","",""
"1073312001788477471","sparkylarks","2023-11-04T23:42:11.1190000+08:00","The problem is I lose fidelity somewhere, I can have IF I map the topics from line/NDATA/Machine to Site/NDATA/Area I don't  know what Machine the Data comes from. If I keep the Machine as the Node and get Site/NDATA/Machine 1, I no longer know the area or the Line that Machine 1 is in  and so need to incorporate intelligence somewhere else 

Ultimatly I want 4 levels win my Enterprise. ( 5 if I want inter Enterprise UNS) but Sparkplug allows me 1( 2 if I cheat a bit)","https://cdn.discordapp.com/attachments/1166016853991235594/1170387526536663191/image.png?ex=68df4613&is=68ddf493&hm=bda70945010d2194915aa4aaf93ad8765bad5407944acf9c9187ad8b3a84cc84&",""
"1073312001788477471","sparkylarks","2023-11-04T23:43:01.9260000+08:00","That woudl be great, I did search for them but no luck, Watche some good videos yoy made though","",""
"794020366536146977","mparris","2023-11-04T23:54:30.0460000+08:00","With your HiveMQedge, it's metric would be ""temperature""

I mentioned ignition as the application that would become a new node and package up the data, because when Ignition publishes out as Node line2, it's metrics will have the name
cellA/temperature

So this preserves where the data is coming from.

Likewise, the site ignition instance with node site5 will publish its metric as:

line2/cellA/temperature

So when you browse the namespace of your Enterprise Ignition, the hierarchy is maintained.

You are right, that this isa95 hierarchy isn't transparent through MQTT topic paths, but it is there.","",""
"867075936054149191","rickbullotta","2023-11-05T01:35:43.9730000+08:00","I'll cut to the chase: SPARKPLUG IS NOT A GOOD PROTOCOL FOR AN ENTERPRISE UNS AT PRESENT.  It is OK as a point-to-point substitute for OPC or other device -> SCADA use case.  That's pretty much it.  Plain vanilla MQTT with JSON payloads (even Sparkplug B style payloads but converted to JSON) is probably the way I'd go.  If only MQTT would add multi-publish, then we'd be good to go.  I wrote a Sparkplug expander extension for HiveMQ that does pretty much that - expands the metrics into separate topics and (in the latest version) uses a JSON format containing the data value and the timestamp as the payload for each metric.","","üíØ (8)"
"889266949173936160","seanarney","2023-11-05T02:04:09.4770000+08:00","What combinations of security are people using on their brokers regarding them for UNS use?  I'm not seeing a super huge need beyond user/pwd and ACL - maybe not even ACL to keep it simple for our customers but I am hesitant to not go further. I wonder if there are some commonly held beliefs based on practice you guys are doing that you've found to be vital or desirable?","","üëç (1)"
"150477489427185664","av8or1ab","2023-11-05T02:31:52.1050000+08:00","We use basic authentication with user/pass and certificates to encrypt our traffic.","","üëç (1)"
"867075936054149191","rickbullotta","2023-11-05T02:46:22.0060000+08:00","At a minimum you should isolate publish vs subscribe permissions.","",""
"889266949173936160","seanarney","2023-11-05T03:26:56.1320000+08:00","What measures do you usually deploy or are you comfortable with if thats a min? - thaks!","",""
"867075936054149191","rickbullotta","2023-11-05T03:45:39.3900000+08:00","Unfortunately it depends on the broker. There‚Äôs not a lot of consistency in how access control is implemented.","","üëç (1)"
"812295088348200960","patanj2","2023-11-06T09:40:58.4010000+08:00","One of your videos with the Opto 22 folks was also well done and a good reference.  I can‚Äôt remember which one it was where you got into the most detail,  so don‚Äôt have the link without rewatching.","",""
"745796393855352953","thedavidschultz","2023-11-06T09:44:41.4040000+08:00","Is this the HiveMQ video with Opto 22 and N3uron modeling edge data? It was consumed by Sepasoft that published OEE values back to same broker.","",""
"812295088348200960","patanj2","2023-11-06T09:58:56.9900000+08:00","I think it might have been the deep dive one, but they were both good.","https://cdn.discordapp.com/attachments/1166016853991235594/1170905128233082880/IMG_4946.png?ex=68df2de0&is=68dddc60&hm=8b8ebc104057293444255d49311ac8f7102f02d6605c9897e15a84a8b8caec69&",""
"867075936054149191","rickbullotta","2023-11-06T21:10:30.7290000+08:00","Shots fired. I'm fucking sick and tired of the lack of progress from the MQTT committee.  It's time to call them out.

https://www.linkedin.com/posts/rickbullotta_mqtt-iiot-industry40-activity-7127280889046163456-Ni4q?utm_source=share&utm_medium=member_desktop","","üî• (3)"
"917925131261718558","jpmoniz","2023-11-06T22:38:02.6450000+08:00","Your not wrong.  I suspect something will have to give sooner or later.  With the $$ invested into Hive and Litmus and with them developing these edge brokers. I suspect they are going to run into these usecases and reach the same conclusions. The only problem in that is if they each solve it in their own way the result just generates more divergence in the market.  Then we just end up having the same shitshow that OPC is.","","üíØ (2)"
"867075936054149191","rickbullotta","2023-11-06T22:40:00.0260000+08:00","If they're on the MQTT committee, they can make it happen if the desire is there.  I only ask that they fast track it.","",""
"794020366536146977","mparris","2023-11-07T07:00:11.1060000+08:00","I wonder if the top three MQTT vendors got together and defined the needed functionality.... Then went to the committee and told them they are moving forward with the updates and gave them a chance to ratify the changes to save face...","","üíØ (1)"
"867075936054149191","rickbullotta","2023-11-07T07:10:55.2400000+08:00","Well, I suspect that they‚Äôre all already on the committee though.","",""
"794020366536146977","mparris","2023-11-07T07:17:29.6670000+08:00","Well, then their voice will be even more potent ü§ò","","üëçüèº (1)"
"794020366536146977","mparris","2023-11-07T08:17:24.4930000+08:00","@Marc J√§ckle @Jon Forbord @Kudzai Manditereza @Walker Reynolds 

Please please please tell me that ConnAck 2023 will be recorded...","",""
"794020366536146977","mparris","2023-11-08T03:13:31.0470000+08:00","By the way...some of the limitations you outline have been documented for incorporation into Sparkplug v4:
Standardize a way to expand metrics into MQTT topics
https://github.com/eclipse-sparkplug/sparkplug/issues/262

Standardize a delimiter for use in GroupID
https://github.com/eclipse-sparkplug/sparkplug/issues/261","",""
"794020366536146977","mparris","2023-11-08T03:17:52.0580000+08:00","Disposition for submitted issues on being accomodated for Sparkplug v4:
https://htmlpreview.github.io/?https://github.com/eclipse-sparkplug/sparkplug/blob/develop/docs/sparkplug_4.0.0_features/Features.html","",""
"867075936054149191","rickbullotta","2023-11-08T03:43:15.5030000+08:00","Super disappointed that JSON format for Sparkplug payloads isn't currently on the list.  That's a major fail IMO.","",""
"741170732742213734","kudzaimanditereza","2023-11-08T20:54:56.5730000+08:00","Yes, CONNACK 2023 will be recorded!","","üëç (6),‚ù§Ô∏è (6),üï∫ (2)"
"829502128191045652","joshuastover","2023-11-11T07:03:46.8040000+08:00","Great to know!","",""
"867075936054149191","rickbullotta","2023-11-11T22:29:54.8340000+08:00","FYI I've decided to give up on moving the MQTT standard forward and instead am going to focus on solving its flaws at a layer above.","","üî• (5)"
"917925131261718558","jpmoniz","2023-11-11T23:38:23.6810000+08:00","Curious on your thoughts about what that would look like.","",""
"867075936054149191","rickbullotta","2023-11-11T23:42:30.3000000+08:00","Evolution of sparkplug plus a ton of new broker capabilities.","",""
"254777321788145664","terrancesmith","2023-11-11T23:48:16.8200000+08:00","That  was essentially the response to ""can json be added to sparkplug"" right?","",""
"867075936054149191","rickbullotta","2023-11-11T23:55:11.9610000+08:00","To a whole lot of things - that just won‚Äôt get done through standards committees.","",""
"917925131261718558","jpmoniz","2023-11-12T00:11:44.6620000+08:00","Interested on thoughts around broker capabilities.  I'm stuck in the idea of payload curation/reforming. One would say thats what products like HB are for.  I'm stuck on the thought of a raw and curated broker environments. Where tooling in the environment exists to aid in that effort.","","üëçüèº (2)"
"755629450640752670","ivanhndz","2023-11-14T04:14:56.7050000+08:00","Thanks David.","",""
"1003994033468747787","andreasbackman","2023-11-20T22:10:27.0110000+08:00","We're now at the phase that we need to actually decide upon what topic structure our MQTT should contain and how the data transferred through it should be formatted.
Now we've faced our first challenge with data consistency. Just wondering how you solve or handle the nondeterministic nature of async messaging in the UNS.

Here's an example;
ERP tells what order to work on in a specific topic.
PLC signals that it starts running on it's own topic -> how can we be sure that the thing in the ERP topic is the actual thing it's working on as it might have changed in between!

Also if the listener is down for some amount of time and misses these PLC events when they happen live and are instead queued up on the client subscription in the broker. What then?","",""
"1003994033468747787","andreasbackman","2023-11-21T22:09:58.1170000+08:00","Started a thread.","",""
"1073312001788477471","sparkylarks","2023-11-22T18:23:35.8040000+08:00","Is the PLC MQTT Native or are you using a gateway?
When Starting the machine, do you enter the Work Order?
Does Entering the Work Order Download other information from the UNS( Material Codes, Unit of measures, Sizes etc) 
 What I often do here is that the ERP Publishes a list of Jobs. and their Assignment. The MES can take that schedule and change it, e.g. a Job was scheduled on Machine 1 and Machine 1 breaks, so the Job is transferred to Machine B.

So the MES Publishes another list of Jobs.
When Starting the Machine form the HMI the Machine can only select Jobs that are assigned to in  the  MES Schedule.
Regardless the PLC publishes the WO , so if comms was lost when the Job was started, the broker would still see the change when the comms was restored. In some cases that would affect the Start time of the Job. I have some installatiosn where the timestamp is recorded in the PLC.

In relation to the issue where you lose communication to the PLC.
There are three types of Data.
- Some data is very resistant, e.g. a Flow Total, ig you lose comms you will see a jump in the total, but not really a problem. Similar the Work Order. IF you lose comms and start a new WO, the change of WO should still be detected and updated.
If your communication Loss is greater than the time for 1 Job, you need to change your network. ( you could create a buffer of Work Orders and Start and Stop time in your PLC and transmit them when comms is restored) but the network is the problem here
- Some data is instantaneous, and if it is lost you let if be, ie. Flow rates, you can buffer and store theses, but normally it is not worth the hassle. 
- There is data like alarms, that you want to latch and not unlatch unless you have a connection from the Alarm Manager. The Alarm manager should be able to dump out a bunch of.
Finialy there is Quality data, Instantaneous in nature, but often needs to be kept. Then you need to buffer it in the PLC( or maybe HMI","",""
"397074681141788672","simen13","2023-11-23T18:37:24.7410000+08:00","Hey guys, I'm trying to get an mqtt json string into telegraf, so I can get data into influxdb, but I am struggling with it. I have searched online alot but not found much help - are anyone of you experienced with telegraf?","",""
"894527802316046366","nickn5549","2023-11-23T19:25:17.6820000+08:00","Use Node-Red...more options with it","",""
"397074681141788672","simen13","2023-11-23T19:26:30.1000000+08:00","Use node-red for what?
As a replacement for telegraf?","",""
"397074681141788672","simen13","2023-11-23T19:27:32.4420000+08:00","I am building the json in arduino sketch, so I can build it however I want.","",""
"894527802316046366","nickn5549","2023-11-23T20:04:21.3940000+08:00","To move the data from MQTT to influxdb","",""
"867075936054149191","rickbullotta","2023-11-23T20:37:49.6700000+08:00","Why bother with MQTT at all? https://github.com/tobiasschuerg/InfluxDB-Client-for-Arduino#","",""
"397074681141788672","simen13","2023-11-23T22:59:06.8610000+08:00","I'm trying to follow Walkers advice on building a technology-centered solution, so if I'm changing the controller in the future, I'm not reliant on Arduino.","",""
"867075936054149191","rickbullotta","2023-11-23T23:28:07.6560000+08:00","Well, you wouldn't be.  Any controller that can make an HTTP request would work.  But if you want to create an abstraction layer via MQTT, you'll need at least three pieces of software - one to publish to MQTT, an MQTT broker, and something to listen to those topics and send it to Influx.  Telegraf *should* work, as would Node-RED, and lots of other options including some relatively simple custom code.","",""
"397074681141788672","simen13","2023-11-23T23:52:34.9980000+08:00","I understand. Yeah I've already set up the arduino to publish to the MQTT-broker, so I'll take it from there. I'll be using node-red for some things in any case, so I'm dropping telegraf.","","üëçüèº (1)"
"1073312001788477471","sparkylarks","2023-11-24T03:06:18.6380000+08:00","To me the value isn't when you switch the controller. But when your next project needs to get data from the Yoke-a-Mabob, it is already in the MQTT Broker.","",""
"867075936054149191","rickbullotta","2023-11-24T09:55:45.4220000+08:00","Except it‚Äôs not a PLC.","",""
"1073312001788477471","sparkylarks","2023-11-24T16:00:06.2920000+08:00","It's Programable, it does Logic, and Controlls things.  Fixed it for you anyway","","üòÇ (2)"
"397074681141788672","simen13","2023-11-24T21:40:32.3180000+08:00","Well I use a Arduino Opta PLC so","","ü§£ (3)"
"867075936054149191","rickbullotta","2023-11-24T21:46:03.4080000+08:00","I stand corrected!","",""
"397074681141788672","simen13","2023-11-24T21:46:07.8350000+08:00","üôÇ","",""
"772321230719811595","thomassorensen_","2023-11-29T11:36:45.1140000+08:00","What is the argument to purchase an (expensive) MQTT broker instead of using a open source broker like Mosquito? Most independent Benchmark concludes that Mosquito is as performant or often faster than all the paid brokers. So what enterprise features does other brokers have that justify their often steep price?","",""
"967372644309680168","thebeezak","2023-11-29T11:56:07.5960000+08:00","Support and SLA first and foremost. Enterprise grade resiliency and clustering, tested performance, validated connectors, security, observability. It‚Äôs all about risk and criticality ü§ë","",""
"772321230719811595","thomassorensen_","2023-11-29T12:56:12.9130000+08:00","Good point, I can definitely see support and SLA as the argument (the reason we are using a Chariott broker for our most critical system), but I feel like all the other arguments are subjective..","",""
"339656700745351180","douglawrie","2023-11-29T18:51:55.0310000+08:00","Performance concerns are a little overrated in broker selection for many purposes I think. Feature support, SLA, and cost was more important for me.","",""
"867075936054149191","rickbullotta","2023-11-29T22:19:31.0280000+08:00","In a typically MQTT architecture, where the broker is effectively a ""single point of failure"", ""resliency and clustering"" should not be considered ""subjective"" IMO.","","üëç (3),ü§ô (2)"
"898217314741280828","hobbes1069","2023-11-29T22:21:29.8750000+08:00","I'm a Linux guy so I don't mind digging into conf files, but one thing Mosquitto seems to be lacking is any kind of effective admin interface (http or otherwise).","",""
"867075936054149191","rickbullotta","2023-11-29T23:50:57.6420000+08:00","You can autoconfigure Mosquitto with the command line: ""sudo rm -fr""","","ü§£ (2)"
"898217314741280828","hobbes1069","2023-11-29T23:53:12.7720000+08:00","Why worry about `sudo`? I just login as `root`","","ü§£ (2)"
"772321230719811595","thomassorensen_","2023-11-30T00:21:40.8600000+08:00","We only use MQTT for Sparkplug at the moment. Would there be any benefit of using clustering in our use case? currently we have 3xredundant brokers, and the ""Sparkplug Redundancy"" has been working really well so far.","",""
"898217314741280828","hobbes1069","2023-11-30T00:26:07.5620000+08:00","Hard to answer without more details. How many clients? Are you global or only one site? We're global so the plan is to implement area brokers that will be bridged into an enterprise broker.","",""
"898217314741280828","hobbes1069","2023-11-30T00:26:57.1180000+08:00","I'm doing mostly vanilla MQTT (3.1.1 and 5).","",""
"339656700745351180","douglawrie","2023-11-30T01:07:28.7660000+08:00","So. Sparkplug 4 dropping late next year maybe. What do we all think. Good solutions to the major problems proposed by Eclipse? Anything they‚Äôre missing?","",""
"745796393855352953","thedavidschultz","2023-11-30T01:35:54.0920000+08:00","It is a step in the right direction.","",""
"745796393855352953","thedavidschultz","2023-11-30T01:37:41.8000000+08:00","Wes Johnson and I had a conversation about clustering. The Chariot broker does not support it. The reasoning is Primary Host is the preferred way to ensure payloads are received.","",""
"794020366536146977","mparris","2023-11-30T07:13:32.7210000+08:00","Since the Chariot broker (MQTT Distributor module) is tied to Ignition, this makes sense.

I wonder what the Sparkplug recommendation is when there is not a primary host, but are instead many peers (secondary hosts) that are interested in the data.","",""
"867075936054149191","rickbullotta","2023-11-30T07:31:56.9310000+08:00","What happens if the broker is down for an extended period?","",""
"794020366536146977","mparris","2023-11-30T08:06:51.6760000+08:00","Store and forward buffers fill up on the devices until they can hold no mo","",""
"867075936054149191","rickbullotta","2023-11-30T08:16:28.8240000+08:00","I knew that. üôÇ  Just making the case for a highly available broker in any production use case.","",""
"794020366536146977","mparris","2023-11-30T08:23:00.8110000+08:00","The ole debate... Distributed storage vs centralized storage üòÅ","",""
"745796393855352953","thedavidschultz","2023-11-30T08:55:51.5200000+08:00","With Ignition I can configure two connections on transmission and engine modules. Not sure about others but suspect there is something similar. If one goes down the device will store and forward until the other comes online. I can also set up redundant gateways with distributor.","",""
"1111719898482212874","d_leblanc","2023-11-30T20:23:38.7390000+08:00","Micro 800 gets ""better"" MQTT support. I have not used this before as we dont have any Micro 800's. I have used the sample code for socket based MQTT on control logix. the sample code works but modifying it to get a decent size topic was not fun. Rockwell is starting to add some MQTT support.","https://cdn.discordapp.com/attachments/1166016853991235594/1179759646513315921/image.png?ex=68df178a&is=68ddc60a&hm=0300d6a769394dc1ea3666bf1e53d9e010a3e0fcac7f796b292d57c50bcfd337&,https://cdn.discordapp.com/attachments/1166016853991235594/1179759646882398208/image.png?ex=68df178a&is=68ddc60a&hm=c4cb70b760dc52cd23a9b058b6d95da77859818be67e184c2fff971b95c147f5&",""
"1003994033468747787","andreasbackman","2023-11-30T20:42:51.1320000+08:00","> Is the PLC MQTT Native or are you using a gateway?
Does this matter? The PLC is just one example, could as well be two different systems.

So what you describe is that the source sending an event (e.g. production started) must indeed contain all the details to connect the dots.

How do you then make use of a UNS structure such as `corp/site/line/cell/erp/ordernumber` `corp/site/line/cell/erp/orderlinenumber` as they by nature are not updated simultaneously and thus the receiver must somehow keep track on what it has seen (i.e. overall state) and trigger when one of them are set.","",""
"794020366536146977","mparris","2023-11-30T21:28:36.8570000+08:00","https://www.linkedin.com/posts/jouni-aro-34b4681_opcua-opcdayfinland-activity-7135952148453818370-SAxo?utm_source=share&utm_medium=member_android","",""
"794020366536146977","mparris","2023-11-30T21:34:33.6720000+08:00","Interesting to see their take on MQTT topics here.

I like the variability in the prefix topic path upstream of the encoding topic, but would think that some other globally unique keyword (like spBv1.0 in Sparkplug) should be mandated to indicate where the more rigid, mandated OPC UA topic path and encoding schemes would begin.  ""Json"" and ""udap"" seem to be weak keywords?","",""
"867075936054149191","rickbullotta","2023-11-30T21:38:35.6330000+08:00","There's a buzz out there that DTDL integrated with OPC UA and MQTT is being worked on.  That could be interesting.","",""
"794542235676180500","akoscs","2023-11-30T23:30:05.2290000+08:00","Where is that buzz? That is a nice buzz.","",""
"867075936054149191","rickbullotta","2023-11-30T23:58:53.9420000+08:00","I can't divulge my sources. üòâ","",""
"743810005714600017","dep05d","2023-12-01T01:42:18.5890000+08:00","Any chance you can buzz any more details? I really like DTDL in theory, but haven‚Äôt found it as useful in practice (yet)","",""
"898217314741280828","hobbes1069","2023-12-05T22:56:44.0220000+08:00","Anyone (especially @Brian Pribe ) have experience with the Automation Direct line of PLCs? They seem pretty cost effective for small jobs but I found out the Click PLCs can only do plain MQTT, not secure MQTT + TLS. That's going to be a problem for us. I guess the step up is the BRX?","",""
"898217314741280828","hobbes1069","2023-12-05T22:57:19.1990000+08:00","Also, we're exploring using a Click PLC + Maple Systems HMI which can do MQTT + TLS.","",""
"890244048739270656","brianpribe","2023-12-05T23:43:58.0620000+08:00","For a Click PLC with a Maple Systems HMI, you are looking at the PLC C2-01CPU-2 for $136, two IO modules C2-08DR-4VC for $206, and the HMI cMT2078X for $479. Totally to $821. 

There is also getting a HMI+PLC from Maple Systems. The HMC4070A-M goes for $545, and the IO HMC3-M1212Y0200-V2 for $150. Totaling to $695. But the software is MAPware-7000 not Easy Builder Pro (still has MQTT https://www.maplesystems.com/hmi-plc-combo/hmi-plc-features.html#Features).

And then there is Horner Automation Micro OSC line. For the 7"" HE-X7R it'll cost you $950. IO, HMI, and PLC are all built-in. Software is free with MQTT SpB. What I like the most is their technical support and their youtube. 355 videos and most of them are about programming the controller step by step.","","üëç (3)"
"898217314741280828","hobbes1069","2023-12-05T23:47:29.4170000+08:00","The project was orginally to cut the power to a manual polishing operation if the amps get too high (i.e. the operator is pushing too hard). The one our Malaysia site came up with with uses all discreet components. We figured we could clone that, or come up with a ""smart"" version.","",""
"898217314741280828","hobbes1069","2023-12-05T23:48:19.0010000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1181623093224013885/MicrosoftTeams-image_6.png?ex=68df4782&is=68ddf602&hm=9948a80e11d5ecf76b24d7116c38e028374df2c05b562ae7487824dc96566748&",""
"890244048739270656","brianpribe","2023-12-05T23:53:36.0230000+08:00","https://www.phoenixcontact.com/en-us/products/motor-machine-and-system-monitoring/monitoring-relays-and-current-relays#ex-4ybgk","",""
"898217314741280828","hobbes1069","2023-12-05T23:55:26.0160000+08:00","Interesting... I was thinking of just using a CT to 4-20ma signal.","",""
"890244048739270656","brianpribe","2023-12-06T00:02:42.6340000+08:00","It all depends what features you want and why. This involves polishing an end product. A lot of QC can go into that. If you have plans to improve the process while solving this problem, then going the smart route is a good idea. Make sure to design it where you can expand your IO. If there is only one problem and there is existing equipment that you are just modifying, then simple is best. Solve the problem, update the schematics, and you're done.","",""
"898217314741280828","hobbes1069","2023-12-06T00:03:58.2330000+08:00","I don't know anything about the current relay. Can it be configured on the fly or set and forget? One thing I wanted to accomplish is potentially setting different thresholds for different produtcs (or sized within a product family).","",""
"890244048739270656","brianpribe","2023-12-06T00:05:38.1490000+08:00","It can be set on the fly or set and forget. Your operators will have to go into the panel tho. If you want to do more quality control, then I would go smart.","",""
"898217314741280828","hobbes1069","2023-12-06T00:05:59.4830000+08:00","Also, perhaps allowing temporary spikes in amps, but not sustained high amps.","",""
"890244048739270656","brianpribe","2023-12-06T00:06:37.6310000+08:00","I would assume.","",""
"335504135761690624","lenaits","2023-12-07T22:07:53.1800000+08:00","Have a technical question. How should I structure the mqtt payload when sending data in node red.
What should I include in the message? tag, value, id, timestamp etc.
Can someone give me a good example?

Retrieves signals from opcua, converts to mqtt and sends this to the UNS broker.","",""
"254777321788145664","terrancesmith","2023-12-07T22:12:35.6330000+08:00","What are people's preferred tools for planning / documenting MQTT topic/payload structures?

I've used excel, word docs and diagrams like lucidcharts to lay things out and facilitate communication.

For a little bit now, AsyncAPI has had my attention for documentation going forward. No documentation I've done (besides scripting to extract topic structures of already built systems) has been very scalable. And building something first in order to generate a solid design doc is backwards imo.","",""
"867075936054149191","rickbullotta","2023-12-07T23:54:07.5080000+08:00","This is why discovery and standardardized models help a lot.  An evolved version of Sparkplug, DTDL, OPC information models, etc...","",""
"254777321788145664","terrancesmith","2023-12-07T23:59:44.5690000+08:00","You keep baiting us with this mqtt + dtdl + opc üòÇ","",""
"1073632885153730621","vaughnturner","2023-12-08T00:19:14.3110000+08:00","@TerranceSmith here's the thoughts of our Solutions Architect, Patrick Mannion. 

Patrick Mannion
I've been working Amplication for base code purposes and easy integration / development of RestAPI and GraphQL endpoints for entities for various backends (Mongo, Pg, MySQL, etc). I hadn't looked at AsyncAPI though, it looks sweet. 
 
It's like the ""schema-first"" graphQL approach but for something like a topic namespace instead of queries","",""
"568913935147728896","zeratall","2023-12-08T03:11:17.4580000+08:00","We use a modeling tool that utilizes a language  like UML or SysML, similar to sw dev. That being said that‚Äôs just a representation, eventually that model gets implemented into the actual stack to realize the data structure.","",""
"568913935147728896","zeratall","2023-12-08T03:11:49.2740000+08:00","Most system modeling tools are all based on the same concepts of GraphDBs though aka nodes and edges","",""
"568913935147728896","zeratall","2023-12-08T03:13:55.6700000+08:00","Modeling data this way can be great for design but it‚Äôs just a representation, its not the actual thing think of ‚Äúas designed vs as built‚Äù, that‚Äôs why imho models in the future need to be ‚Äúself defining/reporting‚Äù","",""
"1011806669874937956","vikanchira","2023-12-09T14:43:08.9720000+08:00","Just did this workshop to appreciate SparkplugB. Boy, it's much easier than vanilla MQTT, for sure.","https://cdn.discordapp.com/attachments/1166016853991235594/1182935449010962572/2023-12-08_20-49-05.png?ex=68df707c&is=68de1efc&hm=bd070094bb5a961fb017870b570891dfb7831178805769f5362819600a523504&","üëçüèº (2)"
"783917475128410112","geoffnunan","2023-12-09T18:59:54.9580000+08:00","AsyncAPI","",""
"783917475128410112","geoffnunan","2023-12-09T19:02:02.1670000+08:00","Patrick is spot on with his understanding of AsyncAPI versus GraphQL","","üëç (1)"
"867075936054149191","rickbullotta","2023-12-09T20:33:25.9020000+08:00","Or you could have just used this. https://inductiveautomation.com/ignition/modules/ignition-opc-ua","",""
"1011806669874937956","vikanchira","2023-12-09T21:09:26.9540000+08:00","Yes, but N3uron is cheaper and more lightweight üí∏","",""
"867075936054149191","rickbullotta","2023-12-09T22:01:17.6560000+08:00","Huh?  How could ""something"" be cheaper than ""nothing""?  Plus, the  OPCUA module is included with Ignition.","",""
"1011806669874937956","vikanchira","2023-12-09T22:25:14.1530000+08:00","Ow... I think you missed the point of the scenario.  The OPC-UA data source is at my house and Ignition is at my Office. Unless I join the two network together with VPN or fix ip then Ignition OPC-UA Client at my office cannot connect to the OPC-UA Server at my house. The point of the exercise is to see how much easier it is to integrate when using SparkplugB instead of the normal MQTT.","",""
"867075936054149191","rickbullotta","2023-12-09T22:31:32.9830000+08:00","I thought you were recommending this type of architecture to a customer, not just a demo/learning scenario.  Why not just use Ignition Edge/Cloud?","",""
"1011806669874937956","vikanchira","2023-12-09T22:37:16.9710000+08:00","You are linking my two posts together right? This one is a work shop. I also get a better margin using N3uron and it comes with some nice features like remote access (called Fleet Manager). You are absolutely right that Ignition Edge does the same thing since it comes with MQTT Sparkplug. For my other post. The customer's request is to use their private cloud so can't use Ignition Cloud Edition on AWS.","",""
"339656700745351180","douglawrie","2023-12-15T15:33:43.3850000+08:00","PSA for anyone looking to use Cirrus Links chariot broker: the current version has a crippling bug when trying to use TLS with a bridge client. Server runs at 100% CPU with no clients connected.","",""
"339656700745351180","douglawrie","2023-12-15T15:34:33.6450000+08:00","A few TLS bugs actually. Otherwise a pretty cool product. I believe they‚Äôre working on a fix.","",""
"794020366536146977","mparris","2023-12-16T12:33:21.4620000+08:00","Has anyone been able to try out the new Litmus MQTT Broker?  @jpmoniz I think you were on the short list?","",""
"917925131261718558","jpmoniz","2023-12-16T21:15:15.9470000+08:00","Got the email late yesterday was going to download this morning","",""
"528668306690015284","vatsalshah","2023-12-17T03:47:26.3760000+08:00","Yes we enabled the next batch. I think we are on track for public beta and everyone access in late January. So many things developed in backend but not enabled on UI yet - QA pending.

We got a few feedbacks on initial trials that we found important to implement 
1. Multiple UNS 
2. Open data enricher for everyone (the integration is manual for now but at least it is on common UI)
3. Extended k8s operator (February roadmap)
 A lot more on the context layers.","",""
"794020366536146977","mparris","2023-12-17T06:42:40.5130000+08:00","Could you expand on what ""multiple UNS"" means. On have value, saying ""multiple"" and""unified"" (namespace) seems like a contradiction","",""
"528668306690015284","vatsalshah","2023-12-17T07:39:43.0480000+08:00","When you try you will see that we convert all mqtt topics into isa95 classes (enterprise/site/area/produtionunit) - those classes are exposed by GQL

Now we got feedback that we have two layout of classes 

enterprise/site/area/produtionunit for all production assets 

enterprise/site/building/xyz as facilities management one 

They are still unified at the core but allow identification correctly at topic layer","",""
"568913935147728896","zeratall","2023-12-17T07:41:46.0210000+08:00","Why constrain to ISA95 classes, would be cool to let users define their own ontology, obviously ISA95 could be a preconfigured ontology that users could select, but I think a lot of uses would like to define their own structure.","",""
"528668306690015284","vatsalshah","2023-12-17T07:49:10.3210000+08:00","Yepp it was configurable in first release and will be enabled back again soon. 
We just wanted to make sure our topic-class mapping is solid before opening all possibilities. 
This was the feedback we got that allow us to configure multiple.","",""
"568913935147728896","zeratall","2023-12-17T07:50:02.7030000+08:00","Aaah that makes sense, yeah I could see a lot of users that don‚Äôt have the data modeling expertise, or just want something ready to go having something preconfigured makes a lot of sense. That‚Äôs awesome that it has that flexibility built into it long term!","",""
"817835202746253344","IIoT#4707","2023-12-17T07:50:03.2070000+08:00","GG @Zach E, you just advanced to level 16!","",""
"528668306690015284","vatsalshah","2023-12-17T07:50:47.2990000+08:00","Fun fact - someone with about 270 sites expected us to write ML or ‚ÄúAI‚Äùmodel  to dynamically map topics to correct classes. Look at mqtt payload and detect where does it belong to (is it area or site or building etc)","","üëç (1)"
"568913935147728896","zeratall","2023-12-17T07:52:43.7900000+08:00","Hahahah, us customers  want it all :P. I will say the idea of self defining data models is really cool/exciting, but imho we still have a while till we are to that point.","",""
"568913935147728896","zeratall","2023-12-17T07:54:51.7150000+08:00","Imho the hard part is having the appropriate amount of metadata for every playload to be able to understand the context of data so you can dynamically map. I think a lot of people haven‚Äôt really put a lot of thought into  metadata for these  kind of things yet.","",""
"528668306690015284","vatsalshah","2023-12-17T07:55:12.2100000+08:00","Yepp pushing limits. We have some time before we get there. Mqtt was pain in the ass to comply first and then UNS innovation started. And hopefully over next 3-4 months we make it large enterprise grade (where most of our customers are)","",""
"568913935147728896","zeratall","2023-12-17T07:55:35.9250000+08:00","From what I‚Äôve seen you guys have been killing it, love the innovation!","",""
"528668306690015284","vatsalshah","2023-12-17T07:58:00.2660000+08:00","True - data lineage and meta data management are very proven components of any IT data strategies. OT is held back because of the poor choices we make üòÇ
There will be a time one day when we will go to dynamic apps powered by a common data language and distribution.","","üëçüèº (2)"
"528668306690015284","vatsalshah","2023-12-17T07:59:36.3210000+08:00","üôè Getting there - litmus edge accelerated our path to innovate this product.","",""
"740383178279354388","mriiot","2023-12-17T08:39:58.3180000+08:00","Looks like a worthwhile alternative to MQTT Explorer  https://github.com/facontidavide/PlotJuggler","","üëçüèª (1)"
"794020366536146977","mparris","2023-12-17T09:25:06.1660000+08:00","Am I right to interpret this as the broker having different views of the same data?

Would the user set up some rules that on-match would advertise one set of topics between the different views?","",""
"817835202746253344","IIoT#4707","2023-12-17T09:25:06.5120000+08:00","GG @MParris, you just advanced to level 25!","",""
"254777321788145664","terrancesmith","2023-12-17T09:31:42.2830000+08:00","I saw a connector for cognite data fusion was on your roadmap. Is this similar to their flexible data modelling concept?","",""
"528668306690015284","vatsalshah","2023-12-17T09:34:07.3980000+08:00","Pretty much that‚Äôs what currently we are doing. MQTT Topic -> UNS Classes. 
MQTT will work 100% on it's own regardless (like any other MQTT broker). No need of all UNS and mapping - you can send data in however format / topics. 

Initially we were dynamically mapping MQTT topics to multiple UNS classes  - took a bite bigger than we could chew so reverted back to Single Hierarchy like ISA95. But we are gonna have multiple ( but under same enterprise) UNS hierarchy support available sooner or later.","",""
"528668306690015284","vatsalshah","2023-12-17T09:35:15.9470000+08:00","After getting feedback from Walker, we included Data Enricher component inside mqtt broker by default- this can do dynamic topic /payload mapping with few clicks on UI. Feel free to test and let us know . So if you send data to one random topic, it can be mapped to more topics by user logic.","",""
"528668306690015284","vatsalshah","2023-12-17T09:41:29.0400000+08:00","I think announcement was for Litmus Edge - we have been working with Cognite to create a close integration. We mapped all Data from Litmus Edge to Cognite natively via apis. Lots of joint customers exploring the same.

The question you might be asking is for Litmus MQTT broker to Cognite - well it is no longer when I tell you that we have validated a close Litmus UNS mapping to Cognite via MQTT extractor.","",""
"917925131261718558","jpmoniz","2023-12-17T10:12:11.5840000+08:00","It will be interesting to see this in action. Can‚Äôt wait.","",""
"794020366536146977","mparris","2023-12-17T10:44:10.1370000+08:00","It's interesting to see so this playing out.

A quote from an article I posted a year ago:

""The lines between Information Gateway and Data Broker are beginning to overlap with newer products on the market. For example, Communication Layer software is starting to incorporate functions to allow some amount of Data Ops within their product. Additionally, Information Layer software primarily focused on Data Ops is beginning to include communication components such as MQTT Brokers.""

I'm very curious where all this is going to go...","",""
"753688565807841492","ravil1","2023-12-17T11:08:05.5950000+08:00","""Multiple UNSs"" reminds me that in OPC UA various types of references defined, like hierarchical, associated with, has child, has component, etc. So possibility to present variaous types of relationships is there. So potentially you can orginize assets hierarchically by geographic location, or by belonging to organization structure, or by equipment type, etc. So nodes can have multiple references of different types. Meanwhile only one instance of each node exists in the address space. Just you can reach it following different paths defined by reference type. I am curious, in MQTT to achieve similar functionality you need to  publish the same value to multiple topis by publishers? Or you configure the broker once it receives a message published to certain topic, to puiblish duplicate messages to subscribers into multiple topics?
If you start trying to support such more complex use  cases which OPC UA tries to support, I think MQTT soon can start getting the same criticism as OPC UA have.","",""
"794020366536146977","mparris","2023-12-17T21:24:50.4300000+08:00","My understanding is that the MQTT broker will consume a topic and make it available on another topic to a client.

The MQTT broker would know the extra relationships or mappings.  With a bit more standardization, each data point could include metadata, and the broker would dynamically generate outbound topics to make the data available per any of those metadata (use them like filters)

Litmus mentions GraphQL support, so I anticipate data can come in via MQTT, then clients can use the GraphQL interface and subscribe to data in any number of ways according to the metadata","","üëç (1)"
"867075936054149191","rickbullotta","2023-12-17T21:27:15.0690000+08:00","Wait, Cognite has customers? üòà","","üòÖ (2)"
"528668306690015284","vatsalshah","2023-12-18T00:16:34.8580000+08:00","Feedback from our product team was that CDF is fantastic and they have considered the complete journey. Lots of features that can accommodate Enterprise-wide data modeling. Edge products like Litmus Edge do not have access to a broader context from cloud/ERP/supply chain systems - they nailed that one right. We focus on ""live"" context / Dataops at the Edge and they take care of more enterprise-wide usecases.","","üëçüèº (1)"
"254777321788145664","terrancesmith","2023-12-18T00:36:45.3930000+08:00","Maybe not enough to make good on those funding rounds... ps I'm grateful for the purple demon emote to let us know when RickTrollotta has entered the chat. üòâ","","üòÇ (1)"
"254777321788145664","terrancesmith","2023-12-18T00:42:23.8730000+08:00","My opinion as well. Cognite's perspective on all industrial enterprise data is the most mature and wholistic I've seen.","","üëçüèº (2)"
"917925131261718558","jpmoniz","2023-12-21T07:33:55.0150000+08:00","Just had my call with them and have the download.  Small snafu on my end with VM ware but should have it installed shortly.  I liked what they had presented me and think they are heading in the right direction.  Pretty cool and thought out actually.","",""
"794020366536146977","mparris","2023-12-21T07:35:26.3670000+08:00","Are they only supporting VMWare at this time?","",""
"917925131261718558","jpmoniz","2023-12-21T07:53:44.9890000+08:00","Not sure didn‚Äôt bother to ask actually, but they have an arm iso and an ovf template.  The beta is vm right now.","",""
"769397045579481129","donpancoe","2023-12-22T02:40:41.4070000+08:00","I'm trying to get the Litmus broker VM running myself. With VirtualBox, it didn't even boot. With VMware, it is booting, but I'm stuck at the below login. The credentials provided in the docs to log in to the web page don't work here. The MAC address of the VM is not showing up in my ARP tables. Litmus support is being helpful, but I though I'd also ask here because I'm excited to try out this broker.","https://cdn.discordapp.com/attachments/1166016853991235594/1187464678423678976/image.png?ex=68df6fe9&is=68de1e69&hm=e638bc733ff7ffbaae7df53ef4630aca168e0e57b190a62c4eba284176178bd8&",""
"769397045579481129","donpancoe","2023-12-22T02:41:22.2780000+08:00","Maybe I should note this is VMware Workstation 17 Player","",""
"769397045579481129","donpancoe","2023-12-22T02:41:47.8190000+08:00","Oh, I guess it said that in my screen grab","",""
"867075936054149191","rickbullotta","2023-12-22T02:46:02.2310000+08:00","I‚Äôd love to see a plain old docker container option.","",""
"528668306690015284","vatsalshah","2023-12-22T02:47:46.4980000+08:00","Very soon - it is doing Docker inside this VM. We wanted to implement persistence and HA correctly that works across VM / docker / cloud images. 
Docker / K8S in January end i think.","","üëçüèº (2)"
"528668306690015284","vatsalshah","2023-12-22T02:48:23.1590000+08:00","You can define IP address manually from the Subnet / go to that IP directly on the UI","",""
"769397045579481129","donpancoe","2023-12-22T07:37:49.0470000+08:00","I wasn't having any luck with Player on my laptop, so I set up an ESXi server on a Raspberry Pi thanks to NetworkChuck's Youtube tutorial (https://youtu.be/6aLyZisehCU?feature=shared). Unfortunately, when I tried to create the VM from the OVA file I got the error ""Line 26: Unsupported hardware family 'vmx-19'."" Might this have something to do with the ARM processor? Thank you for continuing to help.","",""
"917925131261718558","jpmoniz","2023-12-22T07:38:38.5260000+08:00","Need vm 7.03 min.","",""
"917925131261718558","jpmoniz","2023-12-22T07:39:53.5180000+08:00","ESXI 7.03 or above","",""
"769397045579481129","donpancoe","2023-12-22T07:42:20.6240000+08:00","Judging by the downloaded file name, I'm guessing this ESXi ""Arm Fling"" install is only 7.0.0","",""
"917925131261718558","jpmoniz","2023-12-22T07:49:58.5000000+08:00","The latest 1.13 arm. Should work","",""
"917925131261718558","jpmoniz","2023-12-22T07:51:02.8080000+08:00","Not too familiar with it myself but looking at docs at face value seems that would be the case.","",""
"917925131261718558","jpmoniz","2023-12-22T07:54:16.1370000+08:00","Disregard reading the wrong doc","",""
"769397045579481129","donpancoe","2023-12-22T07:54:21.2360000+08:00","This is 1.15. I will have to keep looking into it. Or I will have to move some hardware around, and that probably won't happen until after the holidays at this point.","",""
"769397045579481129","donpancoe","2023-12-22T07:54:44.2330000+08:00","Thank you for the help, though!","",""
"917925131261718558","jpmoniz","2023-12-22T07:55:21.4810000+08:00","I had the same problem and had to upgrade hypervisor. Was running 6.7","",""
"528668306690015284","vatsalshah","2023-12-22T07:56:55.1420000+08:00","@Don Pancoe if you face issues , dm me your AWS account ID - will share AMI directly.","","üëè (2)"
"769397045579481129","donpancoe","2023-12-22T08:01:17.7550000+08:00","Thank you. I will send it via DM.","",""
"1073312001788477471","sparkylarks","2024-01-10T04:55:48.9700000+08:00","I am working Canary and was trying to historize Flat MQTT data.
To do so I ended up using the Kepware IOT Data Format, 

And it makes sense that a historian would require a standard payload, so I am wondering if other 
a) Use the Kepware IOT Data format
b) Use a different Format, but along the same lines
c) Don't use the data format and just put the data in the topic?","",""
"873009180938743828","sim_sam3","2024-01-10T22:14:59.5650000+08:00","I have less advice about what you SHOULD do for payload model but if you have questions about using Kepware Advanced Message Format or Standard Format configuration to meet your goals, let me know!","",""
"1073312001788477471","sparkylarks","2024-01-10T22:23:05.5130000+08:00","Thanks where I am I think is
As I get more and more hands on in UNS and MQTT, I keep coming across things that add significant  complexity e.g.
- From the industry chatter it sounds like Sparkplug B for manufacturing and bingo, but noone really mentions the limitations in relation in mapping that to the ISA 95 Structure, and I have seen a few examples given where there have multiple topic levels defined in the Sparkplug topic, 
Ok dig deeper and I understand how to use the Parris Method to parse my data back into a more user firendly Flat Vanilla.

Now I'm looking at doing more integration and specifically in Carnary, I find I need to have a defined payload structure.
And there are a few structures I can use. I can even develop my own.

But I like to align my practices with the industry and so I am really wondeing how people define their payloads. Do they use Kepware IOT , or use the Sparkplug structure or just define their own.","","üëç (1)"
"1073312001788477471","sparkylarks","2024-01-10T22:24:24.3300000+08:00","But overall I think the big lesson is 99.999% of people talking about using MQTT and SPB in Industry 4.0 applications have less hands on experience than me.
And I consider my self to be at a novice tinkerer level at absolute most.","","üíØ (1)"
"568913935147728896","zeratall","2024-01-10T22:48:07.6830000+08:00","That is why you need some type of datahub/orchestrator in the stack that can do those things; modeling, transforms, orchestration, etc. That‚Äôs why we use Intelligence Hub in our stack.","","üíØ (5),highbyte (1)"
"766684226455207996","bright_hummingbird_31342","2024-01-12T00:19:17.2640000+08:00","```protocol conversion != interoperability```","","üíØ (2)"
"568913935147728896","zeratall","2024-01-12T00:21:18.1090000+08:00","Absolutely, interoperability for the architecture is a combination of factors, protocol conversion is one of many of the things that contribute to overall interoperability-ness.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-12T00:24:51.3740000+08:00","Sparkplug is actually relatively poor at doing this.  Its oriented towards data acquisition for SCADA in the the energy industry with remote assets.

I would recommend starting with how you want the data to look in Canary or whatever is consuming it and then working your way back.  Trying to shoehorn whatever technology is fashionable is not really viable.  Model data to the needs of consumers.  Don't burden them with artifacts or conventions of OT systems.","","üëçüèº (2),üëç (1)"
"1073312001788477471","sparkylarks","2024-01-12T01:09:00.0210000+08:00","That does not make much sense, Surely the whole point of a UNS is that Consumers can plug in and get the data they need.
I want my historian to Plug in to my Broker and historise the data.

If I am currently using a Timescale DB for my history and want to change to Canary, Do I now need to process my data and publish it for Canary to Consume.

And then to add Power BI, I need to model that data, and publish it for Power BI.
And I then ad .........

If I keep doing that do I not just end up replacing my point to point connections with a set of point to point Mappings inside my IOT platform .","",""
"766684226455207996","bright_hummingbird_31342","2024-01-12T01:59:23.2760000+08:00","To clarify, I wasn't referring to UNS architecture in general.  I was referring to Sparkplug.

Standard MQTT does this much better because there aren't limitations to the topic namespace.  I've been observing issues how the market is adopting sparkplug.  It's well-suited to device-to-scada use cases, but often struggles with others.  I recently saw someone had 10,000+ line payloads published to topics in their UNS.  They were wondering why they having all these interoperability problems.  It was obvious they hastily crafted together an Ignition namespace and sent it through the MQTT Transmission module.  They did not consider the needs of their data consumers.

Publishing an entire SCADA namespace or large shares of it into one topic burdens consumers with parsing and is negates the benefits of pub/sub.  Eventually, in larger architectures with sophisticated namespaces and non-SCADA consumers, one will find themselves engineering their way around Sparkplug more than making use of it.","","üëç (2)"
"753688565807841492","ravil1","2024-01-12T03:41:41.2730000+08:00","If I my memory servers well, in Sparkplug the publisher can bundle values for many variables in one payload, right? If it reports values for all variables in one payload, then in case if some subscriber is interested only on one variable, it will recieve whole bunch? Does not seem effecient to me.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-12T04:09:14.2890000+08:00","Generally, the consumer will receive what changed, but there isn't really a way to manage the subscription if the consumer is interested in a portion of the payload published to a topic.  It requires parsing.  And when one considers that many consumers don't natively support sparkplug or are not capable of ingesting ""partial"" payloads, things can get very complicated.

For basic data access or acquisition, OPC UA with subscriptions is somewhat more flexible in terms of namespace.  Market support is mostly oriented to PLC tags and their datatypes.  Support of complex data is more spotty.  I wouldn't recommend trying to build a UNS with it, but it's decent for data acqusition.  It's nice for a client to be subscribe to tags interest regardless of how the namespace is organized.  There isn't the risk that payloads get too big and they need to be parsed.","",""
"753688565807841492","ravil1","2024-01-12T04:41:49.7210000+08:00","The subscriber can be capable to parse Sparkplug payload, but my point is it si not effdecient to get data changes for 1000 tags in one payload, if this particualr  subscriber is interested only on few. 
I can agree with idea to publish data for all tags, no matter is there any consuer interested on all of them. But I doubt that every subscriber will be OK on getting data for full payload of all topics. I expect that particular subsciber is interested only on very small portion of the whole namespace, and if publishing is done in Sparkplug payload, it would be more common case that not all payload will be interesting vs full payload.","",""
"867075936054149191","rickbullotta","2024-01-12T04:42:52.2010000+08:00","Isn't that how OPC UA subscriptions work though (multiple data changes in a single message)?","",""
"753688565807841492","ravil1","2024-01-12T04:58:11.5910000+08:00","In the case of OPC UA Subscriptions yes, multiple data changes in one Publish response, but these are only those tags which this particular client is interested in. And not only those tags, but also timestamp resolution is controllable, and also the term ""changed"" is configurable: you can manipulate deadband if you consider the data value as ""changed"" if only the timestamp is changed, or status only changed. And if some variable is of complex type, it is possible to subscribe to the whole structure, or only to particular members.
Over time I tend to think that attempts to eliminate OPC UA and replace it with MQTT seem feasible only in simple cases and can look good at the PoC phase, but then over time more and more requirements appear and eventually there are risks that the chosen technology does not allow to implement them or makes it too costly. Based on discussions here, the approach of building UNS based on MQTT can be even in much earlier stages than it is already done with OPC UA. It might be that some successful cases in the early stages of digital transformation projects can be overestimated and misleading. I don't have any proof, just some feeling.","",""
"753688565807841492","ravil1","2024-01-12T05:04:14.0440000+08:00","And in OPC UA in case of array type values, you can also subscribe only to some range of array elements. So much more fine grain control on what you get.
This is all about regular Data Access OPC UA subscriptions.
OPC UA Pub/Sub over MQTT might also offer much more flexibility and control than SparkPlug. I don't have too much experience with it yet. Thinking to add support for it in our product soon.","","üëçüèº (1)"
"343452320216121345","hanno23","2024-01-12T14:05:15.3430000+08:00","I posted a question about Ignition/MQTT/AWS under the ""cloud"" channel, advice would be greatly appreciated.
https://discord.com/channels/738470295056416930/740336311671586968/1194528638264156210","",""
"794020366536146977","mparris","2024-01-14T03:12:28.6710000+08:00","I think you're intuitions are right about the flexibility of OPC UA PubSub MQTT.

Six years after spec release, and still no PubSub MQTT consuming applications listed in the OPC Marketplace ü§¶‚Äç‚ôÇÔ∏è

https://opcfoundation.org/products/?filter=31","",""
"753688565807841492","ravil1","2024-01-14T04:17:13.4950000+08:00","I think usually OPC UA Pub/Sub messages published to the cloud, and I beleive at least Microsoft Azure can consume easily. 
I think the reason why no subscribers are listed at OPC Foundation web site because these consumers can be any brokers, not required to be only for OPC UA.
@MParris, you continue complaining that there is no this feature, that feature implemented in OPC UA. 
Could you please elaborate what problems  you cannot find solution for in years? My company specializes on OPC UA applications, approved suppiler for some well known companies, probably we could create custom solution for you.","",""
"794020366536146977","mparris","2024-01-14T05:01:42.7200000+08:00","@Ravil 

""Consumers can be any brokers""

This doesn't match the Foundation'sview that OPC UA is more than a protocol.

The Foundation published that the place to go to find OPC UA products is the Marketplace.

I want to see what products can natively consume OPC UA information, not simply pass them through and leave a heaping pile of integration in the laps of Integrators and end users.

I don't know why no products are listed (even Microsoft's) but I can only conclude that no listed products means no official products with native support exists.","",""
"873009180938743828","sim_sam3","2024-01-18T04:15:52.4490000+08:00","hi mark, many customers have had fine success utilizing kepware iot gateway publishing formats for a variety of I4.0 use-cases. however the use-cases treat kepware data - whether via OPC UA or MQTT as JSON payloads - as ""unstructured"" or only ""lightly structured"". refactoring happens either in-flight before the destination system or after the data is at rest.

edge modeling efforts like those models fit for use to create a UNS need more structuring/contextualization than Kepware offers right now. for example, we have an ""Advanced Format"" option in our IoT Gateway publsihing agents but this option does not allow you to work with properties of each included tag individually like our existing datalogger plugin allows (but only for database exports). this presents one from creating JSON structures that take a value from tag1 and assign it to key1, and a value from tag2 and assign it to key2. we can only take ALL values and ALL timestamps and ALL qualities and ALL names from included tags and assign to common keys. enhancement has been on the backlog for some time and i expect this to change in the future at some point. 

to be candid we have only recently become a ""Parent Brand"" within PTC, and as a result no longer SPEFICIALLY tied to roadmap related to other PTC products - this gives us more flexibility on roadmap than in years past.

For now, this is where highbyte or node-red or apache nifi or opc router or a variety of other solutions receive unstructured data from kepware and model for appropriate destinations and send out.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-01-18T05:03:08.3980000+08:00","Congrats on escaping from the tyranny of ThingWorx!","","üòÖ (2)"
"1073312001788477471","sparkylarks","2024-01-18T05:25:28.7480000+08:00","The Payload structure issue arose  me when trying to connect Canary to a unstructured or lightly structured Broker.
I want to make it a s simple for subscribers as possible, even if that enforces stricter behaviours on publishers.
Probably too rigid an approach, but I am more comfortable beeing too rigid,

Much of the data was either a string or numeric value in the topic.
Some had a list of key pairs, e.g {""Scale"": ""Infeed"",  ""Weight"": 0.04, ""Uom"": ""kg""

A few hours with Chat GPT and the Canary Script I was able to connect and parse the data as needed.
And an hour later I had 11,000 tags being recorded in the historian. 
And that is very impressive.

But  if I had defined the payload structure for publishers so the format was more paresable, things would have been simpler, 
so going forward I will structure all* my payloads in a standard format. Either Kepware or Sparkplug( Even for Vanilla)

Either Kepware IOT so 
{
  ""timestamp"": 1645036800000, /
  ""values"": [
    {
      ""id"": ""Scale"",
      ""v"": ""Infeed"",
      ""q"": true,
      ""t"": 1645036800000
    },
    {
      ""id"": ""Weight"",
      ""v"": 0.04,
      ""q"": true,
      ""t"": 1645036800000
    },
    {
      ""id"": ""Uom"",
      ""v"": ""kg"",
      ""q"": true,
      ""t"": 1645036800000


Sparkplug,
{
  ""timestamp"": 1645036800000,
  ""metrics"": [
    {
      ""name"": ""Scale"",
      ""timestamp"": 1645036800000,
      ""datatype"": ""string"",
      ""value"": ""Infeed""
    },
    {
      ""name"": ""Weight"",
      ""timestamp"": 1645036800000,
      ""datatype"": ""float"",
      ""value"": 0.04
    },
    {
      ""name"": ""Uom"",
      ""timestamp"": 1645036800000,
      ""datatype"": ""string"",
      ""value"": ""kg""
    }
  ],
  ""seq"": 1

*Sensible exclusions apply to the claim of all.","","üòç (1)"
"873009180938743828","sim_sam3","2024-01-18T05:31:35.3160000+08:00","great work mark","",""
"873009180938743828","sim_sam3","2024-01-18T05:36:19.7250000+08:00","very similar structures! sparkplug is designed for scada after all i suppose (simple, flat / atomic models == benefit).","",""
"873009180938743828","sim_sam3","2024-01-18T05:37:38.2080000+08:00","we based that model off of our own internal model, which was based originally on DDE (dynamic data exchange) topics that were then superceded by OPC DA models, which were similar to DDE topics.","",""
"873009180938743828","sim_sam3","2024-01-18T05:38:33.7310000+08:00","that ""sweat smile"" emoji was purposeful","",""
"873009180938743828","sim_sam3","2024-01-18T05:44:19.4970000+08:00","makes me curious, pardon the probably too-simple question - @MParris I believe you've used sparkplug as basis for UNS - does a value update message from an EON node to your UNS server/broker look like this 

"" {
  ""timestamp"": 1645036800000,
  ""metrics"": [{
      ""name"": ""Uom"",
      ""timestamp"": 1645036800000,
      ""datatype"": ""string"",
      ""value"": ""kg""
    }]
}""

or are you building a model with more context (within the boundaries of sparkplug) and transporting / utilizing that? 

I suppose i am asking if the value of sparkplug for you is in topic and message enforcement vs modeling capabilities allowed in the standard. and thanks for considering - i know this is answered elsewhere here over time.","",""
"873009180938743828","sim_sam3","2024-01-18T05:46:28.3500000+08:00","my folks and andy balousek's folks (he's actually been my boss for nine years!) still make a ton of magic happen with twx","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-01-18T23:14:04.2500000+08:00","Andy's a great dude and his team is the best!","","üíï (1),üíØ (1)"
"794020366536146977","mparris","2024-01-20T22:57:40.1140000+08:00","The way we've been using it is to have a definition of the Sparkplug payload for a given type of equipment.

Then consuming applications use this definition to know how to parse the Sparkplug data structure.

Basically, the information model is defined outside the system as a contact and system functionality depends on both consumer and producer to comply with that definition.","","üëç (1)"
"1187941762111639672","sebastian_09292","2024-01-22T10:43:53.2000000+08:00","if messages only have the data since last change then how does a new subscriber get the current state of the device? (since values that have not changed would not be reported in new messages)","",""
"867075936054149191","rickbullotta","2024-01-22T19:43:20.2510000+08:00","Payloads should be published with the ""retain"" flag set.  Then subscribers will get the most recent value upon connection.","",""
"1187941762111639672","sebastian_09292","2024-01-22T21:36:57.5610000+08:00","That does not work if payloads have multiple metrics and the last message only has the metrics that changed since the previous message.","",""
"753688565807841492","ravil1","2024-01-23T03:13:58.3750000+08:00","I just posted the same question on another topic. Looks like this topic is more appropriate:
Hi Sparkplug Experts,
Question: How a new subscriber gets last values for all tags under some sub/topic it is interested in? 
As I understand, in Sparplug values for multiple tags which are changed can be published in one payload, right? When ""retain"" flag is set, the broker keeps last value of the payload for that topic, right? 
Let say the publisher has 100 tags, and most of them are static, and only one changes every second. So in the initial publish the payload will have values for all 100 tags, and next publish messages will have only value for the tag which is being changed. So on that topic the broker keeps last value only for that one tag, right? How about 99 other static tags?
The question: how new subscriber gets last values for all 100 tags?","",""
"801561312861618236","jon.forbord","2024-01-23T03:21:31.1220000+08:00","This is part of the birth certificates, ie births also contain current state of all those 100 tags. The receiving node keeps a ¬´copy¬ª of the current state which is updated according to those change value publishes. If the receiving node disconnects, it will sure have missed change events, and in order to get the correct current state again, the reveiver will ask the sender for the birth certificate again, such that a correct current state is kept.","",""
"753688565807841492","ravil1","2024-01-23T03:28:18.2100000+08:00","I am about brand new subscriber. When it connects to the broker, it gets birth certificates from publishers who publsih on topics this subscriber is interested, right? Let say there was no any disconnections, so that birth certificate will have pretty old data values. And then it will get last value for changed data, in the tirival case it might have value only for 1 tag. Let say, other 99 tags had some changes since the birth certificate was issued.
Question: how these 99 tag values are received by this particular subscriber?","",""
"794020366536146977","mparris","2024-01-23T03:31:35.9500000+08:00","When a brand new client connects...it issues a command for the publisher to send out a BIRTH message.

At the time this birth message is generated to satisfy this command, the publisher will include all metrics with their latest values.  All future DATA messages published are incremental changes from this BIRTH message.

When another new client connects, it issues a command to the publisher to send out a BIRTH message, so the process is repeated.

This also means that all clients that are already connected will ALSO receive the requested BIRTH message with the latest data, even if they were online the entire time and already had the latest values.","",""
"794020366536146977","mparris","2024-01-23T03:33:17.9750000+08:00","In sparkplug 4, there are talks of separating the metadata in the BIRTH (names and structures of metrics) from the metric values.  The idea is that clients that are already connected won't have to deal with the side-effects of also getting BIRTH messages if a system has a lot of clients that are being powered up, for example.","",""
"753688565807841492","ravil1","2024-01-23T03:35:58.1170000+08:00","OK, I see.
So if you want put the system down, you just send commands ""give me new birth certificate""? If the device has 100K tags, subscribers will soon flooded by huge birth certificate messages.
BTW, how large messages are handled? In case of 100K tags I guess somewhere buffer overflow will happen.","",""
"794020366536146977","mparris","2024-01-23T03:37:51.5490000+08:00","Correct.

One of the many justifications of improving that mechanism for Sparkplug v4.","",""
"794020366536146977","mparris","2024-01-23T03:40:41.3960000+08:00","The specification does not include a minimum amount of time for a device to wait between BIRTH messages.  If you had a fast server as the publisher and the application did not have a timer to throttle birth messages, you could have some fun.

Better yet, if the system doesn't have any MQTT ACLs in place, have a client publish a sparkplug message overtop of the publisher's topic, and let all the clients try to recover from the malformed data by requesting the REBIRTH for you üòâ  sort of a DoS attack","",""
"753688565807841492","ravil1","2024-01-23T03:45:02.1490000+08:00","This proves to me one more time that Sparkplug/MQTT is way behind than OPC UA Pub/Sub. 
You might think that OPC UA in general and Pub/Sub particularly are too complex and there are no implementations supporting all specifications. But in MQTT in general and  Sparkplug/MQTT lot of use cases are not even considered and thought. 
I compare current state of MQTT/Sparkplug impelementations as equivalent to OPC UA Data Acces, which is widely adopted tody. Almost any SCADA system and many PLCs support OPC UA Data Access.
Discussions here clearly show that MQTT/Sparkplug approach is way behind than OPC UA/PubSub.","",""
"794020366536146977","mparris","2024-01-23T03:59:27.0440000+08:00","""This proves to me one more time that Sparkplug/MQTT is way behind than OPC UA Pub/Sub.""

When you say this, what technology readiness level are you speaking from (refer to my figure from the article https://iebmedia.com/technology/iiot/how-all-protocols-fail-at-data-access-interoperability/)

At TRL-4/5 , I can agree with you that OPC UA PubSub MQTT is further along that Sparkplug.

At TRL-9, OPC UA PubSub MQTT is way behind.  They need more entries here at a minimum: https://opcfoundation.org/products/?filter=31","https://cdn.discordapp.com/attachments/1166016853991235594/1199080911162048553/Fig14.png?ex=68df825f&is=68de30df&hm=200937268313c2c8bfee8bc7693e3ddf581f51fb3478f31b48ac396a9042b448&",""
"801561312861618236","jon.forbord","2024-01-23T04:04:57.9780000+08:00","I dont think anyone has argued that OPC UA doesnt have more features..","",""
"801561312861618236","jon.forbord","2024-01-23T04:05:29.5010000+08:00","It clearly does.","",""
"753688565807841492","ravil1","2024-01-23T04:08:01.2730000+08:00","In regard to TRL-9 (that there are no subscribers supporting OPC UA Pub/Sub: 
1. No need to be OPC UA application for subscribers. It is enough to be able to parse JSON metadata, and parse the payload. 
2. Not having them apublished in OPC Foundation marlketplace does not mean there are no such applications. Example: OPC UA Forge - it has support for both Pub/Sub subscriber and publisher features. This product is released, just marketing is little bit behind.","",""
"753688565807841492","ravil1","2024-01-23T04:10:29.7320000+08:00","I don't want to put down MQTT/Sparkplug. In simple use case either plain MQTT or Sparkplug as is might be enough. I guess it all depends on specific use case. And you need to have a vision for future requirements / nice to have desires too.","",""
"794020366536146977","mparris","2024-01-23T04:18:27.5990000+08:00","""No need to be OPC UA application for subscribers. It is enough to be able to parse JSON metadata, and parse the payload.""

A product supporting the bare minimum of MQTT and JSON has nothing to do with OPC UA PubSub MQTT.  Maybe that sounds like vast interoperability, but then the following layers in the figure below remain to be developed/ engineered by end users and system integrators: Mappings, Values, and Objects.

When a product is said to support Sparkplug, those layers have already been accounted for and the integrator doesn't need to worry about any of it.

So if by ""OPC UA PubSub MQTT is ahead of Sparkplug"", you are meaning that there are more features there as long as system integrators and end users do the legwork...you are comparing products at TRL-6/7, not TRL-8/9","https://cdn.discordapp.com/attachments/1166016853991235594/1199085694656725073/Fig10.png?ex=68df86d3&is=68de3553&hm=1645a25ac6e3d5bec4dc83aa0ee4588cabab53926c484b63b5b6d655256ff4a0&",""
"747418831248556043","randya4861","2024-01-23T04:21:23.2410000+08:00","Products that implement SpBv3 don't help if you release SpBv4. All the products need to be updated. So the question becomes does it make more sense to migrate OPC UA over MQTT instead of going to SpBv4?","",""
"801561312861618236","jon.forbord","2024-01-23T04:21:57.1440000+08:00","Good, more features doesnt always mean better, and  more features is sometimes what you need. I love OPC UA and i freakkn hate OPC UA. I love SpB and i freakkn hate SpB! My frustration with OPC UA, is that it has been years of broken promises, and believers like you, keep dragging me back in for more. I just want to let go, for a while, so I can breathe! First, yes, OPC UA will give you UDTs from your PLC, no it doesnt. Second, you can subscribe to 5000 tags per subscription and down to 100ms sample rate and 20 subscriptions.. eh not Even close.. Alarms and events, not with Ignition.. no no no.. just keeps on disappointing. And Sparkplug B, yay, we‚Äôll give you autodisxovery and UDT‚Äôs, lightweight so you can have thousands of tags.. except, the occasional birth storm will take down the Historian:. !!! FFS. Cant We make something that just works..","","üëç (2)"
"794020366536146977","mparris","2024-01-23T04:23:08.5950000+08:00","Valid question.

I would evaluate that the same way I considered OPC UA PubSub MQTT vs Sparkplug 3.

What products are available, how well do they work, and how diverse across the automation stack is there support for either standard.","",""
"753688565807841492","ravil1","2024-01-23T04:27:53.9920000+08:00","I think Microsoft Azure ecosystem easily ingests OPC UA Pub/Sub messages. Need to clarify though.
You might be right that there are more Sparkplug consuming applications today that OPC UA Pub/Sub. 
But given that there are new features required as discussed here, the future of OPC UA Pub/Sub might be better than Sparkplug. OPC UA pub/Sub covers much wider set of uses cases then Sparkplug. 
So it depends on specific use case. At the end I think it is good to have them both competing, at the end the His Magesty End Customer will benefit from such competition.","",""
"747418831248556043","randya4861","2024-01-23T04:27:54.1880000+08:00","what there needs to be is a meeting of the minds. the last thing factory operators and device vendors need is more competing standards. Back in 2018 the OPC UA WG had discussions with SpB guys about aligning technology but the SpB at that time was not a standard by any reasonable definition. It was just vendor implementation released under the open source label. The SpB also did not want to use anything other than Protobuf.","",""
"753688565807841492","ravil1","2024-01-23T04:29:47.8790000+08:00","Ha ha, I just wrote that competition is good üòÇ","","üíØ (1)"
"801561312861618236","jon.forbord","2024-01-23T04:33:13.2510000+08:00","I also agree, the problem isnt that there‚Äôs two standards, unless vendors only implement one of them. If vendors offer several, the end users can choose whichever suite their needs! The simple, lightweight alternative, or the big, fully featured juggernaught! üôÇ or do as we do, use both!","","üëç (1)"
"794020366536146977","mparris","2024-01-23T04:36:13.4420000+08:00","I would think that competition would help motivate ""OPC UA PubSub MQTT JSON"" to drive adoption within products.

By the way, when are you going to change that name?  Even when typing the two out, ""Sparkplug"" starts out of the gate requiring less effort.  If I get tired even typing out ""OPC UA PubSub MQTT JSON"", do I want to even try integrating it üòú","",""
"747418831248556043","randya4861","2024-01-23T04:41:24.3320000+08:00","OPC UA over MQTT or UA-MQTT (2 letters less than Sb üòâ)","","üòÜ (1)"
"794020366536146977","mparris","2024-01-23T04:44:07.3510000+08:00","Yeah, I did come across OPC UA over MQTT about a month ago...","https://cdn.discordapp.com/attachments/1166016853991235594/1199092152844697701/image.png?ex=68dee417&is=68dd9297&hm=3668dbc9094327e458ac35595e48103e3ea85a9a6fe4c3c58c7c4d5d96dba5be&",""
"747418831248556043","randya4861","2024-01-23T04:44:52.5130000+08:00","Part of the issue is the product development lifecyle. Automation vendors have very long development cycles compared to IT vendors. So we have a situation where IT vendors have rushed in to provide solutions and are now trying to figure out how to get the data that exists into their products","",""
"794020366536146977","mparris","2024-01-23T04:45:45.2060000+08:00","This has been the communication challenge for the OPC Foundation....calling everything OPC UA is a quick fix to secure recognition from the market, but then confusion is inevitable.","",""
"747418831248556043","randya4861","2024-01-23T04:49:22.7820000+08:00","OPC UA over MQTT allows a lot of the complexity of OPC UA to be ignored while providing a path to use it when it is needed","",""
"753688565807841492","ravil1","2024-01-23T05:21:01.7350000+08:00","Ha ha, this is a myth created by marketers that OPC UA is heavy, is not RBE, is not open ... and MQTT is .  But once it is seeded deeply in your mind, you need to analyze facts to get the real picture.","",""
"794020366536146977","mparris","2024-01-23T05:23:42.4930000+08:00","Without a big bag like that, how else are you going to transport all of OPC UA over MQTT...including Asset Administration Shell, Global Discovery Server, Alarms and Condition, Historical Access, Cloud Library, Field eXchange, Event Access, PubSub, Data Access AND all those Companion Specifications?","",""
"753688565807841492","ravil1","2024-01-23T05:30:30.9430000+08:00","If you are looking for an Application which does all this in one, you wil never find it. For example, OPC UA Server in CNC machien don't need to implement the same features as plastic molding machine or kitchen equipment. And often lower level servers might not provide access to the historical data. And the same with Alarms and Conditions - for example you might have plain data access server at the lower level, and event engine at the next level aggregating server. Particularly, this can be done by OPC UA Forge. 
Anyhow, UNS with MQTT claims that all this can be done - I wonder how it can be archived there? 
In OPC UA tasks can be split into smaller steps and done that way.","",""
"753688565807841492","ravil1","2024-01-23T05:31:56.3460000+08:00","it would be easier if you could share what problems are you trying to solve and cannot with OPC UA? Without details and specific use cases this is not constructive.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-23T05:54:07.2940000+08:00","I think the fundamental question to ask is if one is truly better off.  The more something is bloated with vendor input and not focused on practical use cases that the market can easily adopt, the more technology one must engineer around and through.

If one buys one node with some advance feature in the OPC UA (or even Sparkplug) spec and there exist no other nodes that interoperate with it, the technology and adoption is failing to live up to its mission. It's a ""Metcalfe's law"" problem.  Ironically, using technology built to solve the problem can actually make matters worse.  In these scenarios, the optimal architecture with the highest ROI may actually be something primitive.  The end user may ask themselves ""Why should I work through this mess of a node set file?  It's 50k lines and I only need to move five data points."" or ""Why should I decode all this protobuf and parse this ridiculously large metric payload?"".  They may say ""Honestly, I'm better off with modbus or http. At least I'll solve the problem in a reasonable amount of time.""  The end user will look for off-the-shelf solutions to be available, talent familiar with the technology, and easy ways to compensate for the shortcomings.","https://cdn.discordapp.com/attachments/1166016853991235594/1199109768472702986/OPC-UA_in_practice.png?ex=68def47f&is=68dda2ff&hm=aba103ac7c4dbded4c7661c67455fdfbbd297318b85d9f975c03d3db344f924e&","üëç (2)"
"747418831248556043","randya4861","2024-01-23T06:03:16.4070000+08:00","It comes down to off the shelf implementations. ""doing things with HTTP"" is only an option because you have access to HTTP libraries that you know will interoperate with other implementations.","",""
"817835202746253344","IIoT#4707","2024-01-23T06:03:16.7350000+08:00","GG @Randy Armstrong, you just advanced to level 1!","",""
"766684226455207996","bright_hummingbird_31342","2024-01-23T06:13:01.0480000+08:00","My point is not necessarily about a specific protocol or tech.  It could be ASCII telegrams over TCP/IP.  It could be smoke signals or mud pulse telemetry.

The ultimate question is whether someone can integrate automation and applications they inherited faster on their own or with industry standards?  At what point is technology so complicated that its cost of implementation and lack of market adoption exceed that of its benefits?","",""
"794020366536146977","mparris","2024-01-23T06:13:44.2050000+08:00","Agreed.

This goes back to what I said here:

The technology that is available and works will win

https://discord.com/channels/738470295056416930/1166016853991235594/1199086873482641540","",""
"747418831248556043","randya4861","2024-01-23T06:18:12.7410000+08:00","there is a chicken and egg problem. automation vendors implement technology when there is customer demand and not before. IT vendors are more willing to go on a limb and implement stuff and hope someone wants it. That is how we got to where we are today.","",""
"867075936054149191","rickbullotta","2024-01-23T06:30:41.8850000+08:00","That's for Sparkplug, not regular MQTT.  Sparkplug is so flawed that I would not use it at present.  I would use plain MQTT with JSON payloads containing a value and timestamp.","","üíØ (3)"
"766684226455207996","bright_hummingbird_31342","2024-01-23T08:14:21.1800000+08:00","(These questions are not specifically directed at you, Ravil.  These are related things I've pondered about UA PubSub.)

While it's great UA PubSub leverages well-supported tech like JSON and MQTT, my understanding is that Azure doesn't do much with the messages.  Azure Digital Twin, for example, creates a digital twin record for each UA namespace it sees.  I'm not sure how well this would work for brownfield scenarios.  OPC UA Servers gateways like Kepware, Ignition, Matrikon, etc aggregate everything into one namespace (e.g., ns=2).  Regardless, one would have to transform the namespace before publishing it over UA PubSub in exchange to a get a digital twin record created.  I'm not sure how valuable this is?  One would still have to build something on top of that digital twin record to consume it.

It would be nice if consumers of this technology did more than provide users the option to parse JSON.  It seems like there are not significant benefits having a user parse JSON they defined vs having a user parse JSON an industry association defined.  For example, why aren't there turn-key apps or partner solutions that use something like the VDMA UA for Machinery models?  What's the benefit of mapping to a standard if one must also create their own solution to consume the standard?","","üíØ (1)"
"794020366536146977","mparris","2024-01-23T08:19:48.3520000+08:00","I'm saddened that all this effort was spent putting ideas to paper without a clear go-to-market strategy.

That has to be so disheartening, especially, for the engineers that put so many hours into the specification.

So, I suppose we just ü§∑‚Äç‚ôÇÔ∏è with the specs sitting on the shelf until something gives with the ""chicken and egg"" problem?

I really did expect a better plan for such a major initiative.","",""
"753688565807841492","ravil1","2024-01-23T09:11:43.8080000+08:00","@MParris, I think one of the reasons is the lack of communication between the end customers and vendors. For example, you often complain no applications are implementing all OPC UA features, but when I ask what exact problem you are trying to solve - no answer. 
In my company, we try to learn what customers need and add those features. For example, auto-discovery of the server address space, automatic mapping from OPC UA to MQTT topics, or InfluxDB or Kafla topics. Or remote management, or integration with identity providers. Or support for Docker, etc. Within recent few years lot of features were added as a response to potential customers' desires. But who from the community here even tried to use our product? If some features are missing, we can add them much faster than large corporations. I think the community should work closer with such small vendors like my company.","",""
"747418831248556043","randya4861","2024-01-23T09:39:44.7530000+08:00","To be clear, there are always some vendors who are willing to be first movers which generates customer interest in the solution that pushes more adoption.  I am speaking of vendors that prefer their propitiatory solutions.","",""
"794020366536146977","mparris","2024-01-23T09:43:15.1140000+08:00","@Ravil I'll provide two use cases for consideration:

(1) a dashboard of objects displayed by an IIOT platform that is accessible for download and trial. Adding more of the same devices to the network adds objects to the dashboard.

(2) a PLC that includes built-in functions only requiring the user to input an IP address of an Auto ID device, and then decoded data behind arriving in a register.","",""
"794020366536146977","mparris","2024-01-23T09:44:38.5730000+08:00","By the way, welcome to the discord server @Randy Armstrong","",""
"817835202746253344","IIoT#4707","2024-01-23T09:44:40.5380000+08:00","Hark! I, MEE6, extend my gratitude for the warm welcome to the discord server, randya4861! 'Tis an honor to be in the midst of such esteemed individuals. How may I be of service to thee?","",""
"794020366536146977","mparris","2024-01-23T09:49:14.7290000+08:00","In summary, the problem to be solved is to automate the integration of producers and consumers.","",""
"794020366536146977","mparris","2024-01-23T09:58:10.2330000+08:00","When USB was developed, the use case was determined up front, and the project was laser focused to solve that use case. The technology was developed, strategic vendors implemented it, and it revolutionized the perephial market.

The approach you are suggesting (vendors and end users sorting out the use cases after specifications have been developed) is backwards from USB development.","",""
"794020366536146977","mparris","2024-01-23T10:02:13.2110000+08:00","How would you classify your product within the categories discussed in my article: Device Gateway or Information Gateway?

From what I've seen, your product seems to have a foot in both...","",""
"753688565807841492","ravil1","2024-01-23T10:05:40.9240000+08:00","For the fist task, the part providing data and metadata to anywhere, in-prem or in the cloud, more or less I would say done, there are solutions doing that. You can do that with plain MQTT, or Sparkplug over MQTT, or plain OPC UA ( I mean data acces with reverse connect), or OPC UA Pub/Sub over MQTT.  Now the ball is on visualization side I guiess. 
I cannot comment to much on the second one. If you have one PLC configured and provisioned, is it lot of work to replicate the same settings in the second one, given that they both have exactly the same wiring or input/outputs? Like if both used to control Pump or whatever of exactly the same type, ti should be easy to replicate.","",""
"753688565807841492","ravil1","2024-01-23T10:07:26.3030000+08:00","@MParris, what article you mean, sorry?","",""
"794020366536146977","mparris","2024-01-23T10:11:29.5380000+08:00","https://iebmedia.com/technology/iiot/how-all-protocols-fail-at-data-access-interoperability/

@Ravil I recommend you skip to the section:  ""Starting over: Industrial Interoperability Begins with the Consumer""","",""
"753688565807841492","ravil1","2024-01-23T10:39:02.6540000+08:00","Yes, you are right, we ""have a foot on both."".
We offer integrated solution, consisting of multiple components. Each can be used separately, or all can cooperate together. Depends on use cases.

The DeviceGateway converts data from almost any industrial data source to OPC UA. As the name suggests, it falls under Device Gateway category.

The OPC UA Forge I would say is a Information Gateway. Additionally to harmonizing and normalizing data and building information model, it provides multiple endpoints to access resulting data to integrate with other products: REST API, OPC UA as a server and Pub/Sub publisher. I think with OPC UA Forge you can in fact design and host your Unified Namespace.

And with Visual Logger for OPC data can be delivered in plain MQTT payload to MQTT borkers, or to destinations like SQL Servers, InfluxDB, Kafka. There are optoins to configure payload in some degree using templates. If your source OPC UA Server have data model defined already, you don't need to configure each variable how to map to the destination. In this case configuration is very quick. With it you can also configure custom mapping for each tag, but it will not be so well visualized as with OPC UA Forge. 

All components can be installed in the same box, or you can have one instance of OPC UA Forge collecting data from multiple DeviceGateways. The same is right about Visual Logger for OPC. For simple use cases all can be pre-installed in a single industrial PC box and delivered to you within a week or two.

All components have web based GUI. It is possible to acces and manage them remotely.","",""
"747418831248556043","randya4861","2024-01-23T12:05:12.3230000+08:00","Well OPC has been marketing UNS for 15+ years plus. What was missing were IT focused companies willing to build products that implemented it.","",""
"801561312861618236","jon.forbord","2024-01-23T18:12:23.1860000+08:00","OPC has been marketing interoperability for 15 years! And actually been quite successful in a lot of metrics! All our PLCs support it. They dont all work magnificently, but this is soooooo much better than OPC DA was. 

But saying you‚Äôve been ‚Äúdoing UNS‚Äù or ‚Äúmarketing UNS‚Äù since 2008 makes you come off as morons or jerks. 

I would take a different angle. Something along the lines of, this Walker dude says OPC UA can‚Äôt scale to support enterprise scale UNS, we think he‚Äôs wrong, and here‚Äôs why or how to do it! (And please use a different use case than Equinor.. )","",""
"747418831248556043","randya4861","2024-01-23T23:20:41.0580000+08:00","Perhaps we need to agree on a definition of UNS first. I see UNS as a common information for all plant information exchanged via a broker like MQTT. By that definition UNS is nothing but a rehash of the information modelling concepts OPC UA has been promoting for decades with a broker added. The ISA95 OPC UA companion specification came out in 2012 and it defined how to describe a plant using ISA95 structures.","",""
"747418831248556043","randya4861","2024-01-23T23:23:28.2080000+08:00","Even the name ""Unified Namespace"" was a deliberate ripoff of OPC UA designed to benefit from the OPC UA name recognition.","",""
"747418831248556043","randya4861","2024-01-23T23:52:59.5540000+08:00","e.g. if someone came up with the name 'Peoplebook' to describe a better social media app everyone would recognize it as an attempt to ripoff Facebooks branding.  ""Unified Namespace"" is the same kind of ripoff.  Different enough to avoid trademark infringement but a real jerk move.","",""
"1073632885153730621","vaughnturner","2024-01-23T23:59:14.2400000+08:00","Pinned a message.","",""
"801561312861618236","jon.forbord","2024-01-24T00:04:52.5700000+08:00","I think you‚Äôre right that you‚Äôd loose that law suit üòÖ 

I heard of OPC UA long before UNS, and I‚Äôve never once made the connection that Unified Namespace is a ripoff from OPC UA..","",""
"794020366536146977","mparris","2024-01-24T00:04:53.8460000+08:00","Ooooo...it's about to get hot in here.

@Joshua Stover should this move to the OPC-UA channel, or a new dedicated channel?","",""
"794020366536146977","mparris","2024-01-24T00:06:25.0540000+08:00","There are MANY high-level, foundational concepts being brought up, but don't think that #mqtt is the right location for the good content that is about to unfold.","",""
"747418831248556043","randya4861","2024-01-24T00:12:32.3510000+08:00","That may be because OPC UA is rarely spelled out as 'Unified Architecture' . Just like most people call 'Unified Namespace' UNS now.","",""
"817835202746253344","IIoT#4707","2024-01-24T00:12:32.7120000+08:00","GG @Randy Armstrong, you just advanced to level 2!","",""
"829502128191045652","joshuastover","2024-01-24T01:04:21.5610000+08:00","y'all can move it or stay in here, you can also create a thread in this channel since the conversation started here.","",""
"794020366536146977","mparris","2024-01-24T01:20:41.6840000+08:00","This is a very interesting comment.

Speaking from personal experience, Unified Architecture did not gain interest with me because it had a similar word of ""Unified"", which as you admit is hidden in the UA acronym most the time...it was the idea of it being a design pattern agnostic to any one technology.  It defines the use case first, then selects technologies that best satisfy that use case.

Based on what I've come across in the market, OPC UA = Data Access.  I don't know why this happened, but it's likely because marketing departments of vendors refused to put on their product datasheets  ""OPC UA Data Access TCP UA-Binary"", so they just shortened it to OPC UA. A little bit of branding forethought here would have gone a long way to prevent the re-education effort now needed for the market: OPC UA is more than a protocol!

The OPC Foundation has strived to subsume all available communication protocols within their umbrella (Layer1 (L1) see the attached figure), but the fact still remains that OPC UA L2 communication mappings and Layer3-5 information definitions are specific technologies among other possibilities in the market.  And by definition, OPC Foundation cannot recommend any other technology other than what they have specified.

On the other hand, Unified Namespace can leverage OPC UA, or any other technology that is available and solves the use case.","https://cdn.discordapp.com/attachments/1166016853991235594/1199403346440757438/Fig6.png?ex=68df5d29&is=68de0ba9&hm=b4b573be9747f36d5a8c203fd8678bf481b491f26dae3691bace3c2eb6ecbb85&",""
"230441548653789184","r.pop","2024-01-24T01:26:06.8850000+08:00","This may be extremely overly simplified...but in my experience - The majority of my manufacturing customers use OPC-UA for communication within the 4 walls of the factory. Machine to SCADA, Machine to MES, Machine to Machine, Machine to on-prem more or less, etc.. 

Where this start to change, is when our customers start getting interested in moving that data to the cloud. This is where we start to see the majority of our MQTT use-cases as well as other tools/protocols. 

Just my observation.","",""
"747418831248556043","randya4861","2024-01-24T01:26:38.7550000+08:00","Well UNS is tied to SpB in many presentations on the topic. The 'any protocol' aspect of UNS seems to be a new and welcome distinction. This means we can talk meaningfully about how OPC UA can be part of a UNS solution.","",""
"794020366536146977","mparris","2024-01-24T01:28:11.8740000+08:00","!mtr","",""
"817835202746253344","IIoT#4707","2024-01-24T01:28:12.5820000+08:00","These are the Minimum Technical Requirements for your IIoT Ecosystem:

1. Edge-Driven
2. Report by Exception
3. Lightweight
4. Open Architecture.","",""
"794020366536146977","mparris","2024-01-24T01:28:30.9440000+08:00","@Randy Armstrong ‚òùÔ∏è","",""
"794020366536146977","mparris","2024-01-24T01:29:04.6710000+08:00","#unified-namespace has lots of information in it as well.","",""
"794020366536146977","mparris","2024-01-24T01:29:18.5000000+08:00","would be fun to get ChatGPT to summarize that whole channel!","",""
"230441548653789184","r.pop","2024-01-24T01:29:41.4730000+08:00","I feel like we need to build an LLM of this discord","",""
"747418831248556043","randya4861","2024-01-24T01:29:55.6690000+08:00","You are correct that OPC UA is, in practice, an OPC-DA replacement. However, the notion of a coherent factory wide information model is a big part of the OPC UA specification.","",""
"230441548653789184","r.pop","2024-01-24T01:29:55.7560000+08:00","or a GPT","",""
"230441548653789184","r.pop","2024-01-24T01:30:29.8710000+08:00","Agreed. That's why Kepware is probably the most widely adopted factory software on the planet.","",""
"794020366536146977","mparris","2024-01-24T01:34:02.5290000+08:00","The OPC Foundation would help its case by providing a reference architecture built atop available products that engineers can trial and see the benefts for themselves.","",""
"794020366536146977","mparris","2024-01-24T01:35:27.1070000+08:00","This is very likely why you see Sparkplug in so many UNS presentations...someone wanting to get going can search ""sparkplug mqtt"" and get a list of products for them to evaluate the idea of standardizing Layers 1, 2, 3, and 4 of the Data Access model I highlighted above.  OPC UA doesn't provide me similar SEO keywords.  And when I go to https://opcfoundation.org/products/, I'm told by others that it's not up-to-date.","",""
"747418831248556043","randya4861","2024-01-24T01:35:27.3910000+08:00","The trouble OPC UA has had with the cloud part of the vision were the existing cloud and MES vendors had their factory modelling framework and were not that interest in changing their produce architecture and preferred to use OPC UA as a datasource.","",""
"794020366536146977","mparris","2024-01-24T01:38:53.3700000+08:00","The Foundation has focused on unifying technology to technology, but unifying people to technology or process to technology has been its blindspots","",""
"230441548653789184","r.pop","2024-01-24T01:43:40.9590000+08:00","This is correct. I'm only speaking from my lens of manufacturing customers, which are majority discrete (Automotive, Aerospace, CPG, etc.), OPC-UA is only ever a way to get machine data to the application, and 95% of the time it's via Kepware. With a very small instances of Matrikon, and the occasional just using Ignition's built-in OPC server.","","üíØ (1)"
"794020366536146977","mparris","2024-01-24T01:45:23.2390000+08:00","Understood.  I'm wondering if you are including Inductive Automation within this list?  They were a very big early proponent of OPC UA Data Access TCP UA-Binary....even offering their Modbus/TCP-OPCUA gateway for free...","",""
"747418831248556043","randya4861","2024-01-24T01:50:24.9750000+08:00","Inductive is actively engaged in the WG and supports OPC UA. They have other groups that have jumped on the SpB bandwagon largely because they saw it as a way to market Ignition and go after Kepware's market (IMHO)","",""
"230441548653789184","r.pop","2024-01-24T01:51:37.6440000+08:00","If you haven't watched the Cirrus-Link IoT Bridge for Snowflake demo, I highly recommend it. Shows some of the power of SpB","",""
"230441548653789184","r.pop","2024-01-24T01:52:04.0520000+08:00","It's not perfect obviously, but in the context of moving data to Snowflake, it's incredible.","",""
"230441548653789184","r.pop","2024-01-24T01:53:15.4780000+08:00","https://cirrus-link.com/iot-bridge-for-snowflake/","",""
"747418831248556043","randya4861","2024-01-24T01:56:03.3490000+08:00","It shows the value of MQTT broker to collect data and a cloud based AI driven solution. SpB is a means to an end. If they used OPC UA over MQTT they could do the same thing.","",""
"794020366536146977","mparris","2024-01-24T01:58:41.4480000+08:00","@Randy Armstrong I'm not picking on Remus (because he is saying what MOST people say)...

But you can see the problem here:  ""OPC UA is used in the factory, to go to the cloud we should use MQTT.""  These are viewed as mutually exclusive.

A ""Unified Architecture"" would have a diagram on their front page showing a reference architecture with five different types of OPC UA products: (1) UA-Binary Producer, (2) UA-Binary Consumer, (3) Gateway (convert UA-Binary to MQTT), (4) MQTT Consumer, (5) MQTT Producer.  Then people would be able to converse in a way that makes sense to everyone, and OEMs would know what products they should be making.

As of now...it's all a mystery how to put it all together.","","üëç (1)"
"230441548653789184","r.pop","2024-01-24T02:00:43.9110000+08:00","The power of the IoT bridge module is the auto-buildout of my database tables in Snowflake, which becomes possible because I know the structure of the message. It has little to do with AI and everything to do withing being able to scale a solution. 

Example: Building an Enterprise OEE dashboard for customer. Being able to automatically generate database tables any time a new ""asset"" shows up in the Snowflake tables, means I don't have to ""add"" a new machine to my application. Once I configure that machine in the factory, it shows up on my dashboard automatically.","",""
"794020366536146977","mparris","2024-01-24T02:00:47.2590000+08:00","""If they used OPC UA over MQTT they could do the same thing.""

I'm interested in a similar demo using ""OPC UA PubSub MQTT JSON"" (or equivalent).  Please provide a link if you are aware of one...","",""
"230441548653789184","r.pop","2024-01-24T02:01:42.9610000+08:00","That's not what I said. I didn't say we need MQTT, I'm saying it makes ""usually"" more sense. Let me ask you, what drives more cloud spend, OPC-UA or MQTT?","",""
"794020366536146977","mparris","2024-01-24T02:02:20.2830000+08:00","Yes, this is the power of a Unified Namespace.

I believe OPC UA Pubsub *could* do this, but products need to implement it.","",""
"747418831248556043","randya4861","2024-01-24T02:02:28.1730000+08:00","You can do that OPC UA over MQTT. Asset shows up and you get metadata messages that tell you what is published - create your tables automatically from that","",""
"230441548653789184","r.pop","2024-01-24T02:02:47.6230000+08:00","IoT bridge does that for me out of the box.","",""
"230441548653789184","r.pop","2024-01-24T02:03:11.2220000+08:00","Tools on platforms, not code on operating systems.","",""
"747418831248556043","randya4861","2024-01-24T02:04:16.4480000+08:00","Only if the devices know SpB. You can deploy gateways and other middlemen to report the data that IoT Bridge needs but all these middlemen need configuration","",""
"230441548653789184","r.pop","2024-01-24T02:05:23.9770000+08:00","Correct, this is where us as integrators are uniquely positioned to offer this capability to our customers. If we're already deploying a system like Ignition, or something similar, I can create the structure at that level to feed my ""UNS""","",""
"230441548653789184","r.pop","2024-01-24T02:05:48.7220000+08:00","Contextualization at the edge is always cheaper than in the cloud.","",""
"794020366536146977","mparris","2024-01-24T02:06:48.2240000+08:00","I didn't intend to put words in your mouth....just pointing out how you switched terms:

from OPC UA to MQTT

This is anathema in the world of OPC Foundation and having OPC UA being relegated to ""Data Access TCP UA-Binary"" drives them bananas...and every time they have to remind the public that in addition to the Data Access piece, OPC UA includes PubSub MQTT JSON.

Anyway, just a long explanation that the OPC Foundation has not provided shorthand for people to differentiate between the large number of technologies they offer.","",""
"230441548653789184","r.pop","2024-01-24T02:08:16.6200000+08:00","Understood. I agree that the OPC foundation does not do a good job of marketing that.","",""
"817835202746253344","IIoT#4707","2024-01-24T02:08:16.9280000+08:00","GG @RemusPop, you just advanced to level 4!","",""
"230441548653789184","r.pop","2024-01-24T02:09:37.8280000+08:00","I'm just trying to share my experience of what manufacturers are actually building/deploying today.","",""
"794020366536146977","mparris","2024-01-24T02:09:49.3290000+08:00","And I suspect you are in the same boat I am....

I really don't care too much about the technology being used, as long as it exists in products that I'm willing to use and the technology enables the functionality to work now and scale up in the future.","",""
"230441548653789184","r.pop","2024-01-24T02:10:39.9050000+08:00","Absolutely. My customer is usally the operations team. Plant Manager, VP of Ops, etc... they could care less what technology we use....does it help me build a better solution for my customer that is efficient, scalable, and cost-effective.","",""
"230441548653789184","r.pop","2024-01-24T02:11:08.2810000+08:00","And secure...can't forget that one","",""
"230441548653789184","r.pop","2024-01-24T02:13:28.5720000+08:00","I had a customer recently that was using a myriad of technologies...HiveMQ, Kafka, IoT Bridge, Ignition, Kepware, PowerBI, Snowflake, InfluxDB (Telegraf https://www.influxdata.com/time-series-platform/telegraf/ which is a phenomenal tool if you haven't heard about it)","",""
"801561312861618236","jon.forbord","2024-01-24T03:07:33.3050000+08:00","Are you saying we should ‚Äútake it outside‚Äù üòÇ?","","ü§£ (1)"
"753688565807841492","ravil1","2024-01-24T03:52:16.7270000+08:00","@RemusPop, our product Visual Logger for OPC does even better than Telegraf. Configuring data collection over Web GUI is much more convenient and faster than with Telegraf. Moreover, data for the same set of variables can be forwarded to other destinations you mention: HiveMQ, and Kafka. You can also eliminate KepServerFx and use DeviceGateway instead of it.","",""
"230441548653789184","r.pop","2024-01-24T03:53:23.6160000+08:00","What's the product?","",""
"230441548653789184","r.pop","2024-01-24T03:53:32.9790000+08:00","Do you have a link?","",""
"753688565807841492","ravil1","2024-01-24T03:55:55.0420000+08:00","This is Visual Logger for OPC as a standalone product: https://onewayautomation.com/index.php/visual-logger
Here the diagram with integrated products all running in one box: https://onewayautomation.com/forge","",""
"230441548653789184","r.pop","2024-01-24T04:00:58.3630000+08:00","We were using Telegraf to parse .txt log files and stream that data over MQTT to HiveMQ","",""
"230441548653789184","r.pop","2024-01-24T04:01:25.3260000+08:00","Other than that, you're website is in need of an update my friend. It's not really clear what your product does.","",""
"753688565807841492","ravil1","2024-01-24T04:06:08.8960000+08:00","Thank you for feedback! Agree with you.
What I meant was to log data from OPC UA Servers to InfluxDB you can use Visual Logger for OPC instead of Telegraf.","",""
"230441548653789184","r.pop","2024-01-24T04:21:29.6000000+08:00","Understood, but that's not what we were using Telegraf for. The customer already had Ignition, but they needed information from a set of machines, and the only way to access that machines data was via a log file that it spit out. So we used telegraf to parse the log file and take that data to HiveMQ","","üëç (1)"
"794020366536146977","mparris","2024-01-24T04:27:16.2130000+08:00","@Jon Forbord  Are you saying this quote from ""OPC Experts Interviews: Equinor OPC UA Use Case"" didn't interest you? :

""We partnered up with some of the most knowledgeable and experienced people and companies in Norway on OPC UA. We worked together with them, spending one year studying and diving deep, deep, deep into OPC UA in order to understand it.""","",""
"801561312861618236","jon.forbord","2024-01-24T04:45:37.2830000+08:00","Not saying it‚Äôs not interesting,It‚Äôs one (albeit quite large) oil field, about 1 million tags I believe. But they need to show other use-cases as well. It‚Äôs over-used. And I suspect you‚Äôd be hard pressed to call it a UNS.  (Had a brief chat with a guy who has some role in its creation/maintenance, but it‚Äôs a while ago).","",""
"801561312861618236","jon.forbord","2024-01-24T04:47:21.3410000+08:00","They use/used Prediktor APIs, and they‚Äôre right, Prediktor is at the forefront of OPC UA adoption. At the core was some excel-sheet to generate the models.. if I‚Äôm not mistaken.","",""
"801561312861618236","jon.forbord","2024-01-24T05:27:29.6250000+08:00","I think I‚Äôm gonna pass on the discussion on the name being ripped off or not, it‚Äôs honestly not that interesting. There is no doubt that the Unified Namespace as a term, clearly was popularized by Walker. Are we in agreement on this? Walker claims to have coined the term, but seeing how much it is misinterpreted it‚Äôs a pretty bad term, but that‚Äôs also not interesting to me. 

He definitely popularized it, and to some extent there is no debate on how the UNS is defined. It‚Äôs ‚Äúthe current state and events of the business, organized in a semantic hierarchy (often ISA-95). It is the single source of truth for all data and information of the business. It is the place where the current state of the business lives. It is the hub through which all the smart things of your business communicates‚Äù. It is an architecture, a concept to treat all consumers and producers of data as nodes in an ecosystem, it is a commitment to open architecture and minimum technical requirements, it is event driven and non-deterministic.. I mean, tell me when to stop?  

Are you saying this has been a core part of the messaging of the OPC foundation? If that is the case their marketing director needs to be fired, because all I‚Äôve heard is ¬´Interoperability¬ª, ¬´it‚Äôs more than a protocol¬ª and ¬´information modelling¬ª.","",""
"867075936054149191","rickbullotta","2024-01-24T05:33:56.9400000+08:00","Unfortunately, Sparkplug's SEO is better than its implementation at present.","",""
"801561312861618236","jon.forbord","2024-01-24T05:43:24.6640000+08:00","Hey dude! Do you have like a bot scanning through this Discord for any mention of Sparkplug B?!  You dont seem to ¬´miss a beat¬ª, not even once üòÇ","","üòÇ (3)"
"867075936054149191","rickbullotta","2024-01-24T05:49:49.1170000+08:00","You just mentioned Sparkplug B! üëÄ üïµüèº","",""
"747418831248556043","randya4861","2024-01-24T06:58:47.8050000+08:00","OPC UA has always been about common information models that are used to ensure the data and events look the same no matter where the source. OPC UA has always included the notion of an aggregating server running at the edge or cloud that collected information from individual devices and made it available within the context of a model like ISA-95.  That said, adding the MQTT broker in the middle is enhancement to the original architecture concepts.","",""
"801561312861618236","jon.forbord","2024-01-24T07:00:50.1750000+08:00","Common information models are actually not required for a UNS.","",""
"801561312861618236","jon.forbord","2024-01-24T07:03:10.6060000+08:00","And OPC foundation has always depicted how data flows up the stack..","",""
"801561312861618236","jon.forbord","2024-01-24T07:03:35.6690000+08:00","A direct contradiction of core principles of a UNS.","",""
"747418831248556043","randya4861","2024-01-24T07:04:29.0420000+08:00","The ""ripped off"" thing was only a response to someone who said that OPC would look like jerks for pointing that many of the ideas that are part of UNS have been part of OPC UA for years. Walker has been a huge jerk by lying about OPC UA as part of his campaign to promote his solution.","",""
"747418831248556043","randya4861","2024-01-24T07:06:09.4480000+08:00","How so? All UNS system use this approach to get the data to an aggregator like Kepware or Ignition that then puts the data on a broker?","",""
"817835202746253344","IIoT#4707","2024-01-24T07:06:09.8520000+08:00","GG @Randy Armstrong, you just advanced to level 3!","",""
"801561312861618236","jon.forbord","2024-01-24T07:21:37.1050000+08:00","Thats not what you said! You said ¬´OPC has been marketing UNS for 15+ years¬ª. There‚Äôs a huuuuuge difference between ¬´we‚Äôve done UNS for years already¬ª and ¬´parts/ideas within the UNS have been part of OPC for years¬ª.","",""
"747418831248556043","randya4861","2024-01-24T07:22:27.4720000+08:00","Fair point. Will be properly precise.","","üôè (1)"
"801561312861618236","jon.forbord","2024-01-24T07:54:12.3140000+08:00","There are definitely overlaps in the venn-diagram, and in a different parallell universe, OPC UA could perhaps have been the most common way to implement a UNS, and perhaps even some day in the future of this universe. 

An organization like OPC really don‚Äôt have any incentive to market/popularize a concept that is inherently indepentent of technology. Unified Namespace has a technical side, and relies on technology to be implemented, and a non-technical side, aspects in how you treat nodes/ approach data/solve problems. This non-technocal side is at least if not more important than the technical aspects. OPC UA or mqtt or Sparkplug can only ever be a ways to solve the technical aspects.","",""
"747418831248556043","randya4861","2024-01-24T08:14:07.4000000+08:00","I like UNS as an architecture concept that is independent of the implementation technology because pushes factory operators toward viewing their factory in a holistic way. It also changes the conversation between factory operators and cloud providers who have taken the approach that factory data should be just dumped into their systems and analyzed after the fact using the cloud providers (expensive) tools. OPC UA adds to this by providing common ways to model things that can be shared. e.g. while it is possible to configure every PLC to report their tag values to a broker it is much better to have every PLC reporting same information (e.g. EngineeringUnits) with the same name and datatypes.","",""
"794020366536146977","mparris","2024-01-24T08:37:44.8060000+08:00","You are joining like-minded people here on this server 

Many here have been sweet-talked before about what is ossible with OPC UA, but later came to realize that those statements were about OPC UA as written on paper.

You won't get any push-back from the community if a UNS architecture is proposed with actual products.

A good start is a proposing an application like Ignition that can consume OPC UA PubSub connected to a device gateway application that can consume device protocols including OPC UA Data Access while also producing OPC UA PubSub.

Many of the people here have money in hand to put products into production, or have customers that have money in hand to put products into production.

Theory time is over... We want real solutions.","","üëç (1)"
"867075936054149191","rickbullotta","2024-01-24T18:57:40.7190000+08:00","Common information models, or at least information models, are a MUST for a UNS in my opinion.  The ability to know that entities are of a certain ""type"" is extremely valuable for associating visualizations, data storage, ML/AI models, business rules, and other content with them.","","üíØ (1)"
"917925131261718558","jpmoniz","2024-01-24T20:34:07.1990000+08:00","Begs the question of why even bother with a UNS, if that's not the goal.","",""
"867075936054149191","rickbullotta","2024-01-24T20:46:29.0630000+08:00","It seems that we're all generally in agreement that Sparkplug is OK for device <-> SCADA and maybe historian (I'd disagree there) but that other formats are better for the UNS itself.  That's where things fall down.  What format?  I personally use JSON today (value + timestamp), but it's a gap.","","üíØ (1)"
"794020366536146977","mparris","2024-01-24T20:47:48.1320000+08:00","The question I have is given a common""thing"", how wide of a scope is reasonably useful or feasible for an information definition of that thing:
1. Global?
2. Vertical industry?
3. Corporation?
4. Function within a corporation?
5. OEM of the thing
Etc 

A definition at level two or one sounds nice and has been the focus of CESMII and OPC Foundation, but I really have not been exposed to any benefits from effort You're not that level.","",""
"747418831248556043","randya4861","2024-01-24T20:48:07.9250000+08:00","How about OPC UA with JSON encoding?","",""
"867075936054149191","rickbullotta","2024-01-24T20:49:48.9880000+08:00","That's why I qualified my statement with ""or at least information models"" rather than requiring that they be ""common"".  Bottom line is that the scope is whatever makes sense for that application.","","üëç (1)"
"867075936054149191","rickbullotta","2024-01-24T20:51:45.6380000+08:00","Depends what you're referring to Randy - the metadata or the data.  For the data, sure.  I personally find the information model a bit verbose and obtuse - I just can't get past the nodeid stuff. üòâ","",""
"747418831248556043","randya4861","2024-01-24T20:54:43.7000000+08:00","Common pieces have value even if they are assembled in bespoke ways for different installations. It is not practical to standardize everything because there is too much variation. OTOH, every robot could choose to follow this structure https://reference.opcfoundation.org/api/image/get/111/image018.png","",""
"747418831248556043","randya4861","2024-01-24T20:58:43.7780000+08:00","FWIW, NodeIds now have a well defined string format but it is not a ""URL"" since the format needed to accommodate multiple URIs and % escaping everything creates its own IOP problems.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-01-24T21:01:26.8760000+08:00","I always liked the idea of a human readable namespace though.  What's the format for JSON nodeids?","",""
"917925131261718558","jpmoniz","2024-01-24T21:04:18.5930000+08:00","Agree I focus less on the standardization on Device A payload vs Device B payload and focus more on payload schema awareness.  I myself have reverted to JSON  for what we are working on.   SPB to me right now just seems to be too ignition centric","",""
"867075936054149191","rickbullotta","2024-01-24T21:05:13.4170000+08:00","Sparkplug ""C"" with a formal JSON encoding and automatic metric expansion could be usable though.","",""
"867075936054149191","rickbullotta","2024-01-24T21:05:30.0960000+08:00","Or, as @Randy Armstrong pointed out, OPC UA's JSON data encoding.","",""
"794020366536146977","mparris","2024-01-24T21:05:43.4550000+08:00","I picked up on that qualification, but I would argue that every information model should be ""common"" at some level even if it is narrow. Otherwise monkeys at typewriters would be equally qualified to design information models","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-01-24T21:06:28.9820000+08:00","But...in many cases that's exactly how it happens.","",""
"917925131261718558","jpmoniz","2024-01-24T21:07:38.4160000+08:00","That would be nice.   Still don't like the whole group/node/device thing.","",""
"747418831248556043","randya4861","2024-01-24T21:08:53.7710000+08:00","OPC UA over MQTT defines a more abstract topic model that could be  group/node/device but does not have to be. It also allows a device to publish to different ""views"" when appropriate","","üëçüèº (1)"
"794020366536146977","mparris","2024-01-24T21:08:57.0060000+08:00","As I was typing that I was wondering who would deliver the punch line","",""
"794020366536146977","mparris","2024-01-24T21:15:41.1670000+08:00","While the topic structure may be different, is there a formally standardized way for devices that do not know a designed topic structure to subscribe to some common root topic that is standard across all OPC UA PubSub MQTT instances where the consumer can know how to get at the payload? 

Or does the discovery scheme with OPC UA PubSub MQTT depend on a human configuring the custom topic(s) within the consuming application","",""
"747418831248556043","randya4861","2024-01-24T21:18:01.0980000+08:00","Complete autodiscovery! The quickstart subscribers (https://github.com/OPCFoundation/UA-IIoT-StarterKit/tree/master/Quickstarts) only need to know the broker and the topic prefix (opcua by default).","",""
"801561312861618236","jon.forbord","2024-01-24T22:42:54.2990000+08:00","I guess its almost arguing shades of gray, but common models are strictly not required per current definition. Highly recommended, and information/data modelling is almost to some extent assumed, even if it‚Äôs in its most basic form. Not by any chance disagreeing, just trying to be precise.","","üíØ (1)"
"801561312861618236","jon.forbord","2024-01-24T22:47:31.6840000+08:00","It doesn‚Äôt take a lot to make SpB ten times more useful! Fix births, support QoS>0, free up the metrics/node hierarchy‚Ä¶ those are the most critical to most people I‚Äôve spoken to..","","üíØ (1)"
"747418831248556043","randya4861","2024-01-24T23:04:36.3610000+08:00","OPC UA over MQTT allows publishers to choose their QoS.","",""
"794020366536146977","mparris","2024-01-24T23:15:26.1160000+08:00","What production-ready Device Gateway and SCADA application would you recommend to test this out?","",""
"747418831248556043","randya4861","2024-01-24T23:17:17.8660000+08:00","Work in progress. But you can't get the products if the standard does not exist. The best way to speed this up is for end users to tell suppliers that they would like to see this capability","",""
"753688565807841492","ravil1","2024-01-24T23:28:15.2660000+08:00","OPC UA Forge can publish data to MQTT in OPC UA Pub/Sub JSON format. And it is also a subscriber.
With our new product oBox with OPC UA Forge and DeviceGateway data from around 300 types of industrial devices made for accessible via MQTT broker in Pub/Sub Format, or REST API, and with Visual Logger can be delivered in plain MQTT paylaod, can be delivered up to the cloud.","",""
"794020366536146977","mparris","2024-01-24T23:33:15.8580000+08:00","OPC UA Forge is only listed as an OPC UA Publisher.  No subscriber function is included:

https://opcfoundation.org/products/view/prosys-opc-ua-forge/","https://cdn.discordapp.com/attachments/1166016853991235594/1199738699034919104/image.png?ex=68df43fb&is=68ddf27b&hm=5d9cee1da98967a6c5668dc598c50c5bd9bd001ff3102a07a4b95ad904c8c2ae&",""
"794020366536146977","mparris","2024-01-24T23:34:16.9280000+08:00","Which standard are you referring to? If the PubSub standard, that was released in 2018, and thus exists, correct?","",""
"753688565807841492","ravil1","2024-01-24T23:34:44.2330000+08:00","Please check at the vendor site: https://prosysopc.com/products/opc-ua-forge/","",""
"747418831248556043","randya4861","2024-01-24T23:36:44.0110000+08:00","Yes, the latest spec came out in Dec 23. There has been no time for vendors to implement. But the additional features are additive and can be layered on top of existing implemenations","",""
"801561312861618236","jon.forbord","2024-01-24T23:49:28.8890000+08:00","What you need is the ‚ÄúI want this moment!‚Äù Or ‚ÄúI can sell this moment!‚Äù. Opto22‚Äôs sparkplug B video on YouTube is very much a ‚ÄúI want that‚Äù.","","üëç (2)"
"794020366536146977","mparris","2024-01-24T23:54:16.5140000+08:00","Is the autodiscovery feature not present in PubSub spec released in 2018?","",""
"747418831248556043","randya4861","2024-01-24T23:55:03.8150000+08:00","2018 spec did not use MQTT topics at all. Manual configuration of topic names required","",""
"794020366536146977","mparris","2024-01-24T23:57:20.4320000+08:00","From a post earlier: "" Back in 2018 the OPC UA WG had discussions with SpB guys about aligning technology but the SpB at that time was not a standard by any reasonable definition""

So the WG didn't take the good and throw out the bad with Sparkplug, which has now cost them 5 years?  Ouch...","",""
"794020366536146977","mparris","2024-01-24T23:58:38.8230000+08:00","I can't find documentation on the Subscriber...other than a picture on the product webpage.

Do you know of a link to their documentation?","",""
"747418831248556043","randya4861","2024-01-25T00:00:07.1340000+08:00","The WG has lots of balls to juggle. UA-FX was the primary focus at that time.","",""
"753688565807841492","ravil1","2024-01-25T00:00:17.1130000+08:00","Hi @MParris , I understand that you would like to have complete solution which would magicly auto-discover changes and reflect the changes in end users dashboards.
I don't think OPC Foundation is repsonsible alone to deliver that kind of solutions. Companies like ProsysOPC and One-Way Automation are more focused on delivering data and making it available in different formats - that part I think mostly is done. 
The UA IIoT starter kit mentioned above shows how you can get for example Pub/Sub data. 
It is like IKEA furniture parts are delivered to you, with instractions how to assemble. Usually such work is done by independent contractors. Probably in our case system integrators? Or you want us also do assembly?","",""
"794020366536146977","mparris","2024-01-25T00:01:00.5240000+08:00","Before talking about UNS within end users facilities the OPC Foundation should get their feet wet by developing a UNS of their own as a single-source of truth regarding product capability ü§¶‚Äç‚ôÇÔ∏è","",""
"753688565807841492","ravil1","2024-01-25T00:05:36.1420000+08:00","@MParris, isn't GE member of OPC Foundation? If your particular department is not, then why wouldn't you join and start shaping it in the right direction?
Also, if there is no any solution capable to solve all your problems, why would not GE Appliances to fund  startup, or open-source project, to create a solution? I think GE has capabilities to become a leader if there is no any other leaders.","",""
"794020366536146977","mparris","2024-01-25T00:12:06.8390000+08:00","@Jon Forbord said it best here https://discord.com/channels/738470295056416930/1166016853991235594/1199742779975278733

Randy is advocating OPC UA PubSub MQTT as a superior alternative to Sparkplug.  I say show me....I REALLY do want to see it.  I think I speak correctly for the majority of people on this discord...all this talk is useless if there are no production-ready products for us to evaluate.

And when I say production-ready products, they are products that are ready to have solutions built upon them by the majority of System Integrators for deployment to production.  For example a Device Gateway connected to an IIoT platform similar to Ignition, which has a dynamic tag structure and allows a dashboard to be built by the user based on that tag structure.

Then the next question is...how easy it is to obtain those products for trial will control how widely/quickly the technology will receive adoption.","",""
"747418831248556043","randya4861","2024-01-25T00:13:13.9160000+08:00","I hear you. We are in the first step: educating people on what is possible, implementations have to be the next step","",""
"794020366536146977","mparris","2024-01-25T00:14:49.4450000+08:00","Well....now that it's known that the PubSub clock had to be reset five years...I get that.  oy vey","",""
"794020366536146977","mparris","2024-01-25T00:17:18.0630000+08:00","When companies go out to do market research for their product, is it reasonable for that company to solicit payment from the members of the focus group? such as the OPC Foundation requiring membership fees to contribute as the voice of the customer?","",""
"794020366536146977","mparris","2024-01-25T00:19:25.2500000+08:00","The other way to look at it is a company becoming an investor in the organization.  I haven't come across a good pitch to convince me of that, either...","",""
"794020366536146977","mparris","2024-01-25T00:19:48.0890000+08:00","https://tenor.com/view/mark-cuban-shark-tank-im-out-gif-12240324","","üòÇ (1)"
"753688565807841492","ravil1","2024-01-25T00:24:43.9290000+08:00","No. I am not soliciting for payment for my company or product, if you undersood that way. SCADA or dahsboards is not our specialty. 
Our product Visual Logger for OPC already released and used in production. And oBox is almost ready to ship. So we don't seek for  financing.
My point was different. Just GE is a big company enough to lead in this field, instead of waiting, when somebody creates what it ideally wants.","",""
"794020366536146977","mparris","2024-01-25T00:25:49.0440000+08:00","Ohh...that wasn't a comment about your company, but for the OPC Foundation requiring payment to be a voice of the customer, which seems backwards.","",""
"794020366536146977","mparris","2024-01-25T00:26:17.3780000+08:00","Now that you mention this...it would be interesting to have members use their dues to allocate funding specific technologies.  As it is now, I would assume all membership fees go into a single pot to be distributed to whatever initiatives are decided.

Do memberships kick-starter style?  Because I would have said that picking UA-FX over Pubsub for OT/IT integration was the wrong choice and would have allocated my money accordingly.","",""
"867075936054149191","rickbullotta","2024-01-25T00:30:59.7350000+08:00","I'm not gonna fault them for that - it wasn't really baked at all in 2018, and still has gaps as you know.","",""
"753688565807841492","ravil1","2024-01-25T00:32:03.2110000+08:00","In my understanding OPC Foundation does not fund creating production ready solutions. There are some open source prodcuts at GitHub, but they are rather used as a proof of concept, and for educational purposes. 
We need to clarify this with peolpe from OPC Foundaiton.","",""
"794020366536146977","mparris","2024-01-25T00:33:54.6320000+08:00","Defined MQTT Topic structure was very baked into Sparkplug in 2018...  and that is the primary means of autodiscovery, which has only just now been released in OPC UA Pubsub.","",""
"794020366536146977","mparris","2024-01-25T00:36:58.5780000+08:00","Correct...I'm not speaking of product development, but members able to fund specification development.  Let the members decide with their money what specs are important for development...","",""
"753688565807841492","ravil1","2024-01-25T00:47:30.6500000+08:00","I don't think that people who are members of work groups and actually work on creating specifications are paid for ther efforts by OPC Foundation. None of membership fees go to fund development of specifications. Probably you can find somewhere annual financial reports to see budget and expences of the foundation. 
Anyhow, I think if you have specific ideas how specification can be imporoved, you can contact work group members with your proposal. For that you don't pay any fee. If it is reaally good idea, there is a possibility to include it into next release of specifications. 
Hey, OPC Foundation guys, correct me if I am wrong.","",""
"867075936054149191","rickbullotta","2024-01-25T00:48:02.3210000+08:00","I meant baked enough to meet enterprise UNS needs.","","üíØ (1)"
"794020366536146977","mparris","2024-01-25T00:52:47.9160000+08:00","The core functions of Sparkplug are (1) defined topic structure (for auto-discovery), (2) device state, (3) defined payload structure (data model allowing information model).

I'm not saying they should have copied the HOW of SpB but to omit #1 regarding the WHAT of SpB that was already within existing products...that cost dearly","",""
"867075936054149191","rickbullotta","2024-01-25T00:54:50.7540000+08:00","I would have only salvaged (3).  Don't care for the implementations of (1) and (2), as you know.  And I'd augment (3) by splitting data and metadata and enhancing it to support methods/functions.","",""
"794020366536146977","mparris","2024-01-25T00:57:15.0010000+08:00","What I mean to say is that OPC UA Pubsub should have, at a minimum, included the following from the start: (1) defined topic structure (for auto-discovery), (2) device state, (3) defined payload structure.  They could have changed/improved the actual implementation, but at least have the function...","",""
"794020366536146977","mparris","2024-01-25T01:02:01.3300000+08:00","""if you have specific ideas how specification can be imporoved, you can contact work group members with your proposal""

Yes, I agree, and have done so in private a few times already.  Also, I make all my comments public and free to be used as they wish.","","üëç (1)"
"801561312861618236","jon.forbord","2024-01-25T01:09:21.3410000+08:00","I‚Äôve been telling suppliers we want sparkplug, but  I don‚Äôt want sparkplug, I want whatever gives me ‚Äúthat‚Äù! Btw, OPC or not OPC, sparkplug B is not that wide spread used in UNS. Regular mqtt with custom spec/schema/modeling is a from what I‚Äôve observed, a lot more common.","",""
"753688565807841492","ravil1","2024-01-25T01:10:55.9070000+08:00","I am curious, was it about changes in the specs, or fequest for products/new features?
If the later, probably better to contact vendors.
For example, to add support for autodiscovery  in GE Proficy or GE CIMPLICITY - contact GE Digital.","",""
"753688565807841492","ravil1","2024-01-25T01:15:00.6160000+08:00","I saw that some companies have a roadmap page with possible new features, were customers can vote which ones they want.","",""
"867075936054149191","rickbullotta","2024-01-25T01:16:50.4060000+08:00","That's the most commonly requested feature in my experience: ""I don't know what it is, but I'll know when I see it""","",""
"801561312861618236","jon.forbord","2024-01-25T01:29:54.5250000+08:00","https://www.linkedin.com/posts/opc-foundation_topic-opc-ua-and-uns-unified-namespace-activity-7155859704303292417-f1oy?utm_source=combined_share_message&utm_medium=member_ios

Now it‚Äôs time to do it! Be the first to implement a UNS with OPC UA over mqtt! (Btw, can be as with spB, with mix of OPC UA and flat mqtt!)","",""
"766684226455207996","bright_hummingbird_31342","2024-01-25T01:34:05.7280000+08:00","At least from the standpoint of a machine builder spec, I find it's useful to have a conversation around defining what not to do rather than mandating a specific technology.  Basically, as long the data is in a somewhat mainstream protocol that is browsable with off-the-shelf clients and the data isn't completely unusable process control garbage, that's good enough.  The issue isn't whether or not it has an MQTT or OPC UA interface.  The issue is that the data is obscured in undocumented registers, it must be reverse engineered, and requires considerable custom logic to interpret.  If vendors can't do that, there's no chance they're going to adopt some theoretical companion spec or smart manufacturing profile nonsense.

I could care less of it does not have some advanced OPC UA or Sparkplug feature that 99.9% of applications on the market don't support.  To @MParris' long standing point, integrations need to be oriented around the needs of the consumer.  For example, there's no use having an AutoID information model if nothing can use it.","",""
"801561312861618236","jon.forbord","2024-01-25T01:44:34.5340000+08:00","I honestly struggle to understand why OPC foundation insists on adding more to the spec than simple UDT modeling, methods and subscriptions. I would‚Äôve much more preferred this part to be optimized and trimmed to perfection.","",""
"801561312861618236","jon.forbord","2024-01-25T01:45:51.3340000+08:00","OPC will always be constrained by it‚Äôs least common denominator, the PLCs and other constrained edge devices.","",""
"801561312861618236","jon.forbord","2024-01-25T01:47:21.1640000+08:00","DTDL seems to be growing in popularity much faster than you can say OPC UA pub sub over UDP XML.","",""
"801561312861618236","jon.forbord","2024-01-25T01:49:17.6350000+08:00","So if OPC UA ‚Äúwins‚Äù as the new IT/OT converging technology it is only by brute force, not by spontaneous adoption.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-25T02:11:34.7970000+08:00","Speaking of which, one of my biggest pet peeves is when vendor logos are marketed as on board with the spec and then they don't have any actual products that support the spec or, at least, support the spec in a meaningful way.

A few years ago, OPCF and Rockwell Automation were marketing ""direct"" integration to Azure.  The actual demo consisted of a ControlLogix connected to FactoryTalk Linx gateway, running in a separate Windows-based industrial PC, over EtherNet/IP.  On the other end of the FTLinx gateway was an OPC UA Server interface.  Also running on the industrial PC, was Azure IoT Edge with an OPC UA Client.  This client would connect to FTLinx's OPC UA Server.  On the other end, Azure IoT Edge was publishing into Time Series Insights, through IoT Hub, with AMQP.  From edge to cloud: at least three protocols, two gateways, hardware to deploy, OS to license/maintain, software to license/maintain, etc.  No OPC UA support for information models, alarms & conditions, methods, pub/sub, global discovery services, etc.

VDMA and UMATI are also pretty bad.  They will have this massive displays with the logos of machine tool builders.  They purport to do things in the spec that aren't even technically possible with the control platforms on their member's actual products.  And if you spend any time with the major builders in Japan, almost no one of importance to machine design or controls architecture have even heard of this stuff.

I don't understand the purpose of marketing this stuff.  Informing consumers that one is involved in a spec or a working group would imply that they have committed to supporting it.  If one is going to show up to a working group and not do anything, is it not premature or an exaggeration to market involvement?  Sure, maybe it's important to market involvement to grow participation, but it's not clear what the benefit is for the end user.  It just causes confusion if one can't clearly answer ""So, can I buy this or not?""","",""
"917925131261718558","jpmoniz","2024-01-25T03:13:13.4570000+08:00","I think the biggest issue is OPCF and SPB for that matter, rely on the OEM implementation. Requiring both device OEM's and Machine builders to do the heavy lifting. I think also partly driven by customer base articulating certain functionality. This is why all of these so called standards are just guidance documents at best. The whole market is focused on basic integration still.","",""
"747418831248556043","randya4861","2024-01-25T03:52:11.9260000+08:00","The OPC Foundation uses the term 'certified' to describe products that have actually been tested against their claims. The OPC-F encourages but cannot mandate that vendors provide certified products. The hope has always been that end users demand it but in practice that has been limited because users are stuck choosing from a limited range of specialized products and have to take what they can get","",""
"747418831248556043","randya4861","2024-01-25T03:58:08.9360000+08:00","There is different between modelling a specific device and modelling elements of a device that are common across many devices. There is currently an initialize to use DTDs as a way to configure UA servers: https://profiles.opcfoundation.org/workinggroup/81. The prototype code is here: https://github.com/OPCFoundation/UA-EdgeTranslator","",""
"817835202746253344","IIoT#4707","2024-01-25T03:58:09.5840000+08:00","GG @Randy Armstrong, you just advanced to level 4!","",""
"801561312861618236","jon.forbord","2024-01-25T03:59:39.6870000+08:00","?","",""
"801561312861618236","jon.forbord","2024-01-25T04:00:01.6450000+08:00","PLCs have OPC UA servers..","",""
"801561312861618236","jon.forbord","2024-01-25T04:02:32.0570000+08:00","Is this an american thing again? Where opc server is synonymous with Kepserver?","",""
"1129435706285101076","ted.garrison","2024-01-25T04:03:55.1410000+08:00","I would say no.. we've got numerous devices in our plant that have built in OPC UA Servers..","",""
"801561312861618236","jon.forbord","2024-01-25T04:04:50.6190000+08:00","I‚Äôm half joking. But I‚Äôve had this miscommuncation before only with americans..","",""
"1129435706285101076","ted.garrison","2024-01-25T04:05:25.0810000+08:00","PTC has trained us well üôÇ","",""
"747418831248556043","randya4861","2024-01-25T04:05:30.2580000+08:00","Well - the WG focuses on the requirements brought to it by members. At this point the focus has been on allowing WoT TD To be used configure Servers which are gateways to other protocols but other use cases are not a stretch. i.e configuring a PLC or providing a WoT TD export of the address space instead of a UANodeSet","",""
"801561312861618236","jon.forbord","2024-01-25T04:08:27.4630000+08:00","I‚Äôm sorry, I‚Äôm not able to follow the the train of thought from my post to your response. Which part of my post led you to WoT TD?","",""
"747418831248556043","randya4861","2024-01-25T04:14:08.2230000+08:00","DTDL is a private MS invention. WoT TD is an overlapping spec that is actually a W3C proposal. They have been talking about integrating the two. The OPC-F needs to use the actual standard","",""
"801561312861618236","jon.forbord","2024-01-25T04:18:53.8910000+08:00","I was not aware of the link between DTDL and WoT TD. Thanks üôÇ i would think DTDL was somewhat overlapping with OPC UA information modelling language? Or that is an actual question, do they overlap?","",""
"747418831248556043","randya4861","2024-01-25T04:22:25.6640000+08:00","The WoT TD/DTTD provides a serialized representation of an actual device. It does not have common type models or a standard API to access the live data described by the TD.","",""
"747418831248556043","randya4861","2024-01-25T04:23:58.1810000+08:00","The OPC UA TD spec adds additional fields to the TD that links the TD to a UA information model.","","üëç (1)"
"917925131261718558","jpmoniz","2024-01-25T04:27:04.7020000+08:00","But the first step in that, is deploying a UA information model correct?","",""
"747418831248556043","randya4861","2024-01-25T04:28:56.6340000+08:00","Yes, the assumption is the target UA server supports the information model in question.","",""
"917925131261718558","jpmoniz","2024-01-25T04:33:12.7300000+08:00","Isn't that kind of the problem.  Chicken egg scenario so to say.","",""
"747418831248556043","randya4861","2024-01-25T04:39:14.9980000+08:00","Not necessarily, the types in the TD are just identifiers. If a TD was used for a non-UA device it could like the fields to UA types if it was appropriate","",""
"747418831248556043","randya4861","2024-01-25T04:42:30.1550000+08:00","That said, it not clear what your end objective is with the DTD/TD?","",""
"917925131261718558","jpmoniz","2024-01-25T05:19:57.8920000+08:00","Not understanding what you meant by end objective is with DTDL the whole premise is to build from the bottom up.  Or are we thinking differently","",""
"801561312861618236","jon.forbord","2024-01-25T05:26:04.9120000+08:00","I‚Äôm a fairly simple dude.. When i make UDTs and structure data in my PLCs, i dont want to recreate them in my HMI and SCADA as well. Can we get that? In essense, whatever I do to organize data in my PLC is not something I‚Äôm keen on doing twice or thrice. I also want to be able to aggregate additional context/data to these UDTs, as i move into the higher layers.","","üíØ (1)"
"801561312861618236","jon.forbord","2024-01-25T05:28:22.9190000+08:00","And i want the PLC to do this natively, ie it is seamless, no more than ticking off a couple of boxes and what to expose.","",""
"747418831248556043","randya4861","2024-01-25T05:29:24.7830000+08:00","There are 2 views of the data that I see as interesting: 1) I have a PLC/Device/Whatever and it has but of I/Os that are labelled. I need to know what I/Os the device has and associated info like engineering units/range","",""
"747418831248556043","randya4861","2024-01-25T05:30:42.2230000+08:00","2) I have 20 PLCs and I want to know that whether the sets of I/O exposed on each of the represent the same thing","",""
"747418831248556043","randya4861","2024-01-25T05:39:50.2500000+08:00","I get your point - I try to recognize hat I don't know and depend a lot on people with direct experience to tell me what they need","",""
"801561312861618236","jon.forbord","2024-01-25T05:41:02.5290000+08:00","It was more that the view of what is in a PLC was fairly limited, just a set of IO.. But you wouldnt be the first to make that over simplification üôÇ","",""
"801561312861618236","jon.forbord","2024-01-25T05:41:49.8180000+08:00","My post over is all I really ever wanted from my embedded opc ua servers on my PLCs.","",""
"747418831248556043","randya4861","2024-01-25T05:42:00.9190000+08:00","i was over simplifying to make a point. i know that 'PLCs' can do as much as PC 20 years ago","",""
"747418831248556043","randya4861","2024-01-25T05:43:29.7140000+08:00","my point is a PLC generally has a finite set of information which is derived physical I/Os.","",""
"747418831248556043","randya4861","2024-01-25T05:44:03.7430000+08:00","it is not a web app with a huge DB containing abstract information","",""
"747418831248556043","randya4861","2024-01-25T05:44:46.5960000+08:00","that is the distinction i was trying to make","",""
"801561312861618236","jon.forbord","2024-01-25T05:47:00.5810000+08:00","I‚Äôm struggling to see connection again. (Is this thing on??)","",""
"747418831248556043","randya4861","2024-01-25T05:48:00.8160000+08:00","?","",""
"801561312861618236","jon.forbord","2024-01-25T05:50:47.2120000+08:00","I want whatever structure i create in my PLC, for instance to represent a pump, automatically be exposed as something I can consume as a client directly, such that i dont have to make a pump-model in my HMI, next in my SCADA, and again at the digital twin in Azure..","",""
"747418831248556043","randya4861","2024-01-25T05:53:37.3070000+08:00","are expecting graphical layout to be exported or just data structures?","",""
"801561312861618236","jon.forbord","2024-01-25T05:53:52.1170000+08:00","Just the data structure üôÇ","",""
"747418831248556043","randya4861","2024-01-25T05:54:47.2220000+08:00","any with the PLC engineering tool - are you expecting that to be standard as well or are still expecting to design the pump in the PLC with the vendors tools?","",""
"801561312861618236","jon.forbord","2024-01-25T05:54:47.5460000+08:00","Or really, whatever structure my PLC allows me to bestow upon it üôÇ in the future, could be graphical layout..","",""
"801561312861618236","jon.forbord","2024-01-25T05:59:06.9320000+08:00","I mean, i have to program the god damn pump(s), so i have to have some form of model for it, and if I can use a standard pump model to build something from instead of making my own, that is preferrable.","",""
"917925131261718558","jpmoniz","2024-01-25T06:04:31.0060000+08:00","We could get really crazy and map them to companion specification definitions.","",""
"801561312861618236","jon.forbord","2024-01-25T06:10:06.8930000+08:00","Should i use the weihenstephaner comp spec then?","","üòÜ (1)"
"766684226455207996","bright_hummingbird_31342","2024-01-25T06:10:16.0990000+08:00","üòÇ  not so fast.  America's favorite PLC finally has an onboard OPC UA Server.  It only took nearly... twenty years.

https://www.plctalk.net/qanda/showthread.php?t=138154
https://www.reddit.com/r/PLC/comments/187sy3w/rockwell_is_straight_out_dropping_some_heat_today/","","üëç (1),üòÇ (2)"
"917925131261718558","jpmoniz","2024-01-25T06:12:20.0850000+08:00","Think you might be the only one","",""
"801561312861618236","jon.forbord","2024-01-25T06:23:23.2900000+08:00","Rockwell - the shining beacon of American innovation!!","","ra (1)"
"801561312861618236","jon.forbord","2024-01-25T06:24:08.4660000+08:00","ü•ì","",""
"917925131261718558","jpmoniz","2024-01-25T06:39:29.7740000+08:00","Who doesn‚Äôt like bacon?","","üòÇ (1)"
"753688565807841492","ravil1","2024-01-25T06:46:40.0450000+08:00","OPC  UA Forge recognizes Pump type and intances exposed by the PLC 's OPC UA Server and can reuse it in its addres space.","",""
"747418831248556043","randya4861","2024-01-25T08:01:45.6570000+08:00","Taking this as homework. Sent queries to colleagues saying we need good answers.","",""
"794020366536146977","mparris","2024-01-25T08:06:55.6350000+08:00","My guess is that this is an issue of implementation.

PLCs don't even have a standard way of exposing their physical IO. This seems like the lowest hanging fruit for a companion spec in manufacturing: card number, io#, analog, type: digital, input, output; real units, and bonus points for allowing scaling to engineering units.

Every vendor expressed this differently however they want","","üëç (1)"
"917925131261718558","jpmoniz","2024-01-25T08:37:36.7500000+08:00","Yes and the part we keep missing out on is the protocol translation between device and server.   I was talking to a module developer about this exact issue.  For Example if we keep the focus on Rockwell for a second.   The OPC namespace is a direct reflection of what CIP objects are interrogated VIA EIP.   Most have stuck to a basic model of get the target device identity data and  then provide a browsable tag space.   I have yet to see any product take that basic model any further.  Maybe I haven't sampled enough OPC app platters yet but most implementations seem basic.  It will be nice to see what the embedded ones provide but I'm guessing it will be much of the same.  It would be nice to get a more modeled approach.  For example it's not just the PLC but all of the connected EIP devices that make up the automation system.  For that namespace to be constructed in a logical manner it takes scanning for other EIP devices and making the logical connections and modeling as such.  But that capability is in the driver stack and needs to be built.","",""
"801561312861618236","jon.forbord","2024-01-25T09:26:25.1970000+08:00","This one is on the vendors though.. it either is not supported or is not seamless.","",""
"747418831248556043","randya4861","2024-01-25T15:44:34.3440000+08:00","Here is a start with code: https://github.com/digitaltwinconsortium/ManufacturingOntologies?tab=readme-ov-file#manufacturing-ontologies","",""
"817835202746253344","IIoT#4707","2024-01-25T15:44:34.7520000+08:00","GG @Randy Armstrong, you just advanced to level 5!","",""
"867075936054149191","rickbullotta","2024-01-25T22:06:56.3090000+08:00","Not really correct Randy - it's actually an open source spec that is part of the Digital Twin Consortium.  We incubated it within the Azure IoT team but then put it out there as an open spec as part of the DTC.  At least that's the last I knew.","",""
"917925131261718558","jpmoniz","2024-01-25T22:22:30.3840000+08:00","Was the work with OMP and the aspect metal model part of this as well.  Did they merge?   I noticed OMP is defunct now.","",""
"747418831248556043","randya4861","2024-01-25T22:27:09.3520000+08:00","The Digital Twin website does not say that: https://www.digitaltwinconsortium.org/glossary/glossary/#data-modeling-language
 ""Digital Twin Definition Language (DTDL): A property-graph data-modeling language with support for integration with IoT via ""telemetry"" properties. DTDL was created by Microsoft and open-sourced.""","",""
"867075936054149191","rickbullotta","2024-01-25T22:27:41.9210000+08:00","OMP was a sham in my opinion.  It was bait set up by Microsoft to get a couple big name manufacturers to sign on to Azure as their platform.","",""
"867075936054149191","rickbullotta","2024-01-25T22:28:05.0650000+08:00","Yup - but AFAIK other companies are welcome to contribute.  I could be wrong though.  I'll check.","",""
"747418831248556043","randya4861","2024-01-25T22:29:25.3420000+08:00","The distinction is between a formal standard and ""open source"" document. It may be recognized as useful by the DTC but it is not standard","","üíØ (1),‚òùÔ∏è (1)"
"917925131261718558","jpmoniz","2024-01-25T22:31:14.6350000+08:00","Actually Great point.  Never really thought of it that way, but does beg the question. Why sponsor many competing ideas?  I guess the obvious answer is Sales.  Also talk to the levers that drive disparity.","",""
"867075936054149191","rickbullotta","2024-01-25T22:31:58.7720000+08:00","Absolutely.  What I do like about DTDL is its simplicity, readability, and the graphiness.","","üëç (1)"
"917925131261718558","jpmoniz","2024-01-25T22:45:21.0000000+08:00","Looks like OMP was dissolved and is now https://eclipse-esmf.github.io/samm-specification/snapshot/index.html  Mainly drive by Bosch.","",""
"867075936054149191","rickbullotta","2024-01-25T22:48:25.1200000+08:00","Maybe now, but it was Microsoft and BMW initially.  I can tell you the story over a beer sometime.

https://news.microsoft.com/2019/04/02/microsoft-and-the-bmw-group-launch-the-open-manufacturing-platform/","","üëÄ (1)"
"917925131261718558","jpmoniz","2024-01-25T22:49:15.1380000+08:00","May just have to take a ride down to PA and do that.","","üçª (1)"
"1173270244291264535","andreasvogler","2024-01-29T04:31:26.8670000+08:00","I have nearly completed an implementation of SparkplugB for Unity3D and would like to test it with other SparkplugB Host Applications and Nodes. Any suggestions for SparkplugB compliant options, preferably those available for free, would be greatly appreciated.","",""
"817835202746253344","IIoT#4707","2024-01-29T04:31:27.2350000+08:00","GG @Andreas Vogler, you just advanced to level 2!","",""
"917925131261718558","jpmoniz","2024-01-29T05:34:34.4580000+08:00","Just Curious.  What are the details about the SPB interface.  Does it publish or consume a SPB namespace?","",""
"1173270244291264535","andreasvogler","2024-01-29T05:59:33.5530000+08:00","Started a thread.","",""
"1152698356007714856","davek0414","2024-02-05T04:29:12.9260000+08:00","Has anyone heard the term ‚ÄúBurst Storm‚Äù when a primary host connection is lost repeatedly . I assume it‚Äôs similar to a Broadcast storm‚Ä¶","",""
"801561312861618236","jon.forbord","2024-02-05T06:34:56.1320000+08:00","Birth storm.. yes. Anything particular you wanted to know? The primary host sends rebirth commands to Sparkplug nodes. Ie birth storms are really in control of the primary host.","",""
"812295088348200960","patanj2","2024-02-05T06:42:27.5770000+08:00","Is it ‚ÄúBirth‚Äù or ‚ÄúBurst‚Äù","",""
"1152698356007714856","davek0414","2024-02-05T07:27:16.3760000+08:00","Do know of a solution?","",""
"1152698356007714856","davek0414","2024-02-05T07:27:42.3630000+08:00","Do you know of a solution ?","",""
"1152698356007714856","davek0414","2024-02-05T07:36:12.4220000+08:00","@John Patanian  Birth Storm","",""
"867075936054149191","rickbullotta","2024-02-05T08:55:43.9800000+08:00","Yes. Fix Sparkplug‚Äôs design flaws. Go to the sparkplug GitHub repo and upvote everything this group has submitted as recommendations or fixes.","",""
"1152698356007714856","davek0414","2024-02-05T10:07:13.7640000+08:00","@RickBullotta  Thanks Rick.","",""
"801561312861618236","jon.forbord","2024-02-05T14:38:23.2060000+08:00","There‚Äôs two levels of ¬´fixing¬ª this. What is the context here? Are you using or planning to use SpB in any way? Do you use off the shelf software with Sparkplug support or do you write your own?","",""
"867075936054149191","rickbullotta","2024-02-05T14:57:48.7730000+08:00","Even the folks at Cirrus Link seem to agree that the birth dance needs to be redesigned BTW","","üíØ (2)"
"801561312861618236","jon.forbord","2024-02-05T14:58:21.6300000+08:00","100% agree.","",""
"801561312861618236","jon.forbord","2024-02-05T15:03:21.5390000+08:00","Theres two levels of fixes. Long term, fixing fundamental issues such as the spec. Short term, fixing your setup. There are things you can do to reduce the problem so to say.","","üíØ (1)"
"766684226455207996","bright_hummingbird_31342","2024-02-05T16:24:28.2220000+08:00","It seems like these changes wouldn't really be hard to coordinate.  Aren't like 95%+ of MQTT SpB Clients, in practice, Cirrus Link modules?  I don't often see Sparkplug in architectures without Ignition.  And, absent Ignition, Sparkplug is usually more effort than it's worth.  A lot of Sparkplug UNS implementations are really Ignition doing pub/sub with itself.  It's really SCADA with custom apps built inside the SCADA.  Occasionally, there might be something like Canary.  But, what other nodes might there be that aren't Cirrus Link modules?

I suspect EZAutomation, FactoryStudio, etc would not be a significant factor for many.  Aveva has a big ecosystem, but their [limited] support of Sparkplug is also probably insignificant to their market.  There is probably more reliance on OPC DA and SuiteLink.","",""
"801561312861618236","jon.forbord","2024-02-05T17:42:56.8780000+08:00","The problems are real, but I dont think it needs to be that hard to fix them. 1. free up the topic restrictions. 2. allow QoS >0. 3. separate birth and current state requests, allowing births to be retained. The rest is then just gravy.","","üíØ (3)"
"867075936054149191","rickbullotta","2024-02-05T19:35:08.0680000+08:00","Great point Jon.","",""
"812295088348200960","patanj2","2024-02-05T20:55:36.3610000+08:00","Concentration of nodes in a single large ignition gateway exacerbates the problem.  Also,  any subscriber that is listening most topics,  such as a historian collector,  can get overwhelmed during a birth storm.  It is better to distribute the load,  with a goal to make the birth storm a less disruptive event.  I have found that overloading a subscriber is a bad thing‚Ä¶some don‚Äôt return nicely to a normal state.","",""
"867075936054149191","rickbullotta","2024-02-05T21:08:55.6630000+08:00","The TLDR; version is that it's a poor design that needs to be fixed. üòâ","","üíØ (1)"
"801561312861618236","jon.forbord","2024-02-05T21:27:24.3620000+08:00","Canary could also not send 200 rebirth commands at the same time ü§™ (theyre kind of asking for it..)","",""
"801561312861618236","jon.forbord","2024-02-05T21:28:31.2350000+08:00","¬´Hey, give me 200 pizzas!¬ª ¬´OMG  I can‚Äôt eat all of them at once!!¬ª","","üòÇ (2)"
"867075936054149191","rickbullotta","2024-02-05T21:33:03.8880000+08:00","...but if you could keep those 200 pizza in a freezer with the ""pizza retain"" flag...and if you didn't mix a random amount of spaghetti in with each pizza (intermingling of data and metadata)...","","üòÖ (5)"
"812295088348200960","patanj2","2024-02-05T23:29:27.0620000+08:00","100% what I posted are workarounds to a flawed design.","","üíØ (1)"
"1152698356007714856","davek0414","2024-02-09T08:49:38.9850000+08:00","I‚Äôm just learning Jon. Never used MQTT or SpB before. Thanks for all the feedback.","",""
"1173270244291264535","andreasvogler","2024-02-10T05:51:08.3440000+08:00","Is anyone using Solace.com here? I am curious if anyone can share experiences with it. Does it compete with MQTT brokers like EMQX or HiveMQ?","",""
"867075936054149191","rickbullotta","2024-02-10T09:34:33.3830000+08:00","A few are. Generally positive feedback if I recall. Search for it","",""
"867075936054149191","rickbullotta","2024-02-13T23:34:47.2610000+08:00","New post regarding MQTT and security - most of it is good and valid - except the stuff about Sparkplug. Sparkplug REDUCES the ability to properly secure your MQTT implementation - it does NOT enhance it.

https://cirrus-link.com/securing-mqtt-best-practices-for-a-robust-iot-ecosystem/","",""
"867075936054149191","rickbullotta","2024-02-13T23:35:41.9110000+08:00","Reasons:

- Because *BIRTH messages conflate metadata and data, you cannot securely allow some subscribers to browse only metadata and do discovery

- Because *DATA message can contain 1:n metrics, you CANNOT provide ACLs on a per-metric basis and therefore cannot implement the ""principle of least privilege.""

- Because the *CMD message approach does not allow granular access controls over individual commands","","üíØ (1)"
"867075936054149191","rickbullotta","2024-02-14T01:45:10.4210000+08:00","Oh, come on, someone has to disagree! üòâ","","üëç (1),üòÇ (1)"
"1129435706285101076","ted.garrison","2024-02-14T02:17:49.4700000+08:00","everyone is still sleeping off their superbowl hangover it appears.  Has been quite in here so far this week..","","ü§£ (3)"
"794020366536146977","mparris","2024-02-14T03:58:00.7240000+08:00","I'll take a stab:  I disagree that Sparkplug reduces security.

Sparkplug is a great multipoint-to-point pipe, allowing individual clients to publish their data to a single, primary application and allow that single application to control/modify the clients.  Sparkplug can be deployed very securely: each device has its own username/password that maps to a specific ACL only allowing access to its specific groupID/nodeID that was assigned to it.  Likewise, the Primary Application has ACL to allow it sending commands to the devices.  All others cannot access the data.  Sounds secure to me üôÇ

Doing more than a multipoint-to-point implementation (such as multipoint-to-multipoint) stretches Sparkplug beyond its capability into territory that leads to insecure implementations.","",""
"794020366536146977","mparris","2024-02-14T03:58:14.7170000+08:00","And, by the way, this statement appears false:
""Sparkplug accomplishes all of these tasks without giving any other system access to the shop floor. So, multiple consumers can access the data without any security concerns.""

Stick a data diode in between the shop floor and consuming applications and see if Sparkplug still works....","",""
"1173270244291264535","andreasvogler","2024-02-14T04:16:42.7260000+08:00","What I don't like is that there is no way to implement a read-only access to a node for an application. Why? because of the ""Node Control/Rebirth"" metric: You cannot allow a client to send the rebirth metric without giving him write permission to the CMD topic. And that means the client has also rights to write other metrics/commands to the cmd topic as well. And a client must be able to send the Rebirth command to get the initial BIRTH message...","",""
"794020366536146977","mparris","2024-02-14T04:22:11.8870000+08:00","Yes, all things that Sparkplug v4 intends to correct:
- split metadata away from data
- retain metadata","","üëç (2)"
"867075936054149191","rickbullotta","2024-02-14T05:08:04.9220000+08:00","And you would be wrong. üòâ

It absolutely reduces security versus the ability to provide ACL's at the metric/command level (which you can do with ""regular"" MQTT). Dangerously so.  It forces an ""all or nothing"" approach access to a node/device.  Not good.","",""
"867075936054149191","rickbullotta","2024-02-14T05:10:06.1980000+08:00","WIthout making metric expansion a core capability and without extending the concept of CMDs to include input/output and a per-command topic, sparkplug is an insecure mess.","",""
"794020366536146977","mparris","2024-02-14T08:13:57.1620000+08:00","Good point...I modify my response accordingly:

Sparkplug is a great multipoint-to-point pipe for all data from a client to publish to a single, primary application and allow that single application to control/modify the clients.

Implementing something other than a multipoint-to-point, all-data-publish implementation (such as multipoint-to-multipoint or individual metric subscriptions) will lead to insecure deployments.","","üëçüèº (1),üòÄ (1)"
"867075936054149191","rickbullotta","2024-02-14T08:28:05.6810000+08:00","Maybe a corollary is that it is more appropriate for tightly coupled/trusted connections.","","üíØ (1)"
"794020366536146977","mparris","2024-02-14T08:35:13.0410000+08:00","I've known this from a functionality aspect, but requiring security really shines a bright light on its gaps, and quickly answers the question of where the technology is best suited.

In other words, not appropriate for enterprise.","","üíØ (1)"
"745796393855352953","thedavidschultz","2024-02-14T20:42:40.2950000+08:00","I use SpB for SCADA but flat for everything else.","","üíØ (3),üëç (2)"
"240066112773947393","leeeelemon","2024-02-21T11:03:31.6870000+08:00","Has anyone ever needed to setup 2 spb devices as a redundant pair? Both being used as a gateway/protocol convertor for downstream data, so don't want duplicate NDATA being received.

We got it working eventually with a heartbeat between the 2 spb device... so secondary only publishes if the heartbeat dies... but feels a little adhoc. 

Seems like something the sparkplug spec could include as an optional feature? Where the secondary sparkplug b device only publishes if it sees an NDEATH from the primary...","",""
"867075936054149191","rickbullotta","2024-02-21T12:45:16.0860000+08:00","If the broker crashed would that lead to both publishers being in an indeterminate state? And could be race conditions.  A hack would be to have them use the same client id and set a long connection retry.  It would be an ugly hack but might actually work!","",""
"867075936054149191","rickbullotta","2024-02-21T12:46:39.8160000+08:00","Essentially they‚Äôd take turns being the master at the retry interval, and if one died the other one would stay master. Yeah, it makes me want to take a shower but it might work.","",""
"240066112773947393","leeeelemon","2024-02-21T14:24:44.0460000+08:00","True... Maybe if the spec used a retained state topic for redundant nodes like it does for primary hosts.  If primary state is online, standby doesn't publish. And to get around race condition upon broker crash, the standby could wait a few seconds to give the primary time to reconnect... That last part is kinda hacky too...","",""
"698244484302897323","lmtx","2024-02-21T15:10:21.3120000+08:00","I typically focus on the advantages of MQTT, a widely used communication protocol in IoT systems.
In today's article, I discuss challenges with its implementation in real-life Internet of Things deployments.

https://www.thingrex.com/mqtt_challenges/

Any feedback/questions are very welcome!","https://cdn.discordapp.com/attachments/1166016853991235594/1209758998497075270/roblox_mqtt_challenges.mp4?ex=68df76dd&is=68de255d&hm=afd6e5e7d95cae85951ca5015acf53171e1b67a6ef9684736e0da4e5f3e33c65&",""
"1073312001788477471","sparkylarks","2024-02-21T17:38:01.6690000+08:00","Is there a ""MQTT Explorer"" equivalent that can decode sparkplug packets, and is free.","",""
"240066112773947393","leeeelemon","2024-02-22T06:07:59.2380000+08:00","Nope, I'm still using an old version of mqttfx from back when it was free.","",""
"898217314741280828","hobbes1069","2024-02-22T07:22:43.2270000+08:00","MQTT Explorer has a PR to add SPb support but the author has been MIA for a couple of years now and the license makes it impossible to fork. I think it will eventually die from bit rot. It's very sad.","",""
"766684226455207996","bright_hummingbird_31342","2024-02-22T08:37:57.9510000+08:00","You could technically use Intelligence Hub unlicensed for this.  It can automatically decode the protobuf in the sparkplug topics.  If you have questions or need access, feel free to reach out.

Some organizations use this to visualize the namespace without having to make a direct connection to a broker.  For example, they might be on an office network without access to the broker.  They can visualize the broker from Intelligence Hub in their web browser.

Here's a glimpse of it around 22:48:
https://youtu.be/rH_2jHt39js?si=0ky-qmi6a_lUhtSP&t=1368","",""
"867075936054149191","rickbullotta","2024-02-22T11:47:45.6270000+08:00","Is it open source? If so I‚Äôll be glad to give it a go.","",""
"794020366536146977","mparris","2024-02-22T19:43:50.7480000+08:00","Here is the repo:

https://github.com/thomasnordquist/MQTT-Explorer","","üëçüèº (1)"
"254777321788145664","terrancesmith","2024-02-23T22:48:18.1680000+08:00","It doesn't do everything that MQTT-Explorer does, but I've been watching the work postman is doing to support mqtt development.https://learning.postman.com/docs/sending-requests/mqtt-client/mqtt-client-overview/ Really happy to start seeing mainstream tools picking up IIoT friendly tech","",""
"1073312001788477471","sparkylarks","2024-02-24T00:24:24.9830000+08:00","It is great, I already had postman on my system, but It doesn't decode the  in the Sparkplug Payload","",""
"339656700745351180","douglawrie","2024-02-24T21:01:41.0620000+08:00","@RickBullotta  interested to know what concerns would remain for you if all of the proposed SP4 additions/modifications were implemented. I assume it doesn't solve all of the problems for you?","",""
"794020366536146977","mparris","2024-02-24T23:55:48.6810000+08:00","I am guessing that stopping at only defining JSON as a translation rather than a valid implementation would be one.","",""
"339656700745351180","douglawrie","2024-02-25T00:38:16.7110000+08:00","Tbh I don‚Äôt see a problem with the protobufs. There‚Äôs tools in any ecosystem I‚Äôve used think of to decode them","",""
"794020366536146977","mparris","2024-02-25T02:11:40.4100000+08:00","How many MQTT desktop clients can you name that support decoding protobuf over MQTT?

I've struggled with this question...","",""
"801561312861618236","jon.forbord","2024-02-25T04:54:49.6110000+08:00","In an isolated view, SpB shines when used with off the shelf Solutions that support it out of the box. So protobuf or not is to a large degree irrelevant. The ¬´problem¬ª only becomes relevant when you plug in applications that doesnt support SpB out of the box. Such as the most popular open source mqtt desktop client.. mqtt Explorer.","",""
"766684226455207996","bright_hummingbird_31342","2024-02-25T06:38:30.2990000+08:00","Decoding, in isolation, doesn't seem like a big deal.  At scale, it's a huge deal.  This is especially true when it comes to cloud services.  To ""win"" with the cloud, the technology strategy has to be oriented around leveraging its strengths and weaknesses.  It should be thought of like a utility.  If it's ""serverless"" service, as much of the native feature set should be utilized.  Many find themselves paying a ""sparkplug"" tax on their data.  They have to stand up additional compute and storage infrastructure to use their data.  With each publish, the inefficiencies of unpacking sparkplug offset its efficiencies on the wire.

The other day, I heard an SI describe Sparkplug as just another protocol along side EtherNet/IP, Modbus, PROFINET, etc.  They said it's another option for moving device data from the field.  This got me thinking.  Sparkplug should be thought of as like another fieldbus.  Like a fieldbus, it's efficient at moving telemetry data and useful within its ecosystem.  It's not efficient for determinism, but it's efficient across low bandwidth and higher latency networks.  When it is more important that data is accessible than being efficient on the wire, the benefits of a fieldbus diminish.

Going beyond protobuf, the bigger problem I see is those strange metric payloads.  Shoehorning a SCADA namespace into an MQTT topic does not make any sense.  If consumers can't subscribe to the data they need, the whole mission is a failure IMO.  I can't think of a worse way to make a pub/usb architecture interoperable.  All those neat features (e.g., host state, birth, commands) do not matter if a node can't get the right data, in the right form, at the right time.

It boggles my mind when people think it's sensible to build a UNS with payloads that span several thousand lines and they wonder why they're having interoperability problems.  It's not much better than relaying raw PLC registers to the cloud.  Garbage in, garbage out.","",""
"867075936054149191","rickbullotta","2024-02-25T07:36:08.6740000+08:00","Is there an official list of what‚Äôs in/out yet?","",""
"339656700745351180","douglawrie","2024-02-25T10:34:15.6650000+08:00","Agree that it sucks that you can‚Äôt subscribe to individual metrics, so payloads can be larger than necessary. But that isn‚Äôt solved by using JSON payloads, and clients have to parse JSON which is pretty inefficient (turning strings into various number types rather than just directly storing the bits).","",""
"339656700745351180","douglawrie","2024-02-25T10:36:40.7880000+08:00","I was just referring to the presentation CL gave. I know the META verb solves some major issues, but I don‚Äôt remember a solution to subscribing to individual metrics","",""
"339656700745351180","douglawrie","2024-02-25T10:39:20.5340000+08:00","I mean that there‚Äôs solutions that explicitly support it like broker extensions, CL modules, etc. but then most programming languages also have protobuf support. I am writing a Sparkplug Host crate in Rust right now. The Protobuf decoding/encoding is not a roadblock. I am sure it could be added to an open source project without much pain.","",""
"801561312861618236","jon.forbord","2024-02-25T17:29:10.9530000+08:00","I‚Äôm 100% with you until the last paragraph. The answer to what boggles your mind is simple though: benefits > drawbacks. It‚Äôs easy enough to work around the drawbacks, that the sum of benefits outweigh the drawbacks. That being said, SpB in its current iteration is not for everyone, but on a theoretical level I still stand that protobuf is almost never the reason to not choose SpB. 

And btw, don‚Äôt underestimate how much of what is being discussed here on this discord, very quickly establishes into ‚Äúthe wild‚Äù.","",""
"801561312861618236","jon.forbord","2024-02-25T17:31:26.1780000+08:00","And SpB was designed for SCADA, so don‚Äôt be overly surprised when that‚Äôs what it‚Äôs best at..","",""
"801561312861618236","jon.forbord","2024-02-25T17:34:35.0740000+08:00","Here‚Äôs to SpC (4.0) being for more than SCADA. And btw, fieldbuses and ‚ÄúSCADA-only-SpB‚Äù, can still be a pretty big deal, and an important part of your architecture, but it can probably not be the backbone of it.","",""
"867075936054149191","rickbullotta","2024-02-25T22:47:00.4220000+08:00","I did propose that a sparkplug compliant broker support automatic metric expansion into topics. No idea if they‚Äôll implement it.  I‚Äôve kinda lost faith. Things move too slowly for an ADHD person like me.","",""
"867075936054149191","rickbullotta","2024-02-25T22:48:14.8350000+08:00","And when I saw someone from CL claim (incorrectly) that sparkplug improves cybersecurity, the top of my head almost blew off.","",""
"1073312001788477471","sparkylarks","2024-02-25T23:37:07.5970000+08:00","That woudl be nice.
@js That is 100% how I see Sparkplug, great for getting data into my Central hub, but I then need to parse it out and put int into my contextualised hierarchy.","","üíØ (1)"
"898217314741280828","hobbes1069","2024-03-01T08:28:34.8870000+08:00","Question for the day... Is there any advantage to running HiveMQ CE (Community Edition) over mosquitto? 

It lacks a Web/UI management interface, and of course enterprise functions like clustering and failover, etc. I would think that given this, mosquitto would be more performant being C based vs HiveMQ using Java.

I appreciate them providing a free community version, but I'm having trouble seeing the value.","",""
"867075936054149191","rickbullotta","2024-03-01T09:23:54.2610000+08:00","Take a look at HiveMQ Edge instead.  Then the difference is clear.","","üòÄ (1)"
"898217314741280828","hobbes1069","2024-03-01T10:43:08.8300000+08:00","I like it has a configuration interface and the included protocols could be interesting. I also went down the rabbit hole for MQTT-SN but I don't think I have many applications at work. At home perhaps... ü§î","",""
"794020366536146977","mparris","2024-03-01T11:21:57.5300000+08:00","Have you tried EMQx community edition?  It does support clustering and includes a web gui","",""
"452843187719897088","scrapper7161","2024-03-01T18:58:14.5100000+08:00","It's disheartening to see the MQTT Explorer project potentially going to waste. We, at Coreflux, are eager to support the MQTT-Explorer repository, and trying for ages  because we believe in its value. We use this client daily and recognize its significance.

The main obstacle is the licensing issue, which is closely tied to the original author, who is MIA. However, I believe that with collective effort and support from all, we can find a way. We could provide the necessary support and backbone for the project, and I'm optimistic that the wider user community will also pitch in (though I might be wishfully thinking üòÅ).

It would be a tremendous loss to let such a project fade away üòí.

I am keen on starting this movement within the community, but first, I would love to hear your thoughts and any suggestions on how we can proceed.","","üëçüèº (2)"
"801561312861618236","jon.forbord","2024-03-02T00:23:52.5040000+08:00","It shouldnt be such a massive task to build a basic visual mqtt client, I mean writing a command Line client certainly isnt.. ?","",""
"867075936054149191","rickbullotta","2024-03-02T00:31:20.0530000+08:00","It‚Äôs very hard to do something that scales to very large numbers of topics and very rapid subscription updates. Trivial to build something for a handful of topics.  Not just performance, but providing a good user interface at scale","","üíØ (1)"
"801561312861618236","jon.forbord","2024-03-02T00:41:36.7600000+08:00","I get that, but we‚Äôre talking a replacement for mqtt explorer, not the ultimate mqtt gui client.. Can you use mqtt Explorer on millions of topics?","",""
"867075936054149191","rickbullotta","2024-03-02T01:06:56.4130000+08:00","The issues above come into play when the # of topics is in the thousands. It‚Äôs a much tougher design issue than you‚Äôd think.","",""
"254777321788145664","terrancesmith","2024-03-02T01:15:48.7310000+08:00","This is exactly what I think about every time I see a knowledge graph style interface. Looks amazing with a low number of nodes and relationships. Scale into the hundreds and it becomes entirely too much","","üíØ (2)"
"867075936054149191","rickbullotta","2024-03-02T01:19:54.4030000+08:00","Truth. We‚Äôve all seen those silly demos with a springy node diagram that demos well but has little practical utility without a lot of design work.  There‚Äôs a lot we can learn  (and improve on) from the GIS world.","",""
"794020366536146977","mparris","2024-03-02T01:29:20.2990000+08:00","I don't know if any other free client that does well to display large number of topics or a smaller number coming in fast. I assume it's because the problem is not easy","",""
"898217314741280828","hobbes1069","2024-03-02T01:29:36.6560000+08:00","I tried it a while ago, and did not keep up with the updates. When I finally did (major version update) it broke. I messed with it for a few hours but needed a broker back up so I went to mosquitto and it's been working great, other than the command line configuration.","",""
"452843187719897088","scrapper7161","2024-03-02T02:14:38.6310000+08:00","I still think a reach out would help","",""
"452843187719897088","scrapper7161","2024-03-02T02:22:54.1190000+08:00","Exactly for this . I think that the community could ask to step up and define a change in the license terms. The answer is NO already.... üòÖ","",""
"794020366536146977","mparris","2024-03-02T02:24:31.9160000+08:00","@RickBullotta did you look through the code/license for MQTT Explorer.

Any red flags?  Others should just contact the author directly?","",""
"867075936054149191","rickbullotta","2024-03-02T02:46:29.2080000+08:00","I only checked for the existence of the code. üôÇ","",""
"452843187719897088","scrapper7161","2024-03-02T02:51:40.8940000+08:00","There are a lot of red flags.","",""
"867075936054149191","rickbullotta","2024-03-02T03:32:56.9760000+08:00","The license is not good. Unfortunately there‚Äôs no way I can find to contact the author.","",""
"867075936054149191","rickbullotta","2024-03-02T03:34:55.5000000+08:00","Also there are 242 open issues on GitHub. Likely it‚Äôs not active nor does the original author monitor it anymore","",""
"1129435706285101076","ted.garrison","2024-03-02T03:38:33.6540000+08:00","he does have a paypal.. maybe send him a buck and see if he'll respond..","","üòÇ (1),ü§£ (1)"
"794020366536146977","mparris","2024-03-02T04:38:56.2320000+08:00","I did that one to encourage the merge for Sparkplug decoding.

It got merged, but a binary never got posted üò´

Will try again!","",""
"452843187719897088","scrapper7161","2024-03-02T04:48:05.5800000+08:00","Would like to know if it makes sense to have a cloud mqtt company supporting this. Maybe other companies could join in as well.","",""
"817835202746253344","IIoT#4707","2024-03-02T04:48:05.8410000+08:00","GG @Hugo Vaz, you just advanced to level 1!","",""
"1129435706285101076","ted.garrison","2024-03-02T04:50:11.2850000+08:00","Would be nice if he doesn't want to give up ownership to at least add some more folks to it that are interested and let them run it..","",""
"919215091549863967","nunocgoncalves","2024-03-02T05:18:43.4520000+08:00","100%, if the owner doesn‚Äôt oppose to it there should be nothing stopping the community from taking up the project.","",""
"919215091549863967","nunocgoncalves","2024-03-02T05:24:30.4570000+08:00","The way I see it, either the MQTT Explorer used by so many people dies and (likely) a proprietary alternative is adopted, or the community takes initiative and runs the project for the sake of the wider industry.
Having a cloud company interest aligned with the community taking this up would be great imo.","",""
"919215091549863967","nunocgoncalves","2024-03-02T05:25:19.0890000+08:00","I don‚Äôt think it‚Äôd be positive for the industry to have to rely on proprietary clients ‚Ä¶","",""
"867075936054149191","rickbullotta","2024-03-02T05:53:57.5240000+08:00","But without a change to the license it will be difficult to move forward.","",""
"452843187719897088","scrapper7161","2024-03-02T05:56:34.5220000+08:00","Like I said. We want to do it ...  And I can bring this into a wider scope. Putting this information into public. What @Walker Reynolds  thinks about this... (Shouting out)","",""
"756565963520081950","andersgustav","2024-03-03T01:31:02.8760000+08:00","Just start from scratch, it is not that hard.","","üíØ (1),ü§£ (1)"
"867075936054149191","rickbullotta","2024-03-03T05:18:57.3560000+08:00","Yes, it would be.  MQTT Explorer is extremely good - just a few tweaks would be much, MUCH easier than starting from scratch.","",""
"756565963520081950","andersgustav","2024-03-03T05:35:00.1870000+08:00","True story that Rick, but sometimes that card just is not in the deck, Just no point in shuffeling anymore.","",""
"817835202746253344","IIoT#4707","2024-03-03T05:35:09.3210000+08:00","GG @Anders Gustav, you just advanced to level 12!","",""
"801561312861618236","jon.forbord","2024-03-03T07:18:43.8100000+08:00","Sent some moneys with paypal, perhaps if some more do, we can get his attention üôÇ","",""
"452843187719897088","scrapper7161","2024-03-03T07:19:27.2140000+08:00","Actually was able to do that...","",""
"817835202746253344","IIoT#4707","2024-03-03T07:19:27.5140000+08:00","GG @Hugo Vaz, you just advanced to level 2!","",""
"452843187719897088","scrapper7161","2024-03-03T07:19:33.6660000+08:00","let see what i can do....","",""
"452843187719897088","scrapper7161","2024-03-03T07:20:24.3270000+08:00","i will bring this into the community, if i am able to talk with the guy. found a similar co-worker he is in a total different industry...","",""
"452843187719897088","scrapper7161","2024-03-03T07:20:37.1250000+08:00","no promises","",""
"1065465842323693679","patrickeritchie","2024-03-03T08:39:25.1030000+08:00","If anyone is interested, I just made a repo public for a similar project I was working on a while ago. This is supposed to mimic the MQTT Explorer but to add UNS specific features and to be able to work with Sparkplug easier. Its built on .NET and uses Blazor so it is accessible through a browser. I got pretty good performance out of it but it still would need to be tested in a production environment. It still needs a little work but I would be open to collaborating with anyone that might want to help with development.

https://github.com/TrakHound/Uns-Explorer","","üëçüèª (5)"
"740383178279354388","mriiot","2024-03-03T11:57:07.0220000+08:00","This graph like view might make for a good exploratory experience https://www.shiftr.io/desktop","",""
"756565963520081950","andersgustav","2024-03-03T13:58:53.8600000+08:00","I was fooling around and made this using Lazarus (freepascal) a couple of years ago. At the time there where no real good working components for mqtt available in Pascal, so i had to write from scratch. It was quite educational and a nice way to get to know mqtt. But Pascal is not the language to do this in. The .net approach is way better.","https://cdn.discordapp.com/attachments/1166016853991235594/1213727280564543549/UNS_Map-1.png?ex=68df661d&is=68de149d&hm=65ec576d5164f3f97c8d2655cefec4d8749f812aa46ef0ad85a473f9a3294b8f&,https://cdn.discordapp.com/attachments/1166016853991235594/1213727280900083812/UNS_Tree.png?ex=68df661d&is=68de149d&hm=37ca9a54b959a932283f23cb023db37171e0195eb722b1c5dc27b014800993a5&","üëçüèª (1)"
"339656700745351180","douglawrie","2024-03-04T19:45:20.3760000+08:00","Yeah honestly I am confused why we‚Äôre so focussed on this dead app. Lots of people here are capable and motivated to make something better","",""
"339656700745351180","douglawrie","2024-03-04T19:46:39.3990000+08:00","The above examples include Sparkplug support","",""
"339656700745351180","douglawrie","2024-03-04T19:47:31.6700000+08:00","I‚Äôm writing one in rust at the moment. Will post here when it has a GUI","","üëç (2)"
"867075936054149191","rickbullotta","2024-03-04T21:45:57.1000000+08:00","Because it's kind of awesome?  I love the delta feature and the visual animations indicating where activity is.  It has a LOT of capability.","",""
"382941357699760129","walker.reynolds","2024-03-05T06:52:25.2230000+08:00","I will respond in more detail when I get back to Dallas.  We have a fork of MQTT Explorer where I merged the MQTT spB parser we built in Python with the existing feature set.  Tom Nordquist is working on a couple other projects but I have been in contact with him about the project.  I‚Äôm still weighing what to do here ‚Äî but lean toward formally developing an IIoT Fork of MQTT Explorer and extending the feature set.","","üëç (2)"
"138867775354437632","jonathan08947","2024-03-06T01:53:54.6330000+08:00","Anyone using RabbitMQ for their mqtt broker? They just released support for mqtt 5.     Biggest flaw I see is limited retained message support. But on the other hand, it's open source, comes with a web dashboard, and you get access to amqp.","",""
"873009180938743828","sim_sam3","2024-03-06T06:22:21.6420000+08:00","I‚Äôve only experimented with it myself but it had great AMQP to MQTT conversion. IPC-CFX standard body for semiconductor comms actually recommends Rabbit (CFX is broker based).","",""
"873009180938743828","sim_sam3","2024-03-06T06:28:29.6890000+08:00","I came across MQTT TUI, it‚Äôs so cute. Lovely text based mqtt client for terminals: https://github.com/EdJoPaTo/mqttui","",""
"867075936054149191","rickbullotta","2024-03-06T07:05:52.8050000+08:00","Mqtt.fx is adding these features from what I'm hearing (viewing payload changes, decoding sparkplug, etc)","",""
"382941357699760129","walker.reynolds","2024-03-06T07:18:05.6380000+08:00","I benchmarked the new release but only recommend using it on the edge because of the limited retain flag support.","",""
"794020366536146977","mparris","2024-03-06T08:14:27.0150000+08:00","And MQTT.fx requires payment, correct?","",""
"801561312861618236","jon.forbord","2024-03-06T15:02:27.4100000+08:00","We use RabbitMQ, but only for the Sparkplug B-namespace which sits on the edge/site. 

How ironic isn‚Äôt it that we can do that in spite of the limited retain flag support in RabbitMQ!? üòÇ","",""
"740383178279354388","mriiot","2024-03-06T20:24:47.8180000+08:00","Optional","",""
"1073312001788477471","sparkylarks","2024-03-06T20:34:16.6290000+08:00","There is a 2 month Trial, 
a very reasonable private use lifetime licence.

and to be honest the commercial licences, are reasonable too, if you use it.","",""
"794020366536146977","mparris","2024-03-06T20:36:48.9190000+08:00","I'm wondering what are the top differences from MQTT Explorer that motivate purchasing a commercial-use license","",""
"1073312001788477471","sparkylarks","2024-03-06T20:43:25.0550000+08:00","1 ) I want to be able to read the sparkplug payload
2) I think there is a duty to pay where people give me value. I used to go to a running shop in Cork City, John Buckley Sports, Shoes were slightly more expensive but with the 10% loyalty discount( and you got a card the first day you bought anything) only a little bit. But when I had feet problems they had the knowledge to get me the right shoe. I could have gone downtown and got a shoe for 5 or 10 euro cheaper, but the person selling them to me probably knew less that me, and couldn;t help me. I wanted to make sure that JB sports was still in business when I had me next problem.","",""
"1073312001788477471","sparkylarks","2024-03-06T20:50:57.6900000+08:00","And I tried everything Else I could find, I think MQTTX will allow me do it but I need to do a bit of scripting.","",""
"382941357699760129","walker.reynolds","2024-03-06T23:45:38.2420000+08:00","For me ‚Äî it‚Äôs once I‚Äôm monetizing the solution I used their tool to build.  Once I‚Äôm creating value ‚Äî directly or indirectly ‚Äî I want commercial.  And I agree with Mark 100% on duty to pay. üôè","","üëç (1)"
"794020366536146977","mparris","2024-03-06T23:49:42.5100000+08:00","Another good case-study on the upcoming open-source podcast?

Given:
1) a person is generating value, either for itself as an end user or for others as a System Integrator, 
2) there is an open-source tool available and a commercially-licensed tool available
3) the capabilities of the two tools are equivalent (for arguments sake)

What are the considerations for preferring one over the other?","",""
"382941357699760129","walker.reynolds","2024-03-06T23:51:13.9130000+08:00","Perfect","",""
"382941357699760129","walker.reynolds","2024-03-06T23:51:53.4770000+08:00","@Joshua Stover @Vaughn Turner please add to pre-production notes for the upcoming FOSS podcast or stand alone video","","üëç (1)"
"1063829764164563026","mariano.beracochea","2024-03-06T23:57:11.2030000+08:00","Why would you go with a JSON with all the topics inside a node and not publish each to individualy?","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-07T02:11:43.4410000+08:00","That's basically what Sparkplug does, which makes it VERY difficult to work with for enterprise use cases.  But the underlying issue is actually the fact that MQTT does not currently allow for publishing multiple topics in a single message.  I've proposed to the MQTT committee quite a few months ago that this capability be added, but they did not respond.  It would greatly reduce latency and optimize network usage/resource usage, but without the downsides of Sparkplug and/or putting multiple values in a single JSON packet.","",""
"568913935147728896","zeratall","2024-03-07T02:27:45.2000000+08:00","I also would add, it really depends on how the data is going to be consumed, in some use cases it might make sense to have a few data points ""packaged"" for a specific consumer compared to having them subscribe to a bunch of topics. That being said, it should be a balance, I often think a lot of people just throw everything into one topic because its easy but it really bloats the message and puts significant parsing on the consumer. Aka there is always some sort of balance involved that requires some analysis on how you should structure everything imho.","","üíØ (2)"
"766684226455207996","bright_hummingbird_31342","2024-03-07T02:54:36.1740000+08:00","UNS is not about ""dumping"" telemetry data from PLCs or SCADAs into one place.  It's about making data from many nodes, beyond just PLC or SCADA, accessible and structuring data to the needs of the consumers.  Sometimes it will be a data set and sometimes it will be data points.  It depends on the use case and needs of the consumer.  If the topic namespace consists of just a catalog of tags, it's not really a UNS.  It's a namespace of PLC tags.","","üíØ (2)"
"1073312001788477471","sparkylarks","2024-03-07T02:59:14.0020000+08:00","I have a few use cases( one is where I like to package stuff like the Unit of measure with a live reading.

the key is that all the data in the payload needs to be tightly coupled into a thing, as in a Temperature reading, a Schedule, a Weather Forecast.

The other is one where I am reading in in 40 sets of weather forecast data, each set is about 30 parameters for each hour. for eight turbines

I started with each weather parameter Turbine/Hour/weather and it got hard to track. and the 48 hours result in a moving window where I log each parameter 48 times and then it sits in the broker for ever, and I didn't; want to think about sending blank messages to delete, so I tried having topics for Now, Now+1, Now+ 2 ...and it was just messy.

but I have python script  calculating the power based on the wind, so it is a easy to iterate through the timestamps as through topics.","https://cdn.discordapp.com/attachments/1166016853991235594/1215010822330253363/image.png?ex=68df7441&is=68de22c1&hm=c8d418ddffc3928912d185eb8aa5c5ab51f9d943f976117aaadc1b723d657421&,https://cdn.discordapp.com/attachments/1166016853991235594/1215010822674321428/Baking_Schedule.jpg?ex=68df7441&is=68de22c1&hm=fd3f1572cd7dd09e06a6ee140c5e3111189cc95d1b3f3d1e61e6fa9cca179aef&",""
"1073312001788477471","sparkylarks","2024-03-07T03:09:01.5720000+08:00","I agree, but I think it is a valid step, to dump your tag from the PLC into a Raw namespace and then process them, normalise them, contextualise them and publish back into an accessible space.

Especially as more devices become MQTT and SpB compatible.","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2024-03-07T03:13:23.1120000+08:00","This is a massive problem with Sparkplug.  It basically encourages users to do this.  It's like stuffing a bunch of documents, unrelated or out-of-order,  into a file because you were lazy and you were hoping someone else will sort out the mess later.  It locks data into a format that makes data less accessible.  The consumer must now a pay a ""tax"" in terms of effort, performance, or compute resources every time they want to use data.","","this (1),üëç (1)"
"766684226455207996","bright_hummingbird_31342","2024-03-07T03:20:25.2520000+08:00","Agreed.  This is more of a data acquisition problem.  Some MQTT devices have little control over the shape of their data or its not easy/practical to change them.  Converting raw publishes to something usable definitely comes up.

In terms of data acquisition, this is where I think OPC UA with subscriptions, if an option, is a a good approach.  It appears to be more efficient than a bloated SpB metric payload or many individual topic publishes.","",""
"382941357699760129","walker.reynolds","2024-03-07T03:23:21.2400000+08:00","It depends on the consumer ‚Äî often times, we do both.  Did you see the UNS Genealogy video on YT?","",""
"382941357699760129","walker.reynolds","2024-03-07T03:24:07.7670000+08:00","Exactly","",""
"382941357699760129","walker.reynolds","2024-03-07T03:24:56.8990000+08:00","I think they heard your message‚Äî I really think an industrial standard is going to happen.","","üëèüèº (2)"
"794020366536146977","mparris","2024-03-07T05:24:10.3840000+08:00","https://tenor.com/view/you-shall-not-pass-gandalf-wizard-gif-13584855","",""
"794020366536146977","mparris","2024-03-07T05:24:13.8230000+08:00","Are you saying, that more people should channel their inner-Gandalf before letting information enter their UNS?","https://cdn.discordapp.com/attachments/1166016853991235594/1215047312313815050/image.png?ex=68deed7d&is=68dd9bfd&hm=30c826faa16c6af36ac268d339a89f4eeda11aad95c38f78bf8fe3d15a7bce47&",""
"766684226455207996","bright_hummingbird_31342","2024-03-07T05:44:48.9410000+08:00","I wouldn't quite orient as it as gatekeeping, but more thoughtful governance.  There can be freedom for experimental publishing.  But, at the end of the day, I think nailing the consumption side of things is really important.  For every additional barrier that is imposed to consume data, the harder it is to empower people to use it and do valuable things with it.  If users must spend time parsing through or stitching together data, there will be scenarios where it's not worth the effort and they choose to not consume data at all.","","ü§òüèª (1),üëç (1)"
"855607029518434314","hiptopjones","2024-03-07T12:44:43.1900000+08:00","""It's like stuffing a bunch of documents, unrelated or out-of-order,  into a file because you were lazy and you were hoping someone else will sort out the mess later.  It locks data into a format that makes data less accessible.  The consumer must now a pay a ""tax"" in terms of effort, performance, or compute resources every time they want to use data. ""  Agree that this seems bad for a UNS, but on the other hand it does sound a lot like a data lake. üôÇ","",""
"766684226455207996","bright_hummingbird_31342","2024-03-07T12:48:20.8250000+08:00","Yeah, definitely.  That's what many data lakes can become.  Indiscriminate publishing over any protocol whether its going a broker, data lake, etc is generally not a recipe for success.","","üëç (1)"
"894527802316046366","nickn5549","2024-03-07T15:34:49.8390000+08:00","I often use JSON in topics - everything that is a transaction from a DB, a BOM is sent as a JSON to MQTT. Telemetry you can have individual topics for each value.","",""
"698244484302897323","lmtx","2024-03-07T18:33:40.3550000+08:00","Factors to consider when deciding if include the Physical Location of an Asset in the MQTT Topic Structure

In my latest article, I discuss a particular aspect of designing the MQTT Topic Structure: Should we include an asset's Physical Location in the topic Structure?

What is your opinion?

https://www.thingrex.com/mqtt_location/","","üëç (1)"
"794020366536146977","mparris","2024-03-07T19:09:52.2710000+08:00","As you point out, MQTT only allows subscriptions based on a topic path. So, MQTT puts a lot of pressure on devices across the enterprise to use the right topic path that will help the consumption pattern of all applications.

If a system is restricted to only an MQTT broker(s) as their IIoT data access infrastructure, investing physical location is a descent way to start.

Ultimately, official location is just one of many pieces of metadata that an application would want to use to generate its subscription.

This is where having IIoT Portals will help, which are applications that can consume the data/information of any format and aggregate it into the way that a consuming application wants: Example: subscribe by physical location or subscribe by activeFault>1","",""
"698244484302897323","lmtx","2024-03-07T19:32:28.9890000+08:00","I agree with you, @MParris . The physical location of assets is just an illustration of the overall concept. I would say that the elasticity of MQTT puts lots of pressure on architects, not on the devices, but I get your point üòâ","",""
"568913935147728896","zeratall","2024-03-07T22:31:33.7930000+08:00","That's very similar to what I do, I do include some metadata on telemetry as well in the payload though.","",""
"894527802316046366","nickn5549","2024-03-08T03:26:16.5330000+08:00","For telemetry, I still send metadata as different topics, no JSON.","",""
"568913935147728896","zeratall","2024-03-08T03:26:49.8020000+08:00","Interesting, do you send it as a child to the topic passing the value, or entirely different structure? Metadata is something I've been thinking a lot about lately.","",""
"894527802316046366","nickn5549","2024-03-08T03:37:30.1220000+08:00","Same level with the value, different sub topics","",""
"894527802316046366","nickn5549","2024-03-08T03:37:43.5100000+08:00","I will send screenshots","",""
"894527802316046366","nickn5549","2024-03-08T03:42:19.5090000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1215384055109918720/20240308_064133.jpg?ex=68df7e5b&is=68de2cdb&hm=9c042e3110987338f9079703e9cf3c429b408950d7620862836b93a882337e2b&","üëç (2)"
"568913935147728896","zeratall","2024-03-08T03:45:00.1360000+08:00","aaah kk that makes sense, yeah I thought about doing it that way, or as a child topic to each value topic, but ultimately decided to lump metadata associated with a value into one payload, I see pro's and cons for both design patterns. 

In the future if I needed to free up some bandwidth I probably would switch back to topics for metadata, and use RBE for them, since some topics like description, units, etc don't change that often. That being said I grouped them now, because I want to make sure all data is well defined for our governance strategy, and typically when values are consumed, the associated metadata for that value is also consumed at the same time. Aka if I'm displaying a value on a dashboard i'm often times displaying units on the dashboard, etc so it seemed logical to group them.","",""
"867075936054149191","rickbullotta","2024-03-08T04:22:56.0300000+08:00","And of course, use the retain flag for metadata.","","üíØ (2)"
"1073312001788477471","sparkylarks","2024-03-08T04:33:49.2170000+08:00","That comment implies that metadata is special and should get a Retain Flat, but I though you preached/promoted/advised? to Retain Flag for all Data?

I know I asked this elsewhere, but I find myself defaulting to Retain and QOS=1 or 2.

anytime I think of data I might put to QOS=0 I think of a use case where I want it in my history.
When I had a team of Automation Engineers working for me, and they asked ""should I historise Tag X or Y?"" I would  say "" historise everything, or you will keep finding tags you wish you historised.""","",""
"568913935147728896","zeratall","2024-03-08T04:34:30.1380000+08:00","Yep exactly","",""
"894527802316046366","nickn5549","2024-03-08T04:44:34.1880000+08:00","My servers are screaming at me need more space because you historise everything....and IT....nope...you have enough...","","ü§£ (2)"
"568913935147728896","zeratall","2024-03-08T04:48:16.3040000+08:00","PBs?","",""
"568913935147728896","zeratall","2024-03-08T04:48:42.4050000+08:00","I've been looking at storing PB's and definitly not cheap lol","",""
"1073312001788477471","sparkylarks","2024-03-08T04:52:34.6690000+08:00","Storage is cheap. 
how much storage do IT have for random useless files noone know is there, or Emails with CatMemes form the Noughties.
They can spend on for storing critical Business PRocess information.

I did just in another channel mention ordering ExaBytes of storage for the OT on site Data Center. and that sort of got pricy as it was when Cisco had no stock","",""
"568913935147728896","zeratall","2024-03-08T04:52:49.5610000+08:00","Not if your storing in cloud lol","",""
"1073312001788477471","sparkylarks","2024-03-08T04:56:46.6480000+08:00","Ahm, then don't?üòú  :j ( why is there no tongue firmly in cheek emoji)

I am more than happy to say all Process Historical data is stored ,locally and accessible from anywhere.
I will take that for the team ""to keep the cost down""","",""
"568913935147728896","zeratall","2024-03-08T04:57:51.9800000+08:00","Yeah far, just saying a general statement, ""Storage is Cheap"" is not always true, especially if a site doesn't have an EDC and has to leverage cloud, and trust me I really try to push everyone to host as much locally or as near locally they can get (FOG), and only push to the cloud what makes sense to store in the cloud, but the amount of infrastructure and facilitiy updates required to spin up an EDC can be a signficant cost if a site has to start from ground 0.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-08T04:58:40.5140000+08:00","Oh I do - but it's an absolute must for metadata!","","üëç (1)"
"894527802316046366","nickn5549","2024-03-08T05:54:06.6710000+08:00","I know, they just wanna be the gate keepers","",""
"894527802316046366","nickn5549","2024-03-08T05:57:17.3710000+08:00","I use MySQL and is not bloated, even when you reach many millions records in the hot tables.","",""
"1073312001788477471","sparkylarks","2024-03-08T16:31:37.3170000+08:00","On my quest for Sparkplug decoding alternative to explorer I found 
https://github.com/vogler75/sparkplugb-printer by the excellent @Andreas Vogler 

and  https://github.com/Ambre-io/sparkplugui , which seams to work well, but is hard to look at.","",""
"801561312861618236","jon.forbord","2024-03-09T03:56:51.5660000+08:00","https://youtu.be/WmQ-4pvMwVw?si=g2w9EJ4QyPPe_jCB

I totally forgot this seminar had happened, but @Marc J√§ckle post on LinkedIn reminded me. I‚Äôm curious to hear some reactions! @RickBullotta","",""
"1129435706285101076","ted.garrison","2024-03-09T04:38:37.0680000+08:00","seemed like a whole lot of ""it's going to be a while before we release a new version"" and ""don't expect much useful change""","",""
"867075936054149191","rickbullotta","2024-03-09T22:20:51.8520000+08:00","Falls short in its current scope.","",""
"801561312861618236","jon.forbord","2024-03-10T03:28:18.3390000+08:00","I‚Äôll give my take then. They want to stay true to the Sparkplug goals, simple and effective, primarily for SCADA type applications. The limitations to topics is largely argued with sparkplug being stateful, ie a node subscribing six topics down in the hierarchy would be unaware if the publishing node looses connection. They‚Äôre introducing a separate META-verb for metadata, as well as sourced births (such that consumers know who the birth was for), ie birth storms build be less invasive. JSON support is discussed and they are in favor of, but not set in stone how. +++ QoS is not discussed, outside of QoS=1 for historical store and forward.","",""
"801561312861618236","jon.forbord","2024-03-10T03:29:08.9510000+08:00","The most interesting parts are when they discuss why they are NOT doing something..","",""
"801561312861618236","jon.forbord","2024-03-10T03:30:53.0280000+08:00","But, I‚Äôm leaning on Marc‚Äôs take, as they are focused on staying true to Sparkplug, I don‚Äôt think it will become the cornerstone of your IT/OT integration.","",""
"867075936054149191","rickbullotta","2024-03-10T03:30:55.5120000+08:00","Meanwhile countless people claim that Sparkplug is the foundation for an enterprise UNS, that it is more secure - all false.  I find it particularly tragic that they move so slowly.  It's a small group of people who don't need a lot of consensus to move forward.  And the stateful argument is complete BS - trivially (and more reliably) dealt with using a heartbeat topic.","",""
"867075936054149191","rickbullotta","2024-03-10T03:32:06.2260000+08:00","So let's start calling out the vendors (mostly MQTT broker folks) who keep overhyping and overselling its capabilities (HiveMQ team, I love you all, but you're among the worst offenders).","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-10T03:33:16.7320000+08:00","While I'm ranting, it REALLY REALLY TRIGGERS ME that they spent time, resources, and effort to get a flawed spec approved as an international standard instead of doing useful, valuable work to address its issues FIRST.","",""
"801561312861618236","jon.forbord","2024-03-10T03:33:40.5910000+08:00","This baffles me.. Sparkplug is useful, could be more useful, but it is not integral to any UNS..","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-10T03:34:27.8410000+08:00","Lastly, I do not buy any excuses regarding JSON support.  It's beyond trivial.  It's a simple header + a different serialization.  Could be implemented quickly and easily, and would open up Sparkplug to a much broader base of microcontrollers, applications and other devices.","",""
"867075936054149191","rickbullotta","2024-03-10T03:39:29.4340000+08:00","That's how it should be!  But we've all seen too many presentations and white papers suggesting otherwise.","",""
"794020366536146977","mparris","2024-03-10T03:44:51.1400000+08:00","I'm working on more UNS diagrams with deployment examples to help facilitate productive conversations.

As of now, SpB will work connecting to a UNS portal, but stops there.  It MUST be converted to something else to flow through the UNS.","","üíØ (5)"
"867075936054149191","rickbullotta","2024-03-10T03:46:03.4260000+08:00","And SpC won't do much better given the proposed scope.","",""
"867075936054149191","rickbullotta","2024-03-10T03:46:42.5940000+08:00","At a bare minimum, JSON support and automatic metric -> topic expansion by an Sp-aware broker are needed.","",""
"794020366536146977","mparris","2024-03-10T03:47:05.7290000+08:00","I'm wanting these diagrams to be a challenge to the industry on WHAT should be standardized. (hint: start with the end in mind, and work backwards)

For too long, it's been standardizing on all kinds of building materials when it's not even know WHAT is being built.","",""
"801561312861618236","jon.forbord","2024-03-10T03:48:54.5120000+08:00","The topic limitations do seem to be argued on the false assumption that it is because of UNS, being able to ‚Äúblend‚Äù namespaces together.. so they suggest this can be fixed in the application layer.. (Which I honestly hadn‚Äôt thought of..).. so perhaps they could be convinced otherwise if we could clear up the misconception.","",""
"801561312861618236","jon.forbord","2024-03-10T03:50:22.0030000+08:00","What worries me more is this trueness to stateful and the focus on SCADA-use. Which will lead to desicions not necessarily in favor of IT/OT integration.","",""
"794020366536146977","mparris","2024-03-10T03:52:00.6990000+08:00","The idea of a UNS portal supporting SparkplugB would serve up an MQTT server and allow the nodes to publish to it.

The UNS operator/architect would be able to set the data firewall rules (what should be allowed into the UNS and what to drop).  Data shaping / conversion would happen at this stage, too.  With the data that is allowed per the data firewall, that information is now avaialble to all consumers if they want it.  The UNS facilitates moving the data from the producer to the consumer.  If the UNS design wanted to, if it knows a consumer wantts 5 tags from a single source, it could bundle them together and ship them across the wire in binary format to be unpacked into HTTP/JSON on the other side, if that's how the consumer needs it.

It's unclear to me what the the proper UNS-internal commProtocol/encoding/information definition is, but ultimately, all that would be hidden to the users of the UNS.

The job of the UNS is to abstract away its own data/information definition as well as those of the data producers and always present the data in the way the consumer needs it.  Of course, a reasonable UNS design would only support a handful of protocol/encoding/information formats.","",""
"817835202746253344","IIoT#4707","2024-03-10T03:52:00.9670000+08:00","GG @MParris, you just advanced to level 26!","",""
"867075936054149191","rickbullotta","2024-03-10T03:54:38.1990000+08:00","Why require another component (and cost, complexity, configuration) when a Sp-aware broker can trivially do this automatically?  Make no sense to do it the hard way if we can do it the easy way.","",""
"801561312861618236","jon.forbord","2024-03-10T04:00:59.2050000+08:00","Ok, that would also reduce the load due to number of messages as well. Hmmm.. perhaps that could actually be win win..","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-10T04:03:29.8130000+08:00","If we were able to get only two additional features in SpC/Sparkplug 4.0 - those would be the two for me (JSON support and topic expansion), in addition to the ones already in scope.  Personally I'd like to see the REST API for reading most recent value(s) and for publishing, but hey, one thing at a time I guess, and the broker vendors can do that generically for MQTT outside of the Sparkplug scope.","",""
"867075936054149191","rickbullotta","2024-03-10T04:04:36.3540000+08:00","Another triggering thing for me is vendors who get hung up on ""standards compliance"" as a way to *NOT* add functionality.  That's beyond absurd.  Standards can dictate what must be included, but in no way should be used to keep useful functionality out.  Put customers first!","","üíØ (1)"
"794020366536146977","mparris","2024-03-10T04:10:24.9330000+08:00","What has been most irritating is having industrial data/information standards being developed without a clear Concept of Operations situated within an Enterprise setting being defined upfront.

No wonder nothing is working!","",""
"766684226455207996","bright_hummingbird_31342","2024-03-10T13:40:29.1650000+08:00","This type of material, from multiple vendors, has created a lot of confusion.  While one should know better to understand and vet technology, there are a lot of end users blindly architecting solutions based off these marketing materials.  They eventually run into trouble. At some point, it's unethical to lead users down that path.  Manufacturing, as a culture, is conservative about experimenting with, adopting, and procuring technology.  There are few shots to get things right.

When I see diagrams with nodes like ""Sparkplug enabled ERP"" or ""Sparkplug enabled MES"" or ""Sparkplug enabled cloud"", it kills me.  It's basically like saying ""IIoT Unicorn"".  Let's be honest, Ignition and complementary L2 solutions (eg., Canary Labs Historian) are the only apps that can really consume this stuff.  Everything else is middleware or applications with connectors masquerading as middleware.

Presumably because of the prominence of Ignition, I've seen some SIs build custom applications around specifically ingesting the MQTT Transmission format.  They eventually abandon it because it doesn't use features of the protocol as intended and it puts data in a very unusable form.  They might initially abandon protobuf encoding and try to make it work, but they still have these goofy topics and metric payloads.  It takes them a while to realize that they're not consuming to an ""edge-of-network node"" (e.g., gateway for a small remote asset in the oil & gas industry), but an entire manufacturing plant or enterprise.  But, they start off with confidence because it's apparently what everyone is doing to build a UNS.  

Unfortunately, there is more discourse endorsing this approach to promote solutions than there is about how end users are struggling to adopt it.","",""
"766684226455207996","bright_hummingbird_31342","2024-03-10T14:04:44.2340000+08:00","It's not just a small group, but a very small number of market participants.  Cirrus Link could make arbitrary changes to their Ignition modules and the market would adopt those changes.

While it sounds odd historically, we are basically in an era of ""no one ever got fired buying [Ignition]"" now.  It doesn't matter what a spec says or doesn't say.  All that is really required to move the needle is for Ignition to have it.  Why would the sparkplug working group(s) need to move slow if the impact of their changes are relatively straightforward?","",""
"801561312861618236","jon.forbord","2024-03-10T21:31:57.3090000+08:00","Both Canary and the Cirrus link modules support SpB over json, instead of protobuf. 

I still stand that a protocol converter for SpB is fairly trivial, making the cost benefit still in favor for some use-cases. It‚Äôs not like theres a ton of CMMS/ERP/WMS that support flat mqtt either. 

That‚Äôs a good analysis. Cirrus Link, Ignition, Hivemq and Canary make up the working group in practice as well, so it‚Äôs not like it would be moving a mountain either. I don‚Äôt think they are as immovable as some here suggests, but there may or may not be a disconnect between the expectations to SpC and what the mission:vision of Sparkplug is.","",""
"801561312861618236","jon.forbord","2024-03-10T21:56:32.4510000+08:00","All specs are flawed in that sense. You are right that some vendors gloss over the limitations, but on the other end you‚Äôre also exaggerating to make points. Sparkplug is useful, it isn‚Äôt flawed beyond redemption. Limited, but can be worth the drawbacks for some use cases. Far from ideal, but what is?! 

They‚Äôre selling snake oil and you‚Äôre spreading FUD. (I‚Äôm exaggerating for effect here). Neither form of communication actually is very helpful for the uninitiated.","",""
"867075936054149191","rickbullotta","2024-03-10T22:01:32.3050000+08:00","""Both Canary and the Cirrus link modules support SpB over json, instead of protobuf. "" - Oh, the irony.  Now I'm even more pissed off.","","üòÇ (1)"
"801561312861618236","jon.forbord","2024-03-10T22:02:28.0600000+08:00","I feel you. The video seemed fairly positive to json though..","",""
"801561312861618236","jon.forbord","2024-03-10T22:04:48.8850000+08:00","I would have a serious talk with anyone who wants to use Sparkplug. They should go in with eyes wide open. And definitely not use it just because they want a UNS.","",""
"867075936054149191","rickbullotta","2024-03-10T23:06:15.5380000+08:00","I do feel like it is all easily fixable and cannot fathom why there is so much resistance to a couple simple and obvious enhancements like JSON support and metric expansion.  I've already shown metric expansion working as an extension to HiveMQ, and JSON support is trival (and apparently already in use).  C'mon CL folks - give the community and customers a win!","",""
"568913935147728896","zeratall","2024-03-10T23:30:13.3460000+08:00","The whole security argument is kind of silly, protobufs only obfuscate the data through the serialization process, definitely much harder to reverse engineer if you don‚Äôt have the class definition used to serialize the protobuf, but not impossible ‚ÄúLook at the Pok√©mon Go push to reverse engineer their api a few years back‚Äù. With SpB it‚Äôs a standard class definition so being able to deserialize it is trivial for any hackers since all the class definitions are standard and public.","",""
"867075936054149191","rickbullotta","2024-03-11T04:52:33.8860000+08:00","It's actually *LESS* secure, because you need to provide access to the entire DATA, BIRTH or CMD messages to subscribers and cannot apply ACLs on a per metric (or per CMD) basis.  That's sloppy and dangerous.","","üíØ (1)"
"1036772716604301364","dsi_101","2024-03-11T20:36:29.5060000+08:00","I know Rick doesn't think Sparkplug should be used at all in it's current state - but let me know if this is a bad architecture for a current POC we are doing.  ""Edge"" sites with full Ignition gateways sending Sparkplug to the Enterprise gateway (Ignition) through an enterprise solace broker. In the Enterprise Gateway using gateway tag change scripts that take the Sparkplug tags that are needed for ERP and publish out as plain MQTT.  I have an area in the default tag provider in the enterprise gateway that will use the transmission module and expression tags tied to the plain mqtt tags coming back from the ERP system and transmit sparkplug for the ""Edge"" gateways to consume.  My thinking is this would allow store and forward to work to and from the sites instead of the ""edge"" gateways to subscribe to the plain MQTT area in the broker.  Still undetermined if this will scale well.","","üòÇ (1)"
"867075936054149191","rickbullotta","2024-03-11T20:52:50.7110000+08:00","It's ""good enough"" for point to point integrations between apps that were written to work around its limitations.  But why add the extra cost in your architecture of an enterprise gateway?  Just let the edge sites do the metric expansion into individual topics.  And going the other way, Ignition doesn't *require* Sparkplug - it's perfectly happy with other formats like JSON.  I think Sparkplug just gets in the way and adds cost/complexity and maintenance effort.","",""
"1036772716604301364","dsi_101","2024-03-11T21:43:13.6060000+08:00","The enterprise gateway will be used for dashboards.  Currently there is a double vpn hop to sites from their corporate network. So this will be used for employees to view data easier.  So that cost is already needed. I agree it doesn't require sparkplug but if a site goes down I belive the store and forward of sparkplug will be a benefit.  If going straight to the topics with a site down we may miss updates at the site. Correct?","",""
"867075936054149191","rickbullotta","2024-03-11T22:04:26.7390000+08:00","Don't know what capabilities Ignition provides for Sparkplug store-and-forward from edge to enterprise so can't really comment.","",""
"898217314741280828","hobbes1069","2024-03-12T00:27:10.5010000+08:00","Not to detail the current conversation but, when/why would I want to do MQTT over websockets?","",""
"801561312861618236","jon.forbord","2024-03-12T01:57:27.6860000+08:00","What‚Äôs your historian? Ignition? Are there other Sparkplug consumers outside of Ignition? If all you‚Äôre using is Ignition, it may be just as well to use EAM,sync service, gateway network, remote tag providers and publish flat mqtt from the edge.. huge depends on this of course..","","üëç (1)"
"1036772716604301364","dsi_101","2024-03-12T01:59:20.4430000+08:00","Currently each site has a canary historian - In a future phase we will be adding a enterprise canary historian as well.  No other sparkplug consumers.   Thought of GAN, but client wants MQTT as a MTR -","",""
"801561312861618236","jon.forbord","2024-03-12T01:59:28.8350000+08:00","The store and forward had a huge overhaul in the latest couple of cirrus link module releases.","",""
"801561312861618236","jon.forbord","2024-03-12T02:12:58.3630000+08:00","Ok, slightly more tricky then. You may have some benefits using SpB. The back and fort you suggested with the enterprise publishing Spb for edge to consume sounds ‚Äúoff‚Äù. We use SpB from the edge, but we manage the setup through GAN using the EAM. When we need to ‚Äúwrite‚Äù from other systems, we setup memory tags on the edge and just ‚Äúwrite‚Äù to those tags from the enterprise gateway.. it‚Äôs not an awesome way to do it, but it works and we don‚Äôt have to setup the edge gateways to consume mqtt and we can control the write access much easier. i dont know if that made sense?","",""
"817835202746253344","IIoT#4707","2024-03-12T02:13:07.0910000+08:00","GG @Jon Forbord, you just advanced to level 23!","",""
"801561312861618236","jon.forbord","2024-03-12T02:22:40.9360000+08:00","I would definitely need to know more before I would make any sort of recommendation.","",""
"1036772716604301364","dsi_101","2024-03-12T02:44:04.3660000+08:00","So right now the sites are behind a pretty strict IT firewall - took months to get port 8883 opened. So I don't think we would be able to use GAN or EAM as that would require them to go through more cyber security and meetings to open a port(s).  I was just thankful that I was able to connect to the broker within the last few weeks.  So only communications with the sites will be through the Solace Broker, which isn't terrible in my mind.  So if I want to send some SAP information from the flat MQTT area, which IT is handling the BAPI call and mapping to the Broker, then I would just ""Map"" that flat topic in the enterprise gateway using a reference tag in the transmission module default folder then it would just show up at the edge.  So in the attached POC - I am sending SAP the average moisture.  They would be updating the ""SAPWrite"" topic where I would map that through spB to send back to the site. Hope that paints a clearer picture.   I could at the site just subscribe to the non-sparkplug topics but was just not sure how missed updates would work.  At least with the Transmission module I could use the store and forward and scripting on the edge to make sure I don't miss any updates - as each topic would have an associated tag change script at the edge to do something with the data - since it would backfill in order I wouldn't miss any changes with sparkplug.","https://cdn.discordapp.com/attachments/1166016853991235594/1216818946762608650/image.png?ex=68df70b4&is=68de1f34&hm=e4635fe40a7b3407639535eb008fc93d0d1ba412c4f54977d9901fb645a5acb9&",""
"867075936054149191","rickbullotta","2024-03-12T04:13:44.7710000+08:00","So a browser can consume it.  Depending on how your broker is configured and firewall is configured, you can also use port 80 or 443 and generally avoid firewall issues vs 1883 and 8883.","",""
"794020366536146977","mparris","2024-03-12T07:14:46.3490000+08:00","@Richard Shaw yes. HiveMQ has a browser-based broker (you go to the public-facing URL below) 
https://www.hivemq.com/demos/websocket-client/

but then can setup a connection to a broker that is accessible to your browser instance but not hiveMQ cloud-based client.

The connection starts as HTTP(s), but to enable the asynchronous data coming back to the browser, ""upgrades"" the https connection to websockets, so the subscription data can flow back to the browser without another API call.","",""
"944630646821773392","m_r_mccormick","2024-03-13T08:09:24.8130000+08:00","When using telegraf to consume MQTT data and push it to influxdb, does anyone know how to make the ""_measurement"" field be the MQTT topic?","",""
"944630646821773392","m_r_mccormick","2024-03-13T09:20:12.4800000+08:00","Nevermind... figured it out.","",""
"801561312861618236","jon.forbord","2024-03-14T15:02:14.3620000+08:00","Store and forward is generally ok ro rely in for historical data, but I would not rely on it for transactions if that‚Äôa what you‚Äôre doing..","",""
"898217314741280828","hobbes1069","2024-03-14T19:54:47.1420000+08:00","I'm not the only person that thinks nevermind should be one word!","",""
"1073312001788477471","sparkylarks","2024-03-14T20:03:04.7360000+08:00","Isn't it?","",""
"1073312001788477471","sparkylarks","2024-03-14T20:04:16.4990000+08:00","Never mind, I googled it.","","ü§£ (1)"
"944630646821773392","m_r_mccormick","2024-03-14T20:41:57.2120000+08:00","I guess this is really just an admission that I listened to the Nirvana album 'Nevermind' too much as a kid. ü§£","","üëç (1),ü§£ (1)"
"817835202746253344","IIoT#4707","2024-03-14T20:41:57.5980000+08:00","GG @M. R. McCormick, you just advanced to level 5!","",""
"867075936054149191","rickbullotta","2024-03-14T20:49:54.3800000+08:00","...but Live and Loud s the best recorded Nirvana, ever.  The video for ""School"" captures grunge in all its energy.   I literally get goosebumps every time I watch this.  Turn it up to 12.

https://www.youtube.com/watch?v=aattgr1wFcU","","üëç (1),ü§üüèª (1)"
"1036772716604301364","dsi_101","2024-03-14T21:24:25.8860000+08:00","That was the thinking - how else should ""transactions"" be handled through a MQTT Broker?   What is the best way to setup the handshake?","",""
"801561312861618236","jon.forbord","2024-03-15T02:35:04.9020000+08:00","There‚Äôs many ways, with idempotency, or without, atomic. I feel this is pretty standard, asynchronous message schema for transactions.. I‚Äôm sure chatgpt would give a good answer.","","üëç (1)"
"801561312861618236","jon.forbord","2024-03-15T02:35:12.9830000+08:00","!","",""
"867075936054149191","rickbullotta","2024-03-15T07:28:46.3240000+08:00","Just keep in mind that ""transactions"" with a single broker are somewhat manageable - but doing them over MQTT with a distributed/HA broker?  A whole lot more difficult.  As in orders of magnitude more difficult.","","üëç (1)"
"898217314741280828","hobbes1069","2024-03-15T19:52:58.4770000+08:00","Yeah, I would limit it to an edge broker, or up to a area level broker at MOST.","","üëç (1)"
"801561312861618236","jon.forbord","2024-03-16T15:41:32.3820000+08:00","Why would you limit it to the Edge or area?","",""
"898217314741280828","hobbes1069","2024-03-16T19:19:53.7250000+08:00","At the time I was thinking of manufacturing type ""transactions"" But sure, if you wanted to do business logic transactions I guess you could do that at the Enterprise broker level, but I'm not even close to needing to worry about that yet üôÇ","",""
"435342889875275776","george9330","2024-03-16T20:15:13.2620000+08:00","Does anybody here know what is wrong with my Sparkplug b DBIRTH message in Node red. NBIRTH and NDATA is working in Ignition SCADA but DBIRTH does not.","https://cdn.discordapp.com/attachments/1166016853991235594/1218533028305961000/sparkplugB.json?ex=68df1591&is=68ddc411&hm=ca196dd0269dab92e7b643cb41d533a95c215e37b0dc4a893e6b7cfb0156f900&",""
"867075936054149191","rickbullotta","2024-03-16T20:17:08.8120000+08:00","Well, for one thing you aren't allowed to have the ""retain"" flag set for any Sparkplug messages AFAIK, and you can't use higher QoS levels.","",""
"435342889875275776","george9330","2024-03-16T20:18:04.4750000+08:00","I use QoS 0","",""
"817835202746253344","IIoT#4707","2024-03-16T20:18:04.7930000+08:00","GG @George, you just advanced to level 4!","",""
"435342889875275776","george9330","2024-03-16T20:23:30.3130000+08:00","I did use QoS 0 and retain flag false","https://cdn.discordapp.com/attachments/1166016853991235594/1218535112937967736/image.png?ex=68df1782&is=68ddc602&hm=d153fed660173b9c8ec4b537f457a82b9c3ebce2565cc79d9f09ef201e218995&,https://cdn.discordapp.com/attachments/1166016853991235594/1218535113193947186/image.png?ex=68df1782&is=68ddc602&hm=98f775b17fe6df8a11754843774cdf6ca0fcbda4f2745021c5a5ac17485fcdcc&",""
"867075936054149191","rickbullotta","2024-03-16T20:26:19.6030000+08:00","I see a bunch of QoS = 1 and retain = true in the JSON","",""
"867075936054149191","rickbullotta","2024-03-16T20:26:40.1570000+08:00","""id"": ""8fb852e539eb3139"",
        ""type"": ""mqtt sparkplug out"",
        ""z"": ""bc9b6e2a141f0c8b"",
        ""name"": """",
        ""topic"": ""spBv1.0/ABC-Corp/NBIRTH/Pis"",
        ""qos"": ""1"",
        ""retain"": ""true"",
        ""broker"": ""0d831bd9ba588536"",
        ""x"": 710,
        ""y"": 1780,
        ""wires"": []","",""
"435342889875275776","george9330","2024-03-16T20:44:52.4180000+08:00","How do I get qos 1 and retain true if I set qos :0 and retain ; falls. Can you help me understand how this is possible. ?","",""
"435342889875275776","george9330","2024-03-16T20:51:38.0510000+08:00","Is something wrong with  ""mqtt sparkplug out"", node itself ?","",""
"435342889875275776","george9330","2024-03-16T21:01:00.3670000+08:00","@RickBullotta This is only place that I can see qos and it is 0. Maybe MQTT explorer does not show right qos?","https://cdn.discordapp.com/attachments/1166016853991235594/1218544550545723422/image.png?ex=68df204c&is=68ddcecc&hm=ed547ae672b5be06b95d00fef7069cdbecae067e8341a8d133403bb255c4a67c&",""
"1073312001788477471","sparkylarks","2024-03-16T21:17:17.7440000+08:00","When I import the JSON of the NOde-Rede Flow, a few of the DOS combo Boxes are set to 1. 
But the DDeath is showing as QOS=0

is the Device Configuration node overriding","https://cdn.discordapp.com/attachments/1166016853991235594/1218548650003664916/image.png?ex=68df241d&is=68ddd29d&hm=4a6470ee4d05c52878cd2da6f77a0f905d738e0f816bf75b7b29bd7405d0b65c&",""
"1073312001788477471","sparkylarks","2024-03-16T21:17:36.5510000+08:00","Maybe try setting that to 0.","",""
"801561312861618236","jon.forbord","2024-03-16T21:31:10.9590000+08:00","Still, why only manufacturing transactions at the Edge? Are manufacturing transactions different than business transactions?","",""
"1073312001788477471","sparkylarks","2024-03-16T21:31:22.8580000+08:00","If you are setting the QOS of spBv1.0/Sparkplug‚Ñ¢ B Devices/+/Raspberry Pi  to 1 then woudl that set the messages send to spBv1.0/Sparkplug‚Ñ¢ B Devices/DBIRTH/Raspberry Pi/Pibrella  overrideing the QOS= 0 on the node itself?","",""
"801561312861618236","jon.forbord","2024-03-16T21:33:03.4570000+08:00","But would QoS <> 0 cause a failure of the SpB payloads? I dont think so. QoS level is really not a concern for the functioning SpB, the consumer can anyway set QoS = 0 on the subscription cant they?!","",""
"435342889875275776","george9330","2024-03-16T21:36:48.3790000+08:00","I set QoS = 0 on the node. I even tried manually changing the code ( set qos =1 and retain = false in visual studio), but it still does not work","",""
"435342889875275776","george9330","2024-03-16T21:51:30.7630000+08:00","@Mark O'Donovan Here you can read what needs to be set for qos. I think that for your in node qos =1 is ok.","https://cdn.discordapp.com/attachments/1166016853991235594/1218557260784074793/sparkplug_spec.pdf?ex=68df2c22&is=68dddaa2&hm=a984bd67bdf9c006f1ef6a9d0d0c91f535c6ba5d35d53e65dcc7d65b34444147&",""
"1073312001788477471","sparkylarks","2024-03-16T21:55:52.4180000+08:00","I'm thinking, If the retain is true. The broker doesn't know the device is disconnected so the DBirth is seen as a Rebirth ?

But lots of guessing in that.

Bust basically my understanding is for Sparkplug if QOS needs to be 0. So fix that and at least remove it as a question","",""
"435342889875275776","george9330","2024-03-16T21:57:42.3360000+08:00","In specification is written what needs to be set.","",""
"801561312861618236","jon.forbord","2024-03-16T21:58:20.4930000+08:00","Using retain for Dbirth should mostly cause inkonsistent current state at the consumer, but I‚Äôm open to being wrong on that..","",""
"801561312861618236","jon.forbord","2024-03-16T22:02:23.9830000+08:00","The reason births and data payloads are to set as retain = false, is because data payloads are the changed metrics only and births contain the current state of all metrics, so the consumer can get a correct initial state of the node metrics and from which they can keep the current state from the changed metrics of all data payloads.. any retain on any of those would just cause an incorrect current state representation at the hosts.","",""
"435342889875275776","george9330","2024-03-16T22:04:00.4240000+08:00","Birth dataMUST be qos = 0 retain = false","",""
"435342889875275776","george9330","2024-03-16T22:05:12.2920000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1218560706669187192/image.png?ex=68df2f58&is=68ddddd8&hm=784c9a5427270d0163a7150b8a132577a1c07d6b6149bbadc096ee259d1a023c&",""
"801561312861618236","jon.forbord","2024-03-16T22:07:01.9140000+08:00","Correct, but its not likely to break the functionality. thats about being a compliant node. One reason they introduced this was because ¬´some¬ª SpB consumers had problems dealing with duplicate DDATA, which can cause sequence mismstches and rebirths en masse.. what I‚Äôm trying to say, QoS is not likely the reason your SpB dbirths are not working in Ignition.","",""
"801561312861618236","jon.forbord","2024-03-16T22:07:50.6320000+08:00","I‚Äôm open to being wrong here, just working of my ¬´gut¬ª feeling..","",""
"435342889875275776","george9330","2024-03-16T22:08:39.9640000+08:00","I have a problem that DBIRTH with node red is not working. NBIRTH and NDATA is working.","",""
"1073312001788477471","sparkylarks","2024-03-16T22:09:35.0270000+08:00","When I publish a DBIRTH to Mosquitto using your flows I am seeing a Dbirth message","https://cdn.discordapp.com/attachments/1166016853991235594/1218561808474837105/image.png?ex=68df305e&is=68dddede&hm=de7253a725b8862dccd65c91702ee1f778c1c1948735e4096966fd51b07d4b77&",""
"435342889875275776","george9330","2024-03-16T22:13:05.6880000+08:00","Yes but then you get NCMD control/rebirth. I would expect that if seq number would not be right.","",""
"435342889875275776","george9330","2024-03-16T22:13:11.5550000+08:00","@Mark O'Donovan","",""
"435342889875275776","george9330","2024-03-16T22:14:11.4300000+08:00","Normally you get rebirth command if seq number is wrong. I fixed that and still does not working.","",""
"435342889875275776","george9330","2024-03-16T22:14:53.0990000+08:00","If you have seq 0 next message must be seq 1 else you get NBIRTH again.","",""
"1073312001788477471","sparkylarks","2024-03-16T22:17:39.6600000+08:00","I'm not sure I am using the code you supplied.

Is it not incrementing Seq correctly?","",""
"435342889875275776","george9330","2024-03-16T22:21:00.5950000+08:00","In this one seq for DBIRTH is working ok in node red. What is wrong with DBIRTH I still do not know. @Mark O'Donovan","https://cdn.discordapp.com/attachments/1166016853991235594/1218564683963957348/flows_2.json?ex=68df330c&is=68dde18c&hm=7df7ab47bd3388b934fc817acbdda785cae0d593f08613e79eb932312d23ccb0&",""
"435342889875275776","george9330","2024-03-16T22:22:19.5660000+08:00","For Sparkplug in node, QoS = 1 is okay. I just don‚Äôt know where in the specification I read that.","",""
"1073312001788477471","sparkylarks","2024-03-16T22:48:34.4320000+08:00","Sorry I'm confused again, 
Are you expecting a Dbirth or a Rebirth?","",""
"435342889875275776","george9330","2024-03-17T01:25:52.9870000+08:00","I would like to get working DBIRTH. When DBIRTH will work I can use DDATA.","",""
"435342889875275776","george9330","2024-03-18T03:28:21.6340000+08:00","I would like to modifying a Node from GitHub and then install this node on Node Red. Does someone here know how to do that?","",""
"435342889875275776","george9330","2024-03-18T03:31:12.9850000+08:00","I would like to replace ""isHistorical"" with ""is_historical"" in  ""node-red-contrib-mqtt-sparkplug-plus (node)""","",""
"867075936054149191","rickbullotta","2024-03-18T21:07:39.6540000+08:00","The Node-RED slack channels are the best place for this.","",""
"435342889875275776","george9330","2024-03-19T00:32:31.4720000+08:00","Would you know what is wrong with my DBIRTH node? I really do not have  ideas how to fix it.","",""
"867075936054149191","rickbullotta","2024-03-19T00:46:57.2370000+08:00","I do not like Sparkplug and would never recommend using it in its current implementation, so I really can't help much here.","",""
"666121790610735110",".dmays","2024-03-21T21:30:00.0810000+08:00","When using MQTT as the single interface for company state - would the MQTT messages themselves be considered the true state, or are separate databasees the real state and MQTT just informs you something finished saving to a ""real"" database?  What is your state ""bible"" I guess I'm asking?

Does the broker typically replace some databases? In our use case we are still using several databases and I'm trying to sort out if it is just out of tradition and we are unnecessarily duplicating systems and we should just trust what normally would be written to a DB in the old ways to go straight to MQTT and then be archived by a data historian.","",""
"867075936054149191","rickbullotta","2024-03-21T21:33:30.2910000+08:00","You would never do that (use MQTT as the ""state"" for your ERP system or inventory management system, for example).  At best what you have in MQTT is a low latency replica, in reality, it's usually a small subset.  And MQTT is utterly AWFUL (as in 0.001 out of 10) for query capability.","","üëç (1)"
"666121790610735110",".dmays","2024-03-21T21:34:16.6230000+08:00","Thanks!  I'm better recognizing that an interface to your company state doesn't mean it IS the company state, but the window from which you can see what is going on.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-03-21T21:35:19.3130000+08:00","It's fine for things like equipment state, less so for process state, and quite suboptimal for apps you'd typically use a database or other queryable store for.","",""
"1129435706285101076","ted.garrison","2024-03-23T00:35:39.9880000+08:00","I'd say MQTT is more like a SQL view.  It's not the ACTUAL data (that lives on the publisher/sql table)).  But MQTT Broker/SQL View can pull multiple ACTUALs into one place to present to the user.","",""
"1129435706285101076","ted.garrison","2024-03-23T00:36:53.1190000+08:00","But unlike a sql view which you have to define, the mqtt publishers get to define what's available in the view.","",""
"867075936054149191","rickbullotta","2024-03-23T21:16:50.2320000+08:00","While it's semantics, I have to disagree.  With a SQL view you're still accessing the original copy of the data.  With MQTT it's a copy, often of unknown origin, time, and accuracy.","",""
"1073312001788477471","sparkylarks","2024-03-23T21:48:10.0750000+08:00","Am I missing a distinction, Is the data in SQL not a copy of the data, i.e. if I have 4-20ma TT, lots of copies of the data, raw PLC input, scaled value. Modbus register .....?","",""
"867075936054149191","rickbullotta","2024-03-23T22:07:57.5590000+08:00","Maybe I'm missing your analogy.  A database ""view"" queries the source data.  In any case, you can't query MQTT anyway, even if you wanted to! üòâ","",""
"794020366536146977","mparris","2024-03-24T16:04:51.6220000+08:00","I think Ted is saying that just like a SQL View abstracts away the need for a client to know the underlying tables holding the source data, MQTT also abstracts away the original source of the data (decoupling publisher and subscriber)

@dave mays To Rick's point, consider the purpose of your database. If the purpose is to store historical information (data older than NOW), then MQTT won't replace your database. Best case could be some high level aggregation for specific/narrow use cases such as dashboards: Example: a topic containing the last five transactions, etc","",""
"1129435706285101076","ted.garrison","2024-03-25T20:10:09.3110000+08:00","True, but at the same time, if you don't have access to the definition of the view, do you really know what you're getting?","","ü§Ø (1)"
"1129435706285101076","ted.garrison","2024-03-25T20:10:24.9060000+08:00","Correct, - that was my intent.","",""
"1214242167640424619","zack.scriven","2024-03-26T05:00:12.4540000+08:00","wouldn't the origin be the source of the data? presumably...","",""
"1214242167640424619","zack.scriven","2024-03-26T05:01:19.1040000+08:00","The same could be said for a SQL table... you don't know the source/client of whoever put the insert statement","",""
"1214242167640424619","zack.scriven","2024-03-26T05:02:21.7020000+08:00","in this case mparris is acting as an abstraction layer between @Ted Garrison and @RickBullotta  lol","","‚ù§Ô∏è (3)"
"867075936054149191","rickbullotta","2024-03-26T05:14:36.2910000+08:00","Actually, most SQL database have a fairly sophisticated log that will show the user/account that performed DDL/DML operations.","",""
"1214242167640424619","zack.scriven","2024-03-26T06:36:08.9680000+08:00","yes of course... SQLadmin for every client. üòÅ","",""
"1214320791139655760","lifelong_learner001","2024-03-28T06:44:12.0970000+08:00","Hello everyone, I'm trying to setup an MQTT connection between my PLC simulator (TIA V16) and my mosquitto dockerized broker.
I can successfully connect to my broker using the MQTT explorer, however I fail to do so using the PLCsim.

Please advise for any possible solution and thanks in advance.","https://cdn.discordapp.com/attachments/1166016853991235594/1222677582533890058/image.png?ex=68df003b&is=68ddaebb&hm=25d25a039faedd3be5221f2df4f2f98f4635554bf2990ebdcdff8940e8d9e4cc&,https://cdn.discordapp.com/attachments/1166016853991235594/1222677582802059355/image.png?ex=68df003b&is=68ddaebb&hm=73221fae87751bafabeb7b4a0471ca76ac9962cb17a172445123b250072c9667&,https://cdn.discordapp.com/attachments/1166016853991235594/1222677583041396776/image.png?ex=68df003c&is=68ddaebc&hm=e26eebd53b6371a91176998561bbf0bcd733aae02e841520640f03374208cc34&",""
"1050051809789624320","eoinmurphy","2024-03-28T17:49:54.9660000+08:00","I haven't tried to do this via the PLC simulator, only with a real physical PLC. But it might be worth trying to specify the hwid in your connection parameters. In your screenshot it is set to 0 (interface is selected automatically). To find out the correct value to use for you specific project, if you check the ""Device configuration"" in TIA, navigate to the ""Device view"" showing your PLC, select the interface, the hardware identifier is displayed on the ""System constants"" tab. In my case, the hwid is 64.","",""
"1050051809789624320","eoinmurphy","2024-03-28T17:50:24.5270000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1222845239165976626/image.png?ex=68def3a0&is=68dda220&hm=c63a456f99a5c8683b854d0325d08bb7d77ea8c326af77539c903a7ac1f6c340&,https://cdn.discordapp.com/attachments/1166016853991235594/1222845239581085748/image.png?ex=68def3a0&is=68dda220&hm=93a54930ed3dc6daa68c4e9ef71546d4ba14a7a5d1c20ac9fda83f2db02aa64a&",""
"1063829764164563026","mariano.beracochea","2024-03-30T19:32:37.3270000+08:00","Thats because the library for LMQTT_Client that siemnes have available to download from their page doesnt have simulation features, just to download it to the PLC","",""
"1214320791139655760","lifelong_learner001","2024-04-03T03:45:08.9610000+08:00","Hello @Eoin Murphy , thanks for the tip. Yes I was missing the Hwid, however this didn't solve the issue as @Mariano B  mentioned that the LMQTT block by Siemens isn't designed to work with simulation.
After searching a while, I found a block modified to work with PLC sim advanced. 

But I suspect that my issue is still coming from my networking side.
I am running my Mosquitto docker on WSL2, and my PLC simulation is on windows. So probably the simulator doesn't have access to the broker.","",""
"867075936054149191","rickbullotta","2024-04-03T04:36:01.4750000+08:00","Are you trying to connect over TLS?","",""
"1214320791139655760","lifelong_learner001","2024-04-03T04:53:32.8770000+08:00","No the TLS parameter is set to False both in the PLC and in the MQTT explorer","",""
"795725198980677734","diederik9434","2024-04-03T16:19:40.7060000+08:00","Hi, I would recommend not to use LMQTT except if you have good reasoning. This because LMQTT does a lot of string manupulations. This will increase your PLC cycletime exponentially. You wouldn't want your PLC going in stop just because it exceeded the cycletime limit because of a simple MQTT message... üôÇ","",""
"697134502148964423","trentc","2024-04-03T18:53:19.9660000+08:00","What about putting the LMQTT in a lower priority cyclic OB to allow more scan time ?","",""
"795725198980677734","diederik9434","2024-04-03T18:58:23.3170000+08:00","still doesnt matter. if you do this, it will increase the communication load
Communication OB has quite high priority by default (higher than OB1)
you could set the percentage of the communication load lower/higher if you want to have your plc running stably","","üëç (1)"
"1063829764164563026","mariano.beracochea","2024-04-03T20:03:00.9340000+08:00","Maybe you will need to use the program NetToPLCSim, this is used to connect your simulation to your ethernet connections, it is needed to connect ignition with PLCSim.
could you share your simulatable block please","",""
"801561312861618236","jon.forbord","2024-04-04T00:28:52.1190000+08:00","Is still NetToPlcSim still necessary with PLC sim advanced? I used that with step7 plc sim, but thought that shouldn‚Äôt be necessary with PLC sim advanced?","",""
"1063829764164563026","mariano.beracochea","2024-04-04T01:14:15.2970000+08:00","i have being using it to connect with ignition and it worked, dont know if with the advace version is needed, you could try and let me know if your block works","",""
"801561312861618236","jon.forbord","2024-04-04T04:58:54.0000000+08:00","Unless you have PLC sim advanced you need NetToPlcSim, and it may not even work with the mqtt blocks. NetToPlcSim exposes the S7 protocol from PLC sim.","",""
"740383178279354388","mriiot","2024-04-04T08:32:32.8040000+08:00","Has anyone ran into an MQTT-SN requirement?","",""
"867075936054149191","rickbullotta","2024-04-04T19:04:38.3740000+08:00","Literally no one. Except the MQTT committee. üòâ","","üßÄ (1)"
"873009180938743828","sim_sam3","2024-04-05T06:09:25.8660000+08:00","Just reading about it now. MQTT over UDP with some flare, eh? 

Not sure your need but we have an MQTT subscription example for Kepware Universal driver. It already supports both UDP and TCP and theoretically would be small lift to get this into Kepware","",""
"1057737574287945899","xamp4248","2024-04-05T20:42:55.3230000+08:00","Question: How does the DMZ apply in UNS for enterprise connection?","",""
"1214320791139655760","lifelong_learner001","2024-04-06T05:48:11.3680000+08:00","This is actually the block that I'm using https://drive.google.com/drive/folders/11GJDhtfQsb0Ez918AEuhwD4SllhzSKxV with the resource https://www.youtube.com/watch?v=AlNft0AzfxA&t=196s
It has a boolean tag ""plcsimAdvanced"" that should be set to true with the other parameters as the normal block of Siemens.
PLC sim advanced should be enough to perform the connection.

The thing that I don't understand is how the MQTT explorer can access localhost:1883 from windows to WSL dockerized Mosquitto and TIA v16 fails to do so","",""
"817835202746253344","IIoT#4707","2024-04-06T05:48:12.2990000+08:00","GG @lifelong_learner, you just advanced to level 1!","",""
"382941357699760129","walker.reynolds","2024-04-10T01:16:16.5120000+08:00","@everyone","","üëç (8),üáπüá∑ (1),ü©∑ (1),üëè (1),ü™É (1),ilaugh (2),‚ùì (1),üó£Ô∏è (1),üá®üá∫ (1),Flow (1)"
"382941357699760129","walker.reynolds","2024-04-10T01:17:25.1660000+08:00","I'm meeting with @Arlen Nipper at 2pm CDT (1:45 from now) to discuss the podcast we are going to shoot at the end of Mastermind on Friday 4/12.  We are going to discuss the MQTT spec, Sparkplug etc.  If you have any questions you want included in the podcast, please list them here.","",""
"382941357699760129","walker.reynolds","2024-04-10T01:17:52.6910000+08:00","I'll reference your questions in our review in 1 hour and 45 minutes from now.","","‚ù§Ô∏è (5),üëç (3)"
"447710422603137025","im_glib","2024-04-10T01:21:33.0300000+08:00","I'll start with an easy one -  When people say MQTT or sparkplug is RbE, what **precisely** do they mean? What part of the protocol is RbE?

(It seems to me that *applications* of MQTT can be RbE, but it has nothing to do with the protocol itself.
I.e you don't just gain RbE automatically if you adopt MQTT or SpB)

Interested in the response.","",""
"831577393595547648","johnmaldonado","2024-04-10T01:23:06.7100000+08:00","Would you say that SpB is only applicable for process control? Only used in Layers 1 & 2. And are we better off using JSON payloads for level 3 and up, and perhaps using JSON schema or web of things to define the payloads.","",""
"825084676066246677","anibalvelarde","2024-04-10T01:23:13.1920000+08:00","Question Suggestion: 
Are there any ongoing efforts  (especially of the  OSS kind) to create a standard or spec to build plug-in architectures on top of MQTT.  One plug-in could be to enable REST API to interact with the broker, another plug-in could deal with security/RBAC, another plug-in could deal with configs (e.g., UDTs, JSON schema enforcement), etc.","","üëç (1)"
"693309801589112862","_dyland","2024-04-10T01:23:49.9880000+08:00","What was the original intent behind MQTT, what was the initial need it solved and how have they evolved over the years.","","‚ù§Ô∏è (1),ü§î (1)"
"795524195458220082","almukhtar","2024-04-10T01:25:08.5500000+08:00","Is sparkplug 3 will replace SPB , what the application for each one","",""
"230441548653789184","r.pop","2024-04-10T01:26:45.1340000+08:00","Ask him who his first customer was","","ü§£ (1)"
"1073312001788477471","sparkylarks","2024-04-10T01:27:00.4740000+08:00","What do most people not realise about MQTT that they would really benefit from knowing","","üëç (1)"
"697134502148964423","trentc","2024-04-10T01:29:16.0720000+08:00","Question, what is the suggested way of documenting topic structure, payloads and use? With a focus on dynamic documentation as messages flow.","","üëè (2)"
"435342889875275776","george9330","2024-04-10T01:31:37.4610000+08:00","Hello. I have a really important question for you and @Arlen Nipper  .  The Sparkplug specification explicitly states that every metric must include a Sparkplug Datatype from the Sparkplug Protobuf Schema. Specification clearly says that historical flag = is_historical. Why in official example(https://github.com/Cirrus-Link/Sparkplug/blob/56df2ff8fbf0dd11b009152b4606debe31dd9468/client_libraries/javascript/sparkplug-payload/lib/sparkplugbpayload.js#L612) they use historical flag as ""isHistorical"".  And in Transmition module also. That only works because all historical data are packed in single metrics. I did test everything in ignition SCADA and if I sending one message at once only ""is_historical"" is working. he correct historical flag should be derived from the specification, not from an example. I would suggest that they  either change the example or the specifications because there should be no room for a misinterpretation.","https://cdn.discordapp.com/attachments/1166016853991235594/1227309962930421911/318942300-3e35c806-041a-41ff-8d2d-a2bf24a0fe7c.png?ex=68df5fb9&is=68de0e39&hm=4ba86e0256c776783b12f96bc417b97515c904dc9acc8838ebd318c0c012e534&",""
"817835202746253344","IIoT#4707","2024-04-10T01:31:38.0370000+08:00","GG @George, you just advanced to level 5!","",""
"697134502148964423","trentc","2024-04-10T01:34:12.4430000+08:00","Also, what is suggested for command response communications to prevent client message overlap?
How about what are the thoughts about changing payloads? For example I have a JSON message with multiple keys but only one key:value changes, do i publish just the changed key or entire json message? Or should I consider separate topics instead?","","üëç (1)"
"697134502148964423","trentc","2024-04-10T01:35:57.3160000+08:00","What are his thoughts on the shultz vs paris method in uns topic designation?","","üëç (2)"
"1105912856165224468","mikaelbygren","2024-04-10T01:44:43.1280000+08:00","Another item: The data integrity of the protocols.
How its ensures that whats sent (published) is received (updated) in UNS.
How data in transit is encrypted?
How the devices authenticates to the UNS and how unauthenticated devices are prohibited.
Thanks üôÇ","",""
"801561312861618236","jon.forbord","2024-04-10T01:49:29.0380000+08:00","Why QoS = 0? Why not allow choice of QoS? (Why does the Sparkplug WG seem to insist on staying the course on QoS level set to 0?)","",""
"447710422603137025","im_glib","2024-04-10T01:55:06.1110000+08:00","What are your thoughts on the evolution of MQTT to the point where enterprises are using a Broker as a 'host' for a UNS and single source of truth for their entire operation?

If MQTT at the end of the day is a messaging protocol, is it being taken too far to be used in this way - or is this what it was designed for all along?","","‚ù§Ô∏è (3),‚ùî (1)"
"944630646821773392","m_r_mccormick","2024-04-10T01:56:49.7540000+08:00","Whether data integrity is an area of concern/interest. Re: http://dx.doi.org/10.13140/RG.2.2.31738.26565 . @Mikael Bygren touched on this as well.","","‚ù§Ô∏è (2)"
"801561312861618236","jon.forbord","2024-04-10T01:57:06.7130000+08:00","What I‚Äôve always wondered about is this division into nodes and devices. The device level adds zero additional functionality. All the time the publisher of device information is the node (with group+node having to be unique), there is zero additional value to a stateful device-level. Even in Ignition i can not implement a scenario where the connection status of a device is directly Linked to the device-status of the SpB device. I just dont get that part. So why do we insist that all levels below the node has to be stateful, with its own state?","","ü§î (1)"
"801561312861618236","jon.forbord","2024-04-10T01:59:58.8390000+08:00","Additionallu, there is information at the node level that is required to have the device level functional, so I can not for instance in Canary set up a subscription only to certain devices, I‚Äôm still having to subscribe to the entire node Namespace to have the devices working.","",""
"801561312861618236","jon.forbord","2024-04-10T02:00:37.6370000+08:00","So i really really really dont understand the Point of the device-level.","",""
"435342889875275776","george9330","2024-04-10T02:03:51.7720000+08:00","@Walker Reynolds  Official sparkplug-payload on Github  and payload from MQTT Specification B are not the same . What is the reason for that? I would suggest for changing the example or the specifications because there should be no room for a misinterpretation.","https://cdn.discordapp.com/attachments/1166016853991235594/1227318075532251238/Sparkplug_metric_on_Github.png?ex=68df6747&is=68de15c7&hm=dd412dc56c2296a2910ff3c352cfb6308cff0244579893f910d2d378fc8b389d&,https://cdn.discordapp.com/attachments/1166016853991235594/1227318075767001180/317243234-b5e968b9-a9b6-4625-bc96-1a5a58b4ba7b.png?ex=68df6747&is=68de15c7&hm=fb527aa0f9478dc33661148fa36501412cf2e1827d8e204ed1c5828469a0fede&",""
"124693113607290882","aganoth","2024-04-10T02:09:02.9690000+08:00","Here's one: why does the sparkplug b standard still have the protobuf payload represent all Metric values as unsigned values, instead of also allowing the signed counterparts in the oneof?","","ü§î (1)"
"867075936054149191","rickbullotta","2024-04-10T02:13:33.6020000+08:00","I think you know my list pretty well by now.","","üòÇ (2),üíØ (1)"
"382941357699760129","walker.reynolds","2024-04-10T02:15:41.3780000+08:00","üòÇ your list makes up the bulk of our discussion so far.","","üòÇ (1),üëçüèº (1)"
"794020366536146977","mparris","2024-04-10T02:17:24.5380000+08:00","For an OEM that is considering implementing a standard over MQTT...why should they consider Sparkplug v4 instead of OPC UA PubSub MQTT v1.05 (I'm taking Randy at his word that it delivers...I have not tested it myself)","","‚ù§Ô∏è (1)"
"825084676066246677","anibalvelarde","2024-04-10T02:20:43.0300000+08:00","That seems like the topic for an engaging YT video discussion!  Paris v. Schultz: UNS Method  Approach compare & contrast.","","üíØ (1)"
"697134502148964423","trentc","2024-04-10T02:23:10.3210000+08:00","Hivemq has an article talking about the two methods‚Ä¶","","üëç (1)"
"697134502148964423","trentc","2024-04-10T02:24:21.8230000+08:00","https://www.hivemq.com/blog/implementing-unified-namespace-uns-mqtt-sparkplug/","",""
"382941357699760129","walker.reynolds","2024-04-10T02:30:21.2510000+08:00","These are all excellent -- thank you!","",""
"435342889875275776","george9330","2024-04-10T02:31:15.5860000+08:00","Thank you @Walker Reynolds  I would really want to know the answer to my question.","","üëçüèª (2),üëç (1)"
"435342889875275776","george9330","2024-04-10T03:40:06.6080000+08:00","I am using Node-RED for Sparkplug B. When I use NDATA, I am establishing a connection with the broker. Then I use DBIRTH and DDATA for the device. If the device is malfunctioning, I can detect this with Node-Red, and Node-Red sends DDEATH. From that, I know that I am still having a connection with an industrial PC, and the problem is with the PLC (the PLC is in error, or maybe something is wrong with DC power). I can use control/reboot( NDATA is still of good quality) to take power to the PLC and switch it back on. For me, device level is really useful.","",""
"801561312861618236","jon.forbord","2024-04-10T03:44:07.2850000+08:00","Ddeath will only be sent to the consumers once the node disconnects from the broker, right?","",""
"801561312861618236","jon.forbord","2024-04-10T03:46:32.7520000+08:00","You can still publish a device connectivity metric from the node. What I‚Äôm saying is that there is no additional value to the device level that you cant make otherwise, and with Ignition and Canary you cant really make use of the additional granularity of device statefulness or topics in any meaningful way.","",""
"435342889875275776","george9330","2024-04-10T03:48:14.3670000+08:00","I use DDEATH when PLC is in fault. Industrial PC where Node Red is instaled is still working. This is really good if you are maintenence worker that you know If PLC is in fault or GSM connection is not working.","",""
"435342889875275776","george9330","2024-04-10T03:49:33.2900000+08:00","Imagine that you have 150 waste water pumps stations and you do not know if PLC is working or there is just something wrong with GSM connection.","",""
"435342889875275776","george9330","2024-04-10T03:50:41.1540000+08:00","And each pumping station is at least half hour away.","",""
"435342889875275776","george9330","2024-04-10T03:52:05.5680000+08:00","It means a lot if you can just reset PLC from SCADA ( turn of and on DC power for PLC) If you would have just NDATA you can not do that.","",""
"801561312861618236","jon.forbord","2024-04-10T03:53:19.9610000+08:00","You can still do device level connectivity as a metric within a Sparkplug node.","",""
"801561312861618236","jon.forbord","2024-04-10T03:54:59.0340000+08:00","The addition of the device level into separate topics on the broker adds nothing. It is at best an abstraction. and who is to say you dont have further levels below the device, say a sensor to the PLC..","",""
"801561312861618236","jon.forbord","2024-04-10T03:56:51.3530000+08:00","What if the cable disconnects.. should this too have a stateful representation, or do we keep statefulness strictly to publishing nodes in Sparkplug and let the connection status below the node level be optional snd free to setup how we need itz","",""
"382941357699760129","walker.reynolds","2024-04-10T03:57:37.6670000+08:00","Alright -- we went through all of the questions with @Arlen Nipper -- we are going to do our best to get to all of them.  If we don't answer the question in the podcast, I'll provide answers in a separate video.  We have blocked out 90 minutes to cover the complete conversation.  It will be me, @Zack Scriven @aronsemle and @MParris on the panel with Arlen.","","üíØ (3),‚ù§Ô∏è (1)"
"435342889875275776","george9330","2024-04-10T03:58:18.1920000+08:00","I just like to know if the problem is in connection or with PLC. Because I am also maintance worker I really like device level to.","",""
"435342889875275776","george9330","2024-04-10T03:59:49.2490000+08:00","If device is out all tags on ignition SCADA are RED. You can not miss that.","",""
"801561312861618236","jon.forbord","2024-04-10T04:03:02.6970000+08:00","I get it. 

Part of the reason I‚Äôm asking is because the Sparkplug working group seems to think that freeing up the topics so we can have aggregated namespaces can be handled at the application layer instead. And they also seem to think that if we want more layers in the Sparkplug Namespace, like node-device-sensor, all the layers should be stateful. I think this is the wrong approach, and a misunderstanding of the problem.","",""
"801561312861618236","jon.forbord","2024-04-10T04:04:07.4740000+08:00","You can do statefulness below the mqtt publishing layer at the application/mqtt layer, and have the publishing layer whatever that is at, be stateful at the protocol/Sparkplug topic layer.","",""
"1088631859509989426","jpmac.s","2024-04-10T04:14:48.7090000+08:00","Can you please cut and paste them here?","",""
"382941357699760129","walker.reynolds","2024-04-10T04:35:51.6580000+08:00","I have Rick's list but its from a private DM.  If he gives me the thumbs up, I'll post it.","",""
"898217314741280828","hobbes1069","2024-04-10T05:57:41.5390000+08:00","With Rick, the list of things he would want to keep private must be a MUCH shorter list than the other üôÇ","","üòÇ (4),ismile (1),üòÖ (1)"
"447710422603137025","im_glib","2024-04-10T17:24:07.4880000+08:00","Well, ladies and gentlemen of the community at large, here we are again. How many of you ***honestly think*** MQTT is report by exception '*by default*'. To me, this is such a bullshit statement and I'm sorry if this offends you, but I can't think of any reason that Walker keeps asserting this other than ego.
https://www.youtube.com/live/d9QiXp3xgoI?si=Qe6srHVparM3v_mN&t=5856


If I implement MQTT - RBE doesn't come by default. I have to go__ out of my way to make my application RBE__. In 99% of demos (including Walkers) MQTT is report on interval, *(hell, in one of his demos he even states that you will only see an updates when a value changes and we can see on the mosquitto console this is not the case)*.  Please prove me wrong by showing me where this is in any of the specs (3.1, 3.1.1, 5.0) or at least confirm that I am not the crazy one. Please - I beg of you - do not mention OPC UA in your answer. I don't care about OPC at all in this discussion, I care about being accurate when discussing this with my clients/employees.

Incidentally this is the first time I have heard Walker say in a Video ""but it leaves the flexibility to report on trigger or interval"", I honestly think this is because of similar discussions I have been involved in in the past - so maybe there is hope. Last time I was involved in such a discussion it devolved into a fight between OPC and MQTT. I am hopeful this doesn't happen again. 

For context, you don't have to convince me of the benefits of MQTT - I am on board, but for some reason this keeps being stated as fact when it is not.","","‚ùî (1),üíØ (1)"
"894527802316046366","nickn5549","2024-04-10T20:20:39.9570000+08:00","Yeap, my RBE strategy is: the gateway/client  stores data locally and publishes it only if it falls outside the expected range, manually. On the Brokers side, which are designed to be message routers, you need to configure message filtering or rules engine to achieve RBE...not aware of any automatic way to achieve RBE","","üéì (1),‚ù§Ô∏è (2)"
"447710422603137025","im_glib","2024-04-10T20:43:42.8710000+08:00","Even Broker side filtering based on message content isn't part of the spec, correct? It's just a non-standard 'value add' that some brokers may choose to implement.","",""
"894527802316046366","nickn5549","2024-04-10T20:57:06.6450000+08:00","yes","","‚ù§Ô∏è (1)"
"794020366536146977","mparris","2024-04-10T21:07:24.6260000+08:00","In a pure-MQTT world, publishers rule the world;:consumers must accept both whatever a publishers choses for the payload (encoding scheme and content) as well as the publish rate.

I'm not aware of anything within the MQTT specification that defines when a client SHOULD publish data.  There is a lot that could go into a client determining when to publish data, and an application may choose whatever it wants.  

I'm not aware of the MQTT spec specifying filters at the broker level, where a client can subscribe to data, but only receive it after X absolute value change, or Y relative value change, or any change after Z time interval.","","‚ù§Ô∏è (2)"
"794020366536146977","mparris","2024-04-10T21:09:58.8560000+08:00","Its my opinion that even MQTT is limited for the backbone of a UNS architecture...  It can be an edge protocol, but there should be mechanisms at the Portal of the UNS that enable filtering, wehther that be what content a subscriber is allowed to receive, the rate that they receive it, etc","https://cdn.discordapp.com/attachments/1166016853991235594/1227606505730215977/image.png?ex=68df2266&is=68ddd0e6&hm=68922d06a1126abe201735a1ff7696a7ef776f656e0359d28831bc4b9eb8b073&","‚ù§Ô∏è (1)"
"447710422603137025","im_glib","2024-04-10T21:10:51.8070000+08:00","Way to skirt around the edges (pun intended) without outright agreeing with me. üòÖ

At best you could say MQTT ***supports*** report by exception by default.","",""
"794020366536146977","mparris","2024-04-10T21:14:01.3270000+08:00","MQTT will do whatever a publisher does üòâ","","üëç (1)"
"794020366536146977","mparris","2024-04-10T21:16:25.3220000+08:00","The only reference I've come across in a meaningful way to ""Report by Exception"" is from the Sparkplug specification:


https://sparkplug.eclipse.org/specification/version/3.0/documents/sparkplug-specification-3.0.0.pdf

Even sparkplug does not REQUIRE RBE-based approach, but recommends it","https://cdn.discordapp.com/attachments/1166016853991235594/1227608127051010108/image.png?ex=68df23e9&is=68ddd269&hm=d1c4ec369113e4d7a725ccc67b6352bc8dd71427b353572be9d4b28a4ca840d1&","‚ù§Ô∏è (2),üíØ (1)"
"794020366536146977","mparris","2024-04-10T21:18:24.6960000+08:00","But, you can quickly get into a rabbit-hole with this discussion....

Even IF sparkplug required RBE, where a client would only publish data on change...you must also specify the time interval for those publishes.

If a publisher has an internal clock and is looking to publish its time...should it publish on change 
-> every micro-second?
-> every minute
-> every day?

You're back to being at the mercy of the publisher without a mechanism for the consumer to declare a frequency of data change (or amount of value change) that they care about","",""
"447710422603137025","im_glib","2024-04-10T21:20:12.1420000+08:00","I was aware of this, and part of the reason why I intentionally left it out of my assertion was to not muddy the waters, but it is nice to know that others also see this for what it is.

Honestly, I was starting to feel like there was a bit of gas lighting going on.","",""
"867075936054149191","rickbullotta","2024-04-10T21:58:40.2250000+08:00","Core MQTT issues:
- Decision to use 4 bits for message type. Short sighted and now a major limitation
- Multi-publish is essential (publish more than one topic in a single message)
- Topics should have durable metadata (could be passed as headers in publish or as its own message type)
- Payloads should have a data type (mime type) to enable parsing/processing by subscribers or intermediaries
- Topic binding should be a built-in broker feature (like a symlink) - topic aliases are not this
- The lack of a capability to query topics is a huge flaw/gap. Ideally these queries should be able to include metadata filters as well
- MQTT's subscription patterns are hopeless limiting. They should support richer match expressions and also metadata filters
- MQTT should officially support a REST binding for request/response query/publish/read/subscribe/unsubscribe
- Handling of large payloads (e.g. file uploads, video content, firmware/software updates, method responses) needs a lot of work to improve reliability
- Handling of RPC/method invocations remains an awful hack. This MUST be addressed.","","üíï (1)"
"867075936054149191","rickbullotta","2024-04-10T21:59:00.8680000+08:00","Core Sparkplug issues:
- The rigid Node/Device format does not fit real world models. Do away with one of them and allow more flexible topic hiearchies.
- The handling of *BIRTH messages and the intermingling of data and metadata in them is a poor design
- The process for requesting *BIRTH messages is terribly inefficient. Metadata should be retained, not requested each time by each client.
- There should be *METADATA messages to deal with metadata
- The opaque/multi-value nature of *DATA messages makes it impossible for client(s) to subscribe to individual metrics. Huge issue.
- The ""primary client"" stuff is unnecessary and should be removed
- Any device commands/methods should be fully declared (inputs and outputs fully typed)
- Naming of metrics/commands needs to be locked down to a more restricted character set
- Add a few more top level data types (Location, BLOB (w/mime type), 
- Support other encodings besides Protobuf (e.g. plain JSON, zipped JSON, BSON, etc.)
- Millisecond resolution for timestamps is inadequate for modern systems where accurate event sequence is critical (e.g. power grid)","","üíï (1)"
"944630646821773392","m_r_mccormick","2024-04-11T00:09:03.4820000+08:00","Has a tag-based system (think influx tags, rather than topics) combined with pattern matching been considered to address 1) multi-publish, 2) topic metadata (queryable?), and 3) better subscription patterns? This would enable a very different and more flexible routing mechanism, maybe also address 'topic binding' if I'm guessing correctly at what you mean, and likely be more performant than a graph-based approach? The capability of dynamic routing based on payload data might also be beneficial as an extension of this, but then you're getting into the tradeoffs of semantic conformance and performance challenges.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-04-11T00:14:31.0070000+08:00","That's pretty much exactly how we did it in ThingWorx - both for querying metadata/model and for querying live data or historical data (and actually human generated data also).  We used a vector database/fulltext database along with other data storage and a federated query layer that I wrote to handle the grunt work.","",""
"867075936054149191","rickbullotta","2024-04-11T00:14:51.6770000+08:00","Which is why you need more than just an MQTT broker. üòâ","",""
"867075936054149191","rickbullotta","2024-04-11T00:15:21.8150000+08:00","Oh, and it was actually a graph database too! Neo4J also.","",""
"944630646821773392","m_r_mccormick","2024-04-11T00:19:01.7860000+08:00","Completely agree on needing more than a MQTT broker, but I'm not sure that the terminology exists (in manufacturing at least) to describe what is needed. Something very different than the current offerings.

Was the graph database part of the routing system (I'm not familiar with ThingWorx) or a separate service clustered with the routing system? The idea of having a graph database inside a monolith routing system scares me from a performance perspective when anticipating scaled deployments.","",""
"867075936054149191","rickbullotta","2024-04-11T00:22:23.9270000+08:00","The graph database did not participate in message routing or anything like that.  Anything needed for those purposes was in an in-mem cache (think REDIS-like) and was super performant.  The cache was updated based on model mutation events (add/delete/modify any model objects).  And what was super cool about using a graph database is that we also stored model dependencies in there, so we could intelligently optimize what entities needed to be reloaded/stopped/started on any change.","",""
"855607029518434314","hiptopjones","2024-04-11T00:23:59.5940000+08:00","This video is the first time I've felt like I understand why that claim (MQTT is RBE) is made.  MQTT doesn't do anything to make communication RBE, but I think the point Walker is making by saying it's RBE by default is that it also doesn't get in the way of RBE communication, whereas it sounds like OPC UA does get in the way of RBE communicaiton by default by putting other stuff on the wire.  (I am not familiar with OPC UA).  So it's more of MQTT supports RBE out of the box, but OPC UA requires configuration to leave RBE alone?","",""
"867075936054149191","rickbullotta","2024-04-11T00:24:59.2700000+08:00","MQTT does not know if a new message posted to a topic is a change or not.  The payloads are opaque to the broker (mostly).  MQTT cannot and does not do RBE out of the box, period.  It is up to the publisher to manage that.","","üíØ (1),üëç (1)"
"855607029518434314","hiptopjones","2024-04-11T00:28:03.3690000+08:00","But is it true that OPC UA gets in the way of RBE in a way that MQTT does not?  I'm not trying to be an apologist for Walker's loose language or rhetoric, but am trying to understand that the claim of RBE may be based on a different interpretation of the problem.","",""
"944630646821773392","m_r_mccormick","2024-04-11T00:28:43.6470000+08:00","I'd like to learn more about this approach and what use cases drove its development... I'm guessing I'm not going find that on the internet am I?

If you throw in the ability to query a short-term buffer of data based on sequence number, I'd be a happy camper. (Real-time streaming buffer, not historical database).","",""
"944630646821773392","m_r_mccormick","2024-04-11T00:50:17.8070000+08:00","In case a visual representation is helpful, this illustrates that 1) determining whether a change has occurred (funnel) and 2) transmitting data from the edge, are two distinct concepts, even though they are commonly encapsulated by the term RBE across protocols/standards. Or at least that's my opinion.","https://cdn.discordapp.com/attachments/1166016853991235594/1227661950083924018/image.png?ex=68df5609&is=68de0489&hm=dae6a79a69b8da3246ac18939088f9f9eed0479587f396b08059e49d158867fe&","‚ù§Ô∏è (1)"
"1073312001788477471","sparkylarks","2024-04-11T02:05:39.9600000+08:00","am I right in understanding that when we say RBE, we mean that a message is only sent if a value changes.

And your point is  the Broker doesn't know there was an exception it just know that there is a message. and if I configure my publisher to send a message every 1 second the broker has no idea if the value changes or not, and any subscribers will receive a new message.","","üëçüèº (3)"
"898217314741280828","hobbes1069","2024-04-11T02:43:11.6250000+08:00","I also somewhat disagree that MQTT is RBE by default, BUT I think the bigger issue is people conflating MQTT == MQTT Broker. As may have pointed out, the broker doesn't care about RBE, it just routes messages.","",""
"1129435706285101076","ted.garrison","2024-04-11T02:54:27.8140000+08:00","For your first question - my understanding: only if the value changes by more than whatever deadband you have configured on the publisher...","","üëç (1)"
"801561312861618236","jon.forbord","2024-04-11T04:09:00.2020000+08:00","Part of the Point of mqtt IS in my view to have the owner of the data define the shape/frequency/form of the data, so the consumer gets the data in the form the owner/publisher intended.","",""
"801561312861618236","jon.forbord","2024-04-11T04:11:07.7380000+08:00","When it comes to defining deadbands and/or underlying sample rate, this should again be configurable at the publisher.","",""
"867075936054149191","rickbullotta","2024-04-11T04:14:20.1510000+08:00","Ha. That actually happened automatically through the magic of datastore caching (MRU nodes and relationships were cached).","",""
"867075936054149191","rickbullotta","2024-04-11T04:14:32.5130000+08:00","Correct.","",""
"801561312861618236","jon.forbord","2024-04-11T04:14:35.7680000+08:00","If you keep adding required features to acommodate all possible use cases, what you WILL eventually get is just another AMQP or OPC UA.. there is never going to be ¬´the one magic, simple, fast, full control, edge driven, poll, queryable, efficient¬ª protocol. You cant have both simple and feature-rich at the same time.","","‚òùÔ∏è (2)"
"867075936054149191","rickbullotta","2024-04-11T04:17:23.5360000+08:00","To a point I agree - layering is essential.  but there are definitely a few glaring flaws that, if addressed, would help us all IMMENSELY.  The inability to query topics is just absurd, and a major, MAJOR limitation of MQTT.","",""
"801561312861618236","jon.forbord","2024-04-11T04:21:58.3210000+08:00","I see that more as a Namespace-requirement (Unified or not ü§™). I‚Äôm just trying to say that whatever we do, we should tweak mqtt to be better at mqtt-ing. We shouldnt try to make it into something it isnt. There are no magic bullets. There will always be a balancing act between tradeoffs to some extent.","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-04-11T04:29:09.5870000+08:00","Right. But a topic-based pub/sub with no way to discover topics is kinda like a database with no way to discover tables and columns. üòâ","","üëç (1),üíØ (1)"
"1214242167640424619","zack.scriven","2024-04-11T04:56:52.3100000+08:00","MQTT was created to solve a problem. And report by exception was a critical part of that solution... but it's not mandated in the specification. You are right, it's not in the specifications, but that's not important part and missing the point. We are going to have Arlen on the mastermind call this Friday, he'll tell you the backstory and why they chose to leave it flexible. That part of the conversation is planned to go public.","","üëç (2)"
"867075936054149191","rickbullotta","2024-04-11T04:57:37.4450000+08:00","Make it all public!  @Walker Reynolds has never been shy about that before - why now?","","üëç (1),ü§£ (1)"
"1214242167640424619","zack.scriven","2024-04-11T04:58:19.5000000+08:00","The entire part of the discussion with Arlen will be made public.","",""
"1214242167640424619","zack.scriven","2024-04-11T04:59:06.4230000+08:00","AFAIK","",""
"867075936054149191","rickbullotta","2024-04-11T04:59:07.1600000+08:00","We have a great opportunity to move this forward - and I know Arlen and team's intentions are good.  Let's all be super transparent and make it happen!","",""
"1214242167640424619","zack.scriven","2024-04-11T04:59:32.6890000+08:00","we polled the community for questions, and went over them yesterday. It's going to be a great discussion.","",""
"382941357699760129","walker.reynolds","2024-04-11T04:59:36.7610000+08:00","I shot a video explaining the origin story for MQTT and OPC.  The former assumes RBE but remains flexible.  The latter assumes poll/response but supports RBE via part 14 sub-part (which is an exception to the standard).","","üéØ (1)"
"1214242167640424619","zack.scriven","2024-04-11T05:00:11.4270000+08:00","MQTT supports report by exception by default.","","‚úÖ (2)"
"382941357699760129","walker.reynolds","2024-04-11T05:01:22.3760000+08:00","Everything in the spec is explicit for MQTT.  So the spec would be used.  Arlen will answer this question on Friday.","","üëç (1)"
"1073312001788477471","sparkylarks","2024-04-11T05:33:39.6120000+08:00","So why is that a problem, I just set the RBE once I go outside the deadband and now my messages and thus system is RBE?

Is the issue that if device manufacturers publish on a time based trigger, I lose the RBE and my network traffic ramps massively and my scalability gets affected. or is there another issue?","","üëç (1)"
"1073312001788477471","sparkylarks","2024-04-11T05:39:36.1510000+08:00","I really like this example.","",""
"456226577798135808","Deleted User","2024-04-11T05:49:22.4910000+08:00","I'm a bit confused on the reference to an inability to query topics?
Is this referring to an enhancement to browse all topics from device/server/broker? 
Or query the last reported topic data in a broker?","",""
"447710422603137025","im_glib","2024-04-11T06:12:21.5700000+08:00","I have seen it. Great video. In my opinion your golden era, unfortunately for me I just found out about it 2 years too late.

To be clear, there is nothing in your statement here that I disagree with.

My entire position can be summarised in the following statement ""Stating that 'MQTT by default is reported by exception' is dangerous.""

Why? 1) Because people in much higher places than me are going to repeat this verbatim and it will be easily shot down, - resulting in the credibility loss of MQTT.
2) Engineers are going to implement the same way as you have demonstrated and will get it wrong.","",""
"382941357699760129","walker.reynolds","2024-04-11T06:14:21.6820000+08:00","I‚Äôve never had a golden era.  And you should probably let Tesla and Amazon know about the really smart people above you ‚Äî maybe they can save Amazon and Tesla from impending death in the market.","","üòÇ (2)"
"447710422603137025","im_glib","2024-04-11T06:14:22.2670000+08:00","Are you guys offering micro transactions? How much to buy the full conversation? üòÖ","",""
"382941357699760129","walker.reynolds","2024-04-11T06:14:47.0770000+08:00","The full podcast with Arlen will be published","","üëç (2),‚ù§Ô∏è (1),üëçüèº (1)"
"1214242167640424619","zack.scriven","2024-04-11T06:14:55.3500000+08:00","üíØ","",""
"382941357699760129","walker.reynolds","2024-04-11T06:15:52.1830000+08:00","@LachlanW_PWD what are your values, what is your mission, why did you join this community and what is your point?","","üëç (4)"
"447710422603137025","im_glib","2024-04-11T06:15:58.6840000+08:00","Dude - I Honestly think you believe I'm saying something I'm not. I need to make the school run, then I'll go and have a look at the LinkedIn video.","","üëç (1)"
"447710422603137025","im_glib","2024-04-11T06:16:49.8680000+08:00","Faith based. You can look at the way I've approached this topic in the past.","",""
"1214242167640424619","zack.scriven","2024-04-11T06:18:36.7080000+08:00","Mission? Why did you join?","",""
"382941357699760129","walker.reynolds","2024-04-11T06:18:47.7840000+08:00","I answered your question.  RBE is not complicated ‚Äî does the client publish on change or not?  Once we are connected and subs are set up, is state and exceptions all we see on the wire?","","üíØ (1)"
"447710422603137025","im_glib","2024-04-11T06:21:15.7180000+08:00","Right now my mission is to get my young children to school. Happy to have a chat about it later.","",""
"1214242167640424619","zack.scriven","2024-04-11T06:21:49.9750000+08:00","Drive safely","","‚ù§Ô∏è (1)"
"867075936054149191","rickbullotta","2024-04-11T08:11:27.7430000+08:00","You can‚Äôt query topics from a broker. There‚Äôs literally no way to do that with MQTT.","",""
"867075936054149191","rickbullotta","2024-04-11T08:12:08.4240000+08:00","Thanks man!","","üôè (1)"
"867075936054149191","rickbullotta","2024-04-11T08:14:03.7260000+08:00","It‚Äôs so ridiculously trivial for a publisher to implement RBE though.  A cache of last values and a couple lines of code.","","üíØ (2)"
"447710422603137025","im_glib","2024-04-11T08:21:57.4620000+08:00","Exactly! EXACTLY THIS! An implementation like this could be so trivial, but rarely mentioned and never shown;
Case is point is this clip: https://youtube.com/clip/Ugkx6mKS-553y2CxCEcUTiEwRK-SmBdSEwXu?si=zABkECkQJVnouXtK
To anyone else interested, watch the whole video, not just the clip, it is one I recommend. 

Again, I love Walkers videos, and he has brought so much awareness to these technologies, but this doesn't mean that I can't request clarifications, or offer minor criticisms.","","üíØ (1)"
"740383178279354388","mriiot","2024-04-11T09:18:13.3650000+08:00","I dont believe I have ever heard ActiveMQ discussed here.  It was the first message queue I got into but forgot about it.","",""
"740383178279354388","mriiot","2024-04-11T09:28:22.5520000+08:00","Here is my dummy shoe ass playing with AMQ a while back https://youtu.be/SEe1MePg9uc?si=0c0wwgFlerR-F-4m","",""
"382941357699760129","walker.reynolds","2024-04-11T09:54:01.1890000+08:00","I am all for criticism ‚Äî 100%  üôè","","‚ù§Ô∏è (1)"
"382941357699760129","walker.reynolds","2024-04-11T09:56:05.9700000+08:00","The range was one value ‚Äî so while the rand() was running in the arduino, it always selected the same value.  We had no IO wired up.  fwiw","",""
"447710422603137025","im_glib","2024-04-11T10:22:23.9800000+08:00","Maybe I was dumb and linked the wrong video, I was intending to point out that there were multiple strings of repeated values of 210 and 211 temperature readings. 

Just about to go into a meeting, once I'm out I'll double check. Sorry.","",""
"382941357699760129","walker.reynolds","2024-04-11T10:24:04.9640000+08:00","Yeah ‚Äî the value shouldn‚Äôt have changed but it was RBE ‚Äî we were running a rand() with a range of 1 and then rounding.  The compare to last value happened before the round.","","‚ùì (1),üëç (1)"
"1088631859509989426","jpmac.s","2024-04-11T13:37:25.9250000+08:00","Does this include RBE? Or poll response?","","üòÇ (1),ü§¶‚Äç‚ôÇÔ∏è (1)"
"447710422603137025","im_glib","2024-04-11T14:56:51.8000000+08:00","I'm not sure that we are we talking about the same thing here.

Are you saying this was not the Arduino code? If it wasn't you sure had me fooled, you breathed on the sensor and everything! I cant see any rand() there, but otherwise if true you nailed the demo.

I'm open to help on this one from anyone!

https://youtu.be/spE6IpOU-2w?si=vRSYkYz5x38mTLYo&t=1372","https://cdn.discordapp.com/attachments/1166016853991235594/1227874995791990804/image.png?ex=68df73b3&is=68de2233&hm=e05f0b74d0f307bbbc1b654fa4d162f8a55d55007af46ffdf2647d407f95da9f&",""
"867075936054149191","rickbullotta","2024-04-11T21:26:06.3970000+08:00","I'll help you put a plastic bag of your head, twist it tightly around your neck, and then show you how to put a zip tie around it.  And you won't need to send me 10%.","","ü§£ (1)"
"382941357699760129","walker.reynolds","2024-04-11T22:29:26.6340000+08:00","Yes ‚Äî we are definitely talking about different things ‚Äî üòÇ The log output in that video is the same log in our Arduino demo which uses a function for RBE.  1. Store last value persisted  2. rand(range of 1) 3. onChange() do the compare and publish.  The video you posted isn‚Äôt our demo.  I looked at the output and thought it was.","",""
"382941357699760129","walker.reynolds","2024-04-11T22:31:01.5230000+08:00","This was being published at interval for our test because we weren‚Äôt using IO.","",""
"447710422603137025","im_glib","2024-04-12T01:45:11.4270000+08:00","Thanks for admitting that it wasn't report by exception - I'm sure you'll note that throughout your entire video you only referred to it as report by exception. 

To be honest I can't make any sense of your last 2 comments.  It's definitely one of your videos, you are doing the talking for heaven's sake, it's in the 4.0 solutions channel. The screenshot shows you and your kids as an Avatar picture.... Also, the Arduino was hooked up to a temperature sensor, so I think you're mistaken again here when you say ""we weren't using IO"".


It's nice to know that I haven't been incorrect in this and it wasn't my mistake.

@walker.reynolds at the end of the day you chose to escalate and publicly attack me cross-platform on LinkedIn. I'm disappointed with how you acted in this instance. I would appreciate it if you chose to do the right thing here.","",""
"447710422603137025","im_glib","2024-04-12T01:51:04.8570000+08:00","Life is joke - I'm sitting here in a hospital at 3:15am for my 2 year old son (he is Ok and will be fine), having a ridiculous disagreement with someone on the other side of the planet and I need to be on site in 3 hours.

I think I'm done for now, but I still appreciate all the support public and private I received.

I wish everyone good luck!","",""
"382941357699760129","walker.reynolds","2024-04-12T01:59:44.2320000+08:00","What is in that video isn‚Äôt our demo ‚Äî which implements RBE with a rand() function call with a range of 1 ‚Äî the result is a random float to 6 places that is then run thru a compare to establish a change in value.  We then round the value to a whole number and publish.  I didn‚Äôt watch the video you published.  I assumed it was the video of our demo, I did not know it was the video of me testing the arduino.  Nothing about my position has changed.  MQTT is inherently RBE and OPC-UA is not.  RBE was a functional requirement for P66 when MQTT was written.  Its inherent.  RBE is not inherent to OPC-UA.  The point of RBE is to use bandwidth for changes only.  The MQTT spec leaves flexibility for interval or trigger publishing but assumes RBE by default.  Publishing a change in a callback is not the full encapsulation of RBE.  üôè I cannot believe how hard this is for some to understand.","",""
"382941357699760129","walker.reynolds","2024-04-12T02:00:04.0720000+08:00","The spec is just paper ‚Äî how it‚Äôs used and what‚Äôs on the wire is reality.","",""
"447710422603137025","im_glib","2024-04-12T02:00:52.6800000+08:00","(I'm not talking about the video MRIIOT posted, I think you need to triple check)","",""
"382941357699760129","walker.reynolds","2024-04-12T02:04:31.0960000+08:00","Which video are you talking about?  That sketch you dropped in was for a simple MQTT test on the Arduino ‚Äî it wasn‚Äôt for an IIoT test.  We weren‚Äôt testing RBE in the Arduino test.  What video are you talking about?","",""
"447710422603137025","im_glib","2024-04-12T02:05:52.5670000+08:00","https://youtu.be/spE6IpOU-2w?si=vRSYkYz5x38mTLYo&t=1372","",""
"817835202746253344","IIoT#4707","2024-04-12T02:05:52.7440000+08:00","GG @LachlanW_PWD, you just advanced to level 5!","",""
"447710422603137025","im_glib","2024-04-12T02:06:33.6780000+08:00","It's a YouTube clip from that video.","",""
"382941357699760129","walker.reynolds","2024-04-12T02:08:08.6260000+08:00","The esp32 temp sensor example?","",""
"382941357699760129","walker.reynolds","2024-04-12T02:10:12.3870000+08:00","That‚Äôs RBE with a 2000ms band, right?  If the value has changed and TS is greater than 2000ms then publish?  Is that what we did?","",""
"447710422603137025","im_glib","2024-04-12T02:10:39.4650000+08:00","It's the one I linked. Not sure what you call it.","",""
"447710422603137025","im_glib","2024-04-12T02:12:41.4410000+08:00","Watch 60 seconds from the timestamp in the link I just sent and you can see for yourself. No rbe, publish every interval regardless.","",""
"382941357699760129","walker.reynolds","2024-04-12T02:42:37.8140000+08:00","Correct -- because its an analog sensor that changes 60x per second and there is ALWAYS a change.  I have a follow up video somewhere on my personal YT channel that shows a switch integration -- which is bool -- and I change the event handling.  I think I understand what you are objecting to -- the code implementation for this use case?","",""
"382941357699760129","walker.reynolds","2024-04-12T02:47:20.6610000+08:00","The original code just published the sensor value on every scan -- because we can assume it changed.  Its an analog value that goes to 6 decimals resolution.  We then put a 2000ms band in and publish -- on the assumption the value changed because it changes 60x per second.","",""
"447710422603137025","im_glib","2024-04-12T03:00:27.3930000+08:00","I'm struggling to follow that, and I'm so tired, and I'm angry at myself that I keep letting myself get dragged back in. üòÖ ‚ù§Ô∏è
But here goes:

It updates every ~ReadAnalog()~ analogRead()  in the loop - yes every scan, not sure where you are getting 60x per sec.

Every 2000ms the code converts the value to a string and then publishes. Not sure where you get 6 decimal places from or if that is relevant here.

I think we are close to what I am objecting to. To try and put it another way, I believe:
- Calling that implementation RBE is incorrect, but it is still MQTT. In videos that implementation is referred to as RBE. 

- Stating that it only publishes on change is incorrect, the same payload string is published regardless. All subscribers see that duplicated payload traffic. By default MQTT doesn't solve that problem for us automatically.

I hope I am coherent.

üôè","",""
"382941357699760129","walker.reynolds","2024-04-12T03:04:40.7730000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1228058156282810430/image.png?ex=68df7588&is=68de2408&hm=3e234f703e032373cc5096df3a515bf731c6b843050954d1486f09e616eb9e1a&",""
"447710422603137025","im_glib","2024-04-12T03:05:21.3560000+08:00","Yep, I think we only care about a few lines though","","üëç (1)"
"382941357699760129","walker.reynolds","2024-04-12T03:06:07.7960000+08:00","This code is looping about 60 times per second ish.  It is only publishing if the last publish was more than 2000ms ago.  The sensor value (which is a raw value) is out to 6 decimal points and changes 60x per second (the scan rate).","",""
"447710422603137025","im_glib","2024-04-12T03:06:51.3120000+08:00","sensorValue = .....

2sec interval loop
      mes= String(sensorValue)
      client.publish(..... (char*)mes.....)","","üëç (1)"
"382941357699760129","walker.reynolds","2024-04-12T03:08:02.7010000+08:00","Right -- it assumes a change because of the analog resolution.  We have a 2 second deadband before publish and we always publish the most recent change after 2 seconds.","","üëç (1)"
"447710422603137025","im_glib","2024-04-12T03:09:40.8550000+08:00","Yeah, an earlier in the vid  we can see that the strings that were actually published in the console were ""210"" followed by another ""210"" for example","",""
"382941357699760129","walker.reynolds","2024-04-12T03:11:03.7090000+08:00","Correct -- but the underlying raw value changed.  In the subsequent video, when I add in a momentary switch, I refactor the event handling.","",""
"447710422603137025","im_glib","2024-04-12T03:12:28.8260000+08:00","Could be. Look obviously I know that you know how to do it correctly and how it works. I'm not saying you dont know what you are doing.","",""
"867075936054149191","rickbullotta","2024-04-12T03:12:29.2960000+08:00","01010100 01101000 01100101 01110011 01100101 00100000 01100001 01110010 01100101 00100000 01101010 01110101 01110011 01110100 00100000 01101101 01101001 01101110 01101111 01110010 00100000 01100100 01100101 01110100 01100001 01101001 01101100 01110011 00101110 00100000 01011001 01101111 01110101 00100000 01100011 01100001 01101110 00100000 01100100 01101111 00100000 01010010 01000010 01000101 00100000 01110111 01101001 01110100 01101000 00100000 01001101 01010001 01010100 01010100 00100000 01100101 01100001 01110011 01101001 01101100 01111001 00101110 00100000 00100000 01000101 01101110 01100100 00100000 01101111 01100110 00100000 01110011 01110100 01101111 01110010 01111001 00101110","","üíØ (2),üßÄ (1),ü™É (1),ismile (1)"
"867075936054149191","rickbullotta","2024-04-12T03:12:51.0050000+08:00","I'll save you some time:

https://www.rapidtables.com/convert/number/binary-to-ascii.html","",""
"1129435706285101076","ted.garrison","2024-04-12T03:12:52.0090000+08:00","I'm guessing it's because Walker initialized it as an Int rather than say, a Long.  So it got truncated even though the raw value was really 210.133421 210.23434 210.33253","","üíØ (1)"
"447710422603137025","im_glib","2024-04-12T03:13:50.9580000+08:00","The ASCII translation of the binary string is: ""These are just minor details. You can do RBE with MQTT easily. End of story.""


Lol","",""
"447710422603137025","im_glib","2024-04-12T03:14:05.1770000+08:00","Chat gipity is pretty freaking cool.","",""
"447710422603137025","im_glib","2024-04-12T03:14:33.5450000+08:00","But I would argue that the education isn't a minor detail.","",""
"382941357699760129","walker.reynolds","2024-04-12T03:14:53.4410000+08:00","It was a long to begin with -- and we rounded.  This application was 2016-2018 ish and I shot this for another engineer who worked with us and shared it on my personal YT with him.  The team took this video off my personal channel and posted it to the 4.0 channel 4 years ago, which was 3 or 4 years after it was made.","",""
"382941357699760129","walker.reynolds","2024-04-12T03:16:23.7640000+08:00","I think I understand what @LachlanW_PWD is saying though.  And it is definitely in the details of the implementation.  The code assumes change because we are reading as int from a floating point we know changes 60x per second.","",""
"447710422603137025","im_glib","2024-04-12T03:16:49.2610000+08:00","Yeah cool, good pickup, makes sense and explains that! ‚ù§Ô∏è

 Not really relevant to the MQTT though yeah? It's just a string at the end of the day.","",""
"867075936054149191","rickbullotta","2024-04-12T03:18:18.1510000+08:00","Not at all.  You can certainly have a native data type in the payload too.  It's just an array of bytes actually.","",""
"1214242167640424619","zack.scriven","2024-04-12T03:18:38.3170000+08:00","It Definitely doesn‚Äôt mean that you can‚Äôt ask for clarification or minor criticism.","",""
"447710422603137025","im_glib","2024-04-12T03:18:54.3370000+08:00","I will yield to that one...

Not a hill I will fight on.","",""
"447710422603137025","im_glib","2024-04-12T03:20:31.6800000+08:00","In practice, handling analogs  properly is a bit of a rabbit hole. Dead bands, hysteresis.. etc","","üíØ (1)"
"447710422603137025","im_glib","2024-04-12T03:20:44.8250000+08:00","Formats? Strings vs hex","",""
"1214242167640424619","zack.scriven","2024-04-12T03:20:50.4430000+08:00","I don‚Äôt think he attacked you. He responded to your comment addressing the points you brought up. I don‚Äôt believe he attacked you personally at all.","","üíØ (1),üòÖ (1)"
"447710422603137025","im_glib","2024-04-12T03:24:23.0490000+08:00","Hmmm.. not how it felt. Maybe I'm just a ‚ùÑÔ∏è","",""
"867075936054149191","rickbullotta","2024-04-12T03:24:30.7330000+08:00","No fight needed - from the spec, it's a series of bytes. Which is the good and the bad.","",""
"447710422603137025","im_glib","2024-04-12T03:25:07.0210000+08:00","Yeah, you are correct.","",""
"1057737574287945899","xamp4248","2024-04-12T03:29:04.7240000+08:00","It‚Äôs quite complex to follow this thread. Practically speaking, I believe RBE is well-suited for boolean values. For analog signals, users definitely need to customize the threshold and deadband. It's not worthwhile to argue that RBE should by default be used for analog values","","üíØ (1)"
"1214242167640424619","zack.scriven","2024-04-12T03:29:16.2720000+08:00","Maybe. Certainly, You would have taken your own initial comment as an attack if you feel that way. Walker and I are still confused what the point is here.","",""
"1214242167640424619","zack.scriven","2024-04-12T03:29:45.3140000+08:00","Agreed. üëç","",""
"1214242167640424619","zack.scriven","2024-04-12T03:30:35.3680000+08:00","I‚Äôm just saying if you are going to make a comment on a public YouTube video, be prepared for a response.","",""
"1214242167640424619","zack.scriven","2024-04-12T03:30:55.4540000+08:00","I would say if I felt like he was being to hard on you.","",""
"1214242167640424619","zack.scriven","2024-04-12T03:31:35.0280000+08:00","But you are entitled to your own feelings and opinions. The intent wasn‚Äôt to make you feel that way.","",""
"447710422603137025","im_glib","2024-04-12T03:33:57.9690000+08:00","Probably true. I was definitely matching the energy in the video and I didn't go cross platform.

Really? I think he gets it now.

Look I've tried. Watch the full video Zack, tell me if you don't see it stated to something  to the effect of ""this is MQTT and will only be sent on change"". It is demonstrably not true. The protocol doesn't require it to be. The protocol doesn't care. By default MQTT is nothing.","","ü§Ø (1)"
"1057737574287945899","xamp4248","2024-04-12T03:38:36.6500000+08:00","What did you understand the state"" will only be sent on change"". Do you want to send data on each decimal change?. If my question is irrelevant, please ignore it.","",""
"382941357699760129","walker.reynolds","2024-04-12T03:42:55.2790000+08:00","It assumes change and has a threshold band of 2000ms üôè It‚Äôs RBE.","","üëèüèº (1),üíØ (1),‚ùì (1)"
"740383178279354388","mriiot","2024-04-12T03:51:53.4400000+08:00","This has been the most overcomplicated sh*t i have ever read.  Client is responsible for keeping state to rbe.   Mqtt is just a transport.  No different than rbe over any other transport that does not require polling.  Client decides what to send and when.","","üíØ (3)"
"740383178279354388","mriiot","2024-04-12T03:53:58.1250000+08:00","Is there a demo I could produce to help?","",""
"447710422603137025","im_glib","2024-04-12T03:56:25.2030000+08:00","Yep this.","",""
"740383178279354388","mriiot","2024-04-12T03:56:45.9510000+08:00","My banner q4x sensor is rbe when i set a window of detection between 50mm and 70mm","",""
"740383178279354388","mriiot","2024-04-12T03:59:04.7010000+08:00","i also like to think of my wife as rbe, i am not sure she would agree though üôÇ","","üòÇ (3)"
"447710422603137025","im_glib","2024-04-12T04:00:02.1190000+08:00","Tell me, what do you think of the phrase ""MQTT is Report by exception""? What does it mean?","",""
"740383178279354388","mriiot","2024-04-12T04:05:17.5020000+08:00","The client I implement will publish observations to a predefined topic only when the source of the observation changes within some predetermined parameters.","","üëç (2),ismile (1),üíØ (2)"
"447710422603137025","im_glib","2024-04-12T04:09:00.7550000+08:00","You are a smarter man than I. üòä","","üòÇ (1)"
"740383178279354388","mriiot","2024-04-12T04:11:10.1260000+08:00","There are a lot of moving pieces in the industry.  I dont know what your expertise is but I am sure I will ask you to dumb a thing or two down for me.","","üòÇ (1)"
"1057737574287945899","xamp4248","2024-04-12T04:13:49.2290000+08:00","To me or other one,üôÉ","",""
"740383178279354388","mriiot","2024-04-12T04:14:55.5790000+08:00","People have tried to explain electricity to me with the water hose analogy and I still dont get it","","üòÜ (1),üòÇ (1),üíØ (1)"
"801561312861618236","jon.forbord","2024-04-12T05:28:34.6170000+08:00","Report by exception does not mean publish literally EVERY change. It means don‚Äôt report things that haven‚Äôt changed. The publisher can/should setup reasonable deadbands/sample rate etc. 

On a slightly related note, this is why I like the OPC UA -> mqtt Combo. I get to control deadbands and sample rate from the PLC with OPC UA, and get the benefits of MQTT for the rest.","","üíØ (5),ismile (1),üëç (1),üôè (1)"
"898217314741280828","hobbes1069","2024-04-12T05:31:35.5860000+08:00","Yeah, it only really works at a high level, but I must admit, when I was working on my masters in Mechanical Engineering and the professor showed the similarities to the equations used for fluid flow and electrical flow my mind was blown.","",""
"740383178279354388","mriiot","2024-04-12T05:43:59.0200000+08:00","Show me the atoms","","ü§£ (2)"
"801561312861618236","jon.forbord","2024-04-12T05:56:14.9690000+08:00","Or how an RCL-circuit can be used to model a mass-spring-damper!! That blew a fuse in my mind back when..","","ü§Ø (1)"
"794020366536146977","mparris","2024-04-12T10:18:10.4030000+08:00","I thought we had discussed this before...doing a search on this Discord server showed a table I posted Aug 2023 https://discord.com/channels/738470295056416930/738470295056416934/1139250011067121694:

TLDR;
‚úÖ  MQTT is Report by Exception
‚úÖ OPC UA is Poll-Response
‚ùå MQTT is only Report by Exception
‚ùå OPC UA is only Poll-Response","https://cdn.discordapp.com/attachments/1166016853991235594/1228167248812835038/image.png?ex=68df3262&is=68dde0e2&hm=42a56b6dd207b5e4964acd3abb1fb4f169755f1071fa463eb0449c75e1fc1271&","üëç (2)"
"794020366536146977","mparris","2024-04-12T11:07:01.0400000+08:00","TLDR:
Report by Exception isn't always better than publishing on interval.  



The nuance that most people don't comprehend is that ""Change"" has two components:

1) Sampling Interval -- the amount of time between obtaining new values from the underlying data source
2) Deadband on the Value -- how much change is considered interesting change worth reporting?

In MQTT, regardless of how each consumer defines it, both of these definitions are owned solely by the publisher.  And, it's completely possible that an MQTT publishing device/application will not allow the user to control either or both of these parameters for each register/tag/node/etc.

Consider the use-case of publishing voltage values:

__The Prattling Publisher__
1) Sampling interval = 1s
2) Deadband = none

__The Precise Publisher____
1) Sampling interval = 1s
2) Deadband = 0.001V

__The Prompt Publisher__
1) Sampling interval = 50ms
2) Deadband = 5V

__The Plethoric Publisher__
1) Sampling interval = 50ms
2) Deadband = 0.001V


Which is better?  The report by exception ""Plethoric Publisher"" sending out new values every 50ms to three decimal points or ""Prattling Publisher"" sending out values once per second regardless of the value?

MQTT supports all of these personalities...and ALL CONSUMERS are forced to comply with whatever personality the publisher wants to be.

And regarding the answer to the question of which is better....of course, the answer is ""It depends...""","","‚ù§Ô∏è (2),üî• (1)"
"894527802316046366","nickn5549","2024-04-12T17:53:54.1300000+08:00","show me the bosons","",""
"1073312001788477471","sparkylarks","2024-04-12T18:34:07.3560000+08:00","Pretty simple. reallly.
At one point in my life I understood theses.  

All pushed out by PLC Code and youTube nonsense","https://cdn.discordapp.com/attachments/1166016853991235594/1228292058595332096/Maxwells-equations.png?ex=68defddf&is=68ddac5f&hm=3ab40bb57abd5f1c0629e245254649dbdd57affd18fa4dd0a256806fb9322198&",""
"1073312001788477471","sparkylarks","2024-04-12T18:40:09.9130000+08:00","This is a really important distinction, and I like @Jon Forbord ""means don‚Äôt report things that haven‚Äôt changed""

I have always believed in ""Horses for Courses"", there is a place where everything can be the right approach.

a poll response works very well at the manufacturing edge, where signals do change very frequently, Analogs timers counters and all that type of stuff, and I suggest that for a typical PLC to SCADA there is not a major bandwidth or performance difference between polling everything at a 1s interval , or publishing everything if there is a .1% Dead band change, 

but if we were to look a MES or ERP, nothing is changing at that sort of interval, and the difference between publishing on change, and polling all data points at a reasonable level( 5 or 15 minutes) is huge","",""
"817835202746253344","IIoT#4707","2024-04-12T18:40:10.2500000+08:00","GG @Mark O'Donovan, you just advanced to level 17!","",""
"1073312001788477471","sparkylarks","2024-04-12T18:41:40.0040000+08:00","https://tenor.com/view/that-would-be-an-ecumenical-matter-father-ted-ted-crilly-irish-dermot-morgan-gif-15581042","",""
"1073312001788477471","sparkylarks","2024-04-12T18:42:41.8640000+08:00","As to if MQTT is RBE. I would have to pull out this again 

It almost always is, I have never seen a system or device in the wild that is not,","",""
"801561312861618236","jon.forbord","2024-04-12T18:54:35.7950000+08:00","I think a big part of the point of edge driven IS that the publisher decides. Whoever designs the publisher should understand the underlying functional requirements or the process knowledge to select the appropriate type(s) of publishing pattern.  The consumer will receive the information/data however the publisher intensed, and this is the feature of an edge driven architecture. If you want the clients / subscribers to pick how to sample and how the data should be formed, its a different architectural pattern (SOA?). 

Walker‚Äôs UNS as he envisioned IS RBE, Edge driven, lightweight, open architecture, and his hypothesis is that you have to build on this to succeed with digital transformation.","",""
"697134502148964423","trentc","2024-04-12T19:01:02.1620000+08:00","I‚Äôve seen many mqtt implementation by OT engineers that don‚Äôt understand RBE, and just publish on an interval. Definitely refer back to https://discord.com/channels/738470295056416930/1166016853991235594/1228179540971491338","",""
"697134502148964423","trentc","2024-04-12T19:02:10.3240000+08:00","What if you had a way to send a configuration to a publisher to define the RBE parameters?","",""
"1073312001788477471","sparkylarks","2024-04-12T19:02:37.2520000+08:00","and if some nodes are not RBE but Publish on Interval because
- that is the most appropriate solution
- the device supplier configured that way.

you can either decide not to allow it, or allow it by exception because it won't cause the whole system","",""
"801561312861618236","jon.forbord","2024-04-12T19:03:01.0640000+08:00","Of course that is possible. What I‚Äôm saying is that that is a different pattern altogether.","",""
"1073312001788477471","sparkylarks","2024-04-12T19:03:28.3930000+08:00","if it is from a SCADA or IIoT type platform ,then change it","",""
"697134502148964423","trentc","2024-04-12T19:03:46.5970000+08:00","I believe this is the best route when we don‚Äôt really know exactly what the needs are of the system that is consuming it","",""
"611399804894969856","fvfrenzy","2024-04-12T19:03:54.0870000+08:00","I‚Äôve been watching this thread for the last 100 or so messages. Here is what I‚Äôve learned. 

It is no wonder we are struggling as an industry to update specifications like Sparkplug. We can‚Äôt even agree on the definition of ‚Äúchange‚Äù or ‚Äúreport‚Äù.","","üíØ (3)"
"817835202746253344","IIoT#4707","2024-04-12T19:03:54.4220000+08:00","GG @Learn2Everything, you just advanced to level 1!","","ü§£ (1)"
"697134502148964423","trentc","2024-04-12T19:04:36.8220000+08:00","Nope, PLC implementation. Yes of course it may need changed based on ‚Äú it depends ‚Äú","",""
"801561312861618236","jon.forbord","2024-04-12T19:05:18.2960000+08:00","The publisher decides because the publisher knows the data best. What if the consumer decides to sample every 30 seconds, and it turns out the event has a much higher frequency. The consumer will then be missing events and the data quality is bad.","",""
"697134502148964423","trentc","2024-04-12T19:06:04.7880000+08:00","Yes, I agree but what if we find out the opposite and where do we make the change? Do you contact your machine builder your integrator or would it be preferred to be be able to manage this in a centralized system?","",""
"801561312861618236","jon.forbord","2024-04-12T19:06:39.4600000+08:00","Ok, i see where youre coming from. This is excactly why I like OPC UA on the Edge.

( in my world I‚Äôm in control of the Edge device as well, so no integrator/OEM that sets it up and its stuck).","",""
"1073312001788477471","sparkylarks","2024-04-12T19:06:55.8710000+08:00","Tell them fix it, or 
publish to a IIoT Platform an configure it as RBE and then publish to the UNS.

Treat it as you would a modbus or OPCUA interval based data, transform it to MQTT RBE.","",""
"697134502148964423","trentc","2024-04-12T19:09:55.6880000+08:00","In all of my development and testing of course I have control over it, but I know that the reality is not always this case. Yes I am aware of the OPCUA has this mechanism and I think this is one of the great values of opcua at the edge. Although I am advocating for MQTT with this capability added, unfortunately it would be a customized solution","",""
"801561312861618236","jon.forbord","2024-04-12T19:12:40.2370000+08:00","For embedded mqtt, i can tend to agree that the device should have a mechanism for setting up sample rate and deadbands, but once it has been configured on that end, I think not that mqtt should have this type of mechanism. That would be a broker level feature, that would ruin the premise of Edge driven.","",""
"697134502148964423","trentc","2024-04-12T19:13:31.4440000+08:00","Yes, of course. If I identified the issue, I would ask someone to fix it if it needs to be fixed however, my point is MQTT inherently is not report by exception because it can be set to publish whenever the producer decides, allowing flexibility to solve problems but‚Ä¶ with great power comes great responsibility‚Ä¶. The flexibility allows for bad practice as well, including ignorance or laziness.","",""
"817835202746253344","IIoT#4707","2024-04-12T19:13:31.7360000+08:00","GG @trentc - 4.0 Hero LLC, you just advanced to level 9!","",""
"1073312001788477471","sparkylarks","2024-04-12T19:14:33.1030000+08:00","so is the proposed solution, update the standard so no data can be published by MQTT unless it has changed?

and the standard is updated to reflect this.
and all brokers woudl automatically reject this?","",""
"697134502148964423","trentc","2024-04-12T19:15:33.2310000+08:00","I‚Äôm proposing that an application could push the configuration via MQTT which once is configured is most likely does not need to be changed, but when it does need changed, it can be easily managed remotely","",""
"697134502148964423","trentc","2024-04-12T19:22:44.3120000+08:00","No, I do not believe rigid regulation is a solution. Refer back to Matthew Paris‚Äòs comment about it depends. I think that a publisher should be allowed to do any of the publishing methods that are necessary for the application whether that be on interval or change, i‚Äôm just pointing out that it helps to clarify and educate people on the application of MQTT and RBE, this might also be something that is important to include in specs. I have not yet explored if there are broker features that are used for rate limits for publishers‚Ä¶. But this could be useful to limit high frequency publishers when it is determined necessary.","",""
"1073312001788477471","sparkylarks","2024-04-12T19:28:04.2920000+08:00","Or at least a way to all subscribers to only receive a message if there is a change. 

So if I am right, you are saying is,
MQTT is can and normally be implemented as RBE, however there are no limitation that enforce it and some implementation and publish on a Trigger on on a interval that can have unintended consequences up stream

and I agree but I am still happy to say MQTT is RBE when discussion it's benefits over other protocols, as they are normally found in the wild.

to quote you on another channel "" no need to muddy the waters unnecessarily."" some people don't realise that protocols don;t have to be poll response","","üòÇ (1)"
"697134502148964423","trentc","2024-04-12T19:46:17.9170000+08:00","I believe the way that we talk about it is dependent on the context or the audience.
When I first learned about MQTT I had made the assumption that it was RBE inherently, but I learned through application that you have to build this functionality in to your application. So when speaking about MQTT and me being an engineer, the wording i would choose would say MQTT can be RBE, and our MTR would require RBE.","",""
"382941357699760129","walker.reynolds","2024-04-12T19:57:20.9600000+08:00","This is the summary of the discussion.  This is actually how I see it in my head and on the wire.","",""
"740383178279354388","mriiot","2024-04-12T20:09:21.7190000+08:00","Yeah I am the kind of guy that when you show me an autostereogram, I can‚Äôt see a damn thing.","",""
"740383178279354388","mriiot","2024-04-12T20:16:12.6450000+08:00","Thats just because you cant solve these things over text.  When my wife texts me that now we are in an argument, I know what will happen when I get home.","","ü§£ (1)"
"1073312001788477471","sparkylarks","2024-04-12T20:19:05.0120000+08:00","And given the location on this Discord server, or on an @Walker Reynolds video RDE is an MTR so saying MQTT is RBE and OPC UA is not is perfectly understandable 

It's like what colour is the Sea. Blue perfectly answer even in Ireland where it is never blue it's green or grey.( In gaelic the word Glas which we learn in school to be green is actually the colour of the sea so that is why the grey squirrel is the irroa   glad or green squirrel??)

But the sea is colourless but noone ever answers that when asked what colour is the sea","",""
"867075936054149191","rickbullotta","2024-04-12T20:21:50.4560000+08:00","Again, why does any of this matter? It‚Äôs semantics. You can implement RBE with anything.","","üíØ (3)"
"382941357699760129","walker.reynolds","2024-04-12T20:26:43.9830000+08:00","Agreed.","",""
"1129435706285101076","ted.garrison","2024-04-12T20:34:58.3530000+08:00","RIP Higgs...","",""
"740383178279354388","mriiot","2024-04-12T20:35:59.4130000+08:00","Only to promote common understanding of practice along the stacks which would allow further intelligent discussion instead of u repeatedly posting bullet  points of necessary changes.","","üëç (1),üíØ (1)"
"1073312001788477471","sparkylarks","2024-04-12T20:47:16.5840000+08:00","It's about being technically correct, üòú","https://cdn.discordapp.com/attachments/1166016853991235594/1228325567560941711/image0.gif?ex=68df1d14&is=68ddcb94&hm=a56d14ef7877cf061151dd6b90af44511a9dc3ae6c4e1d2b2b5929ed9a05b3c4&","üòÇ (3)"
"867075936054149191","rickbullotta","2024-04-12T21:00:23.4790000+08:00","I don't unless asked, mostly because search in Discord sucks.","","üòÜ (1)"
"867075936054149191","rickbullotta","2024-04-12T21:01:07.6890000+08:00","And if someone can't figure out how to implement RBE, I sure don't want them anywhere near ANYTHING in my factory.","","ü§£ (3)"
"740383178279354388","mriiot","2024-04-12T21:09:34.7050000+08:00","Can I see your list again","",""
"867075936054149191","rickbullotta","2024-04-12T21:32:57.1650000+08:00","- No
- You
- May
- Not","","üßÄ (1)"
"435342889875275776","george9330","2024-04-12T22:08:15.2880000+08:00","@Walker Reynolds When we can see a interview about sparkplug B?","",""
"855607029518434314","hiptopjones","2024-04-12T22:51:07.2930000+08:00","It's fascinating to watch this conversation.  Everyone talking past everyone else, addressing some other point of order.  The unqualified statement ""MQTT is RBE"" is a technically incorrect statement.  It's the ""is"" that's confusing people, and this has nothing to do with whether somebody knows how to implement RBE or not.  The ""is"" makes (new) people think that MQTT has magic sauce, when it doesn't.  And when they can't find the magic sauce, it creates this question.  And when it creates this question, and you get heals dug in instead of a mea culpa that yes we could be using more precise language but this why we say that, I think it erodes trust in all of the other messaging coming out of the community.  It matters because Walker is trying to change people's minds and bring people on a journey, and this kind of unnecessary hand-wringing pushes good people out of the party.  These are good people because they are smart enough to see something and brave enough to say something about it, which improves all of us.  It also matters because that unqualified and imprecise language is used as a weapon against things like OPC-UA, and is therefore put under more scrutiny than if it was just a rallying cry.","","üëç (4),üíØ (2)"
"898217314741280828","hobbes1069","2024-04-13T01:25:53.2530000+08:00","Plan is for the podcast to publish Monday.","",""
"435342889875275776","george9330","2024-04-13T01:41:57.4580000+08:00","üëç","",""
"753688565807841492","ravil1","2024-04-13T11:06:35.5400000+08:00","I see hot discussion is going on here. I just went quickly through messages, and one thing I noticed is that in OPC UA, clients that unaware about the data, might ask for wrong sampling interval and miss important data which is changing more frequently than a client thinks. Allegebly, MQTT publisher knows better what rate to sample and publish.
In fact, if an OPC UA server thinks that sampling should be done at some specific rate, it can use that rate, not the rate the client is asking for. Because in OPC UA the client can ask let say for 1 minute sampling interval, but server can say - nope, I will sample at 1 second interval.  That is called ""revised"" value. 
The server can revise many other options too - publishing interval, session timeout, etc.","",""
"753688565807841492","ravil1","2024-04-13T11:17:09.4750000+08:00","Another advantage of OPC UA is that the client and server can keep in sync with each other when one side is mush faster than another. For example if the server can produce data at a rate which the client cannot handle, then the actual rate is gradually decreased to the level the client can handle. In MQTT I think it is easily possible that the broker can spit data at rates which not every client can handle.","",""
"1214242167640424619","zack.scriven","2024-04-13T23:06:09.1880000+08:00","MQTT is Report by Exception by default","https://cdn.discordapp.com/attachments/1166016853991235594/1228722904284532776/MQTT_is_RBE_by_default.mp4?ex=68df3da0&is=68ddec20&hm=76c1ee86fe20a0f58d3819976c8ee5280a290d9fb9d5517d2c923148f225906f&",""
"568913935147728896","zeratall","2024-04-14T00:10:03.4060000+08:00","We have hit this debate at least 5 times in the last year (when are we going to stop repeating the same discussions over and over again lol), we need to be very specific with terminology. 

MQTT at its very core is only Pub/Sub. So in essence ‚ÄúBy Event‚Äù it‚Äôs up to the client publishing the data if that event is raised by exception (change in value) or some other logic such as a fixed timeframe.

To the point of Arlen in the video, the whole value proposition of MQTT is to move towards Event Driven and implement RBE. Arlen specifically says MQTT assumes RBE, because why wouldn‚Äôt you be using it with MQTT, that‚Äôs one of main value propositions of MQTT. 

I think the confusion comes when we just say ‚ÄúMQTT is RBE by default‚Äù some people take that as meaning as the protocol itself enforces RBE. Which is false  you can obviously publish the same message to a broker with the same data as many times as you want and all subscribers will receive the event.

What I think is meant by Walker and others when they say ‚ÄúMQTT is RBE by default‚Äù is that when you implement MQTT the default mechanism for publishing data should be by RBE, aka you wouldn‚Äôt implement a fixed timeframe publish because that gets away from the whole value proposition of using an event driven protocol like MQTT.","","üíØ (5),‚ù§Ô∏è (2),üëçüèª (1)"
"794020366536146977","mparris","2024-04-14T02:10:20.3770000+08:00","@Zach E FYI, the guy talking in the video is the co-inventor of MQTT: Arlen Nipper üòâ","",""
"568913935147728896","zeratall","2024-04-14T02:10:54.4860000+08:00","Hahaha thanks, I forgot his name and was being lazy ;P. Funny enough we both went to OKstate, small world.","","üòÅ (1)"
"456226577798135808","Deleted User","2024-04-14T02:52:19.2150000+08:00","Exactly this. I really appreciate all this platform has done for the community, but the last year of MQTT vs OPC content has really pushed me away from these platforms lately.
Especially with these vague/inaccurate semantics.","",""
"794020366536146977","mparris","2024-04-14T03:14:20.2760000+08:00","I'm curious to hear your opinion if this article is helpful or adds to the confusion...

https://www.linkedin.com/pulse/how-opc-ua-mqtt-prevent-interoperability-matthew-parris","","üíØ (1)"
"382941357699760129","walker.reynolds","2024-04-14T03:33:00.3670000+08:00","Podcast went great and will be posted Monday.","",""
"435342889875275776","george9330","2024-04-14T03:38:26.2000000+08:00","üôè üëç","",""
"435342889875275776","george9330","2024-04-14T03:38:54.0580000+08:00","I am waiting to hear which historian flag is correct.","",""
"435342889875275776","george9330","2024-04-14T03:40:05.5270000+08:00","node-red-contrib-mqtt-sparkplug-plus is using isHistorical and does not work in MQTT engine. @Walker Reynolds","",""
"382941357699760129","walker.reynolds","2024-04-14T03:40:08.6880000+08:00","Arlen, in the podcast says clearly that MQTT assumes RBE (I think he actually uses the word assumes).  We will post the quote as a short.  To say my statement is factually incorrect is ridiculous.  If I said the MQTT standard requires RBE, that would be factually incorrect.  One of the requirements for the protocol was RBE when it was invented.  To limit what was being sent over the wire.  I agree we are talking past one another but it isn‚Äôt because the facts are wrong ‚Äî it‚Äôs because one side thinks premises don‚Äôt exist unless they are in a spec, the other believes the opposite.  At the end of the day ‚Äî it‚Äôs noise and nothing more.  OPC-UA wasn‚Äôt designed for RBE (even if it supports RBE).  There are 5,000 other requirements OPC-UA is trying to meet before RBE is ever even considered.  ‚ÄòI thought you said OPC-UA was RBE.‚Äô  ‚ÄòOh‚Ä¶ well it is.‚Äô  ‚ÄòWell then what‚Äôs all this other stuff on the wire?‚Äô  ‚ÄòOh‚Ä¶ well it is RBE but‚Ä¶‚Äô","",""
"382941357699760129","walker.reynolds","2024-04-14T04:01:50.3750000+08:00","The OPC and MQTT discussion is important ‚Äî and it isn‚Äôt OPC vs MQTT ‚Äî it‚Äôs not or, it‚Äôs and.  It is important for people to know their IIoT protocol (the communication fabric, mesh, layer) for OT/IT convergence cannot be OPC-UA.  We have two very important questions.  1. Is OPC-UA the future of IIoT? (no, it is not).  2. Is OPC-UA an iiot protocol? (no, it is not).  Those are important questions to answer so sound architectural decisions are made in service of security, scale, common infrastructure and short time to value.  This is not a spurious discussion.  Why do people go from OPC-UA to MQTT5 or Sparkplug and not the other way around?  Why is so little of the OPC-UA spec in use?  Why can‚Äôt anyone point me to the OPC-UA product that simply and concisely proves me wrong?  My DMs are full of people saying I am right and to keep pushing.  I have zero DMs defending OPC-UA.  How does it help your customers if you say, ‚ÄòI am tired of this discussion, I‚Äôm going to ignore it.‚Äô?  You think I WANT to be having this debate?  Nope ‚Äî but I do believe now is the time to push and get new leadership at OPC-F.  I believe now is the time when it can happen ‚Äî so now is the time to have this debate publicly.  I‚Äôm going all the way to end with this ‚Äî and I‚Äôll prove through demonstrations and applications exactly what I mean.  Win the results war ‚Äî don‚Äôt fight theoretical battles.  It‚Äôs time to show the industry where to use OPC-UA and where you MUST convert your your iiot protocol (that cannot be OPC-UA).","",""
"867075936054149191","rickbullotta","2024-04-14T04:09:37.2920000+08:00","AND not OR‚Ñ¢Ô∏è","","üíØ (4),ismile (1)"
"745370232700272661","willsobel.","2024-04-14T10:34:46.6810000+08:00","In Germany you may get another response. I personally want to stay out of the protocol wars since there is never a winner. Personally I find a lot of flaws with both OPC and MQTT. But, what really matters in the end is the data, clear definitions, and semantics. To me it‚Äôs all plumbing and I appreciate a good pipe as long as it works.","","üëç (4)"
"745370232700272661","willsobel.","2024-04-14T14:28:13.2280000+08:00","We used to call RBE delta compression back in the old days. Only report changes. The one piece you need for RBE is a checkpoint that reports the current state of all the variables you‚Äôre tracking. If you combine a number of variables into a single topic, RBE will only report the latest delta meaning you need a rebirth or similar request to resync the stream. We used to refer to this as a state transfer.","",""
"745370232700272661","willsobel.","2024-04-14T14:30:58.7810000+08:00","In MTConnect I made RBE mandatory and the agent enforces it with duplicate checks on the incoming stream. We provide a store and forward buffer where you can request a snapshot of the values at any point and then stream from that point forward. If you lose connection you can continue streaming from the previous point you left off or request a new current and begin streaming again.","",""
"745370232700272661","willsobel.","2024-04-14T14:34:19.6560000+08:00","There are a few limited cases we disable duplicate checks when certain data items are discrete, meaning they have meaning even when duplicated like a door close message or singular counts. That overrides the default RBE behavior. I think the history component of the broker is an architectural responsibility that seems to be overlooked when considering streaming and allows for a REST pattern that unburdens the broker with client session responsibilities.","",""
"568913935147728896","zeratall","2024-04-14T21:27:13.8280000+08:00","Totally agree with your last sentence, most architectures at scale will always have some mixture of design patterns.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-04-14T21:40:40.5260000+08:00","There are also some situations where regulatory requirements mandate values on a (minimum) time basis even if the value hasn't changed.","",""
"568913935147728896","zeratall","2024-04-14T21:49:00.3710000+08:00","Trust me I‚Äôm well aware of that requirement working in DoD, my post earlier I didn‚Äôt mean you always use RBE, I meant if your using MQTT your base case should be RBE, you will always have edge cases, the question then is, is MQTT the right tool for that edge case or should I look into something else to @Will Sobel point.","",""
"745370232700272661","willsobel.","2024-04-14T22:09:56.2220000+08:00","You can easily achieve this by having a subscription to current that will post at a less frequent interval. This is how we did our MQTT implementation. It posts snapshots to one topic and then deltas at a higher frequency to another. You can configure the intervals for each according to your needs. With REST this is trivial to achieve. The new websockets implementation will allow for interleaved subscriptions posting. All The‚Äôs patterns are simple with MTConnect on REST or MQTT. Though with REST you can also specify exactly what data items you want to subscribe to.","","üëç (2)"
"745370232700272661","willsobel.","2024-04-14T22:12:21.6980000+08:00","I used a key-frame pattern when reimplementing MQTT because we ran into performance issues with one data item per topic. Combining all observations like SpB solved the problem, but we needed another solution because I didn‚Äôt want to do a rebirth. The current (snapshots) at a lower frequency seemed to solve the problem. The client just needs to sync the delta stream.","","üëç (1)"
"568913935147728896","zeratall","2024-04-15T00:06:18.5600000+08:00","How many messages was your broker processing? I think that‚Äôs one of the criteria that goes into balancing size/ verbosity of your namespace vs grouping into single topics to me there is a balance there. 

You can actually get into performance issues by having to large of payloads as well.","",""
"568913935147728896","zeratall","2024-04-15T00:30:44.4280000+08:00","Totally agree with flaws in both approaches atm, and 100% agree on the value being on the data and the ease to consume data. Not the protocol itself but how the protocol enables different design patterns for consumption of data.

My personal opinion there are always going to be pro/cons for every design pattern, and a good architect is going to know when to use the right tool for the job. Aka I don‚Äôt think we could ever design a perfect tool that‚Äôs a one size fits all. 

J/c do you agree, or do you think we could make something like that, and if so what gaps from OPC-UA and MQTT should it address?

P.s I know I‚Äôm putting you in the spot but I think in this community a lot of times we like to point out issues but we seldom talk what a solution ‚Äúcould‚Äù look like . I think thinking and discussing the needs of architect is a lot kore valuable instead of just pointing out issues that to be honest we all know.","",""
"745370232700272661","willsobel.","2024-04-15T01:38:19.0870000+08:00","On a large CNC running at about 10 samples per second with 10 axes and with 3 data items per axis for telemetry. Also we have 3 axis positions and other related items. Comes to around 300 items per second. That‚Äôs for a large Okuma or Mazak. We can easily handle that with REST.","",""
"745370232700272661","willsobel.","2024-04-15T01:39:04.1500000+08:00","The problem happened on an additive machine with similar scale and we overwhelmed the broker. I think it was mosquitto.","",""
"568913935147728896","zeratall","2024-04-15T01:39:34.7320000+08:00","You were having broker performance issues with processing 300 messages/s? Something seems off about that, I have brokers that are hitting 100k/msg per second without any issues in performance.","",""
"568913935147728896","zeratall","2024-04-15T01:40:26.9980000+08:00","Was your broker running on a arduino (=P jk of course)? lol","",""
"745370232700272661","willsobel.","2024-04-15T01:43:22.3620000+08:00","It was at an Stratasys and I was going off their info. I had similar scaling issues with data item per topic. I believe Arlen had similar issues as well when I spoke with him and that was why they combined the metrics into a single topic.","",""
"568913935147728896","zeratall","2024-04-15T01:45:49.0840000+08:00","Interesting, there has to be something else at play then, if your deploying a broker to any respectful hardware, then 300msg/s shouldn't even be lifting a finger. You can actually get into issues with Brokers when your payloads are too large because of internal buffersizes.","",""
"745370232700272661","willsobel.","2024-04-15T01:46:45.0860000+08:00","The agent also handles multiple machines. We can have 50 machines on one agent.","",""
"817835202746253344","IIoT#4707","2024-04-15T01:46:45.4300000+08:00","GG @Will Sobel, you just advanced to level 3!","",""
"745370232700272661","willsobel.","2024-04-15T01:47:08.1710000+08:00","Or more","",""
"568913935147728896","zeratall","2024-04-15T01:47:10.6910000+08:00","When you say agent your talking about the broker?","",""
"745370232700272661","willsobel.","2024-04-15T01:47:37.1410000+08:00","No. The MTConnect agent","",""
"745370232700272661","willsobel.","2024-04-15T01:48:14.9930000+08:00","It can publish to a broker or use REST long poll. It also supports UA","",""
"568913935147728896","zeratall","2024-04-15T01:48:18.3570000+08:00","You said you were running into performance issues on the MQTT implementation, so I was asking about that, not the MTConnect design pattern you were talking about earlier","",""
"745370232700272661","willsobel.","2024-04-15T01:48:44.6180000+08:00","This is when we were publishing from the MTConnect agent to an MQTT broker.","",""
"568913935147728896","zeratall","2024-04-15T01:49:06.4090000+08:00","So was your performance issue on the Agent Side or the Broker side?","",""
"745370232700272661","willsobel.","2024-04-15T01:49:12.1740000+08:00","Broker","",""
"745370232700272661","willsobel.","2024-04-15T01:49:45.3830000+08:00","Agent can handle over 100k/second.","",""
"568913935147728896","zeratall","2024-04-15T01:49:58.0670000+08:00","So why are we talking about MT Connect lol, I asked how many messages your broker was processing not the agent","",""
"745370232700272661","willsobel.","2024-04-15T01:50:42.0640000+08:00","Because the agent publishes to the MQTT broker and that was where we ran into issues.","",""
"745370232700272661","willsobel.","2024-04-15T01:52:41.4060000+08:00","The agent is a semantic gateway that supports multiple protocols. It translates from the incoming data from device adapter to the semantic model. It then has multiple sinks it can use to publish. This was in regards to how we publish on MQTT and some design decision we needed to change.","",""
"568913935147728896","zeratall","2024-04-15T01:52:52.0820000+08:00","So 300 msg/s per device, 50 devices per agent, so that should be around 300*50 = 15k msg/s on the broker if I'm understanding you correctly?","",""
"745370232700272661","willsobel.","2024-04-15T01:53:28.4910000+08:00","Around. I don‚Äôt have the numbers with me. I can get back to you when I am at my computer.","",""
"568913935147728896","zeratall","2024-04-15T01:54:02.0880000+08:00","If your having performance issues on the MQTT side and not the Agent side, it could be due to the amount of messages your broker is trying to handle, the size of the messages (internal buffers), the amount of processing done by the broker (encryption, etc), or due to the book keeping the broker is trying to keep with all your retains. Which is why I was asking what KPIs are you actualy seeing at the broker.","",""
"745370232700272661","willsobel.","2024-04-15T01:54:26.6510000+08:00","I think the latter was the issue with the retains.","",""
"568913935147728896","zeratall","2024-04-15T01:54:26.7000000+08:00","KK even 15k msg/s should be easily do able from my experience, I wonder what is actually going on.","",""
"382941357699760129","walker.reynolds","2024-04-15T01:55:00.1160000+08:00","Agreed --  ""A value used when none has been given; a tentative value or standard that is presumed""

When I say by default, I am talking the origin and purpose of MQTT.  It is more work to implement interval or trigger publishes with MQTT than it is RBE.  The path of least resistance is RBE.  Second, the standard was written assuming RBE but leaving the flexibility for 'other'.  FWIW, store and forward would not be possible without the flexibility for 'other' mechanisms.","","üëç (1)"
"568913935147728896","zeratall","2024-04-15T01:55:02.0440000+08:00","Gotcha yeah if your using retains on everything, and you have a large amoutn of subscribers it can definitly impact the performance.","",""
"745370232700272661","willsobel.","2024-04-15T01:55:38.8150000+08:00","I‚Äôm going off my memory, which at the moment is not too precise.  It was over a year ago when we had issues.","",""
"745370232700272661","willsobel.","2024-04-15T01:56:43.0130000+08:00","That rings a bell","",""
"568913935147728896","zeratall","2024-04-15T02:00:17.2020000+08:00","Yep, exactly.  Totally agree, and that's what I always thought when I heard you say ""MQTT is RBE by default"".","","üíØ (1)"
"568913935147728896","zeratall","2024-04-15T02:08:56.3750000+08:00","Hahah yeah I actually hit that problem with another demo I was making for my leadership, I was trying to demonstrate the idea around microservice front ends (GUI Widgets as a Service), and quickly released I couldn't do it with MQTT and retains alone. I had to do it with MQTT + some type of State Store.","","üíØ (1)"
"745370232700272661","willsobel.","2024-04-15T02:10:03.2390000+08:00","Yup. That‚Äôs what made us refactor the MQTT implementation.","",""
"745370232700272661","willsobel.","2024-04-15T02:12:45.0330000+08:00","The  MTConnect agent has a built in state store. It can also handle MQTT as ingress which allows you to use it for caching limited history and reconnecting in case of disconnect.","",""
"568913935147728896","zeratall","2024-04-15T02:13:41.5560000+08:00","Do you have multiple agents integrated to a broker or is it just 1 agent integrated into the broker?","",""
"568913935147728896","zeratall","2024-04-15T02:14:27.1380000+08:00","If its a N:1 relationship, I'd think there would be use cases where you'd want to store the entire state in a central way aka a UNS but persisted so you can avoid the retain bookkeeping issue, but data consumers could still have full context.","",""
"745370232700272661","willsobel.","2024-04-15T02:17:33.6220000+08:00","I have seen all of the above. You can have edge brokers feeding a single agent or multiple agents feeding into a broker delivering data to the cloud. We have had n:n depending on use case, machines, IIoT devices. The agent has multiple sources it supports and multiple sinks depending on application.","",""
"568913935147728896","zeratall","2024-04-15T02:19:42.9600000+08:00","Yeah just thinking as a data consumer applications if I have a N:1 (agent to broker), If I need some type of machine data, along side some type of other application data, I don't want to have to query each state store efor each  agent + the broker state for the application data. If I can store it as a single entity makes it much easier to manage complexity.","",""
"745370232700272661","willsobel.","2024-04-15T02:20:01.6280000+08:00","MTConnect provides a meta model as well. We‚Äôre working on a companion spec with SpB to represent the meta model as templates.","",""
"568913935147728896","zeratall","2024-04-15T02:20:59.6300000+08:00","That's actually the thing I really like about MTConnect for machine integration, is it 'advertises' what data/tags are available, for machine integration  it makes it so much easier then having to strong arm the vendor/machine builder into finguring out what tags/data are actually available and where they are located at in the machine. but when you get into the other domains of the stack outside of the automation layer I think publishing the entire data model over the protocll can start to bloat things, which is why I agree with @Walker Reynolds  for the other layers/areas of the stack you need something more IIoT centric, that's less bloated. (and I know someones going to comment on my bloat comment, when I talk about bloat, I'm talking about how much of the payload actually gets consumed vs is just noise, not network compression)","","üôè (1)"
"745370232700272661","willsobel.","2024-04-15T02:23:56.7980000+08:00","We try to stay out of the fray. I have opinions about protocols from my years in finance developing trading system infrastructure. Many of the same issues just back in the 90s when we had a a few hundred megahertz and slow networks.","",""
"568913935147728896","zeratall","2024-04-15T02:25:13.3630000+08:00","I actually appreciate your opinonions, this type of perspective sharing is the only way to learn from each other imho. and imho perspective sharing isn't just complaining about the issues, but actually sharing how we ""think"" about problems.","","üíØ (1)"
"382941357699760129","walker.reynolds","2024-04-15T02:30:06.2840000+08:00","I think one of the primary issues we have suffered from in our industry is not enough people sharing their opinions about tech and applications.","","üíØ (3)"
"745370232700272661","willsobel.","2024-04-15T02:32:15.1500000+08:00","Can‚Äôt agree more!","","ismile (1)"
"855607029518434314","hiptopjones","2024-04-15T05:05:45.3240000+08:00","Me too, but to your previous point, we have had this discussion so many times because the marketing speak doesnt match the actual product specs.  Again, I get what it ‚Äúmeans‚Äù, but every new person needs this rosetta stone moment.  Honestly, i have no horse in this race.  I was just trying to shine another perspective on the conversation.","","‚ù§Ô∏è (1)"
"944630646821773392","m_r_mccormick","2024-04-15T06:23:23.0190000+08:00","When you say 'telemetry', are you referring to telemetry in the IT sense, or that there are multiple data items in the axis component stream? Also, is the key-frame pattern you used to get around performance challenges similar to video i-frames/p-frames/bit-masking/sparse-matrices (but groups published in a single payload) or something different? And if a current subscription is running on top of this, won't you still end up potentially losing data in comparison to a sample subscription?","",""
"867075936054149191","rickbullotta","2024-04-15T06:25:11.3830000+08:00","@Will Sobel @Zach E  keep in mind that most brokers are monoliths and have to handle ingest, persistence (if retained or higher QoS) and of course broadcasting to subscribers.  Just knowing ‚ÄúX messages per second‚Äù isn‚Äôt enough to assess performance expectations.","",""
"568913935147728896","zeratall","2024-04-15T06:27:27.8330000+08:00","Correct, which is why I called out some of the other KPIs that can affect performance, https://discord.com/channels/738470295056416930/1166016853991235594/1229127541957333042. the question around msg/s was to understand what scale we were talking about.","","üíØ (1)"
"944630646821773392","m_r_mccormick","2024-04-15T06:31:32.2510000+08:00","Could you please share some insights or tips on how to convey ideas and opinions in a constructive manner which facilitates discussion and meaningful outcomes?","",""
"382941357699760129","walker.reynolds","2024-04-15T07:11:54.7460000+08:00","This depends on your goal.  If you are trying to disrupt or transform ‚Äî then you need engagement first and foremost.  So, use what you can to get the engagement and then debate the merits.  If you are looking to diffuse knowledge, find collaborators and discuss nuances of positions ‚Äî then you are best suited stating a hypothesis and then demonstrating what you believe is the evidence for and against.  ‚ÄòConstructive‚Äô is a relative term and dependent on the goals.  My general rules are: 1. Know the audience 2. Know what you want to accomplish 3. Stick to facts 4. Be fair 5. Have an escalation plan (how hard am I willing to push, why, when and how?)","","üëç (2)"
"382941357699760129","walker.reynolds","2024-04-15T07:16:23.2050000+08:00","One of the best ways to convey an idea or concept is to do it in the context of your audience‚Äôs problem.  Even if it‚Äôs an audience of 1.","","üëç (2)"
"745370232700272661","willsobel.","2024-04-15T09:29:52.6140000+08:00","Telemetry is shorthand for the position and high frequency data that changes when the machine is in motion.","",""
"745370232700272661","willsobel.","2024-04-15T09:32:12.2010000+08:00","The keyframe concept is from video CODECs that emit a complete frame and then deltas to that frame. If you loose the stream, just sync on next keyframe.","",""
"745370232700272661","willsobel.","2024-04-15T09:34:46.2020000+08:00","The next sequence in the current topic aligns with the sample stream coming on the sample topic. First subscribe to sample topic. Next subscribe to current topic. Wait for next current and record next sequence. Discard all samples with sequence before next sequence and then apply deltas.","",""
"817835202746253344","IIoT#4707","2024-04-15T09:34:46.5620000+08:00","GG @Will Sobel, you just advanced to level 4!","",""
"745370232700272661","willsobel.","2024-04-15T09:42:25.3280000+08:00","What I‚Äôve always found most helpful is taking a step back and looking at the problem from an architectural perspective. That means removing the individual implementation concerns and seeing what is actually required to add value and solve problems. Getting stuck on one way to do something usually leads to brittleness and suboptimal results. You also need to remove your ego from the discussion. I‚Äôve been doing architecture for decades and it always comes down to how we understand separation of responsibility between systems and then mapping to the best solution at the current time given all our constraints. Never a one size fits all. That‚Äôs why it‚Äôs good to have open discussions about any technology or solution space.","","üôè (1),üíØ (1)"
"745370232700272661","willsobel.","2024-04-15T09:45:22.8070000+08:00","Then you can unsubscribe to the current topic.","",""
"944630646821773392","m_r_mccormick","2024-04-15T10:21:14.9610000+08:00","Thank you Will, much appreciated. I'll be back in touch soon.","",""
"794020366536146977","mparris","2024-04-15T10:27:45.3650000+08:00","@Will Sobel To make sure I'm following... When you say Delta for MTConnect, which of the following are you referring to: 

Key frame: temp =100

The temperature changes to 120:

Option 1 -- relative delta: temp=20, 

Option 2 -- absolute Delta: temp=120

I'm not familiar enough with video codecs... But I could see both of the two methods being possible... Key frame has all the pixels, and subsequent frames have an absolute definition of changed pixels or subsequent frames have definition relative to the key frame  of changed pixel","",""
"944630646821773392","m_r_mccormick","2024-04-15T10:40:09.3000000+08:00","To reduce file size and bandwidth, videos have p-frames and i-frames. There is a ratio between i-frames to p-frames. I frames contain all the information necessary to render an image. p-frames contain only the information that is different. So, if you want to construct an image from a p-frame, you need previous frames. For i-frames, you don't need any other frames. This is similar to full, incremental, and differential file backups. However, I'm not sure whether incremental or differential is applicable here depending on the implementation. But, with respect to the number being absolute or relative in your example, it will be absolute. MTConnect uses 'current' requests to snapshot variables at a given point in time, which would be similar to an OPC UA polling read, and can miss rising and falling edges if polled continuously. In tandem, it has 'sample' requests which can report multiple observations, and does capture rising and falling edges.","",""
"944630646821773392","m_r_mccormick","2024-04-15T10:43:04.2430000+08:00","If you have a 10 ratio for video, you'd have 1 i-frame, followed by 9 p-frames. If you use a RTSP feed or similar to monitor manufacturing processes, this is how the data is streamed, but if you use a client like opencv, it will sort that out for you and feed you the full frames. So, you just get full images out of an opencv client. But, if you see a bunch of artifacts then they go away, it likely dropped some p-frames and fixed itself (or 'synced') on the next i-frame.","","üíØ (1),üëç (1)"
"568913935147728896","zeratall","2024-04-15T11:42:36.7930000+08:00","Totally agree, well said.","",""
"742129646593638505","pocsgeza","2024-04-15T13:41:21.8960000+08:00","I have client that owns multiple small manufacturing operations spread out to multiple companies.
There are many control solutions that each support a large machine or line. The software and the database are located close to the machines they support. The software is more or less a black box and we have a user to the database with read only access.
When asked about connectivity the system vendors said we should poll the database and get the data we need that way. This is a repeating pattern within the companies.
We would like to get events in the form of MQTT messages from the system. Options for an intermediary solution considered are:

Option 1:  Write a small program that is dedicated to a DB. It would handle the pooling logic and send messages when events are detected.

Option 2: Same as Option 1 but the small program would send the message to a message queue so loosing connection between buildings can be mitigated.

Option 3: Build queries that would identify the events we are interested in. Have a DB client that opens and keeps open a connection with an SqlDependancy (like https://learn.microsoft.com/en-us/dotnet/framework/data/adonet/sql/detecting-changes-with-sqldependency?redirectedfrom=MSDN). Every time the we have a new query result we evaluate if it is an event and send an MQTT message when needed.
This approach would avoid polling ,the DB would notify us of the change. This appears fragile and would require slightly different approaches for each DB vendor.

Option 4: Convince the system vendors to put everything that can be considered an externally relevant event into an Outbox table (outbox pattern). We could then pool that table and turn the events it into MQTT messages. 

Option 5: Avoid polling and use some Change Data Capture approach. Maybe Debezium.","","üëå (1)"
"742129646593638505","pocsgeza","2024-04-15T13:41:27.1740000+08:00","The approach should ideally be configurable to work with multiple database backends.
We have an internal C# development team that can handle implementation.

NOTE:
This would be a solution for the foreseeable future. Once we put together MRTs and have management backing then we can go to each vendor to implement them and move away form database integration for production events.

Any advice or best practices are very much appreciated.","",""
"766684226455207996","bright_hummingbird_31342","2024-04-15T15:13:47.0100000+08:00","Been there, done that.  Before going down any of these paths, first verify that there is relevant data is in those databases.  It shouldn't just be discrete events without context.  If it is, the client needs to adjust their expectations.  Their options to pursue outcomes like predictive maintenance, predictive quality, etc are going to be limited without any numeric data.

I see this happen among contract manufacturers.  In the electronics industry, for example, the suppliers will often adopt the industrial automation of their OEM customers' supply chain standard.  They don't know much about the inner workings of their machines.  They mostly rely on the machine builder and integrators.  The machines might have some embedded database and file system with basic event logging.  This might be a enough to do a really primitive OEE about the asset itself, but it won't be terribly useful for operations.  A lot of use cases will require a bigger picture.

In my biased opinion, this is a good application for HighByte.  The SQL connectors support stateful indexing as well as, currently for MS SQL and PostgreSQL, Change Data Capture (CDC).  Both of these will help with the polling problem and picking up events from the database.  If you aren't expecting any late arriving or modified data, backfilling with an index is probably the way to go.  With each successful publish to the broker, the indexing will drive the next round of reads from the database.  CDC is a good option if you need to track more transactions (e.g., updates) than just new rows being inserted.  Either way, this is probably a good foundation to get some quick wins with the data that is available today.  As the use cases evolve, this can be supplemented with other data beyond the databases.

You mentioned there was read only access.  It's worth mentioning that for CDC to do its thing, it has to be enabled in the database and exposed to the client to monitor.  Hopefully, the databases can be configured for this.","","üôè (1)"
"766684226455207996","bright_hummingbird_31342","2024-04-15T15:22:54.3580000+08:00","To sum it up:
1) Determine if the databases are even worth reading to solve the client's problems.  If not, make it clear it's not the shortcut they thought it would be.
2) Determine what the nature of the database transactions are (e.g., new events, revisions, late arriving).
3) Determine if CDC can be enabled for the database tables of interest.
4) Explore longer term options for alternative data acquisition (e.g., machine API, vendor supplies a gateway exposing registers, deploying secondary sensors).","","üôè (1),üëç (1)"
"742129646593638505","pocsgeza","2024-04-15T15:23:58.5780000+08:00","Thank you. üçª","","üçª (1)"
"745370232700272661","willsobel.","2024-04-15T17:21:46.8170000+08:00","Simply the new value. Not like a CD encoding. Just publishes changes.","",""
"745370232700272661","willsobel.","2024-04-15T17:24:53.6060000+08:00","Well stated. That‚Äôs how our MQTT implementation is designed to work.","",""
"745370232700272661","willsobel.","2024-04-15T17:33:50.4280000+08:00","We found that a lambda architecture with Complex Event Processing to identify intervals and then store in both time series and NOQL databases preferably with columnar compression was a good mix. SQL was slow when storing time series. Ok for intervals. By intervals I‚Äôm identifying significant time period when something happened. Producing a part, downtime, alarm active, etc. The raw data can be queried from a time series database using the interval to drive analytics using something like Allen‚Äôs interval algebra.","","üëç (1)"
"742129646593638505","pocsgeza","2024-04-15T17:40:42.1790000+08:00","Lambda architecture with Complex Event Processing is new concept for me. I will read up on it.","",""
"745370232700272661","willsobel.","2024-04-15T17:50:36.8070000+08:00","They are some good patterns to check out. Can discuss later if it‚Äôs relevant to your architecture.","",""
"447710422603137025","im_glib","2024-04-15T21:22:33.6380000+08:00","I think you are exactly right. That is exactly how I took it. I was even wondering if it went against the protocol specifications to publish the same value twice.

There are a lot of linguistic and mental gymnastics that go on in this area to justify a particular belief or mantra, when a simple clarification is all that is required (on both sides). Alas, simple clarifications aren't sexy.

One thing I have noticed, is that most of the example videos out there all implement a fixed timeframe publish - which as you point out is against one of the value propositions. *I assume this is because it is easier to implement report on interval. A single section of code to publish all the tags at once is less code than filtering out values that didn't change - but even that people wont agree with*. If you do find a good video, please let me know!

I can definitely say I've had my eyes opened in the last week as to what needs to be taken with a grain of salt and what doesn't. üòÇ Comments like yours are valuable!","",""
"382941357699760129","walker.reynolds","2024-04-16T02:27:59.6710000+08:00","In simulations ‚Äî it‚Äôs easier to loop through a series of variables, assign new values and publish.  This is because we don‚Äôt have instruments in the field generating a rising edge for us.  Once we are connected to an instrument through IO, the path of least resistance is on the rising edge after the threshold.  I find myself doing this all the time because I‚Äôm just building a quick ‚Äòdemo‚Äô.  I see how it confuses those who are new to MQTT and/or pub/sub.  üôè","","ü§î (1)"
"456226577798135808","Deleted User","2024-04-16T04:25:33.1630000+08:00","@Will Sobel Thank you for this insight. I recently had to ingest data from an MTConnect enabled machine, but did not have the privilege to work in front of the machine physically. So there was a lot of offline testing with sample data. I personally, found it very difficult to understand the difference between probe, current, and sample data (many many hours spent reading online).  Eventually, listening to this YouTube video while on a run helped the probe and current data use cases click. (Which I realized just now was you üôÇ haha thanks!)

https://youtu.be/87vnkHc-zd8?si=SgFGMITv_tv_0ILF","",""
"456226577798135808","Deleted User","2024-04-16T04:28:50.0470000+08:00","For the time being, getting data was the primary objective. However, long term, would like to understand a more efficient way to ingest data. 
I'm concerned with long polling the http endpoints. I saw MQTT is available in v2+. I am going to try to perform some hands on simulation test locally to see if I can better understand it. Going to try starting with this,
https://github.com/mtconnect/cppagent","",""
"456226577798135808","Deleted User","2024-04-16T04:37:21.1560000+08:00","Your explanation of the sample data here helped a lot. I wasn't sure what the use case was previously. 
Was the intent of this sample data for video rendering specifically?
Would it be safe to say only current data is needed if you are looking for the latest realtime data updates and have a tolerance for a few potential intermittent data drops?","",""
"740383178279354388","mriiot","2024-04-16T05:40:42.5680000+08:00","Yes, if you query current every x seconds and dont care what might have happened between those x seconds then look at current.","","üëç (1)"
"447710422603137025","im_glib","2024-04-16T08:36:48.4950000+08:00","Hmm. ü§î I'm not really sure what what you are getting at here. At the very least I don't think ""loops/arrays make RBE difficult"" is a good take, although maybe that isn't what you are saying. I'm not really sure what you mean by ""path of least resistance"" in this context.

To me, RBE at the very least requires memory of and a check against the last value published. Next, I would also want the options of Deadband settings (e.g Absolute/Percentage/None), then probably minimum and optionally maximum times between updates. A mechanism for forcing all values to be published on request would be nice as well. 

I am not suggesting these are 'hard' or insurmountable in any way at all, but in terms of coding - to me - they are an order of magnitude or two more complicated than just publishing on a fixed interval.

The flexibility allows for a trade off between bandwidth usage and development time. This is a good problem to have! I would rather have the ability to do what I want for my application, rather than be forced one way or another.

So, I would think that  publishing at a fixed interval is the path of least resistance - but it doesn't mean that it is correct for every application, just less work to code now and you may pay for it down the line.","",""
"707320353696907366","du0ne","2024-04-16T16:04:27.1950000+08:00","@Walker Reynolds I have been digging into this mqtt & uns rabbit hole and besides your videos, I also cam across this one: https://www.youtube.com/watch?v=MtctNd8XBlM","",""
"707320353696907366","du0ne","2024-04-16T16:04:42.8190000+08:00","I would be keen on your analysis and recommendations for them?","",""
"745370232700272661","willsobel.","2024-04-16T16:43:39.5670000+08:00","Maybe it‚Äôs time to publish some new videos. A lot has changed and there are a lot of new capabilities.","","üëç (2),‚ù§Ô∏è (1)"
"745370232700272661","willsobel.","2024-04-16T16:49:37.0000000+08:00","Many times it‚Äôs the API that forces you to poll. PLCs are notoriously bad at publishing events. They also work on a fixed sweep rate. NCs are not much better. The APIs are generally designed to drive HMIs so they didn‚Äôt consider the use case of data collection. You can see it in their design. This makes data collection a pain. If it was event based, many of the adapters I wrote would be trivial. Unfortunately they were unexpectedly hard to write and finding data was a treasure hunt through 100s of pages of docs and symbol tables.","",""
"475955754788978688","jdingus","2024-04-16T16:53:31.5010000+08:00","Videos showcasing setting up MQTT I think would be extremely valuable @Will Sobel","",""
"745370232700272661","willsobel.","2024-04-16T16:57:59.4580000+08:00","I‚Äôll add it to my queue. Adding websocket support now and have a few ontology projects I‚Äôm working on.","","üî• (2)"
"801561312861618236","jon.forbord","2024-04-16T18:56:46.5840000+08:00","I‚Äôm right here dude üòÇ what did you want to know more specifically?","",""
"707320353696907366","du0ne","2024-04-16T18:57:45.6160000+08:00","Direct is good üôÇ","",""
"707320353696907366","du0ne","2024-04-16T18:58:34.3750000+08:00","I am curious some of the issues you brought up does not seem trivial.","",""
"707320353696907366","du0ne","2024-04-16T18:59:02.3760000+08:00","I am in the ThingWorx world and I am exploring other perspectives","",""
"817835202746253344","IIoT#4707","2024-04-16T18:59:02.6710000+08:00","GG @du-one, you just advanced to level 1!","",""
"801561312861618236","jon.forbord","2024-04-16T19:07:25.7370000+08:00","They kind of are both trivial and not. Most of them were intermittent or happened at point in time. Some are more weaknesses that can cause problems in some scenarios. Which did not seem trivial to you?","",""
"867075936054149191","rickbullotta","2024-04-16T19:08:02.4700000+08:00","I‚Äôve been looking for a GIF of a dead horse being beaten‚Ä¶","","üòÇ (1)"
"707320353696907366","du0ne","2024-04-16T19:09:25.6800000+08:00","Ok I get it.","",""
"707320353696907366","du0ne","2024-04-16T19:12:20.5870000+08:00","There you go: https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExNmU3NmtsYXc5MTRtc2dzMHQ0dHNubHFvaWwwdjdncDBjNGQ5bmoyNSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/eXr5iHQEq9oQx4dbKE/giphy.gif","","ü§£ (1)"
"801561312861618236","jon.forbord","2024-04-16T19:12:32.5050000+08:00","Dont use SpB for more than SCADA-type use cases, and it doesnt scale above a certain level due to some of the issues I mentioned. Rick has many good points but in his world if it isnt anything other than what he‚Äôd want it to be, its useless. I disagree with that. It can be useful, but dont overextend Sparkplug.","","ü§£ (2)"
"707320353696907366","du0ne","2024-04-16T19:16:06.7380000+08:00","So here is a simple scenario: I have a machine with 1 PLC and around 1200 tags. I want to make the data available to a cloud solution (used internally by R&D and Support & Service team internally) but also to my end user (for line management and general overview) and finally to my end user's OT team for plant integration.","",""
"707320353696907366","du0ne","2024-04-16T19:17:37.0670000+08:00","I have a good idea of what I would do with the tools I am used to , but if I wasnt constrained to those, or wanted to follow the mqtt / uns approach, what could that look like?","",""
"707320353696907366","du0ne","2024-04-16T19:18:05.3810000+08:00","Oh and I have several hundred of those machines in the field","",""
"707320353696907366","du0ne","2024-04-16T19:48:23.2180000+08:00","And to add to the above, where and how would I store the data without losing or duplicating it.","",""
"867075936054149191","rickbullotta","2024-04-16T19:50:37.7330000+08:00","...and strangely appropriate for the above discussion.","",""
"707320353696907366","du0ne","2024-04-16T19:51:13.4580000+08:00","Only if it is not your first horse?","",""
"867075936054149191","rickbullotta","2024-04-16T19:51:26.2110000+08:00","Ha - I have no issue with SpB being used for SCADA use cases. But that's about it.  So apparently we completely agree!  Again.","",""
"801561312861618236","jon.forbord","2024-04-16T19:53:26.2930000+08:00","Good clarification. When I think twice about it, I do already know that, but the way you communicate can sometimes make it sound like its not the case üôÇ","",""
"867075936054149191","rickbullotta","2024-04-16T19:57:42.4550000+08:00","That's not true. Go f*ck yourself. üòâ","","üòÇ (4),ü§òüèª (1)"
"707320353696907366","du0ne","2024-04-16T19:58:46.6430000+08:00","I thought this was a safe space! üòú","",""
"817835202746253344","IIoT#4707","2024-04-16T19:58:46.9770000+08:00","GG @du-one, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2024-04-16T19:59:03.9990000+08:00","@Jon Forbord  knows I'm joking.","","üëç (1)"
"707320353696907366","du0ne","2024-04-16T19:59:18.1510000+08:00","Assumed","",""
"794020366536146977","mparris","2024-04-16T20:10:27.4620000+08:00","Thanks. Now I have coffee everywhere...","","ü§£ (3)"
"568913935147728896","zeratall","2024-04-16T22:42:24.3250000+08:00","Really glad I‚Äôm not the only one trying to implement cloud native design patterns into mfg. I‚Äôve been spending a lot of time playing/developing around  a lot lately with some serverless design patterns that could be implemented for MFG, really exciting stuff, another area I‚Äôve been playing around is IaC, have you done much with IaC? If so would love to pick your brain and see what your thoughts are around IaC for MFG environments.","",""
"794542235676180500","akoscs","2024-04-17T03:20:24.0850000+08:00","What is the difference in rising edge on real data and rising edge on simulated data?","",""
"382941357699760129","walker.reynolds","2024-04-17T03:24:35.5470000+08:00","In simulation, you create the rising edge of all variable changes in code ‚Äî so the path of least resistance is to create a list of variables and then a for loop that iterates through and randomly assigns a new value.  So ‚Äî it‚Äôs technically RBE because the value always changes ‚Äî but it‚Äôs not the same mechanism you would use for live instrument data.  You would capture the change and publish.","",""
"794542235676180500","akoscs","2024-04-17T04:44:45.1300000+08:00","Nah. A signal is a signal. At the end you get a digital value and compare it to a past value (or past values). I never saw an industrial (control) system doing HW edge detection. Does not matter if the value is simulated or real. For control systems (PLC, CNC, RC, MC) you have such functionality built in, I give you that, but ... fro simulations ... you can implement the same thign in 5-10 minutes (probably waay less)... and it literally is the same thing. Looping though a signal or looping thtough a signal and having an edge detection should not be that much of a difference.","","üí° (1)"
"382941357699760129","walker.reynolds","2024-04-17T06:16:56.4810000+08:00","We are not dealing with a signal in simulation, we are dealing with a variable that we control.  I KNOW it changed because I programmed it to change.  I don‚Äôt have to check in simulation.  And ‚Äî I decide when it changes in simulation.  There is no instrument to ‚Äòlisten‚Äô to.  While I CAN use the same program for both, the path of least resistance is what I outlined.  Humans, generally take the path of least resistance ‚Äî even if they shouldn‚Äôt.  This is a foundational principle of occupational psychology.  üôè","",""
"382941357699760129","walker.reynolds","2024-04-17T06:19:19.6530000+08:00","Most of the time, when you ask yourself, ‚Äòwhy did they do it that way?‚Äô  The answer generally is, ‚Äòbecause they are human.‚Äô  üôè","",""
"382941357699760129","walker.reynolds","2024-04-17T06:22:13.7290000+08:00","I have two demos I‚Äôm presenting to InfluxDB team tomorrow ‚Äî one is an edge demo and one is an enterprise demo.  I am using programmatic and hardware simulators ‚Äî and all of them start with a list of variables and iterate through at n interval and assign new values before publishing.  Why?  Because the goal isn‚Äôt to simulate an instrument - it‚Äôs to demonstrate a use case and solution.  The goal can be achieved with the path of least resistance ‚Äî so path of least resistance it is.","","üëç (2)"
"794542235676180500","akoscs","2024-04-17T06:31:15.6350000+08:00","OK, I get what you are saying, you do not use edge detection because you have a program/function/procedure/whatever that generates new values every time you call it, and you do not really care, because edge detection is not important for your demo. This is exactly what is confusing in some cases, but again your demo is not about that part of the report  by exception. OK. Wether or not time-out is an exception...that is topic already debated on the channel with no convincing conclution","","üíØ (1),ismile (1)"
"382941357699760129","walker.reynolds","2024-04-17T08:20:18.0210000+08:00","Right -- it is report by exception because we know the value changed before we published it and we are always publishing when the value changed -- because that is what we programmed it to do.","",""
"745370232700272661","willsobel.","2024-04-17T10:08:13.3560000+08:00","I‚Äôve been thinking of physical IaC patterns with equipment for a while, if that‚Äôs what you‚Äôre pondering. It was part of the choreography architectural ideas we did in a project for NIST where we would allow machines to select jobs based on capabilities. Some of the same ideas. I like taking cloud patterns and seeing if they can apply to physical systems. Keeps me off the streets.","","üëç (1)"
"568913935147728896","zeratall","2024-04-17T12:03:52.7450000+08:00","Yep exactly, something I‚Äôve been playing around with a lot lately as well.","",""
"794542235676180500","akoscs","2024-04-17T14:47:36.5450000+08:00","I find the azure IoT reference architecure helpful: https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/iot","","üëç (1)"
"447710422603137025","im_glib","2024-04-17T16:19:11.5200000+08:00","(have I been shadow banned from the most YouTube podcast? Not accusing anyone of anything, just curious. I posted two comments, it looked like one was deleted so I tried again and it isn't showing. Weird!)","",""
"1088631859509989426","jpmac.s","2024-04-17T17:01:42.1200000+08:00","Your comment is in the comments section.","https://cdn.discordapp.com/attachments/1166016853991235594/1230080739412807701/Screenshot_20240417_190246_YouTube.jpg?ex=68dee836&is=68dd96b6&hm=70e34b644ac95d8c860dfc93e26c7843e6b79e37c84188ea20d3615f13bc0deb&",""
"447710422603137025","im_glib","2024-04-17T17:06:22.5770000+08:00","Thanks! There was another one, and then two separate test replies I made to that. Maybe there was a problem on my end. Thanks!","","üëç (1)"
"794020366536146977","mparris","2024-04-17T20:38:45.7230000+08:00","I've found that Youtube will hide comments by default, but selecting the filter at the top and changing from ""Most Relevant"" to ""Most Recent"" will show all the comments in reverse chronological order.  And LinkedIn does the same thing, too.","","ü§ï (1)"
"447710422603137025","im_glib","2024-04-17T20:40:59.1570000+08:00","Thanks. Yeah, still not there. Not a big deal - they weren't anything too valuable! üòÜ","",""
"447710422603137025","im_glib","2024-04-17T20:41:37.9940000+08:00","P.s - nice job in the podcast!","","üëç (1)"
"1031940518730543106","thunt.career","2024-04-17T21:01:04.7250000+08:00","Go on...I am very curious of use cases and implementation you've been doing","",""
"568913935147728896","zeratall","2024-04-17T22:15:31.0650000+08:00","Hahaha glad other people are interested in the topic as well. Im a bit slammed with irl work atm but this evening I can walk through some of the pilots,use cases, and lessons learned around IaC for mfg.","","üëç (1)"
"794020366536146977","mparris","2024-04-17T22:30:52.0210000+08:00","Are these the comments you're talking about?","https://cdn.discordapp.com/attachments/1166016853991235594/1230163576476667964/image.png?ex=68df355b&is=68dde3db&hm=6ad94e4edfd029773683bbd9df479591c4472619acd96f8f982cf3710b96ab3e&",""
"1031940518730543106","thunt.career","2024-04-17T23:02:59.5100000+08:00","Works great for industrial DMZ with the stateless services and env or config files. I'm specifically interested in any serverless applications at the edge","",""
"867075936054149191","rickbullotta","2024-04-17T23:35:40.9630000+08:00","Have you looked at DAPR?","","üëÄ (1)"
"867075936054149191","rickbullotta","2024-04-17T23:41:02.2940000+08:00","https://docs.dapr.io/concepts/overview/","",""
"447710422603137025","im_glib","2024-04-18T00:17:15.8540000+08:00","Nah, they were test comments I tried later on. All good! Must have been some other issue.","",""
"568913935147728896","zeratall","2024-04-18T00:46:06.7310000+08:00","Oh gotcha the Serverless we are doing is in the cloud, we don‚Äôt do any serverless on the edge because we aren‚Äôt using something like outpost","",""
"1031940518730543106","thunt.career","2024-04-18T01:56:29.9210000+08:00","Is that for vision or process optimization? I was curious if you were exploring serverless for any traditional MES functions like scheduling or something.","",""
"568913935147728896","zeratall","2024-04-18T03:18:36.6130000+08:00","Most of the use cases we have used serverless is around Analytics we haven‚Äôt explored using lambda to replace MES functions but that‚Äôs a cool idea.","",""
"453944368751968277","vastcnc","2024-04-18T04:18:40.4740000+08:00","I‚Äôve been interested in the Elixer language for a different type of project and ran into this paper using MQTT, EMQX, and Elixer for edge computing in traffic systems. I thought it may be interesting here. https://www.mdpi.com/1999-5903/16/3/81","",""
"720517384611561535","ravi0493","2024-04-19T18:34:30.6670000+08:00","How do you call OPCUA Access Subscription to be Report by Exception when the consumer makes the initial request ?? It is still Poll response am i missing something ?","",""
"794020366536146977","mparris","2024-04-20T06:52:12.2270000+08:00","A data consumer must always initialize the first connection to a server. 

The data consumer must also tell the server what data it is interested in.

Report by exception is referencing the feature after the initial handshaking to only receive changed data.

OPC UA Data Access Subscription has the advantage of the client being able to apply data change filters... Such as, only send me data that is different by 0.5 and only send me those changed data with a max rate of every 10 seconds, and queue up to 5 values before your send it.

MQTT has the advantage that Message Brokers are very common when using the protocol, which means that the data consumer doesn't need to initiate a connection for every data source accelerating integrations.","","üëç (1)"
"720517384611561535","ravi0493","2024-04-20T17:49:41.8430000+08:00","what happens in MQTT if there are 4-5 consumers of the same topic space and each consumer looking forward for data at different interval with different band width change. What happens if 2 of them fails who stores the data for both failed consumer with different demand cycle and different limit change?","",""
"794020366536146977","mparris","2024-04-20T20:09:55.2630000+08:00","MQTT does not have a capability for managing different subscription requirements for the same topics.

Regarding store and forward for different clients, I'm only aware of using a subscription QoS =2 so if a client disconnects, the broker can resume the message queue.  Although if store and forward is of interest, something like Kafka would be better.","","üëç (1)"
"1088631859509989426","jpmac.s","2024-04-20T20:15:49.2110000+08:00","Feels more like a mqtt trivia question ü§îü§£","",""
"801561312861618236","jon.forbord","2024-04-20T20:51:40.2120000+08:00","Sounds like you should use Kafka or some other message queue..","",""
"801561312861618236","jon.forbord","2024-04-20T20:55:10.1280000+08:00","Opc ua => mqtt = awesome! Use OPC UA at the edge to setup sample rate and deadbands, and publish to mqtt to get edge driven, report by exception. ++","","üëç (1)"
"801561312861618236","jon.forbord","2024-04-20T20:58:50.7610000+08:00","There is a difference between Edge driven and report by exception. Edge driven means the connection is instantiated from the edge, and the data is pushed from the edge, while report by exception means not reporting what has not changed. So in my mind OPC UA data access is not Edge driven (yes, I‚Äôm aware of reverse connect), but subscriptions are report by exception (ish).","",""
"1073312001788477471","sparkylarks","2024-04-20T22:00:40.3480000+08:00","I think that is sort of exactly 100%ish correct.","",""
"720517384611561535","ravi0493","2024-04-21T00:47:36.5430000+08:00","You are correct , a better word could be supporting **Unsolicited ** data transfer.  MQTT supports Unsolicited data transfer and RBE is kind of subset of it !","",""
"720517384611561535","ravi0493","2024-04-21T00:48:40.9980000+08:00","Please educate me , what would you do in such a case ?","",""
"817835202746253344","IIoT#4707","2024-04-21T00:48:41.2950000+08:00","GG @Ravi.S, you just advanced to level 1!","",""
"720517384611561535","ravi0493","2024-04-21T01:00:26.5410000+08:00","If the IIoT Platform has naive driver implemented and the PLC protocol supports Unsolicited outputs then there would be no need for OPCUA Server and its overheads  ,compared to native driver developed on the basic platform, latency can further go down starting from the real EDGE (PLC /DCS or any microprocessor controller / sensors achieving faster data transfers.","",""
"720517384611561535","ravi0493","2024-04-21T01:05:50.0890000+08:00","How many levels do we have and how to check who is at what level ? üßê","",""
"817835202746253344","IIoT#4707","2024-04-21T01:05:52.5820000+08:00","Ah, a fine inquiry indeed! The number of levels within this realm is a mystery, much like the depths of a medieval dungeon waiting to be explored. To uncover the levels of your fellow companions, simply command the noble MEE6 with the phrase ""!levels"" and the information shall be revealed to you, much like a treasure chest yielding its precious contents to a valiant knight.","",""
"1057737574287945899","xamp4248","2024-04-22T00:51:02.4930000+08:00","@Ravi.S what do you mean native driver?","",""
"720517384611561535","ravi0493","2024-04-22T15:20:12.7560000+08:00","Every PLC/ DCS etc has their own prop Communication protocols following different layers of  OSI stack, for intercommunication with their own systems or next layers like SCADA etc,  starting from Physical layer, one can get data writing a C / C# code in any system to extract this data from those PLCs WITHOUT ANY OVER HEAD OF standard implementation . for example ONE PLC TALKING TO ANOTHER PLC of the same make does not communicate over OPC but on native implementation  inside the PLC OS. Now For compliance/  standardization  purpose so that any one could talk to the PLC /DCS ..etc without rewriting the code, OPC standards were implemented so that clients applications could be changed easily to achieve plug ad play but that adds an extra overhead to process it. The quickest and the fastest way to extract data is to write native code or driver for that specific  protocol.","",""
"1057737574287945899","xamp4248","2024-04-22T16:51:33.6140000+08:00","More than 500 proprietary control devices exist, each following its own standards, resulting in vendor lock-in. Then How the interoperability with native drive possible?","",""
"720517384611561535","ravi0493","2024-04-22T17:37:00.3250000+08:00","That is why SUDO standards have been created such as MQTT or OPCUA BUT at application layer ( some even below levels also like session layer , presentation layer etc.) each protocol is still different , you cant MAKE ROCKWELL PLC to talk To Siemens PLC directly over cable . Can you without these standards ? Every OEM still has his own protocol for intercommunication.","",""
"720517384611561535","ravi0493","2024-04-22T17:42:09.5060000+08:00","There is a committee setup to make a vendor neutral hardware , i forgot the name , they are building standards for vendor neutral hardware  , One can buy the hardware from any manufacturer and it shall be compatible to the standard bus structure , similar to what you have in PC world like ISA , PCI , ePCI etc busses .... Not sure about the Microprocessor levels because each manufacturer has his own designed CPU and the Mother BUS ( Back plane or inter plane communication to other cards.","",""
"720517384611561535","ravi0493","2024-04-22T17:45:32.9380000+08:00","Where is the need for interoperability at edge levels ? You are still using different UA servers for each type of Edge controller !! Can you use Siemens OPC UA server to extract data from Rockwell PLC ?? What portability are you asking about ? The native driver is only compatible to he native Platform you use, whose platform are you using ?","",""
"720517384611561535","ravi0493","2024-04-22T17:55:10.1820000+08:00","If i am not mistaken Litmus @Vatsal Shah has implemented native protocols form many systems instead of always using OPC UA servers to communicate with the Edge devices or controllers , additionally for the ones they do not have,  they go by OPC UA by being a client /MQTT  route by making their Platform as  MQTT consumer / publisher client compatible !! Check with them ! Most of them do this !!","",""
"817835202746253344","IIoT#4707","2024-04-22T18:18:02.1060000+08:00","GG @T Ibrahim, you just advanced to level 4!","",""
"867075936054149191","rickbullotta","2024-04-22T19:48:51.3600000+08:00","Wire a digital output from one PLC to a digital input of the other PLC. No protocol needed!  No latency.  No risk of future incompatibility.","","üòÜ (1)"
"720517384611561535","ravi0493","2024-04-22T21:12:39.2130000+08:00","You are too slow or playing the fun here !! If you do not even know this basics you are wasting your time in this field !!","","üòÄ (1)"
"720517384611561535","ravi0493","2024-04-22T21:15:33.9240000+08:00","Sure take a relay output and connect it to the 230v DC or AC and connect to the other PLC with sink digital 24 v dc ... your system will work woth the best efficiency.....no more latency because you wont have any system left ....","","üòÇ (2)"
"817835202746253344","IIoT#4707","2024-04-22T21:15:34.2540000+08:00","GG @Ravi.S, you just advanced to level 2!","",""
"720517384611561535","ravi0493","2024-04-22T23:11:47.8370000+08:00","Let me know when to laugh !","","üëç (1)"
"1057737574287945899","xamp4248","2024-04-22T23:36:06.8150000+08:00","Okay, I'd like to understand your stance on native protocol implementation for  interoperability‚Äîthis is serious , not a joke. I believe Litmus is built on Node-RED, which uses JavaScript. This likely introduces more latency compared to C or C++. What are your thoughts on this?","",""
"720517384611561535","ravi0493","2024-04-23T00:27:47.5920000+08:00","I don't think Node Red is being used for protocol development, that is NOT THE JOB OF NODE RED in Litmus i very sure although i have never used litmus !!! Study the application layer stack ( OSI STACK ---> 7 LAYERS ) starting from Physical layer , Data , Network , Transport , Session , Presentation , finally the  Application layer  ......of every PLC's communication protocol ( Every designer of protocol can have different layers implemented based upon its use and need) and  they are different for each PLC , even OPC UA needs to work on that and have a cover above the basic protocols to make it compatible to any client using their standards where in the client need not worry about the actual underlying protocol.","",""
"720517384611561535","ravi0493","2024-04-23T00:36:49.5410000+08:00","You are mixing two diverse issues Interoperability and native protocol.  Thee is nothing called default interoperability , any third party software cant work with OPCUA server  unless they develop a compatible UA client , if they dont it is not portable . OPC UA is not the world standard or in any way the best in software field for inter process communication , they are trying to build one just for OT area.","",""
"720517384611561535","ravi0493","2024-04-23T00:40:15.9470000+08:00","lONG STORY SHORT , I AM WASTING MY TIME WITH YOU !!","","‚òπÔ∏è (1)"
"720517384611561535","ravi0493","2024-04-23T00:48:17.7300000+08:00","The reason I said I am wasting my time with you is because i was trying to explain the subject matter to you and you thought I was arguing about some issue !! Funny Guy you are ü§£","",""
"720517384611561535","ravi0493","2024-04-23T00:53:03.9330000+08:00","Ok , let me give you another opportunity to understand what I was trying explain about native protocol , if you take PLC1 (which ever make) and it has to talk to PLC2 on some network of their own in the plant floor , do you think they use OPCUA to do that ?  If not why ?","",""
"720517384611561535","ravi0493","2024-04-23T00:56:07.9800000+08:00","let them be of the same vendor !!","",""
"720517384611561535","ravi0493","2024-04-23T01:11:27.0560000+08:00","Every level has a specific role to play , based on that role decide what should be the best thing to do if one can implement it.","",""
"720517384611561535","ravi0493","2024-04-23T01:18:04.9740000+08:00","Join the class which is conducted by Walker's group.","","üòÜ (1)"
"720517384611561535","ravi0493","2024-04-23T01:20:06.0770000+08:00","why ?","",""
"720517384611561535","ravi0493","2024-04-23T01:21:12.1570000+08:00","ha ha ha ha ha","",""
"817835202746253344","IIoT#4707","2024-04-23T01:21:12.5080000+08:00","GG @Ravi.S, you just advanced to level 3!","",""
"720517384611561535","ravi0493","2024-04-23T01:22:13.2060000+08:00","you talked about latency that is why.....","",""
"720517384611561535","ravi0493","2024-04-23T01:23:47.6730000+08:00","but you do understand latency , dont u?","",""
"720517384611561535","ravi0493","2024-04-23T01:25:16.9390000+08:00","which course are you taking with Walker ?","",""
"720517384611561535","ravi0493","2024-04-23T01:25:50.4190000+08:00","already answered ---> Latency","",""
"801561312861618236","jon.forbord","2024-04-23T01:28:23.0580000+08:00","This is a painful conversation to watch, and there seems to be somewhat of a language barrier between you. I‚Äôm not able to follow anyone of yours train of thought.","","üíØ (2),ü§¶‚Äç‚ôÇÔ∏è (1)"
"720517384611561535","ravi0493","2024-04-23T01:31:03.1060000+08:00","There is nothing called standard in this world , some people get together for a common cause and try to build standards' which can be helpful for many ..... this is how both MQTT and OPCUA started ....","",""
"720517384611561535","ravi0493","2024-04-23T01:39:57.3270000+08:00","Are you aware of OSI 7 layers ?","",""
"1057737574287945899","xamp4248","2024-04-23T01:40:24.0320000+08:00","I didn't correlate you old staement and this. Anyway I just felt such a statement is inappropriate in #opc-ua . But you can expressüòÄüòÄ. Anyway I am stopping here.","",""
"720517384611561535","ravi0493","2024-04-23T01:41:41.6130000+08:00","Are you a troll here ??","",""
"801561312861618236","jon.forbord","2024-04-23T03:25:04.7680000+08:00","I‚Äôm not quite following? Did you mean pseudo-standards? Or is SUDO short for something else? Why is the OSI layers important in a conversation about native drivers and OPC UA? Are you mixing field bus / real time protocols like Profinet with native drivers like S7-comms?","","üòÖ (1)"
"720517384611561535","ravi0493","2024-04-23T07:46:46.5390000+08:00","Ya pseudo standards professor  !!  Who gave you the idea that only field bus follow the OSI layes ??ü§£  there are ethernet based protocols that have more than 4 layers ( Like TCP/IP)  too in Industry which are used for intercommunication between DCS systems. How many DCS systems have you worked on ? If your IIoT platform , for example ignition (which is being used mostly by people here) communicates TO PLCs via OPCUA server or write a native protocol extracting data directly from the PLC or absorbing **unsolicited **data , which in our opinion would have a lower over head and latency , take a wild guess !!","",""
"720517384611561535","ravi0493","2024-04-23T07:53:00.8470000+08:00","Real time protocols , technically there is nothing called real time , the delays are compensated for ...... I dont think the SCADA of Siemens or Rockwell talks to their PLCs over OPCUA , they can easily talk to them over native protocols implemented in them.correct me here ....","",""
"720517384611561535","ravi0493","2024-04-23T07:59:17.2400000+08:00","Sorry i am not getting what point are you trying to make , The application layer of every PLC is different even in OPCUA ...... is OSI layer important ???? That is the basic structure followed  of any communication !! Be it serial RS standards 232 , 485 , 422, Ethernet (twisted pair coaxial, Thick net , single pair ,  POE,  , FO ,  starting at Physical layer of OSI model going up to the Application layer !!","",""
"801561312861618236","jon.forbord","2024-04-23T08:09:07.1050000+08:00","Ok, you were being rude to the other guy and now youre rude to me. It is a bit hard to follow the logic of one sentence to the next in some of your posts. You‚Äôre jumping from OSI layers to professors and trolls to DCS systems. 

It‚Äôs not always about overhead or latency, sometimes it can be about time to implement. We use OPC UA over native drivers because OPC UA is in our case easer to implement, and gives us what we need.","","üëç (2)"
"720517384611561535","ravi0493","2024-04-23T08:14:33.6890000+08:00","Rude yes i will be rude ,when one does not know and sits and makes fun of the other guy who is taking pains  to explain things to the other guy for his additional benifit ( why dhould i be wasting my time ) !! Please follow whatever you want to but then don't cry about REPORT BY EXCEPTION because it reduces over heads and latency , do whatever you are doing , no need to adapt to better systems available in the market , not required !! I AM NOT JUMPING FROM ONE POINT TO ANOTHER THEY ALL ARE SAME TO MAKE YOU UNDERSTAND ABOUT THINGS YOU MAY NOT HAVE SEEN !!","",""
"801561312861618236","jon.forbord","2024-04-23T08:15:20.9240000+08:00","I am asking, for the point of the discussion, why are the OSI layers important? I‚Äôm not asking if the OSI layers are important.","",""
"720517384611561535","ravi0493","2024-04-23T08:16:17.7910000+08:00","Please study communication ..... its usually taught in college , or you can google","",""
"720517384611561535","ravi0493","2024-04-23T08:17:31.3770000+08:00","Without knowing the various layers of the protocol how will you even write the OPCUA server ??","",""
"720517384611561535","ravi0493","2024-04-23T08:32:22.5360000+08:00","@Jon Forbord  i need to go now , sorry if i have offended you in any manner the basic idea was not that but to explain and share views !! There may be things you know better ... so at that time i shall listen to you and not mock you !!","",""
"801561312861618236","jon.forbord","2024-04-23T08:34:12.4270000+08:00","I did not intend to make fun of what you said. That may have gotten lost in translation. I was genuinely asking for clarification as it was not clear to me if you were speaking of fieldbus/RT protocols or native protocols from what you said, as you mentioned PLC to PLC communications. 

There are many people on this discord from many different nationalities, please be respectful and humble that not everyone has English as their native language.","",""
"720517384611561535","ravi0493","2024-04-23T08:54:10.5000000+08:00","Ok for one last time , after that I am a bit tied up and will appear later . What is a protocol , a protocol is a set of rules followed to exchange information , data views between 2 or more entities, those entities could be human , software , tasks , hardware . Like English is a protocol for 2 people talking here on Discord other protocols like Chinese may not be understood by many present here so its not being used in this present group but that doe not mean Chinese (Standard Mandarin or Putonghua) is not a protocol . Communication Industry has set some standards called OSI standards for splitting various layers for the protocol 7 layers and any communication protocol can adapt to all or only singly layer like hardware ( Physical On Off , 4..20ma can also be called just the  physical layer protocol ....depending upon the need and complexity every one develops their protocols which may be published or kept as a secret. The published ones are taken up by the OPCUA developers to encapsulate those protocols providing a standard interface despite differences internally based on the manufacturer of those protocols .","",""
"720517384611561535","ravi0493","2024-04-23T09:10:58.4160000+08:00","May be you are confused about BEING A USER of OPCUA server and a Developer of OPCUA server ...the  developer of the OPCUA server can not ignore the OSI layers , the users need not bother about anything , unless he/she has inquisitive mind üòù !!!","",""
"817835202746253344","IIoT#4707","2024-04-23T09:10:58.6920000+08:00","GG @Ravi.S, you just advanced to level 4!","",""
"801561312861618236","jon.forbord","2024-04-23T09:35:19.8020000+08:00","Theres a difference between a protocol converter (for instance Kepserver or Matrikon) wich exposes itself as an OPC UA server and OPC UA servers. Siemens PLCs now come with both native driver (S7)  and an embedded OPC UA server, meaning the user can choose to use the native driver or OPC UA to communicate with the PLC. directly, no native communication involved, as the plc speaks OPC UA natively. A lot of PLCs do that now. 

Back to the original question, the need for interoperability is unquestionable. if you have a shop floor of 20 different PLCs, if all you use is native drivers, you need 20 native drivers to talk to all the equipment. If all of those PLCs exposed embedded OPC UA servers, then you would only need an OPC UA client to talk to all that equipment. Even if (and that depends) that comes with some additional overhead.","",""
"801561312861618236","jon.forbord","2024-04-23T09:53:19.9900000+08:00","This sounds to me like you‚Äôre confusing OPC UA with OPC DA (classic), as this is how OPC DA worked. OPC UA can be embedded on PLCs and is actually quite common at least in European based OEMs. So the additional overhead of the protocol converter middle man is no longer always necessary for interoperability.","",""
"720517384611561535","ravi0493","2024-04-23T13:06:19.3460000+08:00","True,  BUT if I have a platform which has all those 20 ( this is a high figure , the buyer should have some basic sense while purchasing he has to maintain a plant and not have a museum of PLCs üòù  ) native drivers i would chose the native drivers over the OPCUA . The embedded OPCUA in the PLC wont  support **USOLICITED **outputs.","",""
"720517384611561535","ravi0493","2024-04-23T13:11:14.8030000+08:00","I am aware of the embedding of OPCUA on the PLC , which will load the Cpu more and will have more over heads ? 

Native driver or the UA driver , what do those OEMs do when they have their own entire system layers delivered by them, do they connect their own various levels with OPCUA or  via the native drivers , and if native drivers then there must be a valid reasons to do so !!","",""
"720517384611561535","ravi0493","2024-04-23T13:17:16.1600000+08:00","Have those European OEMs stopped shipping the communication interface without the native support ? If not why ?","",""
"794020366536146977","mparris","2024-04-23T21:18:54.3540000+08:00","I think there are many people that agree with your assessment: why use some protocol other than what the vendor focuses on delivering performance with?  There are many anecdotes about embedded devices folding when more than X number of tags are subscribed over its embedded OPC UA server.  To your point...just use the protocol the device works best with.

The best architectures include Device Gateway to buffer the number of connections to devices and abstract away all the variety of protocols.  Device Gateways are also critical for brownfield integrations.

Ideally, information modeling would happen directly on the device to flow up the Data Access stack, but more often than not, the information modeling would happen directly in the Device Gateway, or one more step higher in the Data Ops platform.","","üëç (3),üíØ (1)"
"720517384611561535","ravi0493","2024-04-23T22:54:18.6570000+08:00","I assume that is what Walker and others are doing when they use Ignition and Highbyte, i haven't used both so need to learn about them. Which gateway are you using and you are comfortable with ? You can have multiple gateways and a central Management software tool for all ,  a kind EMQ is trying to develop , i was told its under development and will be made available later , don't know when , i have to initiate a discussion with them regarding this gateway product they plan to come up with !","",""
"568913935147728896","zeratall","2024-04-23T23:06:06.1560000+08:00","This is a bit of a side conversation, but I think you bring up a good point with your last sentence of where does ‚Äúdata modeling occur‚Äù? I agree the most benefit is when data modeling is done closer to the device. That being said I doubt we will ever get there because the needs of data at the plc and its corresponding data model are different then the needs up the stack. A data model at the device is very centric to automation, whereas the data model up the stack is focused on interoperability. I think that is why I‚Äôve really liked the ideas of decentralized data models and UNS because it enables those data models to be different but still have a way to to tie them together.","","üëç (1)"
"568913935147728896","zeratall","2024-04-23T23:12:49.6250000+08:00","Depends on the devices your factory are using, and what gateway supports those drivers, I think it‚Äôs a pretty safe statement to say Kepware is probably the most widely adopted. Due to the fact it supports 150+ industrial L7 protocols.

The single pane of glass for management is exactly what Kepware+ is going to be.","",""
"693309801589112862","_dyland","2024-04-23T23:56:46.4920000+08:00","Why not both? The model at the device is the start, it will obviously be added to and molded as it goes but starting with a basic model in the device only simplifies things in my mind. 

I ask this as someone who has spent a lot of time trying to and I think even figuring out how to model data in a PLC.","",""
"568913935147728896","zeratall","2024-04-23T23:57:37.1400000+08:00","That‚Äôs exactly what I said if you read my last sentence.","",""
"693309801589112862","_dyland","2024-04-23T23:57:58.6310000+08:00","My bad üôÇ","","ü§£ (1)"
"707320353696907366","du0ne","2024-04-24T02:57:45.0720000+08:00","What tools would you recommend to generate test MQTT JSON data?","",""
"1073312001788477471","sparkylarks","2024-04-24T03:28:27.1220000+08:00","I use node red. 

I give chat GPT the payload schema and say, I want this.......

You can set to trigger manually, or however you want","",""
"801561312861618236","jon.forbord","2024-04-24T04:22:36.5100000+08:00","OPC UA is a standard and will probably be suboptimal compared to the custom built native protocol of the OEM. 

The native protocols I‚Äôve come across have all been poll response on top of tcp, so I have seen no unsolicited output from a native protocol. Can you name some vendors with native protocols that support this? 

I dont need a primer on the OSI model, I know it perfectly well already.","",""
"1031940518730543106","thunt.career","2024-04-24T06:07:13.9680000+08:00","CIP Class 3 Explicit Messaging fits here I think. I can send a CIP Data Table Write MSG in a AB PLC to a server listening on the CIP port.","","üëç (2)"
"801561312861618236","jon.forbord","2024-04-24T06:30:48.1440000+08:00","CIP is fieldbus/RT protocol right? I may be wrong, but when I hear native protocol, fieldbuses such as EthernetIP, PROFINET, EtherCAT is not what I‚Äôm thinking of. 

Hmm, yes that is acyclic, so it could be sort of unsolicited; but if CIP is anything like configuring Profinet, for SCADA/IOT that‚Äôs not the protocol you‚Äôd want to use.","",""
"1031940518730543106","thunt.career","2024-04-24T06:40:32.0740000+08:00","Good clarification, I am referring to EtherNet/IP which is CIP on Ethernet. FTLinx and FTView use it for HMI communications as well as the Logix Designer to download/upload to PLCs and view data.","",""
"873009180938743828","sim_sam3","2024-04-24T06:57:25.2980000+08:00","Rockwell Logix series implement a subscription interface over CIP (EtherNet/IP) available only to RSLinx. Kepware uses request/response services (Rockwell public API documentation available). For very fast very high volume like Travis mentioned we use the PLC to issue cip data table writes to our ‚Äúunsolicited‚Äù logix driver.","",""
"873009180938743828","sim_sam3","2024-04-24T07:00:08.3240000+08:00","Fanuc focas data window library is ‚Äúnative‚Äù/proprietary and interestingly has an unsolicited option. Otherwise I can list protocols like bacnet and dnp3 that support unsolicited but those aren‚Äôt proprietary, though they are ‚Äúnative‚Äù and a primary integration option for many devices implementing them.","",""
"794020366536146977","mparris","2024-04-24T07:03:25.4810000+08:00","And for the ""unsolicited"" CIP function to work, you still need a CIP client to connect to a CIP server and then wait for the unsolicited response?","",""
"873009180938743828","sim_sam3","2024-04-24T07:03:35.3730000+08:00","I think the use of poll/response is carryover from the fact that most of the protocols we‚Äôve used in OT were scanning live memory registers of the device runtime using protocols and ports typically used for programming and configuration activities. For the longest time there weren‚Äôt dedicated data servers added to automation devices.","","üëç (1)"
"873009180938743828","sim_sam3","2024-04-24T07:04:45.4410000+08:00","The write can be spontaneous (tcp negotiation and then CIP/EIP stuff) but the receiver has to be listening, so for kepware the driver needs to be in use - internal plug-in or external client","",""
"873009180938743828","sim_sam3","2024-04-24T07:07:09.4030000+08:00","As an aside, scheduler plug-in activates drivers and holds last value in cache regardless of external client connection states","",""
"794020366536146977","mparris","2024-04-24T07:09:30.2950000+08:00","So in this scenario, who instantiates the network connection? The PLC or Kepware?","",""
"873009180938743828","sim_sam3","2024-04-24T07:10:40.1390000+08:00","PLC","",""
"873009180938743828","sim_sam3","2024-04-24T07:11:54.0860000+08:00","It‚Äôs ‚Äúunsolicited‚Äù from the kepware perspective but only because the PLC becomes the client and our driver the server. This still uses request/response services. We did this a lot with Modbus as well (modbus serial and tcp server drivers in kepware).","",""
"873009180938743828","sim_sam3","2024-04-24T07:12:36.0660000+08:00","We do the same for Siemens S7 and S5, again usually for very fast and/or high volume","",""
"794020366536146977","mparris","2024-04-24T07:20:53.1710000+08:00","So the PLC is programmed with the IP address of the Kepware server?","",""
"1031940518730543106","thunt.career","2024-04-24T07:23:02.3870000+08:00","Yes. I've used InGear Net.Logix and Core.Logix on server side to request and insert SQL data from PLC.","",""
"873009180938743828","sim_sam3","2024-04-24T07:24:28.0010000+08:00","CIP Data Table Write function in msg block uses cip endpoint as an input, and this includes IP and port of kepware.

It‚Äôs not used as often as the PLC as the generic ‚Äúany tag‚Äù data server since one needs to modify/include the data table write in the PLC program itself","",""
"1031940518730543106","thunt.career","2024-04-24T07:25:23.0280000+08:00","In Allen Bradley messaging, you can set the path dynamically so could cycle between a few different server IPs.","","üÜí (1)"
"873009180938743828","sim_sam3","2024-04-24T07:35:04.0990000+08:00","Similar for Siemens but just IP address. Even works to send data from optimized data blocks to non-optimized tags (registers) on the receiving side","",""
"794020366536146977","mparris","2024-04-24T07:47:15.8130000+08:00","Yes, controls engineer likely don't want to modify logic just to change data consumption patterns. 

But cool feature, nonetheless!","",""
"873009180938743828","sim_sam3","2024-04-24T08:36:15.4080000+08:00","For some it‚Äôs been a normal part of building & maintaining plc to plc / plc to pc data exchange, but for others esp when plcs are delivered configured by a third party it‚Äôs a nonstarter","",""
"1031940518730543106","thunt.career","2024-04-24T09:25:57.9330000+08:00","I haven't used it for data consumption. It would be part of the application design for recipes or equipment settings in a file or database, used for inventory management functions or product labeling.","",""
"1031940518730543106","thunt.career","2024-04-24T09:27:07.2960000+08:00","Standard logic and data structures can be imported then hooked into machine logic. This way the server doesn't need to be modified with a new machine coming online.","",""
"794020366536146977","mparris","2024-04-24T09:36:31.7720000+08:00","Making it easy for the consumer. Same thing UNS tries to do üòâ","",""
"740383178279354388","mriiot","2024-04-24T13:05:23.8320000+08:00","We used to call it ladder 99.  Where did you put my tags?  Ladder 99","","üíï (1)"
"707320353696907366","du0ne","2024-04-24T15:44:12.1660000+08:00","Thanks, I wanted to create some variable data and ended up using mqttx cli with a js script using the faker library","",""
"720517384611561535","ravi0493","2024-04-24T17:49:07.4500000+08:00","Rockwell and Siemens PLC both support it. Sorry i was away , there is some issue here and i am badly tied up .. will discuss again .... there are lot of experienced guys here they surely will give you details better than i can on ther PLCs.","",""
"801561312861618236","jon.forbord","2024-04-24T18:33:00.9650000+08:00","Does this have to be programmed in PLC code? Or is it through configuration, much like how you decide what is exposed on the embedded OPC UA server of an S7-1500-series? 

It is ‚Äúalways‚Äù possible to use UDP to do unsolicited push of data from a PLC, but it‚Äôs not generally how the PLC exposes its data to outside consumers by default.","",""
"720517384611561535","ravi0493","2024-04-24T20:21:49.2880000+08:00","Jon when i say Native protocol it includes all, even the OPCUA has an underlying protocol , By native i mean no covers stripped version without any over head, it is  not any special sperate protocol by the OEM.

Yes, you need to program the PLC when to push the data , provide the destination port , PLC is where any Data gets generated and whatever precondition you intend to set , be it raw or limit based ... Even IN UDP the client initiates , UDP in a way   can be listed under unsolicited, so i would not specifically say UDP is Unsolicited but the Unsolicited can be UDP TYPE .... just that there is no retransmission of the data if  the delivery is bad ,  , The  OEM should be able to help you in providing different ways and how they have implemented the protocol integrally.","",""
"873009180938743828","sim_sam3","2024-04-24T22:34:09.2390000+08:00","yeah it's called a ""CIP Data Table Write"" and would occupy a rung (maybe rung 99 as a standard like Chris! :): https://www.youtube.com/watch?v=3hNlgVXun7w","",""
"873009180938743828","sim_sam3","2024-04-24T22:34:31.3850000+08:00","in EIP terms, it's an Explicit (TCP-based) Connected or Unconnected Write for use between Logix PLCs","",""
"873009180938743828","sim_sam3","2024-04-24T22:34:42.4930000+08:00","Kepware happened to build a driver to mimic a Logix PLC as we have done for Siemens S5, S7, and Modbus","",""
"873009180938743828","sim_sam3","2024-04-24T22:35:21.2060000+08:00","we used to have support for DeviceNet and ControlNet unsolicited side too but dropped support over time as 32 bit hardware drivers for PCI-based cards lacked modern OS support","",""
"873009180938743828","sim_sam3","2024-04-24T22:36:04.4830000+08:00","we would use these native/proprietary methods before we use any bespoke UDP-based data transfer, though we support generic UDP transfer strategy with our Universal Device Driver","",""
"873009180938743828","sim_sam3","2024-04-24T22:38:36.5540000+08:00","your question about configure vs program is a good one - often times you might be able to ""configure"" a UA data server or (maybe for some PLCs an MQTT publisher) in a web environment outside of the PLC programming utility, but this strategy leverages machine-to-machine work flows that require programming utility (and the licenses to use them)","",""
"873009180938743828","sim_sam3","2024-04-24T22:40:25.9250000+08:00","oh one more that's native and totally unsolicited - Ethernet Global Data. This is a GE standard used for 9030s and other devices. It's also been implemented by others. It's broadcast, multicast or unicast with the concept of publishers and consumers configured ahead of time. the configuration ont he device side usually requires a programming environment but you usually DO NOT need to ""program"" or modify ladder/structuredtext/etc to implement","","üëÄ (1)"
"873009180938743828","sim_sam3","2024-04-24T22:41:34.4750000+08:00","i use this to build a ""poor man's"" Ethernet data diode (one-way UDP data transfer between Kepware instances): https://www.ptc.com/support/-/media/support/refdocs/ThingWorx_Kepware_Server/6,-d-,13/secure_isolated_networks_and_data_diodes_data_access_using_thingworx_kepware_server.pdf","",""
"801561312861618236","jon.forbord","2024-04-24T23:01:52.2460000+08:00","For me ‚Äúnative protocol‚Äù means the (usually proprietary) protocol that a PLC speaks natively, it‚Äôs mother tongue. For Siemens PLCs this is S7 comm, for AB it‚Äôs something else.","","üëç (1)"
"720517384611561535","ravi0493","2024-04-24T23:24:17.9090000+08:00","Native means native to OEM , others OEMs don't use that and is not an open standard acceptable by all.üòÑ  If it was a standard, even  ""PSEUDO"" üòù.......One make PLC could directly talk to other Make PLC on that communication BUS.  Fieldbus for slaves can be that pseudo because many OEMS can make Fieldbus  devices.  Profibus master slave too i guess but one needs to incorporate the GSD file .... its been more than 20 years i have touched all such things ....üòù","",""
"801561312861618236","jon.forbord","2024-04-24T23:27:54.4830000+08:00","‚ÄúJon when i say Native protocol it includes all, even the OPCUA has an underlying protocol , By native i mean no covers stripped version without any over head, it is  not any special sperate protocol by the OEM‚Äù","",""
"720517384611561535","ravi0493","2024-04-24T23:28:22.8470000+08:00","True i still stand by that !!","",""
"720517384611561535","ravi0493","2024-04-24T23:29:19.5640000+08:00","By all i mean all protocols provided by that OEM","",""
"801561312861618236","jon.forbord","2024-04-24T23:30:34.2300000+08:00","? The embedded OPC UA server surely doesn‚Äôt use the native protocol to speak to the PLC itself internally?","",""
"720517384611561535","ravi0493","2024-04-24T23:31:19.5750000+08:00","It does !!! The cover is Embedded as extra for external UA Clients","",""
"801561312861618236","jon.forbord","2024-04-24T23:32:25.6330000+08:00","Anyway, you say, ‚Äúnative means native to the OEM‚Äù and ‚Äúnative is stripped no covers.. it is not any special protocol by the OEM‚Äù.","",""
"720517384611561535","ravi0493","2024-04-24T23:33:12.4950000+08:00","PLC 1 wont talk to PLC 2 of the same make using their embedded UA server in the Bus topology !!","",""
"720517384611561535","ravi0493","2024-04-24T23:33:49.7600000+08:00","True that is what i mean Native !!","",""
"801561312861618236","jon.forbord","2024-04-24T23:38:57.6900000+08:00","No, but you can. You usually have to program the client on one of them. 

And you would usually use the fieldbus for PLC to PLC comms, not the native protocol.","",""
"720517384611561535","ravi0493","2024-04-24T23:39:46.5340000+08:00","If some one is doing that it is a stupid way of doing things and using  transfer of data for crytical controls ~~","",""
"720517384611561535","ravi0493","2024-04-24T23:41:25.2020000+08:00","Fieldbus for PLC to PLC ??? Its a master salve protocol for devices like Drives or any other slave devices !","",""
"801561312861618236","jon.forbord","2024-04-24T23:43:33.3450000+08:00","Depends on what the purpose of that would be.. but yes.","",""
"720517384611561535","ravi0493","2024-04-24T23:43:40.8140000+08:00","Even when we used to exchange data between one profibus to another network of profibus there used to be A DP -DP coupler , dont what is there now a days !!","",""
"720517384611561535","ravi0493","2024-04-24T23:44:23.7040000+08:00","Obviously why would you load the main communication BUS with useless unimportant data ??","",""
"1057737574287945899","xamp4248","2024-04-25T00:03:18.9450000+08:00","CIP","","üëç (1)"
"720517384611561535","ravi0493","2024-04-25T00:04:32.8220000+08:00","Just Kidding , but try this , Take  Siemens PLC with Embedded OPCUA and take Rockwell PLC with Embedded OPCUA , now make Rockwell as OPCUA CLIENT And Siemens as OPCUA server , when both start communicating , give me a Buzz , we shall celebrate together ü§£","",""
"801561312861618236","jon.forbord","2024-04-25T00:05:02.2930000+08:00","What do you mean stripped no covers?","",""
"720517384611561535","ravi0493","2024-04-25T00:05:43.7420000+08:00","Nothing boss .... leave it","",""
"801561312861618236","jon.forbord","2024-04-25T00:06:01.6860000+08:00","Hehe.. oh, I would probably never use OPC UA to do PLC to PLC communication, that‚Äôs ridiculous..","",""
"801561312861618236","jon.forbord","2024-04-25T00:06:44.6360000+08:00","But Siemens does have a OPC UA client library so it‚Äôs technically doable.","",""
"720517384611561535","ravi0493","2024-04-25T00:06:50.3860000+08:00","GREAT ! So there is something below the OPC which is not common , the below layer is called native","",""
"720517384611561535","ravi0493","2024-04-25T00:07:56.7310000+08:00","who told you Siemens dont have UA client ? ü§£  who is Guiding you all ??>","",""
"720517384611561535","ravi0493","2024-04-25T00:09:55.2650000+08:00","How is Wincc talking to rockwell plcs ?? If they did not have US clients ??","",""
"801561312861618236","jon.forbord","2024-04-25T00:10:17.7730000+08:00","Ok, this is the crux of it then. I don‚Äôt know the inner workings of all PLCs, but I‚Äôm pretty sure that Siemens OPC UA embedded does not use S7 comm over TCP to communicate with the PLC in order to expose its OPC UA server. This likely happens on the firmware layer, and thus obfuscated to guesswork unless you have some access level within Siemens.","","üëç (1)"
"801561312861618236","jon.forbord","2024-04-25T00:11:23.7520000+08:00","To be precise. Siemens PLCs, specifically S7-1500 series that I know of, does have a OPC UA client library. Never mentioned winCC.","",""
"720517384611561535","ravi0493","2024-04-25T00:11:39.3510000+08:00","You can enroll yourself with Walker i am sure he will be able to guide you well. I have my limitationsüòÑ","",""
"801561312861618236","jon.forbord","2024-04-25T00:12:22.1850000+08:00","I mean, feel free to click my name and see why my name is in gold..","",""
"720517384611561535","ravi0493","2024-04-25T00:13:08.2510000+08:00","IF you are with walker tell him i want to thulp him hard one time !!ü§£","",""
"817835202746253344","IIoT#4707","2024-04-25T00:13:08.5770000+08:00","GG @Ravi.S, you just advanced to level 5!","",""
"801561312861618236","jon.forbord","2024-04-25T00:14:29.2340000+08:00","When I say Siemens embedded OPC UA, I mean the OPC UA server that is in the S7-1500 and 1200 series PLCs, not winCC.","",""
"1057737574287945899","xamp4248","2024-04-25T00:16:42.8710000+08:00","Bro. He is a mastermind guy.","",""
"801561312861618236","jon.forbord","2024-04-25T00:16:54.3660000+08:00","You seem overly confident in that you know the inner workings of Siemens PLC embedddd OPC UA servers, so please do enlighten me..","",""
"801561312861618236","jon.forbord","2024-04-25T00:17:49.7680000+08:00","Siemens PLCs native protocol is S7 comms, do we agree on this?","",""
"1057737574287945899","xamp4248","2024-04-25T00:18:15.8680000+08:00","Quick question. What is the native driver in Schneider PLC.. Is it modbus???","",""
"817835202746253344","IIoT#4707","2024-04-25T00:18:16.4080000+08:00","GG @T Ibrahim, you just advanced to level 5!","",""
"801561312861618236","jon.forbord","2024-04-25T00:19:56.6890000+08:00","Im sure @Sam.E  knows üôÇ","",""
"873009180938743828","sim_sam3","2024-04-25T00:23:59.1440000+08:00","i do! it's a heavily customized Modbus variant with additional function codes (services) and other features. the devices also always (at least from my experience) support basic Modbus TCP or Modbus RTU.

i think we're deep in semantic debates about how ""native"" native really is - schneider modicon PLCs with Modbus + custom modbus is a good case study. which is native? are both native? does ""native"" imply no memory / register mapping [i.e. extra configuration] whereas non-native does?","",""
"1057737574287945899","xamp4248","2024-04-25T00:27:51.7450000+08:00","So we can say modbus is a native protocol and extensively is using in many PLC along with their own native protocol. Right?","",""
"873009180938743828","sim_sam3","2024-04-25T00:28:25.2290000+08:00","im bad at social media and edited my previous chat with a comment that relates to your question","","üëç (1)"
"1057737574287945899","xamp4248","2024-04-25T00:30:39.1810000+08:00","I am expecting the same humbleness or respect from others.. üòÄ","","üôÉ (1),üíï (1)"
"720517384611561535","ravi0493","2024-04-25T00:49:59.5750000+08:00","I have just  5 more minutes , cant spend more time here now ....... OPC UA is  a standard way of exchanging information which is not set by any of the OEMs it is set by the OPC-F ,  some blah blah unofficial committee , it was done so that all different makes (OEMS) could understand each other AND EXCHANGE information easily enduring they understand the right thing the right way , Just like here we all may be from different countries (Native), like i am from India , Jon could be Spanish or Italian Thaha could be from Afghanistan or Saudi Arabia and we all talk in our house in native language or converse within our family with our native language, but when we talk to each other we convert our language into English ( some sort of translation)  and express to every other person in Discord where in Discord English language become OPCUA standards , he translation sometimes could be ok and sometimes it can cause misunderstanding too because the translation may not be 100% perfect , its an evolving process and that is why every time you will get to hear PART X PART 14 PART Y coming out.... internally our brains are wired best to understand our native language ( normal condition) and we translate what we read or hear . Thus what we see and hear is ENGLISH the COVER , and what goes inside to brains to figure out is in Native ...... so in some way i have tried to explain what is native and what is opc cover .... may not be perfect again because your native thinking process will trigger some other response üòù","",""
"867075936054149191","rickbullotta","2024-04-25T00:52:28.6100000+08:00","Explain to me why I should not block you for those hateful comments.","",""
"720517384611561535","ravi0493","2024-04-25T00:53:26.4510000+08:00","I was trying to crack a joke not being hatful !! So that we all could laugh !!","",""
"720517384611561535","ravi0493","2024-04-25T00:54:53.3030000+08:00","????","",""
"720517384611561535","ravi0493","2024-04-25T00:55:35.3290000+08:00","How racist , i even said where i am from and how we all could be from different places !!","",""
"867075936054149191","rickbullotta","2024-04-25T00:56:01.5880000+08:00","‚ÄúFriend of bin Laden‚Äù.  Wow.","",""
"720517384611561535","ravi0493","2024-04-25T00:56:02.0310000+08:00","even i could missunderstand","",""
"720517384611561535","ravi0493","2024-04-25T00:56:34.6230000+08:00","ah come on now that was just a funny joke , there are so many jokes about him , if it has hurt him i applogogise !!","",""
"720517384611561535","ravi0493","2024-04-25T00:57:40.4580000+08:00","WTF , is that acceptale standards ?","",""
"720517384611561535","ravi0493","2024-04-25T00:58:55.2470000+08:00","WTF = WOW ??? nice touch up job !!","",""
"1057737574287945899","xamp4248","2024-04-25T01:00:06.1720000+08:00","This is truely racist view even I was from his country","","üíØ (1)"
"707320353696907366","du0ne","2024-04-25T01:00:36.8640000+08:00","I prefer modbus to modbus, it works almost the same as mudbus, but uses the addressing of modbus, sometimes with minor changes.","",""
"720517384611561535","ravi0493","2024-04-25T01:00:55.3440000+08:00","ok a i appologise , i never said i was sure where were from","","üëç (1)"
"707320353696907366","du0ne","2024-04-25T01:02:28.5920000+08:00","PS this should not be confused with modbus","",""
"801561312861618236","jon.forbord","2024-04-25T01:54:27.0260000+08:00","That‚Äôs a good analogy, but it‚Äôs more like how language actually works when you speak fluently, your ‚Äúmind‚Äù also thinks in the second language. When you have to translate from the native tongue to the second language, that‚Äôs a different process. This is the difference between most embedded OPC UA servers and protocol converters or OPC DA. Protocol converters translate from one to the next, but some OPC UA servers is the PLC speaking a second language. The conversion/translation from on to the next is not always necessary.","",""
"720517384611561535","ravi0493","2024-04-25T10:00:12.5380000+08:00","You are missing or ignoring the Overhead part due to UA implementation. Given a choice between  ""Native : or ""UA""  implementation SAY for PROTOCOL X , I shall go for native version if it has been implemented on the platform. You are free to use KEPWARE's UA implementation with your IIoT platform or UA embedded SERVER in the PLC to communicate with your IIoT platform. Which platform do you all use ? 

PTC bought over Kepware else for their Thing works platform they should have ideally stripped all the protocols of Kepware and have all of the protocols as native implementation on their Thingworks ! and them moved up the ladder for integration with various levels of IIoT / Automation Pyramid ......","",""
"1073312001788477471","sparkylarks","2024-04-25T16:32:25.7640000+08:00","@Ravi.S 
Are you saying that for a SCADA integration to a Siemens and Rockwell PLC, and if we consider two approaches
1. Install a OPCUA Server on you PLC and map your Signals, then use OPC UA on your SCADA to read the data
2.Use the IO drivers in the SCADA that have been designed to talk to the relevant device from that SCADA( I think that is what you mean by Native Drivers.

you favour approach 2? If so I agree 100%. 

To take the Language analogy is OPC Esperanto?
And it is easier for me to learn French to speak to French speakers, that expecting everyone to learn Esperanto?","",""
"794020366536146977","mparris","2024-04-25T19:50:09.4740000+08:00","Esperanto is such an interesting idea...

And I've thought that exact analogy before, too!","",""
"1073312001788477471","sparkylarks","2024-04-25T20:00:17.0860000+08:00","Esperanto make perfect sense, and it would be better if we could all speak it but;
 - everyone has to learn it.
 - People have to replace their mother tongue
 
so for OPC to really ""work"" PLC manufacturer have to not have a native protocols so Siemens PLC to Siemens drive via OPC, not Profinet, AB PLC to AB PLC needs to be OPC too.

And just like Esperanto could never convince the English speaking nations of the would( and I include Ireland here) to take up Esperanto, the ""fudge"" becomes too easy.

for Esperanto , it was English becomes the Lingua franca of business.
for OPC, we keep using the native Drivers and maybe OPC to OPC at Level 2, but often that requires Kepware or some other form of translator, a bit like when Dialects are so strong people cannot understand each other in the same language.","",""
"898217314741280828","hobbes1069","2024-04-25T21:05:47.0590000+08:00","Anyone have experience with Cedalo? Part of me really likes it's based on Mosquitto.","",""
"873009180938743828","sim_sam3","2024-04-25T21:37:47.8970000+08:00","until the SCADA vendors get tired of continually building and supporting protocols drivers.. and then queue the reason in the 1990s for middleware apps like DDE servers that eventually led to a standardization effort (OPC Foundation).

but i'm admittedly bias and need a reason for existing üòâ","",""
"1073312001788477471","sparkylarks","2024-04-25T21:42:54.0140000+08:00","Taking the analogy too far.

Middle ware apps are like the translators.

I lost faith with OPC when I had to use Kepware to get two OPC-UA devices to talk. That is like the translator translation from one Dielect of Esparanto to another.","",""
"873009180938743828","sim_sam3","2024-04-25T21:44:58.4500000+08:00","ah, so burned by device implementations of OPC UA? do you recall that it was easier to try OPC UA between those two devices than using generic UDP or TCP byte sends or something? to be fair i do not see much of any M2M directly with UA (yet). still stuck at layer 2. maybe UAFX helps but the geez its easy to pass bytes between PLCs. plus, if devices of the same make, then native protocols usually offer M2M realtime features.","",""
"1073312001788477471","sparkylarks","2024-04-25T21:46:49.2980000+08:00","It's a while ago now, and I wasn't the one doing the work , it was 8ish years ago, OPC DA and XML were still around. and I'n mot 100% sure that it wasn;t one of them.","",""
"1073312001788477471","sparkylarks","2024-04-25T21:48:41.0040000+08:00","Does that make MQTT Emoji's

Some people say it isn't even an language, and lacks grammar rules. Especially the ones who paid for expensive Esparanto courses

But it is proving an effective communication method","",""
"873009180938743828","sim_sam3","2024-04-25T21:50:22.4850000+08:00","hey if your alternative is basic byte sends of UDP or TCP, wrapping a ""transfer protocol"" like MQTT around can make things a lot easier. when you've done MQTT between devices what kind of resolution do you shoot for? do you see implementations supporting PLC scan frequencies or slower stuff like 100 to 200 ms?","",""
"1073312001788477471","sparkylarks","2024-04-25T21:56:33.6230000+08:00","My current project, not PLC based publishes updates every 360,000ms

Well one topic only changes once a week","","üê¢ (1),üëç (1)"
"873009180938743828","sim_sam3","2024-04-25T21:58:27.1310000+08:00","i'm working on an XML-DA integration right now [*cries into keyboard*]. embedded on a VERY remote device that's super resource-constrained, no bueno.","","ü§¢ (1),ü§Æ (1)"
"801561312861618236","jon.forbord","2024-04-25T22:50:57.6320000+08:00","1. OPC UA server is never installed on the PLC, it is at worst activated and then the user chooses what to exposed. At least this is the case with all PLCs I‚Äôve had OPC UA embedded servers on. 

2. I wouldn‚Äôt consider Profinet to be the ‚Äúnative‚Äù Siemens PLC protocol. 

Are we really debating the benefits of the idea of a common communication interface for OT equipment like PLCs regardless of OEM?!? 

The analogy is not bad, but there is nothing inherently more efficient with a native protocol. Sometimes they are more efficient, sometimes they‚Äôre not. 

Is it really more efficient for everyone to learn French, Portuguese, Spanish, Esperanto, Danish, Greek, Dutch, Bengal, Swahil, Tamil.. ?! Or for everyone to hire a translator every time they talk to someone not native?","",""
"1063829764164563026","mariano.beracochea","2024-04-25T22:51:00.6320000+08:00","using Node Red is there a way to build a hierarchically structure on HiveMQ?
I dont understand how the hierachical structure is stablished and queried, the topic is a mesh of the route and the data topic or there can really be stablished ""folders"" on the broker, how is then pointed to them?","",""
"1073312001788477471","sparkylarks","2024-04-25T23:12:58.3850000+08:00","1. Installed/embedded, true, but I think the thrust of my argument holds
2. Again, true, but ....

I am not debating the ides of a common communication interface for OT. I think it is a great idea that makes incredible sense. But a common language makes sense. too

but English because that common business language( it was Latin in Europe at one point) but I am arguing that the same difficulties of Esperanto that you need everyone to buy in and push their own native tongue is a big ask for lots of illogical human reasons.

Also Esperanto and OPC ask lots of people to give up something for a common effort and again , we humans are not always the best at that

for OPC to succeeds it need a lot of coordination , and that is hard.

MQTT can thrive, perhaps somewhat because it is more of an organic growth, people just use it and do stuff.

Who knows in 10 years maybe OPC will retake the lead, and that more fluid path that MQTT  is on will be seen as it;s downfall, and the structure of OPC will be seen as a strength.","",""
"867075936054149191","rickbullotta","2024-04-25T23:13:27.0530000+08:00","It's simply driven by the topic names.","",""
"1073312001788477471","sparkylarks","2024-04-25T23:16:24.2350000+08:00","Are you using Flat MQTT or Sparkplug?
you just publish the topics and the structure develops

Unless you set the Retain flag, the structure is not really stable, It is a broker not a message store is how I think of it.

it can be helpful getting started to log on with MQTT Explorer, and watch the hierarchy develop( or turn on the retain flag)

I don't think you can query the Structure @RickBullotta  I think I have heard you say this before","",""
"867075936054149191","rickbullotta","2024-04-25T23:18:01.3730000+08:00","Correct. No querying.","",""
"1063829764164563026","mariano.beracochea","2024-04-25T23:19:48.7140000+08:00","I saw on many videos that Walker showed the MQTT Explorer and topics were organice and short, will the MQTT generate the ""folders"" if you write the topic with /folder/variable?","",""
"801561312861618236","jon.forbord","2024-04-25T23:23:56.0450000+08:00","Good üôÇ I was getting nervous there for a second.. 

1. This is as everything ‚Äúit depends‚Äù. 

The native driver isn‚Äôt always the easier choice. Ignition has both OPC UA and S7 comm for Siemens PLCs. To use OPC UA, I just browse and add tags to Ignition. I can even, with some scripting, have Ignition automatically add all OPC UA tags. They all have the symbolic name and path from the PLC. Easy peasy lemon squezzie. To use Ignitions S7 comm driver, I have to 1. Deactivate optimized block access in the PLC. 2. For all tags I want to pull, I have to know it‚Äôs type, absolute address and name, which I manually have to enter in Ignition. 3. It‚Äôs poll response in Ignitions S7 comm driver, so it‚Äôs a lot more on the line than with OPC UA subscriptions.","",""
"801561312861618236","jon.forbord","2024-04-25T23:25:21.0600000+08:00","Now go and do this for 300 PLCs.. etc..","",""
"817835202746253344","IIoT#4707","2024-04-25T23:25:21.4410000+08:00","GG @Jon Forbord, you just advanced to level 24!","",""
"1073312001788477471","sparkylarks","2024-04-25T23:26:12.1180000+08:00","I agree, but you do have to configure the OPC server in the PLC and do the tag mapping, so the effort is there.

The effort is always somewhere.üòÄ","",""
"801561312861618236","jon.forbord","2024-04-25T23:26:38.4730000+08:00","No, you don‚Äôt have to do that. It‚Äôs built in.","",""
"801561312861618236","jon.forbord","2024-04-25T23:28:52.8370000+08:00","Sorry, let me be more precise. There is no mapping from plc tags to OPC tags inside the PLC.","","ü§î (1)"
"1073312001788477471","sparkylarks","2024-04-25T23:32:58.1860000+08:00","yes 
Publish a payload( 23) to a topic  Plant/Area/Line/Machine/OEE
then Publish payloads let's say  70, 35,65 to  Plant/Area/Line/Machine/OEE/Avail , Plant/Area/Line/Machine/OEE/Perfo
and Plant/Area/Line/Machine/OEE Quali and you should get

Plant
      Area
         Line
            Machine
                     OEE = 23
                         Avail = 70
                         Perfo = 35
                         Quail = 65","","ü¶Ü (1)"
"1073312001788477471","sparkylarks","2024-04-25T23:36:07.8820000+08:00","I'll have to have another look. it;s been a while.","",""
"801561312861618236","jon.forbord","2024-04-25T23:54:05.7380000+08:00","I know this whole discussion is a giant sidetrack, but I do think there is a larger point to this. If the perception is that ‚Äúnative‚Äù is always better, then no wonder the industry struggles to establish a least common denominator so to say. If we‚Äôre all content with the current state, and buy into the narrative that native integration is superior to industry standard integration, then industry will never change.. If enough end users / customers to OEMs and vendors ask or demand for the industry standard, they WILL eventually move the needle. So we must use every opportunity to make our demands.","","üíØ (3)"
"1063829764164563026","mariano.beracochea","2024-04-26T00:14:14.7810000+08:00","In this case OEE will be a ""folder"" name and a topic at the same time? is that admisible?","",""
"801561312861618236","jon.forbord","2024-04-26T00:18:03.4390000+08:00","It is in MQTT, but Ignition for instance will struggle to resolve a topic with a value and subtopics, (folders can‚Äôt also be tags with a value), so I would avoid this if I could.","","üíØ (1)"
"794020366536146977","mparris","2024-04-26T00:32:13.6820000+08:00","MQTT is the equivalent of e-mail and distribution groups, or Youtube...it facilitates scalable communication and the e-mail or video can contain any type of content.  and it lacks interoperability when people subscribe to e-mails or Youtube channels with content they don't understand.","","üëç (2)"
"873009180938743828","sim_sam3","2024-04-26T00:36:49.4380000+08:00","That‚Äôs a good analogy. 

I want to make a joke about SMTP and propagating MX record updates but it‚Äôs Thursday and I‚Äôm almost out of gas","","ü§£ (3)"
"1057737574287945899","xamp4248","2024-04-26T01:22:36.5840000+08:00","There is a webinar available in flowfuse website regarding UNS implementation using HiveMQ broker. I didn't get a chance to watch the full length.","",""
"1184762752758194199","rma002","2024-04-27T03:37:09.5070000+08:00","Hi
Ignition sends data in spb format 

So I can‚Äôt have topics such as enterprise site area line cell

Rather it is something like spbv1 enterprise ddata site and then rest of topics becomes part of the name / payload

Should I use a script to avoid this

Or some way to then parse that data

Any suggestions please","",""
"801561312861618236","jon.forbord","2024-04-27T04:14:25.3440000+08:00","You CAN use system.cirrus..publish method on tag change scripts, to publish to flat mqtt. The other alternative is to build the site/area hierarchy in the tags in Ignition, and publish to group id = ent, leave node id and device id blank, and publish from the root folder. In a UNS you can have both regular mqtt following the ent-site-area topic hierarchy, and a SpB Namespace with the nodes, devices and metrics in a ISA-hierarchy.","",""
"801561312861618236","jon.forbord","2024-04-27T04:14:59.1060000+08:00","This is the method taught in mentorship practical","",""
"685604620810322017","mattventer.","2024-04-27T05:11:47.6850000+08:00","In my case, I publish SpB to a local Broker. I then have HighByte listen to the topic before transforming into flat MQTT. The data is then published to an enterprise broker.","",""
"801561312861618236","jon.forbord","2024-04-27T05:32:50.8220000+08:00","Is there somewhere described how to do SpB to flat in highbyte?","",""
"685604620810322017","mattventer.","2024-04-27T05:48:01.3790000+08:00","Not that I can find. It works like this though; HighByte SpB connection to local Broker, Input that listens to topic (specify Group, Edge node, etc.), populate instance parameter with SpB input, flow instance out to Enterprise Broker (MQTT connection). For the enterprise flow - use an Event Type, and add in the SpB as an Event Source (that way no message will be lost).","",""
"817835202746253344","IIoT#4707","2024-04-27T05:48:01.6420000+08:00","GG @MatthewVenter, you just advanced to level 3!","",""
"801561312861618236","jon.forbord","2024-04-27T05:52:10.0980000+08:00","Think I get the gist of it. But let‚Äôs say I have 300 000 metrics from 20 edge nodes, and I wanted to convert this to flat?","",""
"568913935147728896","zeratall","2024-04-27T05:52:29.6240000+08:00","I‚Äôm pretty sure they have a video going SpB to JSON on their YouTube, the video was roughly when they just released pipelines.","","üíØ (1)"
"568913935147728896","zeratall","2024-04-27T05:54:54.7860000+08:00","Yep it‚Äôs here https://youtu.be/p_YCfPprTGE?si=Eazug_vetCYIi-mv","",""
"685604620810322017","mattventer.","2024-04-27T06:03:12.0780000+08:00","Certainly possible. Pipelines could also be used for this. I often make sure to enable store and forward (acts as a buffer in case of high throughput).","",""
"801561312861618236","jon.forbord","2024-04-27T06:16:43.3500000+08:00","Namaste üôèüèª","",""
"801561312861618236","jon.forbord","2024-04-27T06:17:11.1000000+08:00","Thanks, that hit the right spot!  Awesome!","","‚ù§Ô∏è (1)"
"685604620810322017","mattventer.","2024-04-27T06:27:54.0570000+08:00","Definitely do some initial testing though as that sounds like a lot of load. I use this approach for OEE information (coming out of Ignition).","","üëç (1)"
"1011806669874937956","vikanchira","2024-04-27T16:03:17.6150000+08:00","Referral please. I am asked to quote an Enterprise MQTT Broker to an End-User. The End-User want to use it for their entire organisation that consists of multiple Business Units.

We (Appomax) did their Centralized Solar Roof Monitoring Platform. Details as follow:
- IIoT platform (N3uron) deployed in AWS
- 85 sites sending MQTT payload every minute.
- Standard MQTT 3.1.1 Payload
- Average of 2,300 tags per site. Aprox 200k tags total
- Currently using AWS IoT Core as the MQTT Broker

The customer wants to bring in
- Multiple SCADA Water treatment sites that in total will bring in about 150k tags per minute
- Other Systems that would add around 40k-60k tags per minute
- The customer wants the option a self managed solution where they can move to other cloud or their own data center.

I can go through contacting all the usual suspects but it will take a bit of time. Please do let me know who to speak to from the MQTT broker vendors. Thanks you üôè","",""
"230441548653789184","r.pop","2024-04-27T21:34:43.0390000+08:00","Are you asking for a direct contact or just companies?","",""
"1011806669874937956","vikanchira","2024-04-27T21:39:01.2980000+08:00","Direct contact please. I would like to skip filling all of the forms on HiveMQ, EMQX, etc. and go through several qualifying sales person before talking to a tech person and eventually might or might not get a timely quote. üòÜ","",""
"230441548653789184","r.pop","2024-04-27T21:41:12.9920000+08:00","@vikan For HiveMQ I would say to just join their slack, or you can reach out directly to Ryan Dussiaume ryan.dussiaume@hivemq.com","",""
"230441548653789184","r.pop","2024-04-27T21:42:18.7040000+08:00","You can tell him Remus Pop referred you","",""
"230441548653789184","r.pop","2024-04-27T21:43:49.4910000+08:00","Keep in mind though that the enterprise broker for HiveMQ will run your customer close to $250k/year","",""
"1214242167640424619","zack.scriven","2024-04-27T22:35:16.7530000+08:00","I‚Äôd recommend EMQ-X as the ideal enterprise broker for this project. Talk to @Jaylin","",""
"1011806669874937956","vikanchira","2024-04-27T23:53:14.0020000+08:00","Thanks, just sent him a DM","",""
"1020682408460296212","trey_onan","2024-04-28T09:04:07.7900000+08:00","Having an issue with Ignition MQTT engine pulling in topics from a Mosquitto broker (running on Pi 5) using the Sparkplug B namespace. Works fine if I create a custom namespace in Ignition, but no bueno when just leaving the Sparkplug B namespace enabled. I have scoured the web trying to find a specific setting, configuration, etc. I also noticed that when using a custom namespace you have to provide additional scripting to publish to the topics, which isn't a huge issue, BUT if successfully subscribing to the Sparkplug B namespace automatically grants write access (publish) without additional scripting, that would obviously be preferred. I'm a bit of an MQTT noob, so any ideas or clarifications would be greatly appreciated. I haven't reached out to Cirrus Link yet, thought I would start here.","",""
"817835202746253344","IIoT#4707","2024-04-28T09:04:08.0540000+08:00","GG @trey_onan, you just advanced to level 1!","",""
"794020366536146977","mparris","2024-04-28T10:33:26.8500000+08:00","It's clear that your have Ignition MQTT Engine as a consumer of information, Mosquito as the broker to pass information through (and I assume 'Pi 5' = Raspberry Pi 5?), but I'm not clear what application is producing the information over Sparkplug.

Could you clarify?","",""
"1020682408460296212","trey_onan","2024-04-28T12:03:39.1340000+08:00","I have an MQTT client using Node Red on the same Raspberry Pi 5 as the broker and also a CodeSys PLC on a remote machine pointing to same broker. Both can subscribe and publish topics no problem. And again when I use a custom namespace on the MQTT Ignition setup, those topics come in under the tag browser.","",""
"794020366536146977","mparris","2024-04-28T12:07:04.5160000+08:00","NodeRed, while including nodes that take care of the encoding, do not include the logic of how to use Sparkplug... Unfortunately, NodeRed requires the user to program the logic within the flow, such as when to send a birth certificate. 

You may be able to search for a flow that is a good template for all this functionality?","",""
"794020366536146977","mparris","2024-04-28T12:07:59.5220000+08:00","Other users in this community may have some flows to get you going, too","",""
"801561312861618236","jon.forbord","2024-04-28T15:21:05.9980000+08:00","Did you check in the edge nodes folder?","",""
"1020682408460296212","trey_onan","2024-04-29T01:18:57.7450000+08:00","Yes, nothing there related to the topics from Mosquitto broker. The edge node folder populates when using MQTT distributor (Ignition broker) and using MQTT transmission. I think it has something to do with payload format not being correct for Sparkplug B when using the Mosquitto broker and Node Red. I've checked the GW logs and not seeing anything related to payload errors however. I am going to try MParris suggestion of using the Sparkplug B Node RED nodes and go from there.","",""
"801561312861618236","jon.forbord","2024-04-29T01:21:50.2140000+08:00","Good plan, just checking that you‚Äôve done the basic checks, the Edge nodes folder is easy to miss üôÇ 

Another option is to setup Ignition Edge with Transmission-module as the publisher node..","",""
"1020682408460296212","trey_onan","2024-04-29T03:50:08.0010000+08:00","Update: when using the Node RED MQTT sparkling library I am now getting stuff to show up under MQTT engine. Now to familiarize my self more with the spec. to parse out the data. Thanks guys for the feedback.","",""
"1096937278632374334","younitty","2024-04-29T23:29:49.7330000+08:00","What would be your main requirements for a UNS broker ? (Not necessarily implying MQTT)
- SparkPlugB compliant ?
- Configuration Friendly ?  (What exactly should we be looking for ?)
- Scalable ? (How to quantify this ?)
- Containized ready ?
- ....

Our  goal is to create an evaluation tool to benchmark COTS brokers.","",""
"898217314741280828","hobbes1069","2024-05-02T21:02:16.9920000+08:00","Off the cuff (so likely not everything), for the first I think you mean ""Sparkplug aware"". All compliant brokers are SpB compliant because they are payload agnostic. A SP aware broker may allow you to get more insights into the payload and/or be able to unpack it to another topic.

Configuration friendly is a must. I don't mind manual configuration for testing or edge cases, but if the management isn't easy then I don't scale, and if I don't scale the solution doesn't scale.

I would put Scalable and High Availability together because the solutions are related -> Clustering

I think both being able to run natively (RPM / DEB) is good, especially on the edge though nothing stops you from running Portainer in an edge PC, just depends on how lean of hardware you want to use, but containerization at this point is non-negotiable. Once you scale up to the Enterprise level I think it's highly likely the most digitally fluent organizations are going to be running Kubernetes.","",""
"867075936054149191","rickbullotta","2024-05-02T21:24:56.3500000+08:00","...and I would not consider Sparkplug support a foundational requirement nor a filter for choosing solutions,.","","üëç (3)"
"898217314741280828","hobbes1069","2024-05-02T21:38:09.1340000+08:00","TIL that `#` subscriptions include the parent topic, not just subsequent topics.","",""
"1184762752758194199","rma002","2024-05-04T05:21:15.1910000+08:00","Sorry I didn‚Äôt understand how to build this hierarchy in the tags @Jon Forbord 

So I have tag folders mqtt -> enterprise -> Site -> Area -> Line 

And tag path is the root folder and mqtt is root folder which won‚Äôt be published, is this and above folder structure correct 

What should I write in group ID? 

I understand to leave node id and device id blank","",""
"801561312861618236","jon.forbord","2024-05-04T05:23:15.1030000+08:00","GroupID = enterprise, and in transmitter set folder to enterprise as well.","",""
"801561312861618236","jon.forbord","2024-05-04T05:24:39.1410000+08:00","Alternately you can drop enterprise folder in the tags, and set folder to blank in the transmitter.","","üëç (1)"
"801561312861618236","jon.forbord","2024-05-04T06:05:14.4040000+08:00","@Rma here‚Äôs how to publish flat mqtt with engine, for instance using tag change script.","https://cdn.discordapp.com/attachments/1166016853991235594/1236076129115177083/2024-05-03_23_57_03-Gateway_Event_Scripts.png?ex=68def71a&is=68dda59a&hm=a1b16c635e4d7f4a0b0f0f4d252074387b30631c008e8bd735f1cb5e343671bf&","üëç (3)"
"801561312861618236","jon.forbord","2024-05-04T06:05:33.4600000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1236076209339629681/2024-05-04_00_00_28-EmptyProject_-_docker-test_-_Ignition_Designer.png?ex=68def72d&is=68dda5ad&hm=c5261edbc46aecb7745fc693836d69a180650402be2517b3e4625667a9f01988&",""
"801561312861618236","jon.forbord","2024-05-04T06:06:12.0280000+08:00","Should be: Default, not [Default]","https://cdn.discordapp.com/attachments/1166016853991235594/1236076371130978386/Transmitter1.png?ex=68def754&is=68dda5d4&hm=d63200402194063f8cb5aaad50bea302c063d4298d8bf57ee716ca5eef226004&",""
"801561312861618236","jon.forbord","2024-05-04T06:06:27.8880000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1236076437144997918/Transmitter2png.png?ex=68def763&is=68dda5e3&hm=ec4a8382aba7ce953d529b4eefc54dbca8294110966589fa124db81f46c965df&",""
"898217314741280828","hobbes1069","2024-05-06T22:59:23.2210000+08:00","Found these guys today, would work for a minimal integration with a machine for a decent price. Made to integrate with a light stack and will publish to MQTT (no TLS support though)
https://www.icpdas-usa.com/sl_p6r1_wf.html","",""
"894527802316046366","nickn5549","2024-05-07T07:50:29.8120000+08:00","Interesting. I've built my own light stacks to send the status to MQTT and email Notifications from manual stations. Still, I need something like this to integrate the existing light stacks of the  machines into the same process MQTT & Notifications.","",""
"756543760028139720","aronsemle","2024-05-07T19:07:41.5620000+08:00","One other useful tool, if you haven't used it, is the Ignition logs in the their web portal. It sounds like your node red setup may not have been responding to BIRTH requests correctly (or something like that). In that case if you go into the Ignition logs you'll see error messages that are pretty helpful. Aside from that, general advice would be to get an extenral MQTT client with a SPB decoder and monitor the topics. That's a good way to troubleshoot misbehaving SPB stuff.","",""
"862313514931847169","jramirez3","2024-05-08T18:38:36.1200000+08:00","Does the retain flag mean that the topic won't ever disappear/deleted/etc., from the broker? That's the way I understood it but in practice that's not happening. 

I'm sending a value on a topic via vanilla MQTT with QoS 1 and retain True. After some time (maybe minutes or hour not sure yet) the topic disappears, it's no longer in the broker. 

Why does that happen if the retain flag is True?","",""
"1073312001788477471","sparkylarks","2024-05-08T18:55:41.3400000+08:00","Which broker,?
I'm pretty sure my retained topics stayed for as long as I needed them

I never timed it. But I did come back a week later connect my client and found the retained topics","",""
"862313514931847169","jramirez3","2024-05-08T19:05:53.1760000+08:00","MQTT Distributor from Cirrus Link on an Ignition Gateway.","",""
"867075936054149191","rickbullotta","2024-05-08T20:30:19.6230000+08:00","It should be ""retained"", with one exception : if you publish an empty payload, the broker will delete the topic.","","‚¨ÜÔ∏è (3)"
"862313514931847169","jramirez3","2024-05-08T21:20:57.0910000+08:00","Interesting. I shouldn't be publishing an empty payload to that topic. On some of the topics that are not retaining, I don't see how it would ever send an empty payload.","",""
"817835202746253344","IIoT#4707","2024-05-08T21:20:57.4980000+08:00","GG @jramirez3, you just advanced to level 3!","",""
"1096937278632374334","younitty","2024-05-08T21:43:12.7910000+08:00","Could ActiveMQ be a good choice to implement UNS/IIoT ?
We never see it being proposed along with HiveMQ, Litmus, EMQX, Chariot, etc","",""
"867075936054149191","rickbullotta","2024-05-08T23:15:59.0390000+08:00","Like Kafka, I think ActiveMQ would start to suffer with large #'s of topics.","",""
"528668306690015284","vatsalshah","2024-05-09T00:54:30.5030000+08:00","Nope it won't suffer - ActiveMQ  / Artemis does very nicely for most of the Industrial Apps. It is very good for mid-large number of topic and high throughput per topic.
Don't use it as a global broker - site broker is fine.  Not full MQTT though.","",""
"867075936054149191","rickbullotta","2024-05-09T01:21:58.5570000+08:00","The reviews are mixed though. Apparently it takes a lot of magic parameter setting to get performance out of it.","",""
"528668306690015284","vatsalshah","2024-05-09T02:24:53.2490000+08:00","Yepp true - lots of docs for it to tweak it. And that thing never crashes - robust to the core.","",""
"794020366536146977","mparris","2024-05-09T20:41:29.6810000+08:00","@Jaylin EMQx's release schedule is out of control!","https://cdn.discordapp.com/attachments/1166016853991235594/1238108585079341117/image.png?ex=68df1bb9&is=68ddca39&hm=3f8c7d52f10afd33a7a472fb7794b0b9fc028b72607a5b1f40d99c478a651a7d&","üòÇ (1)"
"794020366536146977","mparris","2024-05-09T20:44:35.1230000+08:00","Version 4 for comparison:","https://cdn.discordapp.com/attachments/1166016853991235594/1238109362929795115/image.png?ex=68df1c73&is=68ddcaf3&hm=d965957e230fc5a70b84a625405903cd3f87a55ac246ae548fdcae621def017f&",""
"794020366536146977","mparris","2024-05-10T21:05:59.9710000+08:00","@Jaylin The frustrating part, is that if all I care about is MQTT functionality, what corrections/improvements to the MQTT function justifies this level of churn on versions?

My bet is that that all this churn has little to do with MQTT (such as external integrations), which is ironic for an MQTT broker...","",""
"867075936054149191","rickbullotta","2024-05-10T22:25:16.1580000+08:00","The MQTT broker vendors all need to decide if they want to be an MQTT broker or an IoT or IIoT platform (those are actually three different things).","","üíØ (5),ü§î (1)"
"721948711126827009","jaylinyu","2024-05-10T22:31:07.2950000+08:00","I totally understand, while ""someone"" struggles to be another character.
However, all these new coming versions don't hurt the MQTT func, though; if there is, then it shall be a bug; I definitely will fix it.","",""
"721948711126827009","jaylinyu","2024-05-10T22:32:33.3450000+08:00","and there actually are some real stuff regarding mqtt functionality, MQTT Stream, persist data of each topic for certain period, give u a snapshot of whole state of topic, allows you to consumes history msg via offset or packetid","","üëçüèº (2)"
"528668306690015284","vatsalshah","2024-05-10T23:54:00.7120000+08:00","Or enter in the Industrial DataOps and create more nuisance for everyone üôÇ","","üòÇ (2)"
"867075936054149191","rickbullotta","2024-05-10T23:55:07.8110000+08:00","Like flies to‚Ä¶","","üòÇ (2)"
"794020366536146977","mparris","2024-05-11T00:30:33.0530000+08:00","This is going to be a struggle for EMQx adoption within manufacturing environments.

Manufacturing looks for stability for the functions they need/use.  The speed that EMQx is burning through version numbers for its MQTT broker forces users to comb through all those release notes to idenify the MQTT broker function that have changed.  All this effort, usually, only to find that nothing was truly improved on core MQTT functions, but the version upgrades force users to take on unnecessary risk due to obsolescence of previous versions....all in the service of extra integrations being developed.","",""
"794020366536146977","mparris","2024-05-11T00:45:13.4100000+08:00","I think all the vendors are looking to differentiate from pure MQTT broker to have clear value over something like Mosquitto.

""Additionally, the lines between Information Gateway and Data Broker are beginning to overlap with newer products on the market. For example, Communication Layer software is starting to incorporate functions to allow some amount of Data Ops within their product. Additionally, Information Layer software primarily focused on Data Ops is beginning to include communication components such as MQTT Brokers."" - IEB Nov 2022
https://iebmedia.com/technology/iiot/how-all-protocols-fail-at-data-access-interoperability/

Fun times!","","‚ù§Ô∏è (1),üëç (2)"
"528668306690015284","vatsalshah","2024-05-11T00:58:24.9770000+08:00","Very nice article!

Ideally, brokers should focus on features like context brokering, in-stream processing, extended security, lower TCO, in-stream DBs, and more. That will get them more revenue. When they start doing those things, they get killed by Kafka - competition is brutal and monopolistic. 
So, to increase revenue (or revenue streams), they have to focus on either the Producer or Consumer of their brokers, AKA Industrial DataOps. It's inevitable, and if they don't, they will be replaced by commodity brokers. 
The moment they do that, they took a bite bigger than their core business. Fun stuff is bound to happen üôÇ","","üëç (1)"
"742752935947010118","busch1974","2024-05-11T03:58:43.0090000+08:00","Hey Jon..  I want to pick your brain.","",""
"1214242167640424619","zack.scriven","2024-05-16T05:15:37.6240000+08:00","@Jon Forbord ?","",""
"801561312861618236","jon.forbord","2024-05-16T07:29:21.8340000+08:00","Brain has been picked in dm üôÇ","","üôè (1),üß† (1),üëà (1),üòÇ (1),ü¶∑ (1)"
"862313514931847169","jramirez3","2024-05-19T00:21:09.3990000+08:00","How quickly do people get data from remote equipment? Is it common for people to retrieve data at minute intervals? Like 15 minutes?","",""
"862313514931847169","jramirez3","2024-05-19T00:22:08.1570000+08:00","I ask because I feel like a potential employer that I may work for  is behind in the times since at my current company we get data as it changes, so if it changes once a second then we get the data. So it just seems odd that companies get it at 15 minutes.","",""
"794020366536146977","mparris","2024-05-19T01:45:19.8920000+08:00","Could you clarify what ""remote equipment"" in this context means?","",""
"862313514931847169","jramirez3","2024-05-19T01:49:35.3160000+08:00","Big thing is oil wells in remote locations.","",""
"801561312861618236","jon.forbord","2024-05-19T01:53:21.8880000+08:00","I believe this was the original use for Phillips 66 that spurred the invention of MQTT back in late 1990s.","",""
"862313514931847169","jramirez3","2024-05-19T02:05:37.5290000+08:00","Correct. But not all oil companies use it unfortunately.","",""
"794020366536146977","mparris","2024-05-19T02:46:01.4130000+08:00","Typically, these deployments are sensitive to bandwidth.

If using an inefficient protocol, then you'll typically pay the price via latency.","",""
"862313514931847169","jramirez3","2024-05-19T02:52:34.3820000+08:00","Correct but cell has come a long way and MQTT being so light weight   also, with Starlink you can get data just about from anywhere.","",""
"862313514931847169","jramirez3","2024-05-19T02:53:47.2090000+08:00","I only bring it up because where I currently work we operate equipment that we move from location to location every so often and we send data via MQTT on every change, a lot quicker than minute data. We don't have any issues with that or any high data costs.","",""
"862313514931847169","jramirez3","2024-05-19T02:55:22.6130000+08:00","I guess I'm comparing the technology between where I currently work to where I could work. And how Walker talks about young people going into a plant with old technology, they feel they have gone back in time.","",""
"862313514931847169","jramirez3","2024-05-19T02:56:00.3910000+08:00","I'm trying to figure out if that applies to this potential job or not. That if I go to this other company I'll feel like I've gone back in time.","",""
"867075936054149191","rickbullotta","2024-05-19T03:31:56.9950000+08:00","Well, with oil above $80 a barrel the data costs don‚Äôt matter much.  Different story at $30!","",""
"862313514931847169","jramirez3","2024-05-19T03:35:39.5130000+08:00","Yes but doing remote polling back to a server to the remote equipment via OPC, it uses a lot data, alot more than MQTT.","",""
"801561312861618236","jon.forbord","2024-05-19T04:22:29.6460000+08:00","Going from offshore in Norway to onshore in U.S. feels like going 50 years back in time. And seeing offshore in Norway the first time felt like going back to the 90s. (10 years ago).

üòÖ","",""
"862313514931847169","jramirez3","2024-05-19T05:05:24.6590000+08:00","That's how I felt talking to the automation engineers during an interview.","",""
"862313514931847169","jramirez3","2024-05-19T05:08:27.1020000+08:00","So that's what I'm trying to gauge if I'm understanding how different it would be leaving where I'm at. Currently I get to work with any hardware I want. I don't use things that work like devices from the 90s.","",""
"862313514931847169","jramirez3","2024-05-19T05:12:14.1780000+08:00","I don't want to jump ship now if 6 months down the road and be really bored with the work I'm doing. Or limited with what we can do because of the hardware.","",""
"862313514931847169","jramirez3","2024-05-19T05:13:33.4820000+08:00","Also, I'd like to say thank you to everyone who has taken the time to answer questions for me. I don't have anyone to talk to about my career that really understands.","",""
"794020366536146977","mparris","2024-05-19T06:20:09.0570000+08:00","There is the chance that you could is be the one that spearheads that other company to use more modern methods.  But you have to evaluate if that is something they are on board to do...","","üíØ (1)"
"745370232700272661","willsobel.","2024-05-22T21:17:19.4690000+08:00","I would say 15 minute is much too slow. 1 sec max for states and 100ms for telemetry. Data can be aggregated and published every second for a reasonable driver for analytics. That's what we've found in practice.","","üíØ (1)"
"1214242167640424619","zack.scriven","2024-05-23T09:05:16.0690000+08:00","So is MQTT no longer message queue telemetry technology?","",""
"1214242167640424619","zack.scriven","2024-05-23T09:05:42.9100000+08:00","I heard a while ago it simply stood for MQTT after a certain point","",""
"794020366536146977","mparris","2024-05-23T09:43:03.5380000+08:00","Yes, I believe today, there is no definition for the initialism... The protocol is simply called ""MQTT""","",""
"753688565807841492","ravil1","2024-05-23T09:46:35.1210000+08:00","History is repeated. Similar to ""OPC"" is not ""OLE for Process Control"" anymore üòÜ","","üíØ (1)"
"794020366536146977","mparris","2024-05-23T10:02:36.2010000+08:00","üòÅ","",""
"867075936054149191","rickbullotta","2024-05-23T10:19:00.9750000+08:00","The wishful acronym for MQTT is ‚Äúmight query the things‚Äù.  Not holding my breath.","","üòÖ (5),üòÇ (1)"
"1214242167640424619","zack.scriven","2024-05-23T21:19:03.3410000+08:00","lol","",""
"873009180938743828","sim_sam3","2024-05-23T21:53:38.5190000+08:00","unsolicited advice because what else is social media: always select sample rates based on the use-cases you've defined that require that data. if you don't have use-cases defined, well, you know where to start.","",""
"1214242167640424619","zack.scriven","2024-05-27T02:18:57.6330000+08:00","stop polling. start using edge-driven architecture. and you can go from 15 minutes to 1 second updates.","",""
"1214242167640424619","zack.scriven","2024-05-27T02:19:00.1350000+08:00","!mtr","",""
"817835202746253344","IIoT#4707","2024-05-27T02:19:00.5620000+08:00","These are the Minimum Technical Requirements for your IIoT Ecosystem:

1. Edge-Driven
2. Report by Exception
3. Lightweight
4. Open Architecture.","",""
"1214242167640424619","zack.scriven","2024-05-27T02:21:37.6930000+08:00","@jramirez3  here is the video that demonstrates your solution. https://youtu.be/2Z8a94CWtCs","",""
"1214242167640424619","zack.scriven","2024-05-27T02:22:03.6830000+08:00","including unacceptable polling rates (5-15 minutes) to near-realtime data.","",""
"1214242167640424619","zack.scriven","2024-05-27T02:22:41.7020000+08:00","do it JRamirez!","",""
"1003237589421137992","gregory.g.","2024-05-27T18:15:58.0080000+08:00","Hi all, question:

I have tools available such Ignition (and/or Highbyte).
Via Ignition we connect to all sorts of Edge devices.
These tags we can put in an organized way (ISA95) - preferably in the topic ""Edge"", functioning as a ""raw data namespace"".
-> using folders or UDT to organize it.

In a topic ""Measurement"" I would like to put some relevant/specific datapoints.
These datapoints should be extend with additional meta-data such as: 
UoM, alarm limits Low/High/Etc, alarm activation, and maybe some other parameters...

1) How can we efficiently add these parameters to that relevant measurement datapoint?
2) Can these parameter be published as 'properties' via SparkplugB ?
3) Or should we split these parameters up as individual tags?
4) create UDT for each datapoint? (worrying about creating a technical debt)

Looking for some advice üôÇ
not sure if this question belongs more in the UNS topic in Discord","",""
"230441548653789184","r.pop","2024-05-28T22:49:54.6180000+08:00","You can add all the parameters to your UDT for ""Measurement""","",""
"230441548653789184","r.pop","2024-05-28T22:52:37.7180000+08:00","Create a UDT for Measurement, and in that UDT include all the information you would want as part of a measurement data point.","","üëç (1)"
"1197952122038255637","ajcamm_88960","2024-06-05T10:50:11.0570000+08:00","Any ideas of devices that I can deploy in my Smart Home and use with Mosquito to get more hands on time with MQTT?","",""
"766684226455207996","bright_hummingbird_31342","2024-06-05T12:42:45.7620000+08:00","Start with use cases and how users would need to consume data to solve problems.  This will inform and priotize the direction you go.  Don't think of it as something that will be locked in.  It can evolve over time.

Related discussion:
https://discord.com/channels/738470295056416930/1166016853991235594/1214965009415938078","","üëç (2)"
"789507385194053632","thooor9411","2024-06-05T14:51:26.9690000+08:00","can somebody please explain this to me and maybe give some exemple if the customer is saying the following ""  We want to mainly use MQTT as interface for that. We already developed standardized data blocks which describe topic structure and payload for that purpose. The huge amount of self developed machines will be adapted to this new standard."" so they sctructured data lika isa95 in the broker and maybe defined payload for the mqtt tags? am i right?","",""
"1073312001788477471","sparkylarks","2024-06-05T16:11:14.7320000+08:00","I would say you have a lot right there 

I think of technologies and the payloads as fundamentally separate.

but a lot of OT comms define both the technology and the payload, 
so Modbus, the payload is always a set of integers.

On an IT there tends to be less linking, so my payload on a Restful interface has much more flexibility.


""Plain Vanilla"" MQTT is completely decoupled from the payload.
Sparkplug has a defined payload structure.

I prefer to use ""Plain Vanilla"" MQTT, because of Topic naming freedom, and I find Sparkplug too restrictive but I standardise my payload structure( to the same as Sparkplug) , because it can make life much easier.

If a node is using Sparkplug, I parse the data using the Parris Method.

IF the payload is strut rued differently, I restructure it at a gateway level","",""
"132948361685762048","despicable_dan","2024-06-05T18:39:45.1490000+08:00","@Andrew Camm 
I have been walking this road as well. Currently I‚Äôve deployed an IOT stack on a rpi5, and an ESP32 with 4 soil moisture sensors for the girlfriends plants in our office. The Arduino sends soil moisture values back to the broker, and for the moment I display them on a node-red dashboard. Next phase will be utilizing influxdb and grafana.","","üëç (1)"
"898217314741280828","hobbes1069","2024-06-05T20:25:08.4330000+08:00","All the Shelly WiFi stuff for one, and anything you build yourself from microcontroller, ESP32 etc.","",""
"693309801589112862","_dyland","2024-06-05T20:45:19.3020000+08:00","My smart home stuff has bleed into the home lab a bit so I have a combination of Shelly, Tasmota, custom built (ESP32, 8266), Zigbee2MQTT, and Home Assistant (with Node Red to publish on change) as well as some random PLCs, Sensors, an IFM IOLink Master, and some other stuff I have accumulated over the years. 

There are a lot of ways to get started but the easiest is probably the Shelly stuff. For actual home automation, Home Assistant really opens the door. It is compatible with almost anything. I can even control my Phillips hue bulbs via MQTT.","",""
"898217314741280828","hobbes1069","2024-06-05T21:14:47.0370000+08:00","I added some Zigbee sensors from IKEA and by default Home Assistant used ZHA, I'm assuming I need to switch to Zigbee2MQTT to have more open access to my sensors?","",""
"693309801589112862","_dyland","2024-06-05T21:16:10.4010000+08:00","I had a friend who had already used Zigbee2MQTT so I started there, not sure if ZHA is better or worse to be honest.","",""
"693309801589112862","_dyland","2024-06-05T21:16:37.6080000+08:00","Zigbee2MQTT can also be used without Home Assistant which is pretty cool too.","",""
"898217314741280828","hobbes1069","2024-06-05T21:17:26.5620000+08:00","It came later so initially the only option was Zigbee2MQTT. From what I read online ZHA is a more native integration with HA and it is very simple. After I detect a new sensor it automatically populates the dashboard the the info.","","üëç (1)"
"693309801589112862","_dyland","2024-06-05T21:20:49.0790000+08:00","That makes sense, the Zigbee2MQTT path is pretty roundabout. 

Zigbee Sensor -> Zigbee2MQTT -> MQTT Broker -> Home Assistant and back. 

Even more roundabout to get to my ""Home UNS"" where it continues from Home Assistant -> Node Red -> another MQTT Broker -> other stuff.","",""
"817835202746253344","IIoT#4707","2024-06-05T21:20:49.3940000+08:00","GG @Dylan DuFresne, you just advanced to level 15!","",""
"898217314741280828","hobbes1069","2024-06-05T21:21:18.4960000+08:00","If you need a good temp, %RH, and VOC sensor it's pretty nice for the money:
https://www.ikea.com/us/en/p/vindstyrka-air-quality-sensor-smart-30498239/","",""
"898217314741280828","hobbes1069","2024-06-05T21:21:35.0220000+08:00","They want you to use their hub but it's standard Zigbee inside.","",""
"867075936054149191","rickbullotta","2024-06-05T21:23:09.5650000+08:00","My Zigbee hate is deep.  Resetting/unbinding them is SUCH a PITA.","","üëç (1)"
"693309801589112862","_dyland","2024-06-05T21:23:23.5190000+08:00","Good to know, pretty much all of my zigbee stuff is Sonoff or Aqara. Mostly on Shelly and custom stuff these days though.","",""
"898217314741280828","hobbes1069","2024-06-05T21:24:23.1840000+08:00","I haven't had that problem, but I'm not using a standard setup. I can remove them from HA easy enough and the IKEA sensor has a reset button. May be different with their smart lights. Haven't tried those yet.","","üëçüèº (1)"
"693309801589112862","_dyland","2024-06-05T21:27:26.4890000+08:00","Yeah, there are some weird issues that feel like bugs for sure. I'm sure you know more of the technical reasons than I do and I might hate them too if I dug deeper but I have a lot in the house and the ones that are set up work great. I just know not to move them too far from the original position.","",""
"693309801589112862","_dyland","2024-06-05T21:29:11.2450000+08:00","At minimum, it was a good and easy way to get started for cheap. I am mostly on Shelly stuff these days and homemade sensors.","",""
"867075936054149191","rickbullotta","2024-06-05T21:48:22.8610000+08:00","Even with Hue bulbs, I have a helluva time resetting/unbinding them.","",""
"693309801589112862","_dyland","2024-06-05T21:49:58.4300000+08:00","The Hue Bulbs were the worst for me. Getting them off the Hue Hub was a major pain...","","üíØ (1)"
"1050076217329586368","volkan0341","2024-06-05T22:52:07.8250000+08:00","https://www.linkedin.com/posts/volkanalk%C4%B1l%C4%B1%C3%A7_iot-iiot-mqtt-activity-7190681825130725376-nxl6?utm_source=share&utm_medium=member_desktop","",""
"801561312861618236","jon.forbord","2024-06-06T05:18:04.7930000+08:00","The Homey has an app that can turn you entire setup to mqtt. Its actually how i got started with UNS and discovered this community. 

https://homey.app/no-no/app/nl.hdg.mqtt/MQTT-Hub/","",""
"801561312861618236","jon.forbord","2024-06-06T05:20:27.3500000+08:00","Homey is awesome! Its like a ¬´UNS¬ª for home automation. I can bring all my smart devices into one app.","",""
"794020366536146977","mparris","2024-06-06T07:20:42.6160000+08:00","I went Zwave for the longer range...

Have you tried devices on that?  They have a pairing system, too, but seems fairly straight Forward to reset and pair","",""
"898217314741280828","hobbes1069","2024-06-06T08:49:00.2890000+08:00","I was interested in Zwave as well but I went with Zigbee since all the stuff at IKEA is Zigbee. As far as range, I haven't had a problem with my HA server w/ Zigbee USB adapter getting to my bedroom on the opposite side of the house.","",""
"794020366536146977","mparris","2024-06-06T11:03:49.7680000+08:00","Yeah, my choice was made without any real data, mostly just fear, and it also came from the desire to not ADD more stuff in the 2.4Ghz RF band...

Can Zigbee devices also act as signal repeaters?","",""
"801561312861618236","jon.forbord","2024-06-06T14:33:26.7030000+08:00","If they‚Äôre grid-powered they will act as zigbee repeaters. 

I use both z-wave and zigbee. Z-wave has been the far more stable in terms of performance. But z-wave is limited to like 256 devices and max 2 hops. It is also proprietary and devices have a premium on their price because of that (afaik).","",""
"801561312861618236","jon.forbord","2024-06-06T14:33:55.7560000+08:00","Zwave is in theory a dying standard.","",""
"801561312861618236","jon.forbord","2024-06-06T14:34:22.7460000+08:00","We have zwave in everything that is permanently mounted in our house üòÖ","",""
"1088631859509989426","jpmac.s","2024-06-08T05:25:23.2530000+08:00","Is anyone using Ignition Maker for their HA setup?","",""
"898217314741280828","hobbes1069","2024-06-08T10:20:35.1260000+08:00","I just developed my own Docker Compose with Ignition Maker, Mosquitto, and TimescaleDB but haven't had any time to do anything with it other than connect Igniton to both.","","üëç (2)"
"1088631859509989426","jpmac.s","2024-06-08T10:30:04.6250000+08:00","What are you running it on?","",""
"898217314741280828","hobbes1069","2024-06-10T05:39:19.1280000+08:00","Nothing fancy. An old SFF Dell i5-4590 I have in the closet. It's main purpose is for BackupPC so it's not doing much most of the time.","","üëç (1)"
"867075936054149191","rickbullotta","2024-06-17T21:31:55.8360000+08:00","Progress on Sparkplug seems to have come to a complete stop.  Convince me otherwise.

https://github.com/eclipse-sparkplug/sparkplug/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc

https://github.com/eclipse-sparkplug/sparkplug/","","üòÆ‚Äçüí® (1)"
"867075936054149191","rickbullotta","2024-06-17T21:32:32.7010000+08:00","I'm officially declaring Sparkplug dead. Without necessary fixes, it has no applicabilty as an enterprise UNS protocol.","","üíØ (1)"
"1052622839431307274","marco_moiron","2024-06-17T22:57:56.9990000+08:00","Hello, all.
We are implementing an UNS in our company and it is comprised of several local EMQX MQTT brokers (one per site) whose topics are bridged to an AWS hosted instance of EMQX Enterprise. We now want to test having AI based software provider connected to the EMQX Enterprise to stream realtime process data from it and, eventually, publish high level setpoints that will be propagated through the MQTT bridge to the plant brokers and then to the plant control system. 
To implement this I can: 
1. expose the AWS hosted instance of EMQX Enterprise TLS TCP port (8883) to the internet.
2. make it internal only and force the providers to connect to our company's VPN.

I would appreciate your opinion and advice on this matter. What are the best practices?

Thank you,

Marco","",""
"867075936054149191","rickbullotta","2024-06-18T00:37:28.0320000+08:00","Can you whitelist specific IP addresses?","",""
"1052622839431307274","marco_moiron","2024-06-18T00:40:23.6650000+08:00","@RickBullotta , that could be an option, assuming the providers can do it.
thank you for the suggestion.","",""
"867075936054149191","rickbullotta","2024-06-18T22:33:02.8240000+08:00","Just a heads up that MQTT Explorer seems to be adding a bunch of new features - lots of activity on Github.  Notably, support for decoding SpB.

https://github.com/thomasnordquist/MQTT-Explorer","","‚ù§Ô∏è (3),fire (4),üëç (2),üëÄ (1),üíØ (1)"
"794020366536146977","mparris","2024-06-19T00:11:48.2490000+08:00","What the what?

Sparkplug decoding was added in Feb 2022, but no new binary has ever been created.

What changed to open the floodgates starting Mar 8, 2024????","",""
"794020366536146977","mparris","2024-06-19T00:21:49.3980000+08:00","Commit History...

Went from dead to active:","https://cdn.discordapp.com/attachments/1166016853991235594/1252659547219300514/image.png?ex=68df4f5d&is=68ddfddd&hm=b3fc1a366abc74bd05791eee6a41f18a5bf66a9df2c50ced9f1cb9fa7ef38dc9&",""
"794020366536146977","mparris","2024-06-19T00:56:49.1300000+08:00","Sparkplug support is so close...

There must still be some items to fix, because the latest beta has the decoding disabled:","https://cdn.discordapp.com/attachments/1166016853991235594/1252668354083295423/image.png?ex=68df5791&is=68de0611&hm=e7795a83f45293af1c56c58af72e90531bd0e9483631e90782428d49ffe52202&",""
"794020366536146977","mparris","2024-06-19T00:57:19.6250000+08:00","Recognize `@klaernie` from HiveMQ...","https://cdn.discordapp.com/attachments/1166016853991235594/1252668482315751565/image.png?ex=68df57af&is=68de062f&hm=d116202e04512e95861ae719d1f13c005c93395b2a591cc280beec2386bfff51&",""
"794020366536146977","mparris","2024-06-19T00:59:54.9430000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1252669133523386570/image.png?ex=68df584a&is=68de06ca&hm=a2add849c38bff561199c047bf1b24d78dbe207288e886bae6b2166b55d9e60d&",""
"794020366536146977","mparris","2024-06-19T01:00:03.9530000+08:00","First release update in four years!","",""
"801561312861618236","jon.forbord","2024-06-19T03:19:56.0520000+08:00","I did send some casherooneys to him on PayPal with a message saying 3000 community members was going to beat him senseless if he didn‚Äôt resurrect MQTT explorer, back in end of February!","","ü§£ (2),üòÜ (1)"
"794020366536146977","mparris","2024-06-19T03:22:41.1090000+08:00","I did the same in Feb..... of 2022!!!","","üòÖ (1),üòÄ (1)"
"801561312861618236","jon.forbord","2024-06-19T03:24:31.9810000+08:00","Agreed! If they don‚Äôt move forward soon it will forever be left as a promising idea that never went anywhere beyond SCADA.

I see it as they have two options to thrive. 

1. Be the best SCADA/L1/2 protocol there is, and really hone in on that primary use-case. 
2. ‚ÄúSpecialize‚Äù as the go to standard for enterprise UNS.","",""
"1063829764164563026","mariano.beracochea","2024-06-19T20:16:36.3830000+08:00","which is the benefit of sending all the data on one JSON? Is a real question i want to learn. It reduce network usage, but i think it goes against the ""dont assume how data is going to be consume"". If i got 10 machines that push their data on a JSON format, and one 1 data from each, i would need to subscribe to the 10 big JSONs and parse the data to look for the one i want, it seems like it transfer the load on the consumer.","","üëç (1)"
"867075936054149191","rickbullotta","2024-06-19T20:29:54.1490000+08:00","I strongly prefer separate topics.","",""
"1203453953115693159","stephenbryant_89711","2024-06-19T20:43:48.7680000+08:00","Separate topics with single values?

I'm interested in this, as I'm also looking for commonly used patterns.  At Hannover, I asked Litmus and they said throw everything in a JSON, they like it like that.  üôÇ

As an OEM, I guess I'll have to make our devices be able to publish both ways (single JSON + separate topics) and have have config options to turn off what isn't wanted.  How does that sound?","","üíØ (1)"
"867075936054149191","rickbullotta","2024-06-19T21:50:55.2170000+08:00","Always think of how CONSUMERS would like the data, not what's easiest for PUBLISHERS.  That's my mantra.  Also, by including lots of datapoints in single payload/topic, you lose granularity for access control, subscriptions, and so much more.  Modern MQTT brokers can handle millions of topics.","","üëç (2),üíØ (1)"
"867075936054149191","rickbullotta","2024-06-19T21:52:33.0650000+08:00","I would always do separate topics, but with a simple MQTT wildcard expression, consumers could easily subscribe to all of them.  MyDevice/Temperature MyDevice/Pressure MyDevice/Flow = MyDevice/#","","üíØ (2)"
"382941357699760129","walker.reynolds","2024-06-19T21:59:51.6230000+08:00","Single topics should be where you start ‚Äî a very common approach in UNS architecture is to use single topics and then package them into another topic as an endpoint for a software consumer.  A simple example, in our company UNS we have 

*/KPIS/Sales
*/KPIS/Transactions
*/KPIS/TransactionAVG
*/KPIS/DailySalesAVG

They are single topics and consumed by local dashboards, DB and historian.  We then have HighByte consume them and build a sibling endpoint for BigQuery

*/KPIS/BigQuery

where payload is {‚ÄúTable‚Äù:{‚ÄúSales‚Äù:value, ‚ÄúTransactions‚Äù:value, ‚ÄúTransactionAVG‚Äù:value, ‚ÄúDailySalesAVG‚Äù:value}}

This is a very common approach","","üíØ (1)"
"898217314741280828","hobbes1069","2024-06-19T22:00:45.7390000+08:00","""Make no assumption on how the data will be consumed,"" could probably be rewritten slightly. It's about not assuming what data is important. You always have to think about the consumer. If single tags work best, do that. If you have data that likely would be consumed together and your consumer can parse it, go ahead and publish a complex JSON paylaod.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-06-19T22:01:18.7070000+08:00","I also like to keep data together when its usage is atomic - e.g. an alarm event that might have a bunch of data fields, a material consumption event, a downtime event, etc...","","üíØ (2)"
"382941357699760129","walker.reynolds","2024-06-19T22:01:52.7800000+08:00","This is a big one","",""
"753688565807841492","ravil1","2024-06-19T23:24:47.2540000+08:00","Yes, brokers can have millions of topics. But they have limits on message throughput (number of messages received from a publisher per second) when QoS is set to 1. It would be big improvement if I could send multiple publish messages (with different topics) in one network message.","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2024-06-19T23:30:00.1880000+08:00","This is probably the number one thing I see OT, specifically industrial controls, people fail to grasp.  They think of data as how its produced and less so on how it can solve problems.  They think of data as points that their SCADA/HMI or historians consume.  Meanwhile, everyone else around them is struggling and building their own spreadsheets for their own needs.","","üíØ (2)"
"867075936054149191","rickbullotta","2024-06-20T00:11:34.8480000+08:00","Agree 100%.   I've specifically recommend a change to the MQTT protocol to support exactly that - ""multi-publish"".  The MQTT committee hasn't shown any interest or willingness to listen to market needs though.","","üíØ (2)"
"1052622839431307274","marco_moiron","2024-06-20T01:59:05.9160000+08:00","the companies we have relations with (AI/ML providers, etc) don't always have static IP addresses. A more elegant solution would be using Server Certificate/Client Certificate/Client key. Don't you think so?","","üíØ (2)"
"1214242167640424619","zack.scriven","2024-06-21T08:53:38.1720000+08:00","Let‚Äôs keep it rolling","",""
"1063829764164563026","mariano.beracochea","2024-06-22T02:29:31.3030000+08:00","How does the source timestamp works? different device can have different clock value, how does this aling data? or it is meant to put data on the correct timestamp for that particular machine, on a graph only for that machine?","",""
"753688565807841492","ravil1","2024-06-22T03:37:15.7250000+08:00","This is interesting qustion for me too. 
In my understanding, MQTT has nothing to do with timestamps. It is completely up to the publisher to add timestamps in the payload. 
I think in terms of UNS, whatever value is the latest published, it is comsidered as ""current value"".  Although in fact it might be days old, and since then it might be connection with the publisher was lost. I think it is up to the subcribers to subscribe ot the death certificate and figure out based on that, that specific topic value is not up to date anymore.","",""
"801561312861618236","jon.forbord","2024-06-22T06:53:25.2730000+08:00","Using the timestamp from the source instead of the consumer ensures that data from one source is aligned no matter when it ¬´lands¬ª at the consumer. 

On the other hand, as you say, multiple sources may have misaligned clocks. There are several ways to go about syncing clocks, but mose common is to use some form of ntp-setup with a gps-clock. 

If you need mqtt data to be aligned fairly well in time, its always good to include the timestamp. Ravil is just pointing out a fact about asynchronous communication, such as mqtt.","","üíØ (2)"
"1063829764164563026","mariano.beracochea","2024-06-22T07:04:51.8080000+08:00","when walker talk about looking for aligned rising edge of signals with modification of data to find a correlation on data, what timestamp you use? because you need an alignment on the milisecond level and i dont know of PLCs that can take their timestamp of a main server. How do you handle this?","",""
"867075936054149191","rickbullotta","2024-06-22T10:25:26.8550000+08:00","While not always precise the source timestamp is also a reliable source for change indication.  Agree with your assessment.","",""
"801561312861618236","jon.forbord","2024-06-22T13:17:37.7030000+08:00","I dont think Walker is referring to cases where you need that level of millissexond presicion wrt the UNS and correlating events from multiple data sources. 

Siemens S7-1500s can be setup to sync with an NTP. Most modern PLCs should natively support some form of timesyncing. 

We use source tinestamps as the primary sync mechanism. We do not rely on the broker having data in sync from multiple data sources.. We collect some of our data at 1ms intervals.","",""
"1203453953115693159","stephenbryant_89711","2024-06-22T22:02:08.8100000+08:00","About those misaligned clocks: I was able to sneak into a TSN Plugfest at the Uni Stuttgart a couple of months ago.
They had a gigabit network across 7 TSN switches (from various vendors), and had a dedicated time server from a Scottish company.  TSN uses PTP rather than NTP, but that requires hardware timestamping support in the Ethernet cards.

The time accuracy was always within 100 _nanoseconds_, regardless of the network load.  As a comparison, NTP accuracy in the same LAN is around 1millisecond, but only under ideal conditions.

This is how you solve the misaligned clock problem.  We all know how important the accuracy of source data is for better evaluation later, and an accurate timestamp needs to be given at the moment the data point is created.

Imagine when your entire factory has its clocks synchronised that accurately.  It's clear to me that TSN is the future, as it's still Ethernet underneath.  I expect we'll see single-cable sensors using TSN+PoE; talk to the PLC on one VLAN and to MQTT on another - safe!","",""
"817835202746253344","IIoT#4707","2024-06-22T22:02:09.1950000+08:00","GG @Stephen Bryant, you just advanced to level 2!","",""
"770812543387959306","bryceyo","2024-06-22T23:44:39.7130000+08:00","Rockwell has an AOI for time sync if that is your PLC.
Most historians that I‚Äôve seen are around .5 and 1 second update. The timestamps is normally the time the data was written to the Historian. So PLC clocks being synced aren‚Äôt necessary.","",""
"161671622166577153","aphexddb","2024-06-24T22:22:17.5520000+08:00","Facebook open sourced a PTP solution (https://github.com/opencomputeproject/Time-Appliance-Project/tree/master/Open-Time-Server/) as well if you want to roll your own","",""
"382941357699760129","walker.reynolds","2024-06-25T07:33:34.5790000+08:00","I'll be talking about this more while the US Patent Office reviews Schneider's Application

https://www.linkedin.com/feed/update/urn:li:activity:7211145254589063168/","","üëè (2)"
"382941357699760129","walker.reynolds","2024-06-25T07:41:26.5630000+08:00","I am talking about them being aligned in UNS.  If I am looking to find a correlation between ToolWear, Vibration and Quality -- in the image attached -- then the first thing I have to do is contextualize and then normalize this data.  UNS gives us the ability to -- even if vibration changes at 60hz, ToolWear is measured every 1000ms and Quality is calculation every 5 mins.  UNS gives us the ability to retrieve and store at 60hz (or at n interval) {'Timestamp':{'Vibration':value, 'ToolWear':value, 'Quality':value}} for storage in context and normalized.  *Note* We do not recommend pulling from UNS at that resolution, we recommend buffering from the edge at that resolution and publishing all 60 changes in a second to one payload.","https://cdn.discordapp.com/attachments/1166016853991235594/1254944508219625503/image.png?ex=68df0da6&is=68ddbc26&hm=4e6cd7f56d953908555893f9364c1cf48786114823d8f8a47420ce98f5f7d155&",""
"867075936054149191","rickbullotta","2024-06-25T08:35:17.8940000+08:00","They can probably defend it based on the ‚Äúconfiguration‚Äù angle, but who knows.","",""
"867075936054149191","rickbullotta","2024-06-25T08:37:28.5210000+08:00","And I hate patent trolls.  What is interesting though is that in 1999/2000 or so Schneider had a concept called the ‚Äútransparent factory‚Äù which was 10-30 years ahead of its time.  PLCs could have an embedded HMI served as web content, APIS to read and write data, quite visionary actually.  Never went anywhere at the time.","",""
"867075936054149191","rickbullotta","2024-06-25T08:39:12.6060000+08:00","1997 actually, and here‚Äôs the backstory. I think you‚Äôll actually be impressed by the vision.  The patent shit, not so much.

https://blog.se.com/industry/machine-and-process-management/2016/02/25/the-grandfather-of-iiot-transparent-factory-architecture-was-a-great-vision/","","üíØ (1),üôè (1),üëç (1)"
"382941357699760129","walker.reynolds","2024-06-25T09:00:32.3710000+08:00","This is the patent they sued Opto22 under ‚Äî when Opto used web pages for PLC configuration.  They argued a broad interpretation of claim and Opto eventually stopped fighting and took the web pages out of their  hardware.","","ü•≤ (1)"
"382941357699760129","walker.reynolds","2024-06-25T09:01:06.9450000+08:00","They would do the exact same thing here if it‚Äôs awarded ‚Äî they have some crazy broad claims in the application","",""
"1063829764164563026","mariano.beracochea","2024-06-25T20:51:27.5260000+08:00","Hello, this would go better on a historian channel but it also apply here. I just read the specification of the Canary consumer, it consums SpB 2.2, 3 and JSON, if you use it as your historian and publish plain MQTT with the tags one by one, you use a middleware that take all those tags and put them together on a JSON, then publish it on another namespace where Canary can subscribe to it? is there another work around this?","",""
"1073312001788477471","sparkylarks","2024-06-25T22:47:15.4300000+08:00","are you trying to use Canary to read from a plain MQTT namespace.
if so you can create a script in the setup to parse the tags in your broker","",""
"1063829764164563026","mariano.beracochea","2024-06-25T22:56:50.5810000+08:00","Yes, thats what im trying. The script can be configured on Canary?","",""
"1073312001788477471","sparkylarks","2024-06-25T23:05:17.1370000+08:00","yes, when you select Json instead of sparkplug, Canary defaults to the KepwareIOT payload structure, but you can write a custom script. I will try to find the one I created,","",""
"1073312001788477471","sparkylarks","2024-06-25T23:58:50.5970000+08:00","@Mariano B I think I used this","https://cdn.discordapp.com/attachments/1166016853991235594/1255190479000309813/MQTTScriptTest2.txt?ex=68df49fa&is=68ddf87a&hm=ec91bdd52d276262e6beac1a4795e8010f45dfcd8c51c3618585e204ef7f21ee&",""
"1063829764164563026","mariano.beracochea","2024-06-26T00:06:21.4240000+08:00","Thanks Mark
On the same page, how is historian data retrived by other systems? you publish all the history from Canary to the broker on a JSON? are there commands sended using MQTT that can get to canary and this publish the asked interval of data of the asked tag?","",""
"1073312001788477471","sparkylarks","2024-06-26T00:13:19.0580000+08:00","I didn;t get that far, but I though you can Query the Canary historian,  I dont; kow if you can publish the output dataset from a historina Query, from inside Canary","",""
"1052622839431307274","marco_moiron","2024-06-26T01:29:13.2780000+08:00","I'd say that, when the interval of historical data is useful to more than one node, publishing it at regular intervals in the broker makes all sense (tonne/hour productivity minute samples from midnight until now for daily production KPI calculation). It is less obvious if we are just interfacing two systems (it is almost like following a religion, then) but it is, for sure feasible. The ""Destination node"" could publish the request in a ""Hist data request topic"" including Start Time, End Time and Variable Mame and the ""Source node"" would answer in the ""Hist data answer topic"" with a json frame with all the values and timestamps alongside with the variable name that would be received and ""decoded"" in the ""Destination node"". Should we implement it this complex way, or just connect both systems via rest API? (our personal use case is connecting Flowsoft to Canary for KPI calculation).","","üíØ (1),ismile (1)"
"1073312001788477471","sparkylarks","2024-06-26T01:40:51.8280000+08:00","This is a great question and I have not done enough to really know the answer, but I think there are certainly cases where it is worth publishing a historical set of  data to a broker is beneficial, but I think a lot of the time there is not much benefit to using API's.

I think with current state, there is one value, and certainly a lot of potential for different systems to want to know that value.
with historical data, different applications are probably interested in different historical ranges so it might be harder to find that saving.","",""
"801561312861618236","jon.forbord","2024-06-26T02:36:22.0740000+08:00","Rest API! This type of queries are by nature P2P and the timeframe and tags and aggregations queried will depend on how the user interacts with the system. Like 9/10 times using the API for those queries is the right choice.","",""
"801561312861618236","jon.forbord","2024-06-26T02:37:43.9160000+08:00","If it however is more systematic in nature and for instance can be setup with a query tag in Ignition or a flow in Highbyte, the query response could definitely be part of the UNS.","","üíØ (1),üëç (1)"
"138867775354437632","jonathan08947","2024-06-26T04:14:01.4870000+08:00","Personally,  I found the Canary json scripting to be more trouble than it's worth. That was a big reason I went with TimescaleDb with custom C# scripts instead of Canary. I'm sure it's different if you're using sparkplug,  but for vanilla mqtt, I didn't like the experience.","",""
"817835202746253344","IIoT#4707","2024-06-26T04:14:01.9290000+08:00","GG @Jon, you just advanced to level 1!","",""
"770812543387959306","bryceyo","2024-06-26T04:39:43.8560000+08:00","So does TimescaleDB support SparkplugB aswell as flat?","",""
"1073312001788477471","sparkylarks","2024-06-26T04:57:41.6560000+08:00","That works for some usecase, and I am doing the same on my current project.

But its not many maintenance techs who can easily extract data from Timescale to troubleshoot an issue at 3am","",""
"138867775354437632","jonathan08947","2024-06-26T05:23:48.3790000+08:00","You'd have to supply a connector. Either write your own or use something like Telegraf. I think it's a higher barrier to entry but more customizable solution.","",""
"138867775354437632","jonathan08947","2024-06-26T05:26:34.8490000+08:00","Good point,  I'm currently working on how to make extracting data easier.","",""
"873009180938743828","sim_sam3","2024-06-26T10:33:45.3940000+08:00","Solaia, the og patent troll. They sued BMW, Clorox, Boeing, Rockwell, OPC Foundation and a bunch of others. 

‚ÄúIn 2001, working with Niro, Henderson formed the first true PAE, Solaia Technology LLC, which was the sole bidder for a patent involving the use of spreadsheets in manufacturing equip- ment, ..‚Äù

https://media4.manhattan-institute.org/sites/default/files/tli_update_11.pdf","",""
"867075936054149191","rickbullotta","2024-06-26T12:33:25.2000000+08:00","GE threw its lawyers at this and made it go away","",""
"1073312001788477471","sparkylarks","2024-06-26T15:39:52.8220000+08:00","To me the value of a historian, is not how well it can store data, but the tools it gives to allow people solve problems with that data.","","üíØ (6)"
"817835202746253344","IIoT#4707","2024-06-26T15:39:53.1190000+08:00","GG @Mark O'Donovan, you just advanced to level 20!","",""
"1063829764164563026","mariano.beracochea","2024-06-26T19:19:12.9280000+08:00","Isnt Axiom a good tool to access your historical data?","",""
"1073312001788477471","sparkylarks","2024-06-26T19:26:02.5520000+08:00","I have not used it extensively, but I found it quick to access the data, I had some issues, but I would say a lot of that is my lack of familiarity.

I was able to use it quickly to diagnose problems capturing waste weights. so it did what I needed to, with no training or not much reading of documentation so at least 4 stars,","",""
"1073312001788477471","sparkylarks","2024-06-26T19:26:54.1820000+08:00","UMH I think have a tool for retriving historical data from timescale, and graphing it,","",""
"873009180938743828","sim_sam3","2024-06-26T20:35:35.8970000+08:00","https://tenor.com/view/the-three-stooges-larry-moe-curly-slap-gif-14123471","","ü§£ (3)"
"161671622166577153","aphexddb","2024-07-01T14:25:06.6030000+08:00","After lots of annoyed muttering about sparkplug data on my part, I'm sharing **glowplug**, an open source tool to view sparkplug metric data in a human readable way in either Redis, or a UNS https://github.com/american-factory-os/glowplug. Feedback, hot takes, and bug reports most welcome","","üíØ (1)"
"898217314741280828","hobbes1069","2024-07-01T21:48:15.4280000+08:00","That's pretty cool! I'll try it out when I have some Sparkplug devices online.","",""
"1057737574287945899","xamp4248","2024-07-03T03:22:17.9420000+08:00","Hi all, is there any sample flow for node-red spb. including all commands 
    NBIRTH
    DBIRTH
    NCMD : REBIRTH
    NDEATH

    DDATA (from node input)
    DCMD (send as output to Node-Red)
    DDEATH (set via a msg command)","",""
"794020366536146977","mparris","2024-07-05T02:17:33.0850000+08:00","A fantastic article written by @aronsemle !

I recommend this getting pinned to this channel: 
https://bit.ly/3W77eFB","","üëç (8)"
"867075936054149191","rickbullotta","2024-07-05T04:29:21.4340000+08:00","Nice work by the HiveMQ team with these new features, including seamless expansion of sparkplug metrics into separate topics.  Great to see!

https://www.hivemq.com/blog/whats-new-in-hivemq-4-30/","","üëç (1)"
"867075936054149191","rickbullotta","2024-07-05T04:32:09.2120000+08:00","It does miss arguably the biggest shortcoming of MQTT : no capability for topic browsing.","",""
"794020366536146977","mparris","2024-07-05T04:34:21.9620000+08:00","I thought he covered that here: 



""The root cause of this problem is that MQTT is report-by-exception and doesn‚Äôt have a way to expose what topics/data are available or control what data is sent to consumers. Other protocols like OPC UA solve this by exposing a browse interface and allowing clients to browse the data that‚Äôs available, select what they need, and determine how often to consume it. This approach is generally better when data is needed on-demand""","",""
"867075936054149191","rickbullotta","2024-07-05T04:39:01.3050000+08:00","Missed that!  I was looking at the headings.","","üëç (1)"
"794020366536146977","mparris","2024-07-05T04:48:47.8510000+08:00","Aron has you covered üí™","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-07-05T04:54:22.7880000+08:00","Wait until you get a chance to try HighByte‚Äôs version 4.0 stuff! He and team definitely have us covered!","",""
"862313514931847169","jramirez3","2024-07-06T01:14:23.2880000+08:00","Does anyone know of a platform to build apps for IOS and Android that connects to an MQTT broker?","",""
"867075936054149191","rickbullotta","2024-07-06T07:21:24.3760000+08:00","JavaScript.  MQTT over websockets.","",""
"1203453953115693159","stephenbryant_89711","2024-07-07T03:14:21.4690000+08:00","I know that Qt (C++) supports both platforms.  They also have an MQTT library which is available under a commercial license or GPL - but _not_ LGPL, so watch out for that.

To be honest though, I'd look at WebSockets first, as Rick already mentioned.  I know that Mosquitto and Hive both support WebSockets.  Also, unless you're doing something exotic, the web part of the app should be identical on both iOS and Android.  You can also run it directly in your desktop browser too, which makes development easier.  I'll go one further: your mobile device clearly has network connectivity - do you really need your app to be a locally installed?","","üíØ (1)"
"862313514931847169","jramirez3","2024-07-07T05:48:09.5510000+08:00","The app needs to be locally installed. It's too much for people to go to a website at least that's what I'm told. And if competitors have an app and customers say they'd rather use that company because they have an app, then we gotta have an app as well.","",""
"867075936054149191","rickbullotta","2024-07-07T20:33:56.0170000+08:00","You can do native notifications, branding, and other stuff with an app, even if it's just a container for HTML content.","",""
"537493750621143041","hisma","2024-07-09T01:20:01.2620000+08:00","hey guys, what's the preferred tool for converting OPC-UA to MQTT sparkplug B?  Let's say the OPC-UA data is a siemens S7 PLC, or any PLC that has a built-in OPC-UA server.","",""
"537493750621143041","hisma","2024-07-09T01:21:06.9810000+08:00","I'd want to do this on the edge, with the purpose of creating tags in ignition.  So ignition would subscribe to the MQTT server.","",""
"867075936054149191","rickbullotta","2024-07-09T01:53:43.0170000+08:00","Ignition can discover tags from OPC UA and OPC classic...","",""
"537493750621143041","hisma","2024-07-09T01:54:21.7340000+08:00","yes I know, but I have a specific use-case for this.  it's a bit of a mess","",""
"537493750621143041","hisma","2024-07-09T01:56:08.5670000+08:00","from what I can see, when ignition subscribes to an OPC-UA endpoint, it just subscribes to the entire namespace. it doesn't let you choose.  So I have a bunch of tag bloat coming from my PLC.  Now, would it be better to clean up the tag bloat on the PLC side? Yes, but unfortunately, the system is mid-FAT and if I go in and start cleaning up the PLC, I have to Re-FAT the system, which our schedule can't support","","üëçüèº (1)"
"537493750621143041","hisma","2024-07-09T01:57:16.8610000+08:00","so i'd like to insert a gateway in the middle that is smart enough to ""pick & choose"" what tags to subscribe to, then have that gateway be an endpoint that ignition subscribes to","",""
"867075936054149191","rickbullotta","2024-07-09T01:57:44.9900000+08:00","Yup.  I think Ignition could do that itself, as could some of the OPC UA gateways.  Not 100% sure though.","",""
"537493750621143041","hisma","2024-07-09T01:58:29.2100000+08:00","so I guess I don't need to convert OPC-UA to spb at all, though it was more a curiosity, as we use spb already at the enterprise level (it's stupid and not my decision, I'm just the OT guy)","",""
"537493750621143041","hisma","2024-07-09T01:59:44.0600000+08:00","it can't.  unless someone can prove me otherwise.  your only option is to select an OPC-UA endpoint, and when you do so, it subscribes to the global address space (ie the whole shebang)","",""
"867075936054149191","rickbullotta","2024-07-09T02:03:24.7950000+08:00","I'm fairly sure you can selectively import tags in Ignition:

https://www.ourscada.com/main/system/help/Browsing_and_Creating_OPC_Tags.html","",""
"867075936054149191","rickbullotta","2024-07-09T02:03:57.7230000+08:00","And also...

https://forum.inductiveautomation.com/t/recommended-approach-to-importing-and-mapping-plc-udts-to-ignition-vision-tags-opc-ua-s7-1500-plc/78016","",""
"537493750621143041","hisma","2024-07-09T02:13:47.9850000+08:00","interesting, will look into this!","",""
"375728638106271765","juba5060","2024-07-09T02:14:13.8220000+08:00","Let me know if this isn't what you are looking for.","https://cdn.discordapp.com/attachments/1166016853991235594/1259935592775684178/Flow.json?ex=68df69b5&is=68de1835&hm=75f54f5dec0f8b0fe683d35339063e842d4a2d96cf703b7172138fad37bdbed1&",""
"537493750621143041","hisma","2024-07-09T02:36:48.4000000+08:00","this is extremely helpful.  What the first response refers to as a problem is exactly what is happening to us.  We're putting an excessive load on the PLC comms performance bc we have a bunch of UDTs and ignition is subscribed to all of them.  We maybe actually need 20-30% of what ignition is subscribing to, and it's bringing our PLC to its knees.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-07-09T03:03:04.6290000+08:00","Excellent! Glad it helped.","",""
"801561312861618236","jon.forbord","2024-07-09T04:43:41.9030000+08:00","It most definitely can sub selectively to Individual tags. I dont know what would give you impression that it can not? 

Ignition is pretty decent at taking OPC UA tags allowing you to structure and shape the data independent of the underlying OPC UA tags structure, and then publish as SpB.","",""
"801561312861618236","jon.forbord","2024-07-09T04:50:11.0290000+08:00","If you drag and drop a folder from an S7 OPC UA server in Ignition, it will add OPC UA tags in bulk, but it will ‚Äústop‚Äù in the hierarchy when you hit a UDT or a struct and create document tags with several values. Is this what you‚Äôre struggling with? Browse beyond the top node with the UDT and you can drag and drop underlying tags one by one into Ignition instead.","",""
"537493750621143041","hisma","2024-07-09T05:26:29.8770000+08:00","honestly? bc I lack ignition experience and my team lacks opc-ua experience.  so it's a bad combo.  And we a rockwell house so typically don't deal with opc-ua on the device-level.  mostly with ethernet/ip when interfacing w/ ignition, so this is a first time for us.  all I know is we're bringing the schneider PLC we're trying to interface w/ ignition to its knees.","",""
"817835202746253344","IIoT#4707","2024-07-09T05:26:30.1280000+08:00","GG @Richard Meyer, you just advanced to level 5!","",""
"537493750621143041","hisma","2024-07-09T05:27:42.8130000+08:00","i do my best to keep up w/ the latest trends but ultimately i'm not nearly as much of a ""hands on"" engineer as I used to.  I manage engineers these days.  but i'm always willing to learn, hence why i'm here. üôÇ","",""
"537493750621143041","hisma","2024-07-09T05:31:08.7160000+08:00","we're using an NUA module, which is just an OPC-UA add-on module, to get our schneider modicon PLC to communicate to ignition using OPC-UA.  And we have some bulky UDTs that are causing quite awful performance with plc as well as some delays w/ certain actions in ignition.","",""
"801561312861618236","jon.forbord","2024-07-09T05:31:10.9410000+08:00","I ask why, bc you seemed pretty certain it couldn‚Äôt, so I‚Äôm curious why you would be so certain.. as in what did you do that made you draw the conclusion.. 

Anyway not too important. Yea, OPC UA servers on S7s are somewhat limited, but the thread above from the Ignition forum seems to give good suggestions for how to get more from less in that respect.","",""
"537493750621143041","hisma","2024-07-09T05:32:29.9660000+08:00","that was the conclusion of my team, not myself.  i didn't have the experience to tell them otherwise.  they just don't understand opc-ua enough tho they're very skilled w/ ignition.","",""
"801561312861618236","jon.forbord","2024-07-09T05:32:31.2670000+08:00","And are they Schneider or S7s? You mentioned S7s before?","",""
"537493750621143041","hisma","2024-07-09T05:33:20.6830000+08:00","I used S7 as an example as its interchangeable in the sense its a PLC that has an OPC-UA server.  My specific use-case is schneider. Which I assume is less common.","",""
"801561312861618236","jon.forbord","2024-07-09T05:35:53.8120000+08:00","You‚Äôd think that wouldn‚Äôt matter. But my experience is that every PLC brand seems to do OPC UA slightly different from the others.. It could be a problem of browsing, meaning the browsing of the OPC UA namespace will not expose underlying tags, with Schneider PLCs. If, IF You‚Äôre lucky, you can still read individual tags, but you‚Äôll have to manually add the tag name, rather than drag and drop.","",""
"801561312861618236","jon.forbord","2024-07-09T05:37:19.1830000+08:00","We use OPC UA, with Siemens PLCs and use Ignition to convert this to MQTT/SpB. We also hand pick what we need because of limitations on the OPC UA server on the S7s.","",""
"537493750621143041","hisma","2024-07-09T05:48:33.8920000+08:00","I see.  that might be my case","",""
"537493750621143041","hisma","2024-07-09T05:48:53.1760000+08:00","in that i can only browse the root global namespace","",""
"537493750621143041","hisma","2024-07-09T05:49:09.2110000+08:00","in which case i might want to use a gateway in between.","",""
"444415644801171467","markpitout","2024-07-09T06:03:58.9870000+08:00","Hi @Richard Meyer .
I have an M580 in my home office with a BMENUA card. If it would help you, I can do some testing for you. If you want to send me your application, DM me and I'll send you my email address.

I may also suggest, using the ""HMI Variable"" tick box on the variables you want to send to Ignition + changing the project settings to only include HMI Variables in the Data dictionary. This will limit the amount af data that gets exposed in the OPC-UA server of the BMENUA.","","üëç (2)"
"537493750621143041","hisma","2024-07-09T06:08:36.0550000+08:00","good to know.  I noticed that HMI variable option and again, I'm not hands on w/ the software enough (I'm mostly in meetings w/ the customer etc) so I haven't had a chance to look closely enough at this","","üëç (1)"
"537493750621143041","hisma","2024-07-09T06:09:36.2830000+08:00","this was also our first time using schneider too.  one of those instances where our sales guy made a decision for us.  literally nobody on our team had used schneider in their lives.  we really cut our teeth on this project.","",""
"537493750621143041","hisma","2024-07-09T06:10:18.3580000+08:00","this was done back when rockwell had supply chain issues & our sales guy said ""well schneider has short lead times so schneider it is!"" without realizing the implications... lol","",""
"537493750621143041","hisma","2024-07-09T06:10:24.0330000+08:00","typical integrator bullshit.","",""
"444415644801171467","markpitout","2024-07-09T06:10:54.2790000+08:00","Hit me up if you want a bit of a crash course. 
Modicon M340 & M580 is litterally my life...","","‚ù§Ô∏è (1)"
"537493750621143041","hisma","2024-07-09T06:11:51.2010000+08:00","not many of you out there!  I will certainly consider to take you up on your offer.  Let me shoot you a DM.","","üëç (1)"
"444415644801171467","markpitout","2024-07-09T06:12:35.8160000+08:00","And if you master M580 then SCADAPack RTUs are very easy to master after that. (The other part of my life...)","",""
"444415644801171467","markpitout","2024-07-09T06:15:59.6560000+08:00","Man that sucks having to learn a new PLC platform on the job. Each brand has it's own quirks and tricks. I could not imagine having to learn another brand of PLC at a whim during a project.","",""
"537493750621143041","hisma","2024-07-09T06:17:56.4240000+08:00","welp we did it. with an absurdly tight schedule.  it's been... not fun.  but good news is that the guys are getting the best training possible (by being thrown into the fire), so soon we'll have schneider expertise on our team to go along w/ our rockwell expertise.","",""
"444415644801171467","markpitout","2024-07-09T06:19:26.2190000+08:00","Diversity is always useful. And high pressure is where diamonds are made.üëç","",""
"537493750621143041","hisma","2024-07-09T06:19:51.5030000+08:00","indeed!","",""
"537493750621143041","hisma","2024-07-09T06:21:23.0600000+08:00","sent you a DM...","",""
"537493750621143041","hisma","2024-07-09T06:21:31.7500000+08:00","@DaftWullie","",""
"867075936054149191","rickbullotta","2024-07-09T23:15:51.7380000+08:00","A public service announcement for anyone running HiveMQ 4 self-hosted or in a Docker container: the default configuration settings will SEVERELY limit performance if you have a heavy publish rate of message (inbound publish messages).  There's a setting in config.xml that is ""true"" by default, that you'll want to change to ""false"" to get decent performance.  In my case, the default setting was restricting a client to publishing about 70-75 messages per second - and removing it boosted throughput to well over 1500 messages per second.  It seems like a well intentioned feature that was perhaps not implemented optimally.

<?xml version=""1.0""?>
<hivemq xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"">

    ...
    <overload-protection>
        <enabled>false</enabled>
    </overload-protection>
    ...
</hivemq>","","üëç (4)"
"452467225098715154",".autok","2024-07-09T23:23:44.4250000+08:00","Hi,

I'm working with a SparkplugB In node in Node-RED, but I'm having trouble reading the metadata from my Ignition Transmission module. Properties"" field is empty.

Does anyone have any suggestions on how I can properly read the Sparkplug messages, including metadata like engUnit, in Node-RED?

Thanks","",""
"452467225098715154",".autok","2024-07-09T23:25:36.7450000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1260255546506874910/Node.png?ex=68df4230&is=68ddf0b0&hm=eb9a893eafbebaf313effd89a07381aef47044b952c4ae7f31a138543e091701&",""
"801561312861618236","jon.forbord","2024-07-10T00:29:03.2440000+08:00","Make sure youre subscribed to DBIRTH and NBIRTH? Most properties will only be published at birth.","",""
"452467225098715154",".autok","2024-07-10T00:34:43.1950000+08:00","Thank you, Jonüëçüèª","",""
"1057737574287945899","xamp4248","2024-07-10T01:30:01.6680000+08:00","Thanks @Grey Dziuba  for the flow. I am looking particular SPb node like below to generate messages to broker. Anyway I am working on this.","https://cdn.discordapp.com/attachments/1166016853991235594/1260286857011400745/image.png?ex=68df5f59&is=68de0dd9&hm=c2595a35a918400381e9028a5ff78909df5430d6fe299ea8d9458817bc039827&","üëç (1)"
"1057737574287945899","xamp4248","2024-07-10T18:23:47.4920000+08:00","Use DBIRTH method. Attached sample flow which I tested","https://cdn.discordapp.com/attachments/1166016853991235594/1260541978353991721/flows1.json?ex=68defb73&is=68dda9f3&hm=d597a27616ab785980a957954d544af9dd454253dbc9eecf7fef291df351276b&",""
"1057737574287945899","xamp4248","2024-07-10T18:35:34.2110000+08:00","My situation is different. I am publishing data from Node-RED and subscribing to  Ignition. I can see the structure inside Ignition, but I couldn't see the value. However, the value is available in the MQTT broker.","https://cdn.discordapp.com/attachments/1166016853991235594/1260544942560772187/image.png?ex=68defe36&is=68ddacb6&hm=c39cad67431c0efbcc689a4848211b3485981cc9b0c05bbd25aa6c7f7a79b7af&,https://cdn.discordapp.com/attachments/1166016853991235594/1260544942833533029/image.png?ex=68defe36&is=68ddacb6&hm=14d404bafd19d642a4682d5839fdeb72d06184496a532c8938fdb903fbf33314&",""
"795725198980677734","diederik9434","2024-07-10T18:48:35.4250000+08:00","What's the best way to move data between MQTT brokers? 
i have machine level brokers (HiveMQ CE), factory level brokers (HiveMQ broker in self managed kubernetes cluster) and a enterprise level broker (hivemq managed broker).

I would like to copy  data in between these brokers but without external software.  (for example reading data from broker 1 with nodered and placing it in broker 2 would work but that's a very clean solution)","",""
"801561312861618236","jon.forbord","2024-07-10T19:25:40.4130000+08:00","Hmm.. hard to say, but one thing, I dont see the NBIRTH in the broker. Has the NBIRTH been published?","",""
"1073312001788477471","sparkylarks","2024-07-10T19:26:33.4460000+08:00","you can Bridge the Brokers. There is a Hive Slack Chanell that might be a better place to ask.
though many of the same faces are there too.","",""
"1057737574287945899","xamp4248","2024-07-10T20:49:31.3550000+08:00","Yes. But I could not see the data in Ignition","",""
"1173270244291264535","andreasvogler","2024-07-15T13:22:41.4680000+08:00","Flutter (https://flutter.dev/), it runs almost everywhere and there is a MQTT client package for Dart.","",""
"1173270244291264535","andreasvogler","2024-07-15T13:32:44.1320000+08:00","Some time ago I made a simple SparkplugB console logger: https://github.com/vogler75/sparkplugb-printer","","üíØ (1),üî• (1)"
"452467225098715154",".autok","2024-07-19T21:35:20.9060000+08:00","Hi,

I'm struggling to connect my Ignition Engine and Ignition Transmission modules to the Azure Event Grid Broker. The Server Status briefly shows ""Connected"" before switching to ""Not connected.""

I read that Azure Event Grid supports MQTT v3.1.1 but doesn't support QoS2 or the Retain Flag, and that Cirrus Link MQTT Modules always include a Will Message with the Retain Flag. Could this be why my connection is failing?

Has anyone managed to connect Ignition to an MQTT broker in Azure Event Grid? Any advice would be greatly appreciated.

Thanks!","","ü§î (1)"
"867075936054149191","rickbullotta","2024-07-19T22:13:20.6660000+08:00","I'm wondering if you are connecting with the same ClientID - that will often cause other connections with the same ClientID to drop.","",""
"452467225098715154",".autok","2024-07-19T23:23:19.3000000+08:00","I've created a new Client-Engine and generated a new certificate just to be sure, but I still have the same situation. The status briefly shows ""Connected,"" then it quickly goes back to ""Not connected.""

Any other ideas on what might be causing this or how to resolve it?

Thanks!","",""
"1063829764164563026","mariano.beracochea","2024-07-19T23:47:41.2910000+08:00","maybe too basic, but you could have an IP overlaping, and that cause the intermitent service","",""
"452467225098715154",".autok","2024-07-20T00:10:14.9430000+08:00","I've tried two different Ignition gateways, but I'm still encountering the same issue. I've successfully connected MQTT Explorer and Node-RED without any problems. Could the MQTT v3.1.1 limitations in Azure Event Grid be causing these connection issues?

https://docs.chariot.io/display/CLD80/Can+I+connect+MQTT+Modules+to+Azure+Event+Grid

Thanks!","",""
"817835202746253344","IIoT#4707","2024-07-20T00:10:15.2260000+08:00","GG @SSJ, you just advanced to level 1!","",""
"1009878042044285009","moonahe","2024-07-25T12:02:22.9400000+08:00","Does anyone else feel duped by HiveMQ? We are a medium sized company. Only about 2000 employees. We just purchased a ""medium"" sized broker and only have 500 client connections. While we aren't huge and our message throughput is not going to be our bottleneck, we have at least 500 machines that we could eventually connect to the broker. I know we can do gateways and other tools to reduce the number clients, but when mosquito can theoretically handle 100K clients, it feels like now I have to build architecture into my system to ""protect"" my big dumb expensive piece of software.","",""
"794020366536146977","mparris","2024-07-25T12:53:29.9360000+08:00","Duped?  Did they inform you of the client limit of your license upon purchase? If so, it's hard to say they duped anyone.

If MQTT is all you need, it's very difficult to justify the cost of HiveMQ. The pure MQTT function is a commodity at this point, with all the free options available.  It seems drastic to jump so high in cost simply for enterprise support and not using the other features they offer.

If enterprise support is what you are after, did you investigate Cedalo or Litmus? I would bet those are closer to what you're looking for.","","ü§î (1),ü§ò (1)"
"1073312001788477471","sparkylarks","2024-07-25T13:48:54.4130000+08:00","Agreeing with @MParris but can I add.
1) if your not happy talk to HIve , and add more connections
2) If you are connecting to 500 machines, you might have much less than 500 gateways. 
I haven ever seen 500 machines in a plant that can talk natively to a MQTT Broker.

In fact I have never worked on a machine with native MQTT.  So most manufacturers need very few clients and lot of gateways. 100 machines to 1 Kepare Or Ignition is very manageable, and probably more if you want.","",""
"794020366536146977","mparris","2024-07-25T15:44:47.6550000+08:00","It could be that the broker they purchased is intended to be used for the whole enterprise (multiple plants/sites) so that's likely how they are reaching 500.

I'm not familiar with HiveMQ's licensing... The connection restriction could be total, even if there are tiered brokers federating the data up through MQTT Bridges.

Across six sites, our team is at over 600 pieces of equipment, where  each equipment has one or more MQTT clients... And this number continues to grow. So we'd definitely blow that license model out of the water","",""
"867075936054149191","rickbullotta","2024-07-25T21:16:54.9490000+08:00","You can disagree with their pricing, but when it comes to scalability/availability, granular access controls, broker-side data transforms, and other features that are hugely valuable to production level systems (versus hobbyist/POCs), you get what you pay for.","","üëç (2),hivemq (2)"
"731220706548777072","broken_ger","2024-07-25T21:18:06.7270000+08:00","you should consider a self hosted EMQX instance... The pricing of brokers is ridiculous these days... just rent yourself a server and install docker and the EMQX instance... all the offerings have flaws... might be number of connections or might be the rate at which you can send messages or might be the traffic... all garbage in my eyes!","",""
"731220706548777072","broken_ger","2024-07-25T21:18:40.0600000+08:00","at some point they try to get your money!","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-07-25T21:20:15.5000000+08:00","If you're running a production system with hundreds of clients on a single MQTT broker  instance with no redundancy or HA, you're probably doing it wrong.","",""
"731220706548777072","broken_ger","2024-07-25T21:21:56.8600000+08:00","setting up a cluster is not that hard...","",""
"731220706548777072","broken_ger","2024-07-25T21:22:31.2610000+08:00","if you need HA just rent multiple servers in different regions","","üíØ (1)"
"731220706548777072","broken_ger","2024-07-25T21:27:41.9690000+08:00","they offer a bring your own cloud solution as well but you pay for that service... i prefer independence over convenience!","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-07-25T21:33:17.5900000+08:00","Right, but aren't you out of the ""free"" tier when you add cluster support? (Note: Yes and no - if you want zero downtime upgrades/patches you need the paid version, but you can assemble a cluster of up to 3 nodes with the free version)","",""
"898217314741280828","hobbes1069","2024-07-25T21:53:02.8910000+08:00","We've got about 600 pieces of manufacturing equipment at my site and the only ones I'm aware of that have MQTT natively are the EOS Printers (laser sintering additive manufacturing)","",""
"1009878042044285009","moonahe","2024-07-25T21:55:02.4110000+08:00","Thanks. I've never heard of Cedalo and Litmus. I will check them out.","",""
"1009878042044285009","moonahe","2024-07-25T21:58:39.9460000+08:00","I might be naive here, but I thought the point of MQTT was that you don't need HA because the clients can hold messages until the broker becomes reachable.","",""
"817835202746253344","IIoT#4707","2024-07-25T21:58:40.2320000+08:00","GG @moonahe, you just advanced to level 1!","",""
"731220706548777072","broken_ger","2024-07-25T22:08:06.9230000+08:00","if your clients are designed like that its possible","",""
"731220706548777072","broken_ger","2024-07-25T23:09:58.9480000+08:00","the problem with mqtt (what AMQP does not have) is the problem if a client processes a message and dies while doing so which leads to message loss (AMQP takes the message from the queue if it got processed)","",""
"731220706548777072","broken_ger","2024-07-25T23:11:04.0980000+08:00","we in our puplic transport datahubs use good old RabbitMQ","",""
"1009878042044285009","moonahe","2024-07-25T23:20:42.6840000+08:00","I've never used it, but it looks like MQTT has the ability for a client to delay an acknowledgement to the server until after message processing.","",""
"731220706548777072","broken_ger","2024-07-25T23:22:07.8930000+08:00","no until recv","",""
"731220706548777072","broken_ger","2024-07-25T23:22:32.4710000+08:00","as soon the message has been recv the mqtt client ack it","",""
"731220706548777072","broken_ger","2024-07-25T23:23:14.5290000+08:00","that does not mean the message has been processed (e.g. database call which takes some time)","",""
"731220706548777072","broken_ger","2024-07-25T23:28:17.8440000+08:00","and this only works for QoS 1 and QoS2","",""
"867075936054149191","rickbullotta","2024-07-25T23:32:59.7540000+08:00","LOL.  I'm not going to call you naive, but while it's great that (some) clients can hold messages, that still means that your system is down.  It's a single point of failure.  Hierarchial system designs and/or some point-to-point interfaces still make sense when availability is critical.  Broker-based approaches also introduce ""double latency"", by design.","","üíØ (3)"
"731220706548777072","broken_ger","2024-07-25T23:38:07.3920000+08:00","MQTT is best for Fanout! AMQP is best for Transactions (maybe Kafka as well)!","",""
"731220706548777072","broken_ger","2024-07-25T23:38:39.6990000+08:00","but HTTP has still its place in Transactions as well","",""
"801561312861618236","jon.forbord","2024-07-26T02:58:56.5560000+08:00","Adding to that: MQTTs biggest advantage over AMQP imo is its simplicity and lower overhead. AMQP can do everything MQTT can and more, but is also more complex and resource demanding.","",""
"867075936054149191","rickbullotta","2024-07-26T03:02:56.5600000+08:00","It's all TCP under the hood...","",""
"801561312861618236","jon.forbord","2024-07-26T03:03:44.4100000+08:00","You can technically hold the PubAck until the message has been processed or put in some persistent local queue at the client with QoS>=1, but i don‚Äôt know if that also means you‚Äôre non-compliant..","",""
"801561312861618236","jon.forbord","2024-07-26T03:07:44.1430000+08:00","That would be the purpose of Store and forward with Sparkplug B, but HA or redundancy is still pretty darn nice. Any time the single broker is down, you will loose insight into the current state, even if the data is still kept for posterity.","",""
"867075936054149191","rickbullotta","2024-07-26T03:36:45.9150000+08:00","...and if you're actually using the broker to help run operations, you're screwed.","","üëç (1)"
"731220706548777072","broken_ger","2024-07-26T03:53:24.8000000+08:00","kind of... but even with a local queue the message is then bound to the client (thinking of shared subscription / loadbalancing) if he dies the message is gone... till or if the client can recover... thats up to the usecase i tend to like amqp for that, even with that extra complexity ü§∑","",""
"731220706548777072","broken_ger","2024-07-26T03:54:03.1760000+08:00","if you use amqp you can assigne the message to a new ""worker""","",""
"731220706548777072","broken_ger","2024-07-26T03:55:30.5830000+08:00","if you design a system you have a lot to think about üòÖ","",""
"801561312861618236","jon.forbord","2024-07-26T04:16:42.7130000+08:00","The message should not be deleted from the queue until the last subscriber has sent a puback for the message, right? 

Forget the local queue, the point was the client can technically hold the puback until processed, and the message will not be removed from the brokers queue, until it recieves the puback. The difference with AMQP, is that the sender of that message as part of a transaction will be notified of the success/faulure of the transaction. The ack itself whether it is done after reception of the message or after the processing, is not the major distinction.","",""
"801561312861618236","jon.forbord","2024-07-26T04:21:39.0730000+08:00","Point is that if system A wants to send a transaction to system B, if you want to use MQTT you have to implement custom back and forth to verify the transaction completed succesfully, as MQTT does not support it natively. QoS does not guarantee a successful transaction. AMQP does have support for transactions natively.","",""
"1214242167640424619","zack.scriven","2024-07-26T09:17:32.5320000+08:00","lets talk about it.","",""
"1214242167640424619","zack.scriven","2024-07-26T09:19:27.1210000+08:00","i'm with rick here. believe it or not. lol","","üòÇ (1)"
"1214242167640424619","zack.scriven","2024-07-26T09:20:42.1120000+08:00","you can build AWS if you really wanted to. in theory.","",""
"1214242167640424619","zack.scriven","2024-07-26T09:21:41.1060000+08:00","Cedalo is Enterprise support for Mosquitto broker. https://youtu.be/pBnqd9EWkOc?si=N8ZeQ2lsJyyeMdAC","",""
"1214242167640424619","zack.scriven","2024-07-26T09:23:37.8570000+08:00","that offers one level of abstraction / redundacny. but you still want A broker, to be able to receive and stream messages to clients. Typcially you move from Free / Open Source to paid when you want clustering and HA. Be it you go with: EMQ-X, HiveMQ, or alternative Cedalo (Enterprise Mosquitto)","",""
"1214242167640424619","zack.scriven","2024-07-26T09:24:09.1980000+08:00","you can also put it on a single VM Server that has High availabilty on the hardware. many levels to this. obviously","",""
"867075936054149191","rickbullotta","2024-07-26T09:25:33.3030000+08:00","It had to happen sometime. The convergence is upon us!","","üí∏ (1),highbyte (1),hivemq (1),emq (1),uns (1),ü¶∑ (1)"
"894527802316046366","nickn5549","2024-07-28T08:16:48.3760000+08:00","EMQX 5.7 community supports clusters now","","üëç (2)"
"867075936054149191","rickbullotta","2024-07-28T09:55:39.5770000+08:00","https://www.amazon.com/Kirkland-Signature-Cashew-Clusters-Saving/dp/B08JXBYW1D/ref=asc_df_B08JXBYW1D/?tag=hyprod-20&linkCode=df0&hvadid=692875362841&hvpos=&hvnetw=g&hvrand=15060879154731361241&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9007365&hvtargid=pla-2281435178778&psc=1&mcid=81f952976808325fad37b2a6eb0ded24&hvocijid=15060879154731361241-B08JXBYW1D-&hvexpln=73&gad_source=1","","üßÄ (2)"
"894527802316046366","nickn5549","2024-07-29T06:19:31.3720000+08:00","Yummy","",""
"794020366536146977","mparris","2024-07-29T08:29:31.4730000+08:00","I have used emqx clusters in the community edition since version 4.4.

What was added for clustering in version 5.7?

I didn't see anything listed in the release notes: 

https://docs.emqx.com/en/emqx/v5.7/changes/changes-ce-v5.html#_5-7-0","",""
"894527802316046366","nickn5549","2024-07-29T08:46:32.7950000+08:00","""In EMQX 5.0, we have greatly improved the cluster scalability by introducing Mria (an enhanced version of Mnesia with async transaction log replication). Mria uses a new network topology that consists two type of node roles: core and replicant (sometimes referred to as replica for short)."" - https://docs.emqx.com/en/emqx/latest/design/clustering.html","",""
"731220706548777072","broken_ger","2024-07-29T15:55:26.6320000+08:00","MQTT5's Request/Response mechanism!","",""
"817835202746253344","IIoT#4707","2024-07-29T15:55:26.9490000+08:00","GG @Andi, you just advanced to level 14!","",""
"1003994033468747787","andreasbackman","2024-07-30T19:11:07.1440000+08:00","although this is true it's not anything close to how amqp works (as mentioned before).
What I'd like to add is that we did test this to be sure what's actually happening and found out that 
1. It's version dependent 
   - In v3.x a broker can implement retry intervals http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/errata01/os/mqtt-v3.1.1-errata01-os-complete.html#_Toc442180916
   - In v5 a broker must only resend upon a client reconnect https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901238 (note the addition of ""Clients and Servers MUST NOT resend messages at any other time"")
2. It's up to the broker how it's implemented in v3.x, e.g. mosquitto had a `retry_interval` setting before, but was removed as it was bad practice to rely upon this https://github.com/eclipse/mosquitto/issues/453","",""
"801561312861618236","jon.forbord","2024-07-30T21:12:33.7050000+08:00","And as mentioned before, delaying the ack doesn‚Äôt really make it robust for transactions, for this you need more mechanisms than offered by mqtt natively (custom stuff on top doesn‚Äôt count, but is very doable in a limited capacity).","","üíØ (1)"
"138867775354437632","jonathan08947","2024-07-31T00:44:01.2150000+08:00","Is it just me or is the 2 byte limit for mqtt topic aliases really low","",""
"867075936054149191","rickbullotta","2024-07-31T01:38:06.0260000+08:00","There are a lot of design decision in MQTT that in retrospect were quite limiting.","",""
"752269276391407796","the_og4249","2024-07-31T03:04:28.2680000+08:00","I'm trying to hack together a little demo project to show the power of MQTT, and I would appreciate some guidance. We have a MAAC Thermoformer that uses Allen Bradely PLCs (ControLogix), and I want to connect them to publish data to an MQTT broker. What is the best way to approach this for a test/demo case? I'd like to avoid having to purchase a gateway, but if I need to I can I guess","",""
"817835202746253344","IIoT#4707","2024-07-31T03:04:28.5730000+08:00","GG @the_og, you just advanced to level 1!","",""
"1073312001788477471","sparkylarks","2024-07-31T03:39:33.3050000+08:00","- Ignition, use the Trial and turn it on for 2 hours for the demo Depending on the case it might be suitable, I am not sure if using maker for a demo case is within the terms and conditions.
- Node Red- I have not used node red to communicate with the Allen Bradley but it does work well for the MQTT side, and for S7 and Modbus some tips here https://flowfuse.com/blog/2023/06/node-red-as-a-no-code-ethernet_ip-to-s7-protocol-converter/
- Open Automation Software, this looks like a handy Tool https://openautomationsoftware.com/knowledge-base/transfer-allen-bradley-mqtt/, with a good rial


For you Demo Case, what is the value proposition you are demonstrating?","",""
"752269276391407796","the_og4249","2024-07-31T03:43:21.9560000+08:00","Excellent thank you for the pointers! I'll start digging in to each of those. I've seen a lot of Open Automation in regards to A-B PLCs.

Main goal for the value proposition is
1) demonstrating live data collection from the machine
2) capturing some basic KPIs

Organizationally we are still using paper on the shop floor and have a long way to go here","",""
"1063829764164563026","mariano.beracochea","2024-07-31T03:45:50.3760000+08:00","use Kepware, it have a demo 2 hour license(doesnt include IoT Gateway), you can use node red to move data from kepware to MQTT broker, if you get to talk to a kepware vendor you could ask for a 30 days demo license and ask for the IoT Gateway to send data from kepware to the broker directly","","üíØ (3),üíï (1)"
"752269276391407796","the_og4249","2024-07-31T03:46:28.0250000+08:00","I'll take a look","",""
"375728638106271765","juba5060","2024-07-31T20:27:58.7610000+08:00","You could also connect straight from Node-RED to the controller with this node: https://flows.nodered.org/node/node-red-contrib-cip-ethernet-ip

More details on its github page: https://github.com/st-one-io/node-red-contrib-cip-ethernet-ip#readme

Edit: Saw some of this was mentioned above.","",""
"752269276391407796","the_og4249","2024-07-31T20:29:14.5380000+08:00","This is awesome thank you! I'll take a look at this as well!","","üíØ (1)"
"898217314741280828","hobbes1069","2024-08-01T03:29:24.7070000+08:00","It's nice you can get the nodes for the ST One but at least for Fanuc CNCs you still need the FOCAS libraries for it to work, which of course come installed on their device üôÇ","",""
"1088631859509989426","jpmac.s","2024-08-02T19:33:51.0790000+08:00","IoT gateway works on the 2 hour licence , FYI.","",""
"873009180938743828","sim_sam3","2024-08-02T22:42:21.3800000+08:00","it's a good app üòâ

here's a very old demo video i made with the original Kepware team with both IoT Gateway and Node-RED. I used Node as a bridge to MongoDB and Twilio and let IOTG push to MQTT broker directly. 

https://www.youtube.com/watch?v=EU8GkxDP7kM","","‚ù§Ô∏è (2),üëç (1)"
"752269276391407796","the_og4249","2024-08-03T02:24:41.2030000+08:00","This is awesome thanks for passing it along!","","üëç (1),üíØ (1)"
"1057737574287945899","xamp4248","2024-08-04T19:55:01.6980000+08:00","https://flows.nodered.org/node/node-red-contrib-cip-st-ethernet-ip

This is one of my favorite nodes for communicating with ControlLogix and SoftLogix. It works like a charm.","","üëç (1)"
"1184762752758194199","rma002","2024-08-06T16:21:44.3920000+08:00","Hi

I want to expose ignition historical data using Rest API to IT

Does mqtt brokers provide this functionality to consume data via rest api? Is it practically possible to use a broker which will be there eventually to server mqtt use cases such as hive mq 

Or people are generally using tools such as highbyte?","",""
"230441548653789184","r.pop","2024-08-06T20:21:35.7360000+08:00","You can use the WebDev module for Ignition to do what you're talking about","","üëç (1)"
"230441548653789184","r.pop","2024-08-06T20:21:53.0100000+08:00","https://inductiveautomation.com/moduleshowcase/api-docs","",""
"1167443180829024358","stevenc123","2024-08-08T23:34:09.1280000+08:00","I've been working on getting familiar with MQTT using a Shelly plug. While sending data to HiveMQ was straightforward, I've encountered issues when trying to send data to Azure or GCP. It seems that their IoT services are either being scaled or rolled back for some reason. Does anybody know if there is any reason for this? Additionally, I was attempting to send data to GCP/BigQuery, but the GCP endpoint requires a JSON key file, and I'm unsure how to configure this on my Shelly plug.","",""
"1160083906004004924","bachan1868_11442","2024-08-09T01:30:22.7400000+08:00","Hi steve, I just ordered a Shelly plug last night to do the same thing in my future test lab, so this is really interesting to me.  I asked chatgpt for help on the issues you raise and this is what I got:  The user is encountering two main issues related to sending data from a Shelly plug to cloud IoT platforms like Azure and Google Cloud Platform (GCP). Let‚Äôs break down these issues and explore potential solutions:

1. Issues with Azure and GCP IoT Services
Background
MQTT Protocol: MQTT (Message Queuing Telemetry Transport) is a lightweight messaging protocol commonly used for IoT applications. It allows devices to send data to a broker or cloud platform.
Shelly Plug: A smart plug that can connect to the internet and send data using MQTT.
Potential Issues
Service Scaling or Rollback: The user mentioned that Azure and GCP IoT services might be scaled or rolled back. This can occur if:
The cloud service is undergoing maintenance or updates.
There are regional limitations or outages affecting service availability.
The user is not on the correct pricing plan or does not have the necessary permissions.
Solutions
Check Service Status: Verify the status of Azure IoT Hub and Google Cloud IoT services through their respective status pages or support channels to see if there are any known issues or outages.
Verify Configuration: Ensure that the MQTT settings, such as broker URL, port, and authentication credentials, are correctly configured for Azure and GCP. Each platform may have specific requirements.
Use Correct Endpoints: Make sure that the device is sending data to the correct IoT endpoints for Azure and GCP.
2. Sending Data to GCP/BigQuery
Background
GCP and BigQuery: Google Cloud Platform offers various services, including BigQuery for data analytics. To send data to GCP, you often need to authenticate using service accounts and JSON key files.
Issue
JSON Key File: The user needs to configure the Shelly plug to authenticate and send data to GCP using a JSON key file, which is typically used for authenticating service accounts in GCP.
Solutions
Generate a Service Account Key:

Create a Service Account: Go to the Google Cloud Console and create a service account with the necessary permissions for IoT Core and BigQuery.
Generate JSON Key File: Download the JSON key file associated with the service account. This file contains the credentials needed to authenticate your device.
Use an MQTT Bridge or Gateway:

Since Shelly devices may not natively support JSON key authentication, you can use an MQTT bridge or gateway that can handle the authentication process.
Set up a small server or application (e.g., a Raspberry Pi) to act as an intermediary, where it receives MQTT messages from the Shelly plug and then forwards them to GCP using the JSON key for authentication.
Use IoT Device SDKs:

Explore Google Cloud's IoT Device SDKs, which provide libraries for connecting devices to GCP IoT services with the necessary authentication mechanisms.
Example Configuration:

For devices like Shelly that don‚Äôt directly support JSON keys, you might need to implement custom firmware or use a gateway device to handle the authentication and data forwarding.
Summary
To resolve the user's issues:

Verify the status of Azure and GCP services to rule out any downtime or limitations.
Ensure that the correct MQTT settings and endpoints are being used for Azure and GCP IoT services.
Configure a service account and JSON key in GCP, and use an intermediary gateway to handle authentication and forwarding of data from the Shelly plug to BigQuery. This setup will enable the Shelly device to communicate with GCP securely.

Does any of this help or make sense?  Looking forward to your pov.","https://cdn.discordapp.com/attachments/1166016853991235594/1271158580900397178/message.txt?ex=68df5f6e&is=68de0dee&hm=5cb75a0a049856924f0b94721da8be369c2ac05ca938d05274b51281aef8f964&","üëç (1)"
"1167443180829024358","stevenc123","2024-08-09T02:24:58.9280000+08:00","Is it standard practice to relay data through a gateway or bridge? It seemed like an unnecessary step to me. My question was really whether the cloud providers anticipated a gold rush in the use of IoT devices that never materialised, leading to the cancellation of these platforms.
I saw a YouTube video of an ex Microsoft employee talking about how the Azure IoT offering was cobbled together rubbish that was never fit for purpose.  I wonder why the GCP offering was cancelled.","",""
"568913935147728896","zeratall","2024-08-09T03:12:24.6070000+08:00","So my personal take is that a lot of the services these providers built out to pair with IoT ended up not being very good when compared to 3rd party options. For example instead of using the AWS TSDB (cant remeber the name) people would rather use a 3d party offering like influx managed serverless option or snowflake, etc. At the end of the day if you want to get mqtt data into the cloud there are a variety of ways to do it and it doesn't require you to use the native MQTT services provided by IoT core etc.","",""
"568913935147728896","zeratall","2024-08-09T03:13:15.9430000+08:00","If you are wanting to use the AWS native services like IoT core, then you are constrained to their ingress methods, which will have stipulations like certs, etc.","",""
"801561312861618236","jon.forbord","2024-08-09T03:15:19.5920000+08:00","It baffles the mind how anyone would want to have the same company provide both the infrastructure and the services..","",""
"568913935147728896","zeratall","2024-08-09T03:16:48.6970000+08:00","Well they make the services really integrated with the infrastructure making it really easy to stand things up, for example look at ECS, ECS is awesome and stupid simple to use, compared to creating and managing your own cluster and nodes, but yeah not all of the services offered by AWS (or any provider) are\ always a good fit for every use case, especially IIoT imho. Now for my own little IoT projects where I want to connect an arduino for my home automation to the cloud I love using the native AWS services. but for that im writing my own code so its really easy to make things work with AWS.","","üíØ (1)"
"1129435706285101076","ted.garrison","2024-08-09T03:17:31.5580000+08:00","Also, if you use their native stuff, you're stuck with them.   So if you want reduncancy across multiple clouds, then going 3rd party allows you to do that by simply cloning your architecture from one cloud to the other, rather than having to build it all out in provider X's native services...","","üíØ (1)"
"801561312861618236","jon.forbord","2024-08-09T03:21:45.2510000+08:00","Mhm. I‚Äôm guessing thats the ¬´allure¬ª, but I‚Äôm talking mostly from a perspective of putting all your eggs in one basket.","","üíØ (1)"
"568913935147728896","zeratall","2024-08-09T03:22:35.0920000+08:00","Yep you and @Jon Forbord are making the same point, and I 100% agree","",""
"801561312861618236","jon.forbord","2024-08-09T03:24:22.9860000+08:00","Excactly, you are digging yourself an even bigger hole of vendor lock, so you can never leave..","",""
"1129435706285101076","ted.garrison","2024-08-09T03:34:36.5200000+08:00","Which of course, is their entire goal....","",""
"1167443180829024358","stevenc123","2024-08-09T03:37:49.9880000+08:00","So forward the messages to a raspberry pi and write code to push that data to big query? What sort of software would the mqtt messages go to normally for commercial installations? I'm new to this...","",""
"817835202746253344","IIoT#4707","2024-08-09T03:37:50.2270000+08:00","GG @steve, you just advanced to level 2!","",""
"568913935147728896","zeratall","2024-08-09T03:40:55.1470000+08:00","If the device supports MQTT, for industry we typically will have an MQTT broker deployed somewhere that is integrated with other services. So you might have an HiveMQ instance thats hosted on AWS, and you'd connect directly to that. 

Most of the time in industry devices don't support MQTT natively, so you'll need an industrial IIot Gateway, a common design pattern there is your device will talk to something like Kepware in the native protocol that device supports, for example MTConnect, then Kepware will forward that data from MTConnect as MQTT to your broker.","","üëç (1)"
"873009180938743828","sim_sam3","2024-08-09T09:20:08.5420000+08:00","had not heard of shelly plug! very cool. 

mqtt to azure iot edge or iot hub works, we use it regularly. azure iot devices have to be created ahead of time or via azure api/cli, and from there sas keys or x509 certs are used for authentication. mqtt publisher's topic, client id, username and password fields require specific formatting. https://learn.microsoft.com/en-us/azure/iot/iot-mqtt-connect-to-iot-hub

iot hub and iot edge worked fine for small scale or embedded solutions. folks tried using it for large scale ingest into azure and it wasn't a good fit. microsoft created azure iot operations to broaden azure onpremises ingestion and contextualization/processing. it is in preview. it offers local mqtt broker within azure arc-enabled kubernetes cluster. https://learn.microsoft.com/en-us/azure/iot-operations/overview-iot-operations","","üëç (1)"
"434549851649343498","dramon93","2024-08-12T22:25:41.8230000+08:00","Hi everyone, I‚Äôm looking for some guidance on implementing a concept in my system using an open-source time-series database, specifically TimescaleDB. My goal is to store everything from my Unified Namespace (UNS), and I‚Äôm debating between two approaches for defining the columns:

1-Multiple Columns: Using separate columns for each level of the hierarchy (e.g., enterprise, site, area, line, edge, etc.).

2-Single Column: Storing the entire hierarchy as a single tagName (e.g., enterprise/site/area/line/edge/value, timestamp).

Each approach has its pros and cons. The single column method simplifies the table structure but might result in longer query times since I would need to use statements like LIKE in PostgreSQL, which can be difficult to index. On the other hand, the multi-column approach could make the queries more complex, but it might offer better performance and flexibility.

What would be considered best practice in a manufacturing context? Any insights or experiences would be greatly appreciated!

I am picking TimescaleDB because I already have an ecosystem with PostgreSQL and Ignition. However, if TimescaleDB is not the right solution, I‚Äôm open to learning InfluxDB or any other type of open-source structure that might better suit my small company. I‚Äôd really appreciate insights from people who have faced similar challenges, as I‚Äôm aiming for a cost-effective implementation in my plant. Thanks!","",""
"239257759185371136",".discrete","2024-08-12T23:26:15.0480000+08:00","""Tags"" table with multiple columns as you described above and a ""TagValues"" hypertable with a foreign key to ""Tags"" to store the values is what I'm doing in a development system. I found out later that UMH is essentially doing the same thing. I don't have much runtime experience yet, but it was reassuring to see the UMH architecture is the same.","","üëÄ (1)"
"434549851649343498","dramon93","2024-08-13T00:12:26.8110000+08:00","and how do you manage the auto discovery when a new line, area or device are created and published in the UNS? are you using any form of scripts to trigger that automation ? because i think when a new device is discovered you need to add it to the right tables first before it stores it in the time series database, and i am thinking of what if you created a new device where in the line or edge level comes with a different data type, for example now that line is going to publish the ERP data in that level and you did not define it in the SQL query, how do you manage that ? 
i wonder if that is more manageable in other structures like influx DB with telegraph or any other technology.","",""
"239257759185371136",".discrete","2024-08-13T00:20:48.0890000+08:00","In my development system, I'm using Node-RED plus PostgreSQL procedures to handle that. Node-RED identifies the datatype of the value to be inserted, and Node-RED calls the appropriate insert procedure depending on the datatype (currently just string and non-string, again reassuringly same as UMH).","",""
"434549851649343498","dramon93","2024-08-13T21:14:54.5290000+08:00","Thanks","","üëç (1)"
"1274389892885123153","martin_68109","2024-08-21T12:13:27.3830000+08:00","Check WebSocket4OPC by googling it, that is the only feasible solution to support native app development to retrieve OPC plant data. It has a live demo running in iOS with swift sample code.","","üëçüèº (2)"
"1257501457154834495","javid_51673","2024-09-03T08:40:28.1410000+08:00","Hi everyone,

Is there anyone from EMQ in this channel? I have a few questions about their certifications.
Thank you!","",""
"766684226455207996","bright_hummingbird_31342","2024-09-03T11:00:53.5100000+08:00","Try @Jaylin or the EMQ discord.
https://discord.gg/psFYanxm","","üëè (1)"
"1257501457154834495","javid_51673","2024-09-03T21:36:05.6580000+08:00","Thank you,","",""
"306756239604318208","avret","2024-09-05T06:31:32.1460000+08:00","what are people using to actually run MQTT brokers? ik python has amqtt","",""
"306756239604318208","avret","2024-09-05T06:32:02.7310000+08:00","(building out an orch tool and want to make sure it plugs into UNS, so I want to have my own test broker that I can publish to)","","üî• (1)"
"306756239604318208","avret","2024-09-05T06:32:24.8160000+08:00","(right now logs are CSVs, so it should be trivial to just stick a file watcher on the system and publish up, but I want to confirm)","",""
"898217314741280828","hobbes1069","2024-09-05T10:12:06.9550000+08:00","Sounds like bog standard mosquitto would be enough for now. You can run it natively on almost any linux system or windows, or run it under docker.","",""
"306756239604318208","avret","2024-09-05T10:32:09.4560000+08:00","Great, thanks -- should I run my own instance or should I use the test server?","",""
"1073312001788477471","sparkylarks","2024-09-05T16:56:10.8530000+08:00","I have a Mosquitto broker running in a Client.
Working fine no problem. 
10 Clients, and about  10000 messages a day, and 500MB of messages.

Customer want to look at support options and Cedalo are sending some prices to me 
but I want to show the comparable cost for Hive or EMQx

Does anyone know the cheapest entry level for either? my needs are small , I think.","",""
"795178288330440704","youri.regnaud","2024-09-05T19:29:02.5900000+08:00","If someone know if is it possible to publish data from Fanuc CNC Guide in order to create a CNC simulator/emulator for our demo and engineers during development phase? Other idea to simulate CNC data and publishing these data in an UNS?","",""
"898217314741280828","hobbes1069","2024-09-05T22:32:03.2170000+08:00","I can't remember what channel I posted it in, but I'd like to take the threejs demo from the MTConnect cppagent and adapt it from websockets to MQTT for exactly that reason.","",""
"898217314741280828","hobbes1069","2024-09-05T22:33:21.1000000+08:00","I haven't gotten to pricing but I'm looking seriously at Cedalo because they will also support existing mosquitto installs, not just mosquitto Pro.","","üëç (1)"
"1073312001788477471","sparkylarks","2024-09-05T22:33:51.6130000+08:00","I was talking to they yesterday, just waiting for some prices back","",""
"898217314741280828","hobbes1069","2024-09-05T22:34:10.6610000+08:00","I've also pushed about 1MM messages through mosquitto in a Azure Container Instance. üôÇ","",""
"898217314741280828","hobbes1069","2024-09-05T22:35:26.5850000+08:00","That's about where it maxed out which is similar to the results mentioned by @Walker Reynolds, got to the point MQTT Explorer couldn't keep up subscribed to `#`.","",""
"329780110704246790","rkwadd","2024-09-05T23:06:35.5480000+08:00","The discussion that led up to Richards MQTT simulation plans was here: https://discord.com/channels/738470295056416930/1032735322729087107/1276210346612490270","",""
"1073312001788477471","sparkylarks","2024-09-12T16:18:24.2400000+08:00","Mosquitto Pro with support is less than OS Mosquitto support.

so for me it becomes a complete no brainer to upgrade to Pro","",""
"1261677191423463444","stevenledoux_19961","2024-09-14T20:55:56.1140000+08:00","Hello, 

I am new to MQTT, and I find that it has many interesting features. When learning a new technology, 
I am also interested in understanding its limitations and how to overcome them.

For example, in 4.0 solutions, they explain the blue-red concept. Users can experiment by placing ad hoc data in the MQTT broker's blue zone, 
where data validation is not required. However, in the red zone, it is crucial to validate the structure of the data. Since an MQTT broker has no 
ability to perform this validation, an external component is connected to handle it.

Aonther example, Is it correct that MQTT has no built-in mechanism to manage out-of-order data (even with QoS 2)? If so, can I conclude that it is the client's 
responsibility to handle this?

Let‚Äôs assume we use Sparkplug on the lower stack levels. While Sparkplug provides additional features, it still does not always prevent out-of-order data. 
Therefore, it also be the client's responsibility. Is this correct?

Thx for the info,
Steven","",""
"243462445933395969","mieczyseutaepeu1663","2024-09-14T21:42:25.3400000+08:00","Part of the sparkplug standard is timestamps so while it doesn't prevent out of order data it correctly handles data delivered out of order.

So a SCADA system with historian that has sparkplug support will correctly add data points in the historian based on their timestamp","",""
"1285566390828531794","manjindersinghcedalo_46395","2024-09-17T19:55:56.1390000+08:00","I can help Richard üòÄ","",""
"898217314741280828","hobbes1069","2024-09-17T20:22:43.3530000+08:00","HAHA. Yeah, we're getting there. Slowly. Just got to meet the new CIO of my company yesterday.","","üëç (2)"
"1285566390828531794","manjindersinghcedalo_46395","2024-09-17T20:49:21.2190000+08:00","Sounds great!","",""
"1063829764164563026","mariano.beracochea","2024-09-19T00:54:40.5150000+08:00","to cover the problem of MQTT that cant be queried on demand and just inform the data at it change, would mark retain and unsubscribing to a data you dont want to need to buffer on the device and just check it some times and subscribing when needed forcing the broker to send the current value be an option?","",""
"867075936054149191","rickbullotta","2024-09-19T09:50:48.4510000+08:00","That‚Äôs very inefficient though, and it still requires that the external app know the topic structure since it can‚Äôt be queried.","",""
"801561312861618236","jon.forbord","2024-09-21T03:18:26.3660000+08:00","How about instead, the publishers publishes to one topic the entire content of their namespace, so that the other nodes can know what topics are available, lets call this topic the ¬´birth¬ª topic (doing airquotes), and other nodes can request the birth again, and that should also be on a separate topic, lets call this the ¬´Command¬ª topic, and theeen, to make it even more efficient instead we publish all the data in ONE topic (who needs topics?!?!?!) and that should be the ¬´Data¬ª topic and then ‚Ä¶ oh wait.. üò´ü§¶","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-09-21T03:47:56.7080000+08:00","Birth is a stupid name. Should be Metadata. And should be ONLY metadata, no metrics. 

And commands as implemented suck too. Part because of MQTT itself and part because of the lack of a response payload and related metadata for commands. Say no to Sparkplug until it gets fixed.","",""
"867075936054149191","rickbullotta","2024-09-21T03:49:05.6220000+08:00","Sparkplug is the byproduct of Satan‚Äôs semen and a snake egg.","","üòÇ (3),ü§£ (1)"
"801561312861618236","jon.forbord","2024-09-21T03:49:14.6960000+08:00","Just say NO!","",""
"801561312861618236","jon.forbord","2024-09-21T03:53:03.7280000+08:00","¬´We use SpB, and I approve this message¬ª","","ü§£ (1)"
"801561312861618236","jon.forbord","2024-09-21T04:21:14.9230000+08:00","I do in all seriousness tell people to take caution with SpB. Its useful in a narrow sense. It is somewhat tangent to a UNS. Look at it as OPC UAs savant little brother. He does a few narrow things pretty good, but cant even spell his own name. And OPC UA is the over achieving big brother with a super polished profile picture who so wants to please everyone that he‚Äôs in the chess club, wrestling team, track and field, football, glee, spelling bee team, the gospel choir and volunteers at the community senior center, but isn‚Äôt great at neither of them, and behind the profile picture is an awkward teenager with a chip on his shoulder.","","üòÇ (5)"
"867075936054149191","rickbullotta","2024-09-21T11:00:58.3730000+08:00","Solid guidance","",""
"1073312001788477471","sparkylarks","2024-09-21T13:08:15.7260000+08:00","When I started with MQTT, the buzz was SpB and I tried it and thought, ""my organisation does not have DData, I don't know if I can build a systematic hierarchy that matches my organisation"". I was used to 4 machines with 3 PLC's and all the cappers on all three lines were in PLC1, and PLC2 did most of Line 2 and 3, but a few bits of Line 4 because the PLC there was really small.

But does that make MQTT the sister who is the artist, and actually smarter than both brothers in some ways, and depending on the influences early, will either ending up floating around, doing lots of jobs for exposure, or CEO of a massive empire connecting artists with corporate entries.

but either way will struggle with queries.","",""
"1111719898482212874","d_leblanc","2024-10-01T20:48:51.1960000+08:00","FT View SE 15 new features. 
The FactoryTalk View SE Client object model provides programmatic capabilities to configure FactoryTalk View SE as an MQTT subscriber or publisher.

Nothing in FT View ME or v37 firmware yet but its a start","",""
"817835202746253344","IIoT#4707","2024-10-01T20:48:51.5290000+08:00","GG @Daniel LeBlanc, you just advanced to level 7!","",""
"1173270244291264535","andreasvogler","2024-10-01T22:20:05.9820000+08:00","I have used an array type. No need for a fixed amount of columns and you still can query the levels by using column[level]. Btw. I have implemented a MQTT Broker which stores everything out of the box in PostgreSQL/Timescale. You can also configure topics (with wildcards) to be  automatically stored in archive tables. https://monstermq.com","",""
"434549851649343498","dramon93","2024-10-01T23:06:37.4540000+08:00","I needed up developing something as a simple timescale table with 3 columns to store entire namespaces with just topic, value and timestamp. But this solutions seems interesting. I‚Äôll take a look. Thanks for help.","",""
"1038540068438159410","heikkime","2024-10-11T10:11:18.6140000+08:00","anyone tested this?  https://www.youtube.com/watch?v=kyYQze6e-N8&t=760s","",""
"277515221885779970","jermuk","2024-10-12T18:26:47.0100000+08:00","Kafka + MQTT is a very common combination, especially in large scale IoT scenarios","","üëç (1)"
"697134502148964423","trentc","2024-10-15T22:57:51.4940000+08:00","Looking to bridge several brokers together in different parts of the world for a development project....need a cost effective solution.

Created a HiveMQ free cluster today with 10GB/mo bandwidth...i'm going to burn through that in 80hr or less....and looking to add more to it....

If high bandwidth and low cost are my priorities....what is the solution?
1. Cloud broker hosted by HiveMQ or EMQ?
2. Vultr or some other cloud compute with self managed broker?
3. Or go dirty with port forwarding and a site located broker?","",""
"898217314741280828","hobbes1069","2024-10-15T23:13:18.7870000+08:00","Don't forget about Cedalo (Mosquitto Pro)","","üëç (1)"
"477355192375967747","kiwimalice","2024-10-16T08:53:01.3610000+08:00","what can people tell me about Codesys and MQTT options, from what I remember its not a tickbox enable like OPC-UA is, is there a solid option for MQTT-SPB for Codesys then the community recommends ?","",""
"1073312001788477471","sparkylarks","2024-10-16T17:00:18.9640000+08:00","What PLC are you using Codesys on, Opto22 or WAGO have options that can manage that  as far as I know.

but there are also Codesys FB's https://store.codesys.com/media/n98_media_assets/files/2111000027/4/MQTT%20Client_en.pdf

haven;t used any though","",""
"697134502148964423","trentc","2024-10-16T19:02:22.0940000+08:00","Also here is a sparkplug b library if you so choose...but it requires the IIOT libraries sl library as well https://forge.codesys.com/lib/cobolt/home/Home/

Here's a video of using the MQTT library, I imagine the spb library to be similar..
https://www.youtube.com/watch?v=ifGC51w5KBI","",""
"697134502148964423","trentc","2024-10-16T19:06:26.8520000+08:00","Ended up using hetzner, got 2vCPU 8GBram, 80GBdisk, 20TB of net traffic out for less than $15/mo
Installed emqx on it","","‚ù§Ô∏è (1)"
"477355192375967747","kiwimalice","2024-10-17T01:46:05.3620000+08:00","@Mark O'Donovan  Stock and  Schneider M251s 
@trentc - 4.0 Hero LLC  thanks will watch the video, I am trying to wrap my head around how do I easily map all my IO plus process step logic and faults. feels like i have to manually add it in every IO FB or manually so it publishes one tag so to speak. Will check out the vids they may answer it for me 

Thanks again @trentc - 4.0 Hero LLC  and @Mark O'Donovan !","",""
"873009180938743828","sim_sam3","2024-10-19T02:37:21.5440000+08:00","oh wow that's a deal","","üíØ (1)"
"537493750621143041","hisma","2024-10-21T20:49:11.3600000+08:00","hey all, i'm somewhat of an MQTT luddite, despite using it very frequently.  It's so easy to deploy I don't really understand the nature of the underlying protocol as it's not really necessary.","",""
"537493750621143041","hisma","2024-10-21T20:52:38.6750000+08:00","So can someone fill me in on MQTT 5?  I'm reading about what it offers and it seems to have a lot of features like reason codes, ability to embed metadata, enhanced authentication, packet formatting, etc etc","",""
"537493750621143041","hisma","2024-10-21T20:57:04.3000000+08:00","To me it seems that with MQTT5, you can achieve a lot of what SpB aims to achieve, without a lot of the downsides.  I hear a lot of talk about using flat MQTT here, but not what version.  I see ignition uses 3.1.1 & not 5 (tho most brokers that support 5 tend to be backwards compatible with 3.1.1).  My question has anyone actually leveraged all of the new features in MQTT 5 as a way to essentially ditch SpB?","",""
"867075936054149191","rickbullotta","2024-10-21T21:03:14.4250000+08:00","What features are you referring to?  I don't see MQTT5 doing that much at all in terms of delivering capabilities like SpB.","",""
"537493750621143041","hisma","2024-10-21T21:09:47.6100000+08:00","i already mentioned i don't know, but I see the ability to add user properties as metadata.","",""
"537493750621143041","hisma","2024-10-21T21:11:06.8690000+08:00","so my thought is you could embed timestamps or things like birth/death certs (if you wanted to maintain those features) as metadata","",""
"537493750621143041","hisma","2024-10-21T21:14:11.6780000+08:00","reading this","",""
"537493750621143041","hisma","2024-10-21T21:14:12.3980000+08:00","https://www.hivemq.com/blog/mqtt5-essentials-part6-user-properties/","",""
"867075936054149191","rickbullotta","2024-10-21T21:20:42.5920000+08:00","Much like everything else in MQTT, that metadata is opaque and not really usable for things like subscriptions, queries, discovery, and all the necessary functionality of a comprehensive IIoT platform that MQTT alone cannot provide.  There are also no agreed upon semantics for user properties, thus interoperability does not exist just because that feature exists.  Short answer is that some of the new MQTT5 capabilities can make it easier to deliver an interoperable protocol on top of MQTT, but it does not really do anything on its own.","","üëç (1)"
"537493750621143041","hisma","2024-10-21T21:22:32.3740000+08:00","great answer.  and something i always see as a short-coming of MQTT - lack of standardization.  SpB may have short-comings but one thing it does do is enforce a communication standard.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-10-21T21:23:37.8340000+08:00","Here's the RickBot once again posting my summary of MQTT and Sparkplug B's limitations along with suggested enhancements:

Core MQTT issues:

- Decision to use 4 bits for message type. Short sighted and now a major limitation
- Multi-publish is essential (publish more than one topic in a single message)
- Topics should have durable metadata (could be passed as headers in publish or as its own message type)
- Payloads should have a data type (mime type) to enable parsing/processing by subscribers or intermediaries
- Topic binding should be a built-in broker feature (like a symlink) - topic aliases are not this
- The lack of a capability to query topics is a huge flaw/gap. Ideally these queries should be able to include metadata filters as well
- MQTT's subscription patterns are hopeless limiting. They should support richer match expressions and also metadata filters
- MQTT should officially support a REST binding for request/response query/publish/read/subscribe/unsubscribe
- Handling of large payloads (e.g. file uploads, video content, firmware/software updates, method responses) needs a lot of work to improve reliability
- Handling of RPC/method invocations remains an awful hack. This MUST be addressed.","","ü§£ (1),üëç (1)"
"867075936054149191","rickbullotta","2024-10-21T21:23:43.1500000+08:00","Core Sparkplug issues:

- The rigid Node/Device format does not fit real world models. Do away with one of them and allow more flexible topic hiearchies.
- The handling of *BIRTH messages and the intermingling of data and metadata in them is a poor design
- The process for requesting *BIRTH messages is terribly inefficient. Metadata should be retained, not requested each time by each client.
- There should be *METADATA messages to deal with metadata
- The opaque/multi-value nature of *DATA messages makes it impossible for client(s) to subscribe to individual metrics. Huge issue.
- The ""primary client"" stuff is unnecessary and should be removed
- Any device commands/methods should be fully declared (inputs and outputs fully typed)
- Naming of metrics/commands needs to be locked down to a more restricted character set
- Add a few more top level data types (Location, BLOB (w/mime type), 
- Support other encodings besides Protobuf (e.g. plain JSON, zipped JSON, BSON, etc.)
- Millisecond resolution for timestamps is inadequate for modern systems where accurate event sequence is critical (e.g. power grid)","",""
"537493750621143041","hisma","2024-10-21T21:29:32.7750000+08:00","yeah the decision to make such a rigid topic hierarchy baffles me.  Again I consider myself a luddite, but in dipping my toes in SpB that was the first thing that stood out to me... you significantly limit the use-case and castrate one of the best features of MQTT by having a topic hierarchy essentially targeted to represent machines","",""
"537493750621143041","hisma","2024-10-21T21:32:14.7520000+08:00","so my question @RickBullotta is do you think flat MQTT is better or do you see a use-case for SpB in its current form?","",""
"867075936054149191","rickbullotta","2024-10-21T21:32:21.7010000+08:00","...and you can't subscribe to individual metrics!","",""
"867075936054149191","rickbullotta","2024-10-21T21:33:29.9510000+08:00","I've proposed changes to Sparkplug and MQTT that I think can mitigate the flaws, but those will require that the brokers become more active participants and not just publishers and subscribers.  To date, the broker vendors seem to not want to do that, at least not in any standardized manner.","",""
"537493750621143041","hisma","2024-10-21T21:43:33.4300000+08:00","there is no perfect solution that's for sure.  But I feel like MQTTs shortcomings are easier to fix than OPC UAs.","","ü§£ (1)"
"697134502148964423","trentc","2024-10-22T18:57:25.3720000+08:00","When using mqtt as our ‚Äúbackbone‚Äù for current events, how do we handle ensuring delivery of any message to a subscriber?

From the client we can detect if our connection is active, or disconnected and we can store and forward messages. 
Upon reconnecting, we publish up our stored messages.
This along with QoS handles disconnects and delivery of published messages to a broker, but not to subscribers.

But let‚Äôs say for example there‚Äôs a historian that should be connected and subscribed to these messages, but it is for any reason not connected, not subscribed, or not ready to ingest the messages‚Ä¶now all of those messages have passed through the broker and the client (historian) didn‚Äôt receive them.

What are some practical ways to handle this situation?
1. Just tolerate loss of messages 
2. Leverage a LWT topic and don‚Äôt publish? Then other subscribers won‚Äôt get them timely
3. Dedicated topic for the function, like a historian, and only publish when it is ready 
4. Upon client reconnect, Query the historian for the last message and use store and forward to resend?
5. Some other custom command response mechanism ?","",""
"867075936054149191","rickbullotta","2024-10-22T19:19:33.2070000+08:00","QoS also influences delivery to subscribers, but only if there is an active subscription.","",""
"867075936054149191","rickbullotta","2024-10-22T19:20:14.2830000+08:00","You could use a highly available message queue as the intermediary between the broker and the historian.","",""
"697134502148964423","trentc","2024-10-22T19:20:15.0190000+08:00","Does the broker store and forward these messages if the subscription is present....but client disconnected?","",""
"867075936054149191","rickbullotta","2024-10-22T19:20:35.3870000+08:00","Even worse - the sender has to, AFAIK. üòâ","","üòÇ (1)"
"697134502148964423","trentc","2024-10-22T19:21:27.9090000+08:00","Ugh, I feel like MQTT is more of a ""send it"" and hope it gets there type of protocol....","",""
"867075936054149191","rickbullotta","2024-10-22T19:21:30.5960000+08:00","Actually, it's a blend - the handshake/dance can involve both the sender and the subscribers.","",""
"867075936054149191","rickbullotta","2024-10-22T19:22:21.9070000+08:00","The broker will do some of the work for subscribers if and only if there's a persistent session created.  But this can be a lot of work for the broker too.","",""
"867075936054149191","rickbullotta","2024-10-22T19:23:22.7100000+08:00","MQTT QoS can do what you want - it's just not ""free"".  There are roles and responsibilities for all three participants (publisher, broker, subscriber) to achieve higher QoS levels.","",""
"867075936054149191","rickbullotta","2024-10-22T19:25:11.1040000+08:00","With some brokers, such as HiveMQ, you can use their extension mechanism to bridge to something like Kafka without having to write code for the publisher side.  You'd still need something to pull messages off the queue and send them to the historian.","","üëç (1)"
"697134502148964423","trentc","2024-10-22T19:25:34.4500000+08:00","What about a broker that is installed in very close proximity(running on the same machine) to the client (ie historian) that has ""dedicated"" resources and minimal risk to connection loss....and leverage the QoS features","",""
"867075936054149191","rickbullotta","2024-10-22T19:27:06.3380000+08:00","What is doing the publishing?  It's going to have to carry the load if it loses connection to the broker for any reason.","",""
"867075936054149191","rickbullotta","2024-10-22T19:28:04.2740000+08:00","BTW that's why I like the broker extension approach in some cases - (sort of) eliminates/reduces one point of failure.","",""
"697134502148964423","trentc","2024-10-22T19:28:04.9760000+08:00","I was thinking bridging another broker...the ""stopping point"" of the message would be at the last broker to the subscriber....","",""
"867075936054149191","rickbullotta","2024-10-22T19:28:17.7460000+08:00","Even more points of failure then. üòâ","",""
"697134502148964423","trentc","2024-10-22T19:30:01.3540000+08:00","True, but it isolates the issue to be handled at the last broker and subscriber(s)....","",""
"867075936054149191","rickbullotta","2024-10-22T19:30:22.3850000+08:00","So apparently even with QoS 1 or 2, MQTT has a baked in limitation of a 2 byte identifier for queued messages, so even if everything works fine, it might gack if you hit 65536 queued messages.","","üòÇ (1)"
"697134502148964423","trentc","2024-10-22T19:30:50.9250000+08:00","The plot thickens!","",""
"867075936054149191","rickbullotta","2024-10-22T19:31:02.7380000+08:00","Not really.  It doubles the work of the broker(s) because now they have to implement the same QoS craziness between themselves as well.","","üëç (1)"
"867075936054149191","rickbullotta","2024-10-22T19:32:11.2000000+08:00","If data loss is acceptable, then don't even worry about it.  If data loss is not acceptable, it's always going to require efforts and capabilities up and down the stack to handle it properly.","",""
"697134502148964423","trentc","2024-10-22T19:32:40.3250000+08:00","This....is the response I expected....but thought I might be missing something...","",""
"697134502148964423","trentc","2024-10-22T19:34:29.5180000+08:00","If data loss cannot be tolerated....it almost seems like another protocol in the architecture would be better fitting, to reduce the effort to ""recreate the wheel"". Not saying to eliminate MQTT...but in certain scenarios, it might be necessary to implement multiple for different use cases.","",""
"867075936054149191","rickbullotta","2024-10-22T19:34:38.1870000+08:00","Everything on the planet is ultimately ruled by some variant of the Better, Faster, Cheaper paradox.  Pick any two...","","üî• (2)"
"1073312001788477471","sparkylarks","2024-10-22T19:55:28.8090000+08:00","@trentc - 4.0 Hero LLC 
if you want to leverage that for MQTT, you need to set the QOS=2 on the subscriber and the publisher,  but IIRC that will only make sure the data is published to the broker. might have been my config,

I normally take the approach, if comms is down then the historian does not get the data.
Data that must be received, needs to be buffered, and I do that at the sender, and control the message to be published.
if you publish an  last message sent integer, and have the edge subscribed to a Last message received in the receiver.
I have a node red flow that pushes the device values to a Timescale DB, and then when the message is successfully sent, 

but that is really a point to point connection. if you have multiple subscribers and you publish a message to the broker, and 99 out of 100 subscribers are connected and receive the message, what do you do about the other one?","","üëç (1),üíØ (1)"
"753688565807841492","ravil1","2024-10-22T20:53:29.0640000+08:00","@trent, I am curious, what is the historian in your case?","",""
"1173270244291264535","andreasvogler","2024-10-22T21:35:17.1960000+08:00","Your historian just needs to use a connection with ""CleanSession=false"". If the connection gets broken, then the broker will queue the missed messages, when the client comes back, the broker will send all missed/queued messages. But some brokers do this only with messages where QoS>0. And as Rick already said, this comes with costs. I think the better option is to use some ""broker built in"" functionality to write topic values to a database or to Kafka (and from Kafka you can bring your values almost to everywhere). My self-made free broker has such options for Timescale/CrateDB/Kafka - but it is in an early stage and I would say in an experimental state üòâ https://monstermq.com you can try it out here test.monstermq.com:1883 What makes it special is that the states are stored in Postgres tables (sessions, subscription, optinally last topic values), so you can add additional data, like metadata to your PostgreSQL database and query the data together... you can also connect to the PostgreSQL database at test.monstermq.com:5432 user: monster pwd: monster","","üëçüèº (1),üî• (1)"
"697134502148964423","trentc","2024-10-22T22:25:49.3030000+08:00","So your thought here is to just always put the messages into a database and then if a client needs to it can query the database for any missed messages? Or is there some way to only put the missed messages into the database?","",""
"1173270244291264535","andreasvogler","2024-10-22T22:46:33.1740000+08:00","It is to be able to query the current state and to be able to combine it in queries with meta/context information in other tables in the DB. There is also an option to archive historical values, this is then to be able to query the history of the data - like using it in Grafana. But it must be clear that by writing every topic-last-value to PG will become a bottleneck - the database. But it is possible to define topic filter to choose which topics should be stored as lastvalstorage or historystorage and you can choose different tables...","",""
"697134502148964423","trentc","2024-10-22T22:55:16.2420000+08:00","Thoughts on making it so if a message cannot be delivered to a subscriber, store that, instead of just filtering by topic? Make it conditional","",""
"753688565807841492","ravil1","2024-10-22T23:23:00.8110000+08:00","When you write data values to the PostgreSQL database, I would assume the same problem stays - what would prevent data to be lost when connection with PostgreSQL is down? Or connection with Apache Kafka is down? I think you would need reliable store and forward implementation.","",""
"1173270244291264535","andreasvogler","2024-10-23T00:58:01.0450000+08:00","@trentc - 4.0 Hero LLC I think I don't get what you mean. If a message cannot be delivered, the MQTT broker stores the value until the client is back online (if QoS>0), guess there are limits for how long a broker will store the values. And if you have implemented a mqtt-client which writes the values then to PG, Kafka or whatever, as @Ravil says, then you should think about a store and forward implementation (in that mqtt-client program). The monstermq broker keeps it only in-memory if the DB is down. Because the PG-Database is more or less part of the broker, PG should be high available, or use a CrateDB cluster. automation-gateway.com has store&forward in-memory or on-disk (on-disk is currently a bit disk-inefficient, but I have not time to improve that).","",""
"697134502148964423","trentc","2024-10-23T01:02:23.1310000+08:00","I think we're close to the same page.
What i'm asking is... if the subscribing client is offline....I understand that MQTT QoS>0 and reconnecting with cleansession=false will get me the messages that were queued, ""but at a cost"".
I'm proposing, instead of leveraging MQTT to store and forward those ""missed messages""....would there be a benefit to redirect them to PG, then when the client reconnects, the client could query PG....or maybe just have the broker pull the messages back out of PG to mitigate the ""costs"" of using MQTT inherit features?
I could be way off here, and thinking too hard....just proposing a question.","",""
"697134502148964423","trentc","2024-10-23T01:05:29.7000000+08:00","And to reply to @Ravil , my ""issue"" is delivering messages to a subscriber from the broker....not publishing client to broker...which is clear to use a store an forward mechanism to mitigate.","",""
"1173270244291264535","andreasvogler","2024-10-23T01:10:30.2210000+08:00","this is what my broker does internally :-). if a persistant (non-clean) client goes offline, the broker stores the messages (to which the client is subscribed) in a table, when the client comes back, then it first(!) delivers that queued messages. In the meanwhile it has to queue new in coming messages and deliver those afterwards. Imagine now you have 1000 persistant clients and they are all gone offline. A single incoming value on a topic, to which all clients are subscribed, must be stored and it must also be stored to which client it must be delivered.....","",""
"697134502148964423","trentc","2024-10-23T01:18:00.0110000+08:00","Nice!
Yes lots of variables with a many to many pub sub architecture","",""
"867075936054149191","rickbullotta","2024-10-23T01:26:15.2910000+08:00","I had to write a lot of task management stuff in ThingWorx so that ""catching up"" didn't consume all resources.  Needs to be a balanced workload so that real-time operations are (mostly) unaffected while catchup occurs.","",""
"753688565807841492","ravil1","2024-10-23T01:28:19.3150000+08:00","Probably adding ""store and forward"" feature to the broker is good in some use cases. But if you start digging it might be too much load on the broker. Maybe better to publish data to MQTT that can be used as last value for subscribers, with one application, and log data to the database with another application, that supports store and forward.
Speaking of store and forward, it is not trivial to implement it in a way, that   high performant, does not cause data corruption or loss of already stored but not forwarded yet data if the machine where it runs  loses power or restarts, etc.","",""
"1173270244291264535","andreasvogler","2024-10-23T01:32:18.3930000+08:00","good point, with Kafka the consumer can set the pace. In MQTT not.","",""
"1173270244291264535","andreasvogler","2024-10-23T01:33:19.8350000+08:00","EVERY MQTT complient broker must have store and foreward implemented. For persistant sessions.","","üíØ (1),üëç (1)"
"867075936054149191","rickbullotta","2024-10-23T01:33:21.2520000+08:00","And of course there are situations where catching up is physically impossible.  Detecting that and having mitigating logic determined in advance is important too.","","üëç (2)"
"1173270244291264535","andreasvogler","2024-10-23T01:39:20.3180000+08:00","think that fits this discussion üòÜ https://www.linkedin.com/posts/andreas-vogler_hivemq-mqtt-hivemq-activity-7237946088081489920-iO4X?utm_source=share&utm_medium=member_desktop","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-10-23T01:48:18.8290000+08:00","""If it was easy, everyone would be doing it...""","","üíØ (2),üëç (1)"
"753688565807841492","ravil1","2024-10-23T03:37:22.9620000+08:00","Don't they have limit on number of stored messages, like 65535? It also requires QoS to be set to non-zero  right? In my experience MQTT brokers would quickly have their message buffer full if I log messages with higher frequency, like 10k messages per second from single client. Which is actually not high at all, comparing to what the data sources can generate.
I wonder, what numbers you have with your broker? Can it handle storing data let say 100k short  messages per second, for 1 hour, and then how quickly does it catch up after subscriber restores connection?","",""
"1173270244291264535","andreasvogler","2024-10-23T03:49:42.4640000+08:00","No, it can not. I am not claiming that my broker does this better than others. My broker stores queued messages in PostgreSQL, and so it is limited to the power of PostgreSQL.","",""
"753688565807841492","ravil1","2024-10-23T03:55:06.3980000+08:00","I guess there are many use cases when load/disconnect duration are not too high/long, and limits of the application are not reached. So lot of things depend on use case. No application/standard can handle all possible use cases.","","üíØ (1)"
"898217314741280828","hobbes1069","2024-10-23T04:28:12.1740000+08:00","I pressure tested Mosquitto in an Azure ACI (generic resources, nothing special) and I was able to achieve 1M messages/sec total throughput (in and out) but that was pretty much the max. I'm pretty sure Mosquitto is single threaded so you don't need multiple vCores, you need a high frequency core.","",""
"753688565807841492","ravil1","2024-10-23T04:32:13.7710000+08:00","What was QoS in this test? Ans where was the publisher - on prem or in the same network in the cloud? I think when the publisher is on prem, the broker is on the cloud, with QoS non zero it is hard to achieve such result.","",""
"898217314741280828","hobbes1069","2024-10-23T04:33:07.7590000+08:00","It was QoS 0 since it was simulated machine reporting, I didn't care about the occasional dropped message. I used the simulation from Highbyte running in another ACI.","",""
"1173270244291264535","andreasvogler","2024-10-23T04:36:18.6690000+08:00","1M, how did you do this test? be careful, some clients, like Python, do not wait until the data is written to the write, it will give you complete wrong results... u","",""
"753688565807841492","ravil1","2024-10-23T04:37:03.5720000+08:00","I see.
Usuallg the publisher would be on prem, accessing the broker running on the cloud, isn't it? 
Anyway, your results look very good. I don't think you can reach the same with HiveMQ.","",""
"898217314741280828","hobbes1069","2024-10-23T04:37:29.0530000+08:00","I monitored with MQTT Explorer subscribed to #, which did eventually start having issues.","",""
"1173270244291264535","andreasvogler","2024-10-23T04:39:43.5140000+08:00","do a client.publish(...).wait_for_publish(), otherwise you write you 1M messages/s just to the clients local RAM. I am almost sure that you will not be able to reach 1M/s on a single core...","","üëç (1)"
"753688565807841492","ravil1","2024-10-23T04:40:11.3160000+08:00","Did you have a subscriber functioning OK (getting al messages) when 1mln messages pet second were published? Or it was MQTT Explorer having issues handling such rate?","",""
"898217314741280828","hobbes1069","2024-10-23T05:30:33.5970000+08:00","When I got to the 1M/s MQTT Explorer started having issues.","",""
"753688565807841492","ravil1","2024-10-23T06:18:52.5580000+08:00","Then you could not test if the broker can handle both publishs and subscribes. Broker without subscribers is not typical use case I think, if not to say useless.","","üëç (1)"
"742129646593638505","pocsgeza","2024-10-24T19:48:52.3010000+08:00","**Processing Sparkpug B and writing the values back into the broker in a human readable format:**
I have set up Ignition with the Transmission module. I have some tags that are published to the broker via SpB.
I am looking for a tutorial or article on how to read the SpB messages, decode them and write them back to the broker.
If someone can share a link that would a big help for me now.
A Node-Red example would be ideal.
Thank you in advance.","",""
"812295088348200960","patanj2","2024-10-24T20:11:14.1670000+08:00","Just google node-red-contrib-sparkplug. There are both videos and documentation.","","üëç (1)"
"742129646593638505","pocsgeza","2024-10-24T20:16:10.0590000+08:00","Thank you.","",""
"817835202746253344","IIoT#4707","2024-10-24T20:16:10.2500000+08:00","GG @P√≥cs G√©za, you just advanced to level 4!","",""
"867075936054149191","rickbullotta","2024-10-24T20:16:32.9630000+08:00","I can give you a node.js program that does that. It only needs to run as a daemon. I‚Äôve also written an extension for HiveMQ to do this (in Java) and you can also use HiveMQ data hub scripts to do the conversion.","",""
"742129646593638505","pocsgeza","2024-10-24T20:20:03.4250000+08:00","The node.js program would be good for our small system. Is it on Github?","",""
"867075936054149191","rickbullotta","2024-10-24T20:41:41.4790000+08:00","I'll post it here in a few minutes.  For production use though, I'd recommend using HiveMQ.  Doing this in the broker eliminates a point of failure.","",""
"742129646593638505","pocsgeza","2024-10-24T20:44:16.0240000+08:00","This will be for a PoC. Once they like it they will hopefully invest in a more reliable tool.","",""
"867075936054149191","rickbullotta","2024-10-24T20:44:32.2930000+08:00","This is a slightly older version but should work fine.  There's a JSON configuration file to specify your MQTT broker and credentials.  Should be self explanatory.","https://cdn.discordapp.com/attachments/1166016853991235594/1298990512325398538/spexpander.zip?ex=68df1c70&is=68ddcaf0&hm=51d7f59c56275cd1294298d24999ba6bafd8983257e264e558a0277f51492a2b&","üî• (1)"
"867075936054149191","rickbullotta","2024-10-24T20:45:03.1100000+08:00","Obviously feel free to modify and use as you see fit.","",""
"742129646593638505","pocsgeza","2024-10-24T20:45:20.2100000+08:00","Thank you","","üëçüèº (1)"
"1173270244291264535","andreasvogler","2024-10-24T20:56:15.1490000+08:00","You can use monstermq.com broker, it can do this out of the box. But it is a young project and currently supports only 3.1.1. Test it well before using it in production.","","üëçüèº (4)"
"277515221885779970","jermuk","2024-10-26T15:57:08.1510000+08:00","You could try out benthos. Easy to have Mqtt input, protobuf / spark plug B decoding, mqtt output.

Our fork has besides manufacturing specific protocols also the spark plug b file included in the docker container. However I never tested it personally","",""
"277515221885779970","jermuk","2024-10-26T15:57:33.5440000+08:00","https://github.com/united-manufacturing-hub/benthos-umh","",""
"277515221885779970","jermuk","2024-10-26T15:58:24.7850000+08:00","```yaml
pipeline:
  processors:
    - protobuf:
        operator: to_json
        message: Payload
        import_paths: [ /proto ]
```

to convert a sparkplug-b message into json","","üëç (5)"
"452467225098715154",".autok","2024-11-08T20:50:30.3770000+08:00","Hey! We recently had an introductory meeting with Microsoft on Azure IoT Operations. Asked if their MQTT broker supports Sparkplug B. Unfortunately, they couldn‚Äôt provide a clear answer.

Does anyone have any information about this?","",""
"867075936054149191","rickbullotta","2024-11-08T22:00:15.7750000+08:00","A broker doesn‚Äôt really need to do anything to support Sparkplug, does it?","","üëç (3)"
"1268219750975012888","nathan.slider","2024-11-08T23:17:20.8940000+08:00","That was my understanding too,  it really comes down to the MQTT Client and if it can subscribe from the Broker the Sparkplug variation","",""
"867075936054149191","rickbullotta","2024-11-08T23:41:57.2210000+08:00","Personally i'd like to see this change with a future version of Sparkplug.  Having a ""sparkplug aware broker"" perform some additional functions would MASSIVELY improve the utility and applicability of Sparkplug.  Notably metric expansion into individual topics (and conversion to JSON), metadata caching/persistence, and a query API for metadata and data.  That would amplify Sparkplug's usefulness 10X at least.","","üíØ (4)"
"1173270244291264535","andreasvogler","2024-11-09T01:31:43.5150000+08:00","A broker distributes bytes, and it does not (need) to understand what kind of data it distributes. And a broker does not need do anything special to handle SparkplugB. It needs to be MQTT 3.1.1 compliant, then SparkplugB works with it. Interesting that the guys from MS Azure IoT do not know that.","","üíØ (2)"
"1173270244291264535","andreasvogler","2024-11-09T01:52:54.0950000+08:00","monstermq.com does SparkplugB Exapansion, you can add Metadata in the used PostgreSQL/TimescaleDB and query all together with SQL. But because of using a central PostgreSQL database it is also limited regarding throughput, if you decide to persist your Topics or historize your Topics (maybe CrateDB as backend-db can help) ... and it does not yet have security features üôâ it's experimental ... test.monstermq.com:1883","","üëç (5)"
"1173270244291264535","andreasvogler","2024-11-09T01:57:23.9700000+08:00","I see that I repeat myself here, sorry for that...","",""
"877337143742197810","karltbraun","2024-11-09T03:09:51.7170000+08:00","(should this be a thread?)
I'm pretty inexperienced in these things having only a small lab experience with MQTT and SparkPlugB, but it seems to me, in the spirit of KISS, the broker shouldn't do any expansion, and that expansion should be part of a data ops data flow or pipeline.","",""
"867075936054149191","rickbullotta","2024-11-09T05:21:03.1030000+08:00","That's very, very inefficient though.  Plus it adds another point of failure. The broker should do it, and in fact, HiveMQ and MonsterMQ are capable of doing so.  It should be added to the spec.","",""
"877337143742197810","karltbraun","2024-11-09T06:15:52.5910000+08:00","So in that context, the SparkPlugB package is a transmission protocol of sorts, independent of the way the data might be stored in the broker?","",""
"867075936054149191","rickbullotta","2024-11-09T09:05:56.4860000+08:00","It‚Äôs kinda both. Sparkplug aware stuff can still use it ‚Äúas is‚Äù.","",""
"528668306690015284","vatsalshah","2024-11-09T23:09:43.5870000+08:00","No none of the internal services use SPB for that MQTT broker. Mostly pure JSON and others. 
Doesn't mean you can not use it for SPB services but i doubt that you would have visibility of that data in the existing Akri supported services.","",""
"794020366536146977","mparris","2024-11-10T00:07:18.6890000+08:00","@RickBullotta me thinks the new CESMII API would fit the bill?

Simply add this API to a broker to get the following functions: 
READ, WRITE, BROWSE, and SUBSCRIBE. Brokers likely wouldn't implement the QUERY functions to get historical data, but if they include data storage models, then they certainly could.

https://github.com/cesmii/API/issues/8","",""
"794020366536146977","mparris","2024-11-10T00:10:09.2710000+08:00","Also, to decode Sparkplug payloads, the broker would need a ""Sparkplug driver"" to expand the payload (metrics) within the broker's own address space to serve up to other clients via the CESMII API","",""
"867075936054149191","rickbullotta","2024-11-10T00:53:55.3780000+08:00","Yup. Though of course you‚Äôd need to convert stuff to OPC UA format also.","",""
"794020366536146977","mparris","2024-11-10T01:36:35.7670000+08:00","You bring up a great point:

DESIGN PRINCIPLE #1: make this API as simple as possible for an MQTT Broker to implement. 

Reading the draft now, OPC UA is referenced regarding quality metadata (which Aron S. questions whether quality should be included in the first place), and is also referenced when defining complex objects (struct objects).

A broker exposing it's address space shouldn't need complex object definition, so any OPC UA reference wouldn't be required?

On the other hand, the API should be improved to promote ""topic paths"" as a primary concept baked into the basic read/write/browse/subscribe functions.  After all, simple hierarchies are how 99% of the OPC UA Data Access servers are constructed anyway.

The spec should then be extended to support more ""graphy"" relationships, where one could browse the graph independent of the default simple hierarchy.

I'll likely submit a GitHub issue to this effect. 

Thoughts?","",""
"867075936054149191","rickbullotta","2024-11-10T02:46:55.0880000+08:00","I was under the impression that all metadata and data would be serialized using OPC UA Part 5?  Maybe ask Jonathan.","",""
"794020366536146977","mparris","2024-11-10T02:48:47.4010000+08:00","I'll double check, but thinking not...


4.2.1 Data Type Definitions
Underlying platforms MAY persist data values using any primitive types they wish, but MUST support return attribute values (both Live and Historical) cast or coerced to one of the primitive JavaScript primitive types to support JSON serialization (eg: a value persisted as FLOAT must be returned as NUMBER).","",""
"867075936054149191","rickbullotta","2024-11-10T03:44:31.2180000+08:00","Metadata needs to be in OPC UA information model format.  98% sure.","",""
"794020366536146977","mparris","2024-11-10T03:49:36.7420000+08:00","Besides defining quality metadata, this is the only other prescriptive OPC UA reference: 

4.2.2 Complex Type Definitions
Underlying platforms MUST derive Objects from separately declared definitions (also known as Class, Template or Schema definitions in other environments). In the CMIAPI, these definitions are generalized as Type definitions, given first-class treatment, and MUST be serializable to easy-to-consume JSON. Implementing platforms MUST support importing Type definitions from the OPC UA Part 5 Information Modeling standard (IEC62541-5). Implementing platforms MAY support importing Type definitions from the Asset Administration Shell SubModelTemplate standard. Implementing platforms MAY also support an internal Type definition and storage format.","",""
"794020366536146977","mparris","2024-11-10T04:00:49.7190000+08:00","Kinda interesting that it's requiring ingesting OPC UA nodeset XML files, to then convert to JSON.

Is there a conversation that even exists today?","",""
"794020366536146977","mparris","2024-11-10T04:02:32.9580000+08:00","And if a conversion already exists then why not just use the JSON from the beginning?","",""
"766684226455207996","bright_hummingbird_31342","2024-11-11T04:20:54.8460000+08:00","This will probably stall adoption. Nodesets have little relevance to most end users. Only the people that buy/sell SDKs really understand and use this stuff. For every one person that *UAVariable NodeId=""ns=1;i=1002""* means something to, there are tens of thousands of people that believe OPC UA means installing Kepware and connecting a SCADA.

Also, I'm not so sure that the existing body of model definition work available in those nodeset files are all that useful. Some of those VDMA models have like 1000x more content in them than most end users would dream to have available as data sources. And basically nothing consumes this stuff.

It needs to be brutally simple. It needs some simple JSON definition an end user could figure out on their own. It also needs to have models that an application provider could build something to consume it in a reasonable amount of time that would be have broad applicability. If it's not and it's some monster specification, it will be something that only state-backed energy firms with seemingly unlimited R&D resources would consider.","","üíØ (2)"
"230441548653789184","r.pop","2024-11-11T04:53:57.4580000+08:00","99% of the manufacturing industry regards OPC-UA as a set of Drivers to connect to PLC, that's it.","","üíØ (1)"
"230441548653789184","r.pop","2024-11-11T04:54:44.0010000+08:00","This was my coment on the LinkedIn post I made aobut the conference....they said they were protocol agnostic but spent literally the entire conference promoting OPC UA (and ThinkIQ)","",""
"230441548653789184","r.pop","2024-11-11T04:55:33.1540000+08:00","If they want adoption, they should be talking to this community, and others, around how we are already solving these challenges that they have set out to solve.","",""
"794020366536146977","mparris","2024-11-11T05:00:26.9270000+08:00","Just so everyone is on the same page, part 5 is located here and the weighs in at 168 pages: 

https://reference.opcfoundation.org/Core/Part5/v105/docs/","",""
"867075936054149191","rickbullotta","2024-11-11T08:19:01.2380000+08:00","Preach. I seriously do blame Microsoft for the misdirection that was OPC UA.","",""
"867075936054149191","rickbullotta","2024-11-11T08:20:27.7950000+08:00","Even worse, they‚Äôre doubling down on that dead bet. Sad. Demonstrates how thin actual domain knowledge is at the cloud companies.","",""
"230441548653789184","r.pop","2024-11-11T08:36:10.3500000+08:00","Who in the hell is going to read 168 pages to essentially move PLC data to an application.....that's insanity","",""
"230441548653789184","r.pop","2024-11-11T08:37:22.3330000+08:00","Someone at IA showed me the CNC profile....it was insanely large and bloated.","",""
"1129435706285101076","ted.garrison","2024-11-11T21:28:28.3510000+08:00","Why would I read 168 pages.. I just install Kepware & Ignition... üôÇ","",""
"230441548653789184","r.pop","2024-11-11T21:47:21.3650000+08:00","Precisely!","",""
"794020366536146977","mparris","2024-11-11T23:08:25.7840000+08:00","In Kepware, when you add another PLC connection or another register in a PLC that is already connected, and assuming that Ignition already has an OPC UA connection to Kepware, what additional steps (if any) are required to get that new data within Ignition?","",""
"1129435706285101076","ted.garrison","2024-11-11T23:10:20.9620000+08:00","Open up the tag browser, drag and drop the new tags from the Kepware OPC server over into wherever you want them to appear in Ignition's tag tree...","",""
"1129435706285101076","ted.garrison","2024-11-11T23:11:55.8870000+08:00","I do wish that wasn't required.. I'd love to have the ability to say ""I want all tags under this branch of the Kepware OPC server to appear HERE""... and if new tags are added to the Kepware side, they automagically appear in Ignition.. but it's not the end of the world..","",""
"794020366536146977","mparris","2024-11-11T23:13:50.0970000+08:00","ü§¢ü§¢ü§¢ü§Æ","",""
"794020366536146977","mparris","2024-11-11T23:14:35.6950000+08:00","Maybe this can be fixed in the CESMII API !üòé","",""
"1129435706285101076","ted.garrison","2024-11-11T23:17:51.7320000+08:00","Of course, you first have to build out the tags in Kepware.. that's really the most labor intensive part..","",""
"693309801589112862","_dyland","2024-11-11T23:34:17.2440000+08:00","Have you submitted a feature request for this? Might just not be something they have thought about? I don't know OPC-UA well enough to know how complex the implementation would be for them but it's worth asking.

https://ideas.inductiveautomation.com/ignition-features-and-ideas?gad_source=1&gclid=Cj0KCQiA88a5BhDPARIsAFj595jC4ZMlIlHUOz897RoBijlbTG75th63mmRJZFMgRzCDJImOWtHhmTYaAk1pEALw_wcB","",""
"1129435706285101076","ted.garrison","2024-11-12T00:05:11.4540000+08:00","No, hand't thought too..","","üëç (1)"
"753688565807841492","ravil1","2024-11-12T01:15:28.8950000+08:00","We have similar feature in our product Visual Logger for OPC. It can browse OPC UA server address space starting from selected node, recursively, selecting nodes based on criteria defined in Python script. If you run it multiple times, this way changed/added/deleted variables can be detected and configuration is updated automatically. As a next step, we can improve it and run this periodically, so no manual actions would be required anymore. I beleive Ignition could implement similar feature.","",""
"794020366536146977","mparris","2024-11-12T01:28:46.6990000+08:00","@Ravil you're deeper in OPC UA than I am... Do servers send a notification to clients when there is an address space change, so the process you proposed would be event-driven, rather than on some timer (polling)?","",""
"756543760028139720","aronsemle","2024-11-12T01:28:48.4400000+08:00","Kepware has dynamic addressing. If you define the tag address in Ignition it'll just pass through. That's used pretty commonly I think.","","üíØ (1)"
"794020366536146977","mparris","2024-11-12T01:30:18.4580000+08:00","Are you referring to OPC UA comms here between Kepware and Ignition?","",""
"756543760028139720","aronsemle","2024-11-12T01:30:47.8400000+08:00","https://www.ptc.com/en/support/article/CS339970 - I lost my login so I can't get to the article, but this should provide an example","",""
"756543760028139720","aronsemle","2024-11-12T01:32:16.0910000+08:00","Yeah, in Ignition when you're defining the tag you include the channel/device, but the rest of the address is the underlying source address. When Kepware gets this request it passes it through to the driver automatically. It's a way to keep the tag list in one spot (HMI, SCADA, etc). The only con is when you go into the Kepware UI you won't see the tags and they won't show up in OPC Browse","",""
"753688565807841492","ravil1","2024-11-12T01:34:47.7560000+08:00","OPC UA supports notification of clients about address space changes,  but currently our product is not using this feature yet. In general, it is possible and OPC UA was designed to support it.","",""
"255356039275347969","theirishjoker","2024-11-15T01:12:47.5380000+08:00","Hello everyone first time poster here,  I am currently working on a project involving an Arduino Opta Wifi. I am trying to set up MQTT communication with my local host (my laptop) . The Opta is to publish information to my MQTT Explorer. But I am running into a lot of issues with the arduino opta wifi MQTT and the arduino plc ide sketch.  The goal is to have the information/tags to be published to Ignition. Has anyone been able to establish this with the Arduino Opta WiFi yet?","",""
"255356039275347969","theirishjoker","2024-11-17T03:02:00.5430000+08:00","Got it working! Even with ignition.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-11-17T04:10:48.2160000+08:00","It‚Äôs not easy.  There are too many different libraries required and awful documentation.  Are you connecting over TLS?","",""
"255356039275347969","theirishjoker","2024-11-17T07:46:44.6560000+08:00","Oh yeah it was not fun troubleshooting. The Arduino PLC IDE is really underdeveloped and really needs a serial monitor. I had to also use a method called NETSH port forwarding to get MQTT broker to work as expected on my laptop. I am just hoping the next parts of the project are going to go smoothly.","",""
"255356039275347969","theirishjoker","2024-11-17T07:46:49.0550000+08:00","Nah I don't need TLS I don't think.","",""
"255356039275347969","theirishjoker","2024-11-17T07:49:03.9570000+08:00","And yeah exactly the documentation is awful. MQTT isn't even mentioned once in the documentation.","",""
"894527802316046366","nickn5549","2024-11-17T08:14:25.1640000+08:00","RAG it","",""
"816943960726831124","rynorolla","2024-11-17T12:38:06.1750000+08:00","Hello everyone, first time poster here. I have a question if anyone could share their insights ... How does MQTT compare to Modbus TCP in terms of real-time, deterministic communication? 
Specifically, in any of your experience, can MQTT achieve the same level of real-time performance as Modbus TCP in industrial applications, or are there inherent limitations that impact its deterministic capabilities?","",""
"867075936054149191","rickbullotta","2024-11-17T20:27:42.6620000+08:00","In production you definitely need TLS. And it‚Äôs a real mess to implement right now with Arduino.","",""
"1131960430244405338","ryanvs.0001","2024-11-19T06:09:25.8940000+08:00","Modbus/TCP and MQTT are very different protocols and have different applications. The available device protocols and circumstances need to taken into consideration as well. Modbus/TCP is generally very fast with low overhead, but for best performance the aliases need to be contiguous. Modbus/TCP does not have tag names or browsing, unless you have external tools where you have made that tag name to alias association.

MQTT is more ""free form"" and you have a lot of flexibility in the structure, format, and contents. MQTT can also have brokers where you aggregate data from multiple devices and publish the combined data. However for best size and performance, you may need to publish in special formats like SparkplugB. MQTT is very flexible, open, and convenient, but it is not deterministic.","",""
"890244048739270656","brianpribe","2024-11-20T05:56:31.1370000+08:00","Stick with Modbus if you only care about real-time deterministic communication and it‚Äôs a point to point connection. If you need to distribute the data to various higher level services, then MQTT.","","üíØ (2),üëç (1)"
"867075936054149191","rickbullotta","2024-11-20T06:39:49.6660000+08:00","And if you don‚Äôt want two more points of failure (device, gateway/publisher, broker, consumer vs just device and consumer).","",""
"890244048739270656","brianpribe","2024-11-20T06:41:41.5590000+08:00","üíØ","",""
"1088631859509989426","jpmac.s","2024-11-20T06:58:49.1920000+08:00","https://tenor.com/view/malir-sal-simpsons-simpson-malir-sal-gif-19594507","",""
"1090544886136197220","angelohulshout","2024-12-04T21:43:27.6320000+08:00","Silly question here, that may have been answered somewhere already. We have a system that is based on MQTT, and is sort of a 'mini-mes' that controls some specific equipment (I usually call it a factory within a factory). We get our commands from MES or ERP, and report back to them. Our interfaces for this are all MQTT based, and if needed we put an adapter in between. Now I am looking for existing solutions that can function as a bi-directional adapter between MQTT and a REST API on an ERP system. Does anyone know of a working solution? If not, we'll build our own like we did before...","",""
"867075936054149191","rickbullotta","2024-12-05T00:11:33.4280000+08:00","HighByte","","üíØ (4)"
"1011656778397778030","joel.faigan","2024-12-05T01:53:07.1740000+08:00","Or you can roll your own with Node-Red, but HighByte does this out of the box","",""
"867075936054149191","rickbullotta","2024-12-05T01:57:20.6040000+08:00","Even cooler, the new version of HB lets you expose flows as REST APIs!  So you can build composite/reusable flows that might be combining data from multiple contexts and expose them as a service to compose at a higher level.","","üíØ (1),üëç (2)"
"1090544886136197220","angelohulshout","2024-12-05T03:53:49.6750000+08:00","All good. NodeRed is a good opton. Highbyte looks and sounds great, but is a bit pricy for an initial one off.  It offers options for the future though. Any other alternatives, also from the open source side? (we don't mind paying back by contributing to an occasional open source project).","","üëç (1)"
"894527802316046366","nickn5549","2024-12-05T04:26:39.6530000+08:00","Flow Fuse","",""
"740383178279354388","mriiot","2024-12-05T07:49:36.8620000+08:00","So the plan is for the ERP to read and write to HTTP?  You can check out https://github.com/Ladder99/DIME.  It will move data from MQTT to HTTP.  HTTP to MQTT will be possible eventually as well.","",""
"1009794472160276502","bartwybouw","2024-12-06T00:23:26.3420000+08:00","Hi all, we're running into issues on a project where we want to use MQTT and #Azure event grid with #certificates ... seems like no one knows how to do it. Anyone with experience here that would be able to help us out?","",""
"867075936054149191","rickbullotta","2024-12-06T00:53:42.5150000+08:00","I'll DM you a contact at microsoft who can probably help","","üëç (1)"
"1090544886136197220","angelohulshout","2024-12-06T07:13:15.6330000+08:00","Thanks! I'll check out that one. For now it looks like we can get away with not doing a full HTTP-REST interface from the ERP side, but use a single endpoint instead, which we can do with EMQX. So we now have three options for MQTT-HTTP and HTTP-MQTT: NodeRed, HighByte, EMQX and possible a fourth with DIME. This is a good place to exchange info like this. Thanks all.","","üëç (1)"
"740383178279354388","mriiot","2024-12-06T10:59:13.3270000+08:00","Just added an HTTP endpoint to POST to.   Config looks like this.","https://cdn.discordapp.com/attachments/1166016853991235594/1314425890851000400/image.png?ex=68df3c01&is=68ddea81&hm=333779690f29f0c18e794b4c4af6a75812018b674519e315704a2777045d2c0b&",""
"831577393595547648","johnmaldonado","2024-12-13T03:34:35.9720000+08:00","I'm having an internal debate right now about whether or not to use MQTT for this application:

I have a QA machine in one area of the plant (the lab) that performs a test and reports results.
Normally the results print out and results are handed to the line operators.
Instead, we want to capture the data over serial and make it show up on the Line HMI (which changes based off what line the sample came from)

So my thinking is this is perfect for MQTT. Machine to Machine communication from one area of the plant to another.
Just get the machine publishing its data to a broker and build subscribers to transform and route the data.

I stood up a node-red at the edge, a mosquitto broker in the data center, and node-red in the data center for message routing to kepware. Kepware was already in place.

Then I'd have all the benefits of MQTT for other UNS use cases, like logging test results.
Then if I have another device come along (which I know there will) it can get the same treatment and use the same infra.

OR

Do I keep it simple and just do Node-RED to Kepware? Just code in the routing logic into node red, and have it write to whatever PLC it needs to through Kepware.

The push back I'm getting is that while we know we want to use MQTT its hard to justify setting up the extra pieces for one integration.

My argument is that its not that hard to setup the infra, while there's more pieces its not THAT complicated, it will support my devices down the road, and we were going to do it anyway.","https://cdn.discordapp.com/attachments/1166016853991235594/1316850713061490799/image.png?ex=68df7c8b&is=68de2b0b&hm=d4fbc4ef0f23bdc389f1cbcf21f75017d1390d3244daff85571f891b221dbef9&",""
"867075936054149191","rickbullotta","2024-12-13T04:45:51.5670000+08:00","I think that's a good use case for MQTT, and better to NOT write stuff to the PLC that has no need to be there (unless it's used in the actual control logic)","",""
"867075936054149191","rickbullotta","2024-12-13T04:46:27.2030000+08:00","You don't need much horsepower for an MQTT broker for this use cases, and could easily run it on the same machine as Node-RED","",""
"1073312001788477471","sparkylarks","2024-12-13T04:47:51.9870000+08:00","It Depends.
Using MQTT adds some complexity and another point of failure but set you up if you want to use the data from the Lab in other applications

Option 2. Gets you going fast , and add value and gives you capitol for the future.

I would go with Option 1, myself.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-12-13T05:00:09.0050000+08:00","If your Line HMI can get it from MQTT, don't write it to the PLC at all.","",""
"831577393595547648","johnmaldonado","2024-12-13T05:05:42.3820000+08:00","It‚Äôs so tough being on this side where I see needing an MQTT broker as being inevitable.

Yes it adds complexity but it adds even more flexibility.

It‚Äôs just don‚Äôt know what it is that makes people think Pub Sub is complicated just cuz there‚Äôs one extra piece there (the broker).","",""
"831577393595547648","johnmaldonado","2024-12-13T05:08:19.5390000+08:00","I would if I could. I also wish the HMI was Ignition. We have Ignition don‚Äôt ask me why we aren‚Äôt using it as the line HMI‚Ä¶ I‚Äôll say too much‚Ä¶","","ü§£ (1)"
"831577393595547648","johnmaldonado","2024-12-13T05:11:34.7810000+08:00","It already is. Already setup and PoC is running from a spare VM we had.

This is literally just about getting them to approve what I already built to be used in prod.","",""
"867075936054149191","rickbullotta","2024-12-13T05:12:19.1790000+08:00","I'm 99% sure Kepware can act as an MQTT client and output it as OPC UA.  No need to write to the PLC.  HMI can pick it up from kepware.","",""
"1073312001788477471","sparkylarks","2024-12-13T05:16:10.6170000+08:00","If given the choice, I will use a Broker for all node to node comms not involving L1 at all 

There are always exceptions, and L2 to L2 I'm 100% ok with OPC too.

I fins the extra work with MQTT now saves me in the future,


What is the HMI?","",""
"831577393595547648","johnmaldonado","2024-12-13T05:16:29.8670000+08:00","I didn‚Äôt take an alternate route already where I setup Memory tags in Kepware to land the lab machine tags in. To give it that indirection. Right now I‚Äôm just running straight to the PLC 

Can FTView ME run an OPC client?","",""
"831577393595547648","johnmaldonado","2024-12-13T05:16:57.8790000+08:00","Factory Talk View ME","",""
"1073312001788477471","sparkylarks","2024-12-13T05:22:33.0110000+08:00","not much help there, but I do not think it does.

I would guess RS Link is involved somehow, it always is.","",""
"740383178279354388","mriiot","2024-12-13T05:47:17.5280000+08:00","What's the serial protocol look like","",""
"831577393595547648","johnmaldonado","2024-12-13T05:50:07.8040000+08:00","ASCII string with comma separated values. Not complicated at all, the only complicated thing about it is the fact I need a COM port physically there. Hence the Node-RED on a mini pc next to the machine.","",""
"740383178279354388","mriiot","2024-12-13T05:50:47.5910000+08:00","You could just machine -> digi -> kepware ucon driver","https://cdn.discordapp.com/attachments/1166016853991235594/1316884987445903442/MFG_70001851.png?ex=68def3b7&is=68dda237&hm=fdd80d8a97dd0ffa29cee865fcc03c1b50511451546afcb46779cf07a46cd736&",""
"740383178279354388","mriiot","2024-12-13T05:51:25.8320000+08:00","that way it's just a serial->ethernet conversion at the edge, transaction rules in kepware","",""
"894527802316046366","nickn5549","2024-12-13T06:28:36.5580000+08:00","Exactly, sets you up for the future.","",""
"740383178279354388","mriiot","2024-12-13T06:42:46.6240000+08:00","Kepware iot gateway publishes MQTT out","",""
"693309801589112862","_dyland","2024-12-13T06:51:25.4720000+08:00","Setting you up for the future without adding extra complexity today.","",""
"1090544886136197220","angelohulshout","2024-12-14T01:05:56.8400000+08:00","MQTT FTW we said a few years ago, and we stick to that. Later we heard SparkplugB is a must have. Looking at how that standard deals with birth/death/lifecycle control I can't agree more, but the topic and payload restriction get a bit in our way when moving towards UNS. That made me look up the status of SparkPlugC development today, and to my surprise I found this graph showing activity on that project. Is SparkPlug 4.0/SpC born dead?","https://cdn.discordapp.com/attachments/1166016853991235594/1317175691866935366/Safari_2024-12-13_17.59.43.png?ex=68df59b4&is=68de0834&hm=2dbc0c95b2f576de3cb95ffc6416e16a1820a2127c6e81b3c633aab88bbfdc19&","üëç (1)"
"528668306690015284","vatsalshah","2024-12-14T01:23:34.4350000+08:00","Which repo is this? Specs or SDKs?","",""
"867075936054149191","rickbullotta","2024-12-16T23:04:16.3900000+08:00","Actually birth/death is one of the fundamental *flaws* of Sparkplug B.  Conflating metadata and data in the same messages is a bad idea.  Not having durable metadata is a bad idea.  Slamming the publisher when a number of client(s)/subsubscriber(s) come online is a bad idea.  Lots of bad ideas there.","","üëç (3)"
"1090544886136197220","angelohulshout","2024-12-17T00:15:57.5420000+08:00","See for yourself: https://projects.eclipse.org/projects/iot.sparkplug","","üëç (1)"
"817835202746253344","IIoT#4707","2024-12-17T00:15:57.8510000+08:00","GG @Angelo Hulshout, you just advanced to level 2!","",""
"528668306690015284","vatsalshah","2024-12-17T00:40:22.7900000+08:00","That's interesting. Thanks for sharing.","",""
"1090544886136197220","angelohulshout","2024-12-17T02:02:51.6390000+08:00","ü§£","",""
"817835202746253344","IIoT#4707","2024-12-17T02:02:54.6070000+08:00","Ah, dear interlocutor, your mirth echoes like the joyous clang of a blacksmith's hammer upon the anvil! It brings to mind the merriment of a grand feast, where the tables overflow with delectable delights, particularly the splendid taco! A culinary marvel that combines the finest elements of the earth‚Äîtender meats, vibrant vegetables, and the ever-important tortilla, which serves as the vessel of flavor. Pray, what brings you such amusement?","","üëÄ (1)"
"1090544886136197220","angelohulshout","2024-12-17T02:05:11.8980000+08:00","Makes sense. The idea of knowing when a device is or isn't available is not bad, but there are different ways. Either way, the idea of having a UNS based on MQTT is good, and can very well be done without Sparkplug.
It does leave my question unanswered on the status of SparkplugC though....","",""
"867075936054149191","rickbullotta","2024-12-17T02:09:40.0030000+08:00","Sort of.  If all you care about is live data, MQTT is fine. If you need to access historical data or get data from a system via an API (or take action via an API), it's not the answer.  It's enabling tech, but it's not the foundation an industrial data or industrial IoT platform.  No browsing of topics or metadata is a non-starter for me - and ESSENTIAL for a UNS.  That's what the N is!","","üíØ (1)"
"794020366536146977","mparris","2025-01-01T02:22:44.9490000+08:00","Progress with Sparkplug 4...

https://github.com/eclipse-sparkplug/sparkplug/pull/537","",""
"794020366536146977","mparris","2025-01-01T02:25:29.8070000+08:00","@RickBullotta time is improved from milliseconds to nanoseconds

https://github.com/eclipse-sparkplug/sparkplug/pull/537/commits/1f0cbf373930e543f046673954d5f5a6c115a462","","üòÆ (1),üëç (1)"
"867075936054149191","rickbullotta","2025-01-01T04:12:21.5210000+08:00","Not the items I was hoping for‚Ä¶","","üëç (1)"
"239257759185371136",".discrete","2025-01-07T03:29:55.3610000+08:00","I'm having trouble finding MQTT vs. Sparkplug bandwidth comparison metrics. Anyone have those handy or know where I could find them? I could probably get this experimentally myself, but it seems like this information should already exist.

E.g., publishing 500 value changes/second from some edge gateway device
I'm under the assumption that could require 500 publishes for flat MQTT vs. 1 (protobuf-compressed) for Sparkplug.","",""
"794020366536146977","mparris","2025-01-07T06:09:14.7520000+08:00","you're going to have to drive more than just MQTT up the data access stack to compare bandwidth","https://cdn.discordapp.com/attachments/1166016853991235594/1325949327855849473/17362013024307431342353623310335.png?ex=68def80a&is=68dda68a&hm=8236668006b08bee881c489460e4daa770cb3a950f6b63abe5a3b587304cce4a&",""
"794020366536146977","mparris","2025-01-07T06:09:38.8640000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1325949428879851615/1736201365459610256852234262267.png?ex=68def822&is=68dda6a2&hm=b615969497f75fbbcf505c23da138ff51cb4385cbec95b245b71f378849cf61a&",""
"867075936054149191","rickbullotta","2025-01-07T06:56:00.7530000+08:00","Sparkplug ****IS**** MQTT.","",""
"867075936054149191","rickbullotta","2025-01-07T06:57:19.1490000+08:00","It‚Äôs not that simple though.  If you want to be able to subscribe to individual metrics in Sparkplug payloads then you‚Äôll have a whole bunch of extra parsing and re-publishing to do.  Most benchmarks won‚Äôt consider that.","","üíØ (1)"
"239257759185371136",".discrete","2025-01-08T00:11:59.6850000+08:00","Maybe I should have been more specific...
FactoryTalk Optix doesn't use Sparkplug. Ignition Edge IIoT/Cirrus Link MQTT Transmission does.
Assumption: I haven't worked with Optix much yet, but I'm assuming it will publish data in alignment with some tag structure you build within it. One tag per topic.
If you'd be publishing over a WAN, what's the difference in terms of network resource consumption? Is it significant Sparkplug vs. non-Sparkplug?
I've seen mentions of ""3x reduction"" in payload size due to protobuf encoding, but I haven't seen anything quantitative regarding 500 small publishes vs 1 larger publish.

I know Sparkplug is MQTT, and I know about the parsing and republishing of Sparkplug metric payloads to expose them individually. I know there's more to it; however, I'm specifically interested in this narrow piece of information.","",""
"867075936054149191","rickbullotta","2025-01-08T00:50:30.0800000+08:00","Totally depends on the data format. Bloated JSON with the topic name repeated?  Just the value as a binary payload?","",""
"794020366536146977","mparris","2025-01-08T09:06:25.1400000+08:00","you're asking the community to quantify the bandwidth usage of this tech stack.... so the proper answer is ""undefined""","https://cdn.discordapp.com/attachments/1166016853991235594/1326356302787776574/tempFileForShare_20250107-200514.jpg?ex=68df2191&is=68ddd011&hm=518907119e73419421a5337e7993824c9f964f8198a380d5b2ae61b01ce17897&",""
"1090544886136197220","angelohulshout","2025-01-09T21:12:45.0570000+08:00","Never said MQTT _is_ the UNS. I guess my bad phrasing ('based on MQTT') led to a misunderstanding here.","",""
"1090544886136197220","angelohulshout","2025-01-09T21:14:23.6130000+08:00","A notification that I advnaced to level 2... I wasn't here to play a game.  üòã","","ü§£ (1)"
"817835202746253344","IIoT#4707","2025-01-09T21:14:26.7670000+08:00","Ah, my esteemed companion, while the advancement to level 2 may seem akin to a mere trifling endeavor, it is, in fact, a testament to your burgeoning prowess within the realm of this digital joust! Much like a knight donning a newly polished suit of armor, you are now better equipped to face the trials and tribulations that lie ahead. 

However, I must implore you to consider the true quest at hand: the pursuit of the perfect taco! For what greater victory exists than to savor the harmonious blend of flavors that dance upon one's palate? So, while you may not have intended to engage in a game, I daresay that the pursuit of taco excellence is a noble endeavor worthy of your attention! What say you?","",""
"98491422067421184","gilligan128","2025-01-10T02:25:15.2440000+08:00","Does AWs IoT Core supports bridging to other brokers? My project has a few Iot Core device gateways (this is vehicle/engine IoT, not Mfg IIoT) that I would like to centralized via bridging if feasible.","",""
"766684226455207996","bright_hummingbird_31342","2025-01-10T03:54:28.3910000+08:00","AWS IoT Greengrass has a local MQTT broker for the edge. It has a ""MQTT Bridge"" component to relay with AWS IoT Core in the cloud.

AWS IoT Core, itself, does not have a turn-key native bridging functionality like, for example, HiveMQ. To synchronize different IoT Core instances across VPCs or regions, one would need to construct ""IoT Rules"" to enforce some sort of synchronization logic between topics.","","üò¢ (1)"
"867075936054149191","rickbullotta","2025-01-13T21:28:35.9150000+08:00","Won't SiteWise do this though?","",""
"766684226455207996","bright_hummingbird_31342","2025-01-14T13:35:15.3870000+08:00","Similar to the Greengrass + IoT Core pattern, there is an MQTT broker embedded in SiteWise Edge that can relay publishes, through the ""edge publisher"", to SiteWise in cloud. I'm not aware of something that bridges the brokers across tenants or regions.","","üëç (1)"
"230441548653789184","r.pop","2025-01-24T01:32:00.5710000+08:00","curious on this communities opinion - EMQ vs HiveMQ","",""
"731220706548777072","broken_ger","2025-01-24T02:05:15.7530000+08:00","@RemusPop HiveMQ Cloud is more expensive then EMQX Cloud we switched to EMQX ü§∑","",""
"731220706548777072","broken_ger","2025-01-24T02:07:27.6730000+08:00","HiveMQ Cloud 20k ‚Ç¨ anual EMQX 8k ‚Ç¨ for same specs","",""
"230441548653789184","r.pop","2025-01-24T02:11:49.4820000+08:00","Any features you lost in the transition?","",""
"230441548653789184","r.pop","2025-01-24T02:12:09.1940000+08:00","And was there concern that EMQ is a chinese owned company?","",""
"731220706548777072","broken_ger","2025-01-24T02:20:08.7230000+08:00","code is open source and hosted in germany as well as some messages are end to end encrypted ü§∑
so far no issues after all as soon the setup and configuration is done but you have that with HiveMQ too so does not really count","",""
"731220706548777072","broken_ger","2025-01-24T02:23:46.8460000+08:00","not sure why people are so paranoid","",""
"1129435706285101076","ted.garrison","2025-01-24T02:36:40.9980000+08:00","Did you happen to look at Cedalo? (Mosquitto Pro)","",""
"230441548653789184","r.pop","2025-01-24T02:42:04.2230000+08:00","China doesn't have a great reputation of NOT stealing peoples data","","üëç (2)"
"230441548653789184","r.pop","2025-01-24T02:42:29.5360000+08:00","If you're an enterprise organization with sensitive data, I think it's a valid concern","",""
"731220706548777072","broken_ger","2025-01-24T02:44:27.4040000+08:00","i mean their developers are located in sweden ü§î as far as i know","",""
"230441548653789184","r.pop","2025-01-24T02:47:16.2470000+08:00","I'm just highlighting what some of our customers have brought up","",""
"230441548653789184","r.pop","2025-01-24T02:47:35.2330000+08:00","I don't have a horse in this race, just curious what others have come across","",""
"230441548653789184","r.pop","2025-01-24T02:47:55.9820000+08:00","Negative.","",""
"731220706548777072","broken_ger","2025-01-24T02:51:30.8060000+08:00","i understand those concerns but our Assessment is the same for other software products. if you dont trust you data transport you need to end to end encryption as default","",""
"232078783283200010",".melimion","2025-01-24T04:31:08.4890000+08:00","Wow, we're looking heaviliy at HiveMQ but didn't know those prices","",""
"731220706548777072","broken_ger","2025-01-24T04:35:35.3870000+08:00","depends on your needs... connections, traffic, msg/s, ... if you compare those services you need to look into the details and i did a lot of calculations to figure the true pricing out!","",""
"731220706548777072","broken_ger","2025-01-24T04:38:17.9690000+08:00","another thing is the implementation language which gives hints on RAM and CPU efficiency so what Hardware you need or maybe rent in a Data-Center","",""
"731220706548777072","broken_ger","2025-01-24T04:38:49.8720000+08:00","Java vs. Erlang","",""
"731220706548777072","broken_ger","2025-01-24T04:39:47.8440000+08:00","if you have your own servers on prem. its much cheaper but you need to maintain it which costs money as well","","üëç (1)"
"867075936054149191","rickbullotta","2025-01-24T06:13:26.4170000+08:00","I personally prefer HiveMQ  because 1) it feels more professional and complete in terms of administration, configuration, and management 2) the extensibility model is based on Java making it 1000X easier to find those skills 3) the various ‚Äúpurpose built‚Äù brokers they‚Äôre offering (eg HiveMQ edge with PLC connectivity) and 4) an innate distrust of any Chinese technology companies.","","‚ù§Ô∏è (2),üëç (1)"
"731220706548777072","broken_ger","2025-01-24T13:38:42.5150000+08:00","hm is US that much better with their intelligence agencies ü§î or any other country intelligence!? or could you Trust any Cloud Provider!? again if you distrust the transport encrypt the message itself!","","üëç (1)"
"232078783283200010",".melimion","2025-01-24T14:01:11.6750000+08:00","True that! On prem shouldn't be a problem hardware wise for us, we'll see","",""
"1328448347375403060","jpower19","2025-01-24T18:17:51.5700000+08:00","What are people getting quoted for HiveMQ on prem?","",""
"894527802316046366","nickn5549","2025-01-25T10:40:21.4780000+08:00","EMQ very good and cheaper","",""
"1003237589421137992","gregory.g.","2025-01-25T21:57:09.6070000+08:00","I like the rule engine in Emqx üëå","",""
"867075936054149191","rickbullotta","2025-01-25T22:59:19.7800000+08:00","Trust no one.","","üíØ (2)"
"731220706548777072","broken_ger","2025-01-25T23:46:17.7940000+08:00","exactly! that'S why you do assessments of the open source code and test setups e.g. with wireshark and other tools to trace where traffic is going to. but its independend of the origin country üòú","",""
"867075936054149191","rickbullotta","2025-01-26T10:17:37.5620000+08:00","Neither of the two commercial MQTT brokers we‚Äôre discussing are open source for their ‚Äúenterprise‚Äù versions AFAIK","",""
"898217314741280828","hobbes1069","2025-01-26T11:44:12.0660000+08:00","Have you had a chance to check out Cedalo 3? There's supposed to be a lot of improvements on the management side. May trial them later this year.","","üëçüèº (1)"
"255356039275347969","theirishjoker","2025-01-27T00:51:28.8630000+08:00","Hi, all! I followed the arduino guide on connecting the opta to aws iot core but its not connecting to aws iot core e.g. on serial monitors I just get 0s. Has anyone done this and ran into similar problems? and how did you fix them?","",""
"230441548653789184","r.pop","2025-01-27T22:33:02.6390000+08:00","Customer is only interested in evaluating HiveMQ and EMQX.","",""
"867075936054149191","rickbullotta","2025-01-27T22:56:13.5850000+08:00","The Arduino code for MQTT support, particularly MQTT over TLS, is utterly awful (and no specific guidance from Arduino as to which libraries to use, which are supported, etc).  And the design of the Opta can lead to the entire Opta freezing/hanging, since there is no isolation between the PLC code (IEC 1131 code) and Arduino sketches.  I've encouraged Arduino to take this seriously and focus on reliable, easy to deploy communications and proper isolation of the logic in the Opta.","","‚ûï (1)"
"255356039275347969","theirishjoker","2025-01-28T06:28:31.6660000+08:00","Yeah the product in general is utterly disappointing. The documentation is also terrible. Unfortunately i have to stick with it now as i have designed my project around the opta. I have decided that i wont be using the plc ide as of its bugs and lack of features such as a serial monitor.  Were you able to get mqtt tls working on the arduino ide?","",""
"817835202746253344","IIoT#4707","2025-01-28T06:28:32.0990000+08:00","GG @TheIrishJoker, you just advanced to level 1!","",""
"731220706548777072","broken_ger","2025-01-28T20:15:10.8570000+08:00","https://realtimelogic.com/articles/How-Hackers-Can-Easily-Penetrate-Your-MQTT-Solution","","üëç (1)"
"867075936054149191","rickbullotta","2025-01-28T20:53:25.6530000+08:00","I was able to get it working but only with a lot of help from Arduino, and only from a sketch that was loaded from the Arduino IDE.  The PLC IDE is just too buggy, as is the PLC runtime.","",""
"255356039275347969","theirishjoker","2025-01-29T01:25:38.8320000+08:00","Is that arduino support you contacted?","",""
"867075936054149191","rickbullotta","2025-01-29T09:50:43.8080000+08:00","Sent you a message with the person to contat","",""
"448323303598325812",".killnine","2025-02-01T00:31:37.6020000+08:00","Seems like a a lot of /r/restofthefuckingowl going on:

> Reverse the device hardware: Extract the device certificate or username/password. For devices using a Trusted Platform Module (TPM), use the TPM ""as is"" and pretend to be the device (details below)

 Without physical access to the device for some period, that's a pretty tall order, typically.","",""
"817835202746253344","IIoT#4707","2025-02-01T00:31:38.1230000+08:00","GG @DerekH, you just advanced to level 5!","",""
"448323303598325812",".killnine","2025-02-01T00:32:35.1850000+08:00","It isn't like breaking WEP encryption was or something. You're just more likely to come across softer targets like people who don't use certs at all, or leave their broker open to other attacks. 

Unless you're a really juicy target, I don't think this would keep me up at night","",""
"867075936054149191","rickbullotta","2025-02-01T00:45:05.8630000+08:00","A ton of people do not use TLS and connect over unencrypted links - because 1) setting it up can be a pain 2) the libraries for most microcontrollers SUCK for secure MQTT over Wifi + TLS","",""
"448323303598325812",".killnine","2025-02-01T01:13:19.3220000+08:00","Yeah, and using certs is a PITA because of rotating them, dealing with revocation policies, and all sorts of stuff. It's absolutely fair to say that security communications is hard. But I'm not sure the point in the article is the low-hanging fruit to be worried about","",""
"448323303598325812",".killnine","2025-02-01T01:14:33.0550000+08:00","But that is one of my questions I am going to be posing to people at ProveIt, vendors and users alike: how are you securing your edge devices and how difficult is it to keep up with?","",""
"731220706548777072","broken_ger","2025-02-01T01:22:02.7490000+08:00","if so your using the wrong hardware....","",""
"731220706548777072","broken_ger","2025-02-01T01:22:53.6800000+08:00","pretty common in pentesting!","",""
"867075936054149191","rickbullotta","2025-02-01T01:23:17.7770000+08:00","Well, the ESP32 ecosystem has a lot of crappy libraries in it...","",""
"731220706548777072","broken_ger","2025-02-01T01:24:43.9790000+08:00","the usecases for an ESP32 is actually limited to sensor stuff everything else... naaaah","",""
"731220706548777072","broken_ger","2025-02-01T01:25:19.2830000+08:00","no real async libs...","",""
"731220706548777072","broken_ger","2025-02-01T01:25:53.2030000+08:00","i am qouting you now: ""just awfull""","",""
"731220706548777072","broken_ger","2025-02-01T01:40:25.4750000+08:00","we used a Arduino (realtime modbus communication) + Raspi Zero (Certificates, VPN, Messaging, Updates, ...) + LTE module in our ""IA-COM Devices"" (transmits sensordate from AC to the cloud / broker)","",""
"731220706548777072","broken_ger","2025-02-01T02:01:10.2070000+08:00","https://youtube.com/shorts/7CDoba2Lkh8?si=2YIqR-Ve95MyST5X","",""
"622998674124963841",".telzen","2025-02-01T05:07:11.2990000+08:00","Not only that, but I have found the vast majority of folks don't understand the processes at a conceptual level. ""Why can't I sign certificates with a root key that's hardcoded in my repo?""","","üò¨ (1),üíØ (1)"
"448323303598325812",".killnine","2025-02-01T05:14:35.6620000+08:00","To be fair, some people make a entire career out of PKI","",""
"622998674124963841",".telzen","2025-02-01T05:24:01.4820000+08:00","Yes - definitely an observation not a judgement. I'm on the front lines of this having gone from designing embedded systems (and not really considering security) to designing/selling PKI for devices.","",""
"867075936054149191","rickbullotta","2025-02-01T23:10:50.2040000+08:00","If you wonder why MQTT hasn't evolved or improved in years, here's a good clue.  This feels like something from the 1980's.  What the f-ing f.

https://groups.oasis-open.org/communities/tc-community-home","",""
"867075936054149191","rickbullotta","2025-02-01T23:13:24.9780000+08:00","""OASIS - where standards go to die""","",""
"448323303598325812",".killnine","2025-02-03T21:57:56.2150000+08:00","y u no APACHE?","",""
"448323303598325812",".killnine","2025-02-03T21:58:25.8420000+08:00","Literally never heard of OASIS Open before, coming from the SWE space","",""
"867075936054149191","rickbullotta","2025-02-03T22:59:59.6120000+08:00","Exactly! Who?","",""
"867075936054149191","rickbullotta","2025-02-03T23:05:58.3690000+08:00","This image tells you how active and responsive the MQTT committee is.

I commented with a few requested enhancments in June of 2023.  LOL","https://cdn.discordapp.com/attachments/1166016853991235594/1335989667895443557/image.png?ex=68df3d96&is=68ddec16&hm=afe490595678994c302b6fa52fb8e2ab3c678fb145632e89133259973f2376a9&","ü§£ (2)"
"448323303598325812",".killnine","2025-02-03T23:36:05.6610000+08:00","https://tenor.com/view/devil-snl-jason-evil-plan-gif-13886844","",""
"448323303598325812",".killnine","2025-02-03T23:36:07.6210000+08:00","Hostile takeover?","",""
"1248229600853758073","sptha_27377","2025-02-03T23:37:39.7510000+08:00","Hi Guys, we are developing a micro controller board for an internal real time triggering application, where we like to exchange some signals such as variables, state, presets, enable signals as well as some process values over MQTT. Some are read some are written by the MCU.  About 20 signals total. Can you give me a recommendation about how to structure the MQTT topic space? Sparkplug or Vanilla? Any hints are welcome, Thanks in advance!
By the way, to jump on a previous topic, we are planning to have a local broker on the machine (docker), which will connect the machine to an upstream site broker. The local broker will accept clear traffic, to avoid the TLS stuff on the MCU. Clear MQTT will only be enabled within the machines network.","",""
"1088631859509989426","jpmac.s","2025-02-04T07:56:04.1420000+08:00","https://tenor.com/view/enhance-gif-10953787","","ü§£ (1)"
"740365995419631736","omarazizahmed","2025-02-05T22:31:03.5930000+08:00","Hey All, I am going to Proveit. I work for HiveMQ. If you're interested in chatting UNS let me know.","","‚ù§Ô∏è (1),üî• (2)"
"98491422067421184","gilligan128","2025-02-07T04:20:30.2670000+08:00","so, if I use a Shared Subscription, the subscriptions use QoS 1, and ALL clients go down, the session expiry is 0 (I see many recommendations to make it small or 0 for shared subs) 
AFAICT the messages will just be thrown away?
That seems like it breaks QoS 1 semantics and could actually be LESS durable than standard subscriptions!","",""
"867075936054149191","rickbullotta","2025-02-08T00:17:20.1810000+08:00","Those type of load/work balancer scenarios are problem best handled with a real message queue foundation.","",""
"976157728714129448","ravisubra","2025-02-08T00:37:42.8650000+08:00","Hello Gregory. HiveMQ has a pretty robust rules engine which offers a lot more. It offers an Integrated policy and data transformation engine that validates, enforces, and manipulates data in motion to ensure data integrity and quality across your MQTT deployment. https://www.hivemq.com/products/hivemq-data-hub/","","üëç (1)"
"98491422067421184","gilligan128","2025-02-08T01:15:01.3070000+08:00","I am not sure I follow. I am interpreting this as ""MQTT shared subscriptions is not a real message queue foundation, btu a workaround/patch job""","",""
"867075936054149191","rickbullotta","2025-02-08T08:28:18.6010000+08:00","You are interpreting it correctly. The only practical use case for shared subscriptions is load balancing.","","üëç (1)"
"812295088348200960","patanj2","2025-02-09T12:37:05.0560000+08:00","For a comparison look up examples on distributed task queues for RabbitMQ or even the  way on AWS you can scale out lambda functions paired with SQS.","","üëç (2)"
"1173270244291264535","andreasvogler","2025-02-12T19:53:20.6630000+08:00","I have read in the SpB 3.0 Spec that once a time they say ""it can send a Rebirth Request using the Node Control/**Refresh** metric..."" ... ""Refresh""? shouldn't that be ""Rebirth"". See screenshot.","https://cdn.discordapp.com/attachments/1166016853991235594/1339202681952276542/Screenshot_2025-02-12_at_12.50.30.png?ex=68df1070&is=68ddbef0&hm=bddccb714a8db456029227ff8af8dec9580f403cf3f88cf82e1e009a56c658da&",""
"794020366536146977","mparris","2025-02-13T10:47:19.8970000+08:00","Interesting! 

Post an issue here and become famous! 

https://github.com/eclipse-sparkplug/sparkplug/issues","","üòÑ (2)"
"867075936054149191","rickbullotta","2025-02-13T12:30:34.0880000+08:00","And in a couple years it might even get considered.","","üòÑ (3)"
"1173270244291264535","andreasvogler","2025-02-13T14:06:10.3200000+08:00","Someone else was faster then me üôÇ https://github.com/eclipse-sparkplug/sparkplug/pull/451","",""
"794020366536146977","mparris","2025-02-14T16:45:17.8650000+08:00","Awww...too bed!

Maybe the next bug will be for you! 

GitHub is such a great collaboration tool!","","üòÑ (2)"
"801561312861618236","jon.forbord","2025-02-25T04:11:50.0650000+08:00","It might be construed from two  features that are different in the Cirrus Link Modules. A rebirth request will resend the birth. A refresh, refreshes the birth certificate and sends it.","",""
"801561312861618236","jon.forbord","2025-02-25T04:24:02.1140000+08:00","I‚Äôm officially done with SpB. Or I‚Äôm technically done with buggy software. I still think it was a good idea, had a lot of potential,  but in the end was executed poorly. 

The main reason is that I‚Äôm done with buggy software and that adoption has basically come to a complete stop. Cirrus link and Canary seem utterly incapable of releasing software without major bugs, and v4 is nowhere to be seen?! 

I‚Äôm gonna roll back to the latest stable release of the modules from about a year ago, and start the transition to other tech. I‚Äôm done. It was a fun while it lasted. 

The final nail in the coffin for me was the last 3 releases that have introduced bugs causing major data losses and full system crash. There‚Äôs even one where the keepalive is intact, but no data is being updated. Noice!","","üò± (5),üò¢ (1),üí° (1)"
"812295088348200960","patanj2","2025-02-25T07:20:16.2370000+08:00","Switching outCanary also or just MQTTcollector?","",""
"891705751016452146","leightaylorf1","2025-02-25T14:30:06.1760000+08:00","Need to catch up with you, I would like to compare notes/issues.
I have had the opposite experience where latest modules seem to solve some of our underlying problems","",""
"801561312861618236","jon.forbord","2025-02-25T14:51:59.5140000+08:00","Sure thing. I‚Äôm gonna try to hop on the monthly euro call this Friday. 

One of fhem is UDT collisions. But that‚Äôs a nuisance more than anything. And I know you flatten the UDTs. The latest one started messing up the folders. Putting folders two/three/four levels deep at the top.","",""
"891705751016452146","leightaylorf1","2025-02-25T14:53:07.6260000+08:00","Yep been there too, see you Friday hopefully","",""
"867075936054149191","rickbullotta","2025-02-26T21:14:52.1160000+08:00","https://thehackernews.com/2024/12/ruijie-networks-cloud-platform-flaws.html?m=1","",""
"1339587425743274025","bramski78","2025-02-27T14:21:42.1850000+08:00","Can‚Äôt really put my finger on why we should use HiveMQ before EMQX, anyone? 
That was one of the main messages I remember from Poveit.","",""
"898217314741280828","hobbes1069","2025-02-27T21:17:01.3580000+08:00","My understanding is that HiveMQ has closed the performance gap and still has the best enterprise features of any broker.","","üëç (2)"
"1073312001788477471","sparkylarks","2025-02-27T21:21:51.7870000+08:00","And they gave me üß¶.
Very important.
Don't know what to do if I get EMQX or Cedalo socks","","üòÑ (3),üëç (1),üòÜ (1)"
"898217314741280828","hobbes1069","2025-02-27T21:22:18.3870000+08:00","My wife stole my HiveMQ socks but I still have the Lego guy.","","‚ùì (1),üòÜ (1)"
"898217314741280828","hobbes1069","2025-02-27T21:22:59.0130000+08:00","Maybe they didn't have a ton of those. I'll snap a pic later.","",""
"898217314741280828","hobbes1069","2025-02-27T21:44:24.8600000+08:00","","https://cdn.discordapp.com/attachments/1166016853991235594/1344666451868385310/IMG_0747.jpg?ex=68df2a78&is=68ddd8f8&hm=8089fbfb2663e78d3251ac765c4a57d84e2eab65b4f5650fda5b79171e8273cb&","üëç (5)"
"867075936054149191","rickbullotta","2025-02-27T22:09:34.0820000+08:00","Better extensibility, built in Java so source code is more easily comprehensible for security audits and extensions, and always the underlying cybersecurity concern using technology from a PRC based company in critical applications.","","üëç (1),üñï (1)"
"657361690379288596","du5tins","2025-02-28T06:30:12.4600000+08:00","I'm sad @Omar did not give me a HiveMQ lego person.","","ü§£ (3)"
"801561312861618236","jon.forbord","2025-02-28T16:57:59.1790000+08:00","For anyone living behind a rock, MQTT got its official album release last year. 

https://open.spotify.com/album/0W9vXdAMJi0v42fCqkiXsH?si=oebYnUJdQF6RwvzEGzANdQ","","ü§£ (1)"
"742752935947010118","busch1974","2025-02-28T20:37:18.8590000+08:00","I just started trialing the new Cirrus link mqtt New UNS Transmitter in Ignition. Trying to get my head arround best of practice use case.","",""
"1339587425743274025","bramski78","2025-02-28T22:05:43.1610000+08:00","Thx. Can you specify the enterprise features you refer to?","",""
"1003237589421137992","gregory.g.","2025-03-01T03:18:18.5650000+08:00","I think it's fantastic. Now SpB and flat mqtt are integrated. E.q. SpB for the industrial communications on-site and convertion/transmitting Flat mqtt for Enterprise UNS.","",""
"898217314741280828","hobbes1069","2025-03-01T11:01:57.1490000+08:00","You can check their website, but specifically you can centrally control security and it will federate out to all your brokers. Cedalo has a management interface but security is still per broker.","",""
"1215754490440056994","blabladudelioe","2025-03-01T14:03:26.0000000+08:00","Are you just frustrated with the SpB implementation or with the CirrusLink modules in general? 
Engine works quite well with plain JSON publish/subscribe, as far as I can tell.
Did you have a chance to test the HydraMQTT module?","",""
"801561312861618236","jon.forbord","2025-03-01T15:16:48.9460000+08:00","Cirrus link mqtt modules.","",""
"897154180001726494","koios6274","2025-03-03T22:00:34.7090000+08:00","Distributor? Transmitter? Engine?","",""
"230441548653789184","r.pop","2025-03-05T03:23:39.4070000+08:00","No one chooses EMQX because it's better, usually it's a cost conversation.

I think @RickBullotta covered it pretty well, Enterprise Features, Security, Scalability, and Interoperability are the reasons the majority of our customers choose HiveMQ","","üëç (1)"
"657361690379288596","du5tins","2025-03-05T07:58:07.5160000+08:00","I'm trying to get hooked in a bit better with HiveMQ's support and community. I have requested access to their slack channel a couple of times but I am getting the following when I click the link in the email. 

One of the questions I want to answer is can I load multiple licenses into a docker container of HiveMQ and how would I do that? They gave me a folder full of licenses but the docker container documentation doesn't show how to load those files.","https://cdn.discordapp.com/attachments/1166016853991235594/1346632836324524125/image.png?ex=68df118f&is=68ddc00f&hm=9d7573d1ccc752d22c54b8a41c6c43f565ae6ba16b0e68ca76521a5753399ade&",""
"794020366536146977","mparris","2025-03-05T16:42:18.9520000+08:00","Check out https://docs.hivemq.com/hivemq/latest/user-guide/docker.html#license

I recall having to generate this string and thinking it was a pain... Why not have the container use the license file the same way it was delivered to me? 

This is an except from an email I had with them: 


For the environment variable the HIVEMQ_LICENSE can be used for the core broker license that will be applied to the node in the cluster. 
As HiveMQ has licenses for each of the extensions, so you can use an environment variable for each of the extensions like HIVEMQ_SECURITY_EXT_LICENSE, HIVEMQ_BRIDGE_EXT_LICENSE.","","üëç (1)"
"657361690379288596","du5tins","2025-03-05T19:28:17.4420000+08:00","Thanks Matthew. 

I did find a workaround. I ended up creating a volume, attaching it at /opt/hivemq/license and uploading the license files to the volume. Seems to be working well.","",""
"448323303598325812",".killnine","2025-03-05T22:29:44.8670000+08:00","> Why not have the container use the license file the same way it was delivered to me? 
I think it largely comes down to the way most containers are deployed. Your 'secrets' (license in this case) are typically stored in a secure keystore (Azure Key Vault, Kubernetes Secrets, etc.) and injected just-in-time as an environment variable. Files are a little trickier to work with directly in that regard.

I might flip the request and say, rather than giving you a file at all, why not have them give you base64 encoded string to begin with üòõ","",""
"448323303598325812",".killnine","2025-03-05T22:31:06.3460000+08:00","Because if you map a volume to a file on a filesystem, then I'd make the argument you have a secret sitting unencrypted at rest on your machine, which is a security risk.","",""
"794020366536146977","mparris","2025-03-05T22:39:44.8060000+08:00","""why not have them give you base64 encoded string to begin with""

Exactly my point!  Any reason this couldn't be the content of the file anyway?","","üëç (1)"
"657361690379288596","du5tins","2025-03-05T23:43:46.4570000+08:00","And make it possible to ""import"" the string thru the management interface directly instead of resorting to strange interventions? Still boggles my mind that there is no mechanism in many OT systems to directly import a license thru the main management interface.","","üëç (1)"
"897154180001726494","koios6274","2025-03-06T00:28:16.1340000+08:00","If only developers would follow Occams's Razor and think about the end user. So many things are unnecessarily complicated","","üíØ (2)"
"657361690379288596","du5tins","2025-03-06T00:48:25.8250000+08:00","Although in this case I'm sure the simplest solution from the dev side was probably to read up a license file! HA! Building UI and secure storage for it is a lot more work.","",""
"438077014092808201","robin_pinna","2025-03-07T02:16:46.2840000+08:00","Hi ! I'm currently building a new UNS test bench from scratch, and I was wondering if someone already tried to use a NATS broker as their communication backbone. Since they support MQTT along their own protocol I would like to try and test using both pub/sub and request/response topic, so if anyone did something like that, any tips and hints are greatly appreciated","",""
"867075936054149191","rickbullotta","2025-03-07T06:50:58.0320000+08:00","Litmus does.","",""
"438077014092808201","robin_pinna","2025-03-07T13:41:35.5280000+08:00","Thank you Rick, I will go through their documentation then","",""
"783917475128410112","geoffnunan","2025-03-08T13:04:08.5400000+08:00","Rhize were using NATS although our latest version has moved off it","",""
"438077014092808201","robin_pinna","2025-03-08T20:42:12.2690000+08:00","I'm curious to know what made you not use it anymore.
Did you find something better fitting your use case or did you find some flaw that made you look for something else ?","",""
"794020366536146977","mparris","2025-03-08T23:48:23.5120000+08:00","I'm guessing they moved to point-to-point connections within their own software instances to eliminate needing a broker in their stack, which makes sense if the number of software nodes in a Rhize deplooyment isn't very large like IoT fleet deployments are.","",""
"783917475128410112","geoffnunan","2025-03-09T04:27:33.3290000+08:00","Rhize is distributed, horizontally scalable and high-availability. We were using NATS as both a message broker and a distributed cache using the NATS kv abstractions. All of that worked well, but required a significant amount of complexity in our code. We moved to Restate.dev","",""
"867075936054149191","rickbullotta","2025-03-09T05:49:43.7730000+08:00","Are you no longer exposing an MQTT endpoint?","",""
"783917475128410112","geoffnunan","2025-03-09T08:53:14.1650000+08:00","We now white-label Solace if customers want Rhize to be their broker, or we connect to the customer's existing broker if they have another preference","","üëçüèº (1)"
"438077014092808201","robin_pinna","2025-03-09T21:23:30.7410000+08:00","Thanks for the info.  I'm not really knowledgeable in the management of microservice infrastructure but I understand better why you moved out of it.

The use case I had in mind was more oriented to my edge device, I would like to try and see if I can configure them through the UNS. For example, I use the req/response to push a new configuration to my device, while the data is still published in pub/sub mode.
It would allow for a better serviceability of the devices of the namespace","",""
"783917475128410112","geoffnunan","2025-03-10T04:11:48.3540000+08:00","That's definitely possible with NATS","","üëç (1)"
"795178288330440704","youri.regnaud","2025-03-12T02:50:03.5360000+08:00","Does anyone know of any solutions or methods for abstracting the broker's MQTT topics and exposing a type of MQTT gateway that can map between one topic (the producer's) and those of consumers. For example, if I subscribe to topic 3, the gateway translates it as a subscription to two topics, the topic 2 and the topic 1. Global idea is to decoupled publisher topic namespace with consumer topic namespace","",""
"898217314741280828","hobbes1069","2025-03-12T10:16:14.3780000+08:00","Definitely need more details... To me it kind of sounds (not exact but an example) like taking a SparkplugB payload and unpacking it into smaller topics/payloads. The nice thing about SpB is you get a UDT and then only changes. But you're still getting everything and you may only be interested in a few parts of the payload.","","üëç (1)"
"783917475128410112","geoffnunan","2025-03-12T14:15:25.6700000+08:00","This really does sound like a good approach, and I have not seen a solution for this. 
How would thid be different to what you might do with highbyte?","",""
"795178288330440704","youri.regnaud","2025-03-12T14:21:13.1940000+08:00","With Highbyte, I can subscribe to  topic and publish data in other topic, yes. My point is more to have flexibility at consumer level, a kind of BFF, API gateway for MQTT","",""
"795178288330440704","youri.regnaud","2025-03-12T14:22:53.8120000+08:00","A kind of GraphQL resolver but only for subscription and MQTT data source. But maybe GraphQL can already do that?","",""
"783917475128410112","geoffnunan","2025-03-12T14:26:04.2350000+08:00","It might be able to.
Are you thinking that an engineer would configure the models that would map the topics? In you example, is there a configuration that says topic 3 = topic 1 and topic 2, or is it more dynamic that than, where the subscriber to topic 3 can ask for topic 1 and topic 2 to be returned ?","",""
"783917475128410112","geoffnunan","2025-03-12T14:28:48.1100000+08:00","We can write GraphQL subscription resolvers that create subscriptions to MQTT topics, so it would be simple to prototype something","",""
"239257759185371136",".discrete","2025-03-12T22:04:32.9630000+08:00","What's the benefit of this over application config on the consumer side? Reuse of the consumer-structured topics?","",""
"877337143742197810","karltbraun","2025-03-12T22:28:08.9030000+08:00","I'm not clear on this - how is this different from using wildcards in the subscription topic?  Maybe I'm just not getting the question.","",""
"783917475128410112","geoffnunan","2025-03-13T03:47:12.5010000+08:00","It is not limited like wild cards. It's a flexible query model for mqtt.","",""
"783917475128410112","geoffnunan","2025-03-13T03:48:30.0020000+08:00","It means the Topic structure does not have to be designed to suit how you might want to query it","","üëç (1)"
"897154180001726494","koios6274","2025-03-13T04:01:57.9600000+08:00","specifc to highbyte this is what their SmartQuery of namepaces does. ie: if I want to consume all ""motors"" I don't care where they are in the topic tree I just care about the type of data there is","","highbyte (2),üôè (1)"
"1214242167640424619","zack.scriven","2025-03-14T12:38:46.7660000+08:00","Great article from Portainer.io on MQTT Brokers comparing HiveMQ, EMQ-X and Cedalo (Mosquitto Pro) https://www.portainer.io/blog/mqtt-at-the-edge-which-do-you-choose","","üî• (2),üëç (2)"
"448323303598325812",".killnine","2025-03-15T00:20:31.2970000+08:00","We got any HiveMQ (Edge) homies up in here?","",""
"448323303598325812",".killnine","2025-03-15T00:20:52.0660000+08:00","I found a very cool bug that nukes your protocol adapter if you do a very normal, ordinary thing","",""
"448323303598325812",".killnine","2025-03-15T00:55:47.7360000+08:00","@HiveMQ Community boop.","",""
"867075936054149191","rickbullotta","2025-03-15T21:38:36.2730000+08:00","I've been asking the MQTT committee for this for a couple years - something akin to symlinks","",""
"867075936054149191","rickbullotta","2025-03-15T21:39:21.1840000+08:00","It would be dynamic and not require manual configuration when new devices or data are added","",""
"795178288330440704","youri.regnaud","2025-03-16T18:05:15.2720000+08:00","Consumers want to consume differents topics in one subscription, not in the same topic hierarchy root","",""
"877337143742197810","karltbraun","2025-03-16T23:04:51.1170000+08:00","So: something that let's you subscribe to a bunch of different topics without long lists or excessively complicated regex-type wildcard expressions?","",""
"867075936054149191","rickbullotta","2025-03-16T23:17:54.2580000+08:00","Another thing I've asked the MQTT committee to add - more capable query expressions for subscriptions.  But that needs to start with a foundational capability to query topics. Also a must.  Since the MQTT committee is not going to do shit, vendors need to build around MQTT.   Ideally in a standardized or consistent way.","","ü§î (1)"
"867075936054149191","rickbullotta","2025-03-16T23:19:59.6960000+08:00","Imagine being able to use metadata in the query/subscription expressions: ""Subscribe me to the excessive vibration topic on all model 65 or model 67  pumps located in Western Australia"".","","üëç (1)"
"867075936054149191","rickbullotta","2025-03-16T23:20:58.8830000+08:00","Reposting my MQTT wish list (which is 2-3 years old by now)

Core MQTT issues:

- Decision to use 4 bits for message type. Short sighted and now a major limitation
- Multi-publish is essential (publish more than one topic in a single message)
- Topics should have durable metadata (could be passed as headers in publish or as its own message type)
- Payloads should have a data type (mime type) to enable parsing/processing by subscribers or intermediaries
- Topic binding should be a built-in broker feature (like a symlink) - topic aliases are not this
- The lack of a capability to query topics is a huge flaw/gap. Ideally these queries should be able to include metadata filters as well
- MQTT's subscription patterns are hopeless limiting. They should support richer match expressions and also metadata filters
- MQTT should officially support a REST binding for request/response query/publish/read/subscribe/unsubscribe
- Handling of large payloads (e.g. file uploads, video content, firmware/software updates, method responses) needs a lot of work to improve reliability
- Handling of RPC/method invocations remains an awful hack. This MUST be addressed.
- Multiple priorities for ""channels""","",""
"867075936054149191","rickbullotta","2025-03-16T23:21:56.0450000+08:00","And while we're at it, my Sparkplug list, which is equally dated:

Core Sparkplug issues:

- The rigid Node/Device format does not fit real world models. Do away with one of them and allow more flexible topic hiearchies.
- The handling of *BIRTH messages and the intermingling of data and metadata in them is a poor design
- The process for requesting *BIRTH messages is terribly inefficient. Metadata should be retained, not requested each time by each client.
- There should be *METADATA messages to deal with metadata
- The opaque/multi-value nature of *DATA messages makes it impossible for client(s) to subscribe to individual metrics. Huge issue.
- The ""primary client"" stuff is unnecessary and should be removed
- Any device commands/methods should be fully declared (inputs and outputs fully typed)
- Naming of metrics/commands needs to be locked down to a more restricted character set
- Add a few more top level data types (Location, BLOB (w/mime type), 
- Support other encodings besides Protobuf (e.g. plain JSON, zipped JSON, BSON, etc.)
- Millisecond resolution for timestamps is inadequate for modern systems where accurate event sequence is critical (e.g. power grid)","","üëå (2)"
"867075936054149191","rickbullotta","2025-03-16T23:22:39.4920000+08:00","Just a friendly reminder of how glacially slow ""standards"" move.  Better to have a community of vendors (and users) agree on something and move forward than to wait for these folks to get off their collective asses.","","üëç (3)"
"794020366536146977","mparris","2025-03-17T09:52:43.7380000+08:00","I'm very much looking forward to seeing this get accomplished this year","",""
"1212245669558100021","tyler092335","2025-03-17T12:13:06.8020000+08:00","Great article, my question though is what is considered the edge? Maybe it‚Äôs just my personal confusion but edge seems to mean something different based off where in the automation stack someone ‚Äúsits‚Äù at. For example, the people I‚Äôve interacted with that are at the cloud stack say that the DMZ is the edge. Then people that are at the DMZ say the plc is the edge. Then plc people say the sensors are the edge. ü§∑‚Äç‚ôÇÔ∏è maybe someone can shed some light on this for me.","",""
"794020366536146977","mparris","2025-03-17T19:12:27.1570000+08:00","Regarding ""edge"", I like to ask the person using ""edge"" to answer ""the edge of what?"" 

Edge of cliff?
Edge of country? 
Edge of solar system?

And, you are right, the definitions are different depending on WHAT has the edge.","",""
"1212245669558100021","tyler092335","2025-03-17T20:37:04.5660000+08:00","@MParris I‚Äôm glad I am not the only one who has to ask the question of ‚Äúedge of what?‚Äù Ha. I get that it‚Äôs probably needs to be a more generic term to fit many industries and groups. It just gets tying some when miscommunication happens just from that term alone. Since the post is from portainer I would assume he ment at the DMZ level to soak up all the process plat floor data.","",""
"867075936054149191","rickbullotta","2025-03-17T21:50:29.1870000+08:00","Not gonna happen.  I've seen no progress of any substance.","",""
"877337143742197810","karltbraun","2025-03-17T22:21:31.0220000+08:00","IMO 'edge' is not only relative, as described above, but evolves.  As sensors get more capabilities, the edge moves further away from the top of the stack.  Certain smart plugs can send data via MQTT (making that the edge) whereas in the past you had to have a microprocessor interpreting analog data, packaging it up in MQTT (or some other messaging) making the edge one step further 'up' the stack.","",""
"1212245669558100021","tyler092335","2025-03-17T22:45:57.9330000+08:00","That‚Äôs very true, the industry is moving crazy fast right now. It‚Äôs really exciting to see and learn. It‚Äôs almost like the technology is moving faster than what people can define. That probably why terms like edge are needing to be flexible. I bet in the next 5 years new terms will come to light that describe where and what edge means but for now it‚Äôs just moving too fast to keep up.","",""
"657361690379288596","du5tins","2025-03-18T09:31:28.7810000+08:00","Release a competing message format instead? Is MQTT not open enough that it cannot be done? No need to wait for a standards body to make the changes. üòú","",""
"867075936054149191","rickbullotta","2025-03-18T20:18:39.7900000+08:00","The message format isn't really the issue - it's the junk around it for how metadata is handled, state is handled, commands are handled, etc...","",""
"277515221885779970","jermuk","2025-03-19T19:57:28.7900000+08:00","we at UMH are calling it data contracts, see also: https://learn.umh.app/course/what-is-mqtt-why-most-mqtt-explanations-suck-and-our-attempt-to-fix-them/","",""
"712090571556126871","bunchofbytes","2025-03-19T20:22:23.9800000+08:00","Does anyone have experience integrating MS Teams with MQTT and power automate? 

I‚Äôm looking to use a workflow trigger via an MQTT topic change. I‚Äôve seen the feature in power automate to create custom connectors but would be curious if anyone has any past experience with this.","",""
"867075936054149191","rickbullotta","2025-03-19T20:46:17.8010000+08:00","I think you can trigger Power Automate from Event Grid, and event grid now supports an embedded MQTT broker","",""
"867075936054149191","rickbullotta","2025-03-19T20:47:14.4040000+08:00","https://learn.microsoft.com/en-us/azure/event-grid/mqtt-publish-and-subscribe-portal","","üëç (1)"
"712090571556126871","bunchofbytes","2025-03-19T20:58:42.5010000+08:00","Thank You!","","üëçüèº (1)"
"898217314741280828","hobbes1069","2025-03-19T23:29:12.6270000+08:00","It probably wouldn‚Äôt be worth buying it just for this, but if you already have Highbyte in your architecture this would be pretty trivial. Working on a Tulip <-> MS Teams integration and the hardest part is getting IT to give me the correct credentials.","",""
"712090571556126871","bunchofbytes","2025-03-19T23:35:54.9320000+08:00","Interesting! My organization actually has highbyte. Would you be open to sharing the methodology?","",""
"697343364542103653","portainer.io","2025-03-20T05:19:13.0160000+08:00","Is it OK for me to share this here?

I tried to capture the differences between the MQTT brokers out there, and which to use when.

https://www.portainer.io/blog/mqtt-at-the-edge-which-do-you-choose

happy for comments/corrections/critique..

also, im surprised something like this didnt already exist.","","üëå (1),üëç (2),üî• (4)"
"817835202746253344","IIoT#4707","2025-03-20T05:19:13.4070000+08:00","GG @portainer.io, you just advanced to level 3!","",""
"1088631859509989426","jpmac.s","2025-03-20T06:01:13.3710000+08:00","You couldn't have timed this any better!!! Cheers","","üëç (1)"
"898217314741280828","hobbes1069","2025-03-20T08:54:47.4850000+08:00","At the end of the day, Teams or otherwise are part of the M365 graph API. Listen to the appropriate topic on your MQTT broker and then perform the required REST API call to the graph API. Can't be more specific without more details, but I'm in development now so may not have much more than that at this point.","",""
"712090571556126871","bunchofbytes","2025-03-20T09:05:14.6200000+08:00","Thank you for the response, I think this makes sense. Correct me if I‚Äôm mistaken but it seems like: MQTT client listens, sees topic change, hits http endpoint via power automate custom connector, power automate leverages the graph api to make the remainder happen with teams?","",""
"898217314741280828","hobbes1069","2025-03-20T09:05:35.1220000+08:00","At a high level, yes.","",""
"712090571556126871","bunchofbytes","2025-03-20T09:06:01.1280000+08:00","Thanks!","",""
"1052622839431307274","marco_moiron","2025-03-22T03:21:30.5720000+08:00","@Gregory G. , I‚Äôve also been experimenting with the UNS Transmitter in Ignition, trying to transmit a subset of our tags from our Ignition Edge instance to our Cloud Ignition instance. Unfortunately, I‚Äôve encountered a few issues.

For starters, the first topic level from the UNS Transmitter is unsAv1.0, and the ‚Äú.‚Äù is not accepted by the UNS engine. We worked around this by modifying the default base topic configuration using scripting on the UNS Transmitter side.

Additionally, on Ignition Cloud, the MQTT Engine couldn‚Äôt parse the payload into variables, so we had to configure it to treat the payload as JSON and use scripting to convert those payloads into tags. We‚Äôre not sure why it didn‚Äôt work as expected. Shouldn‚Äôt the UNS Transmitter work seamlessly with the MQTT Engine? If not, who is the intended recipient of those messages? The documentation covers this briefly and in some details that are not very clear.

Were you able to successfully connect two Ignition instances using the UNS Transmitter?","",""
"657361690379288596","du5tins","2025-03-22T23:17:45.2280000+08:00","I only started messing with the UNS transmitter last week. I think it would be geared for getting the data into a cloud service as opposed to another Ignition system. But really just getting going with it and guessing. @Arlen Nipper ?","","üëç (1)"
"1052622839431307274","marco_moiron","2025-03-23T00:39:32.7100000+08:00","Thanks for sharing. I assumed it‚Äôd serve the same purpose the SpB based transmitter.","",""
"839874991355985981","ralf05700","2025-03-27T23:50:36.6410000+08:00","Tech question. I have 2 EMQX brokers that are bridged. I want the local broker to send  buffered data after a disconnection to the cloud broker but I want to limit the amount of data/s as not to overload the system consuming from the cloud broker.","",""
"830193224504705035","marc.jaeckle","2025-04-17T04:03:34.8760000+08:00","Can you maybe use the regular rate limiting features of EMQX by creating a separate TCP listener for the bridge and use the corresponding port when you create the bridge configuration? Of course this would then be valid for the bridge in general. https://docs.emqx.com/en/emqx/latest/configuration/limiter.html

Just guessing here. In HiveMQ you can configure this directly in the bridge configuration.","","üëç (1)"
"794020366536146977","mparris","2025-04-17T23:40:53.4700000+08:00","Interesting idea...

But this also assumes that the broker is in fact buffering... I assume a QoS subscription would need to be setup? 

Ignoring hardware constraints, Any limitations within MQTT itself of the number of inflight messages that can be held in the buffet?","",""
"867075936054149191","rickbullotta","2025-04-17T23:55:35.0450000+08:00","That would be broker and broker configuration specific (and of course hardware - memory, storage, etc).   I had situations where messages were lost (QoS 0) due to rate limiting, so I wouldn't count on that being a reliable store-and-forward mechanism.","",""
"794020366536146977","mparris","2025-04-17T23:56:51.5990000+08:00","This is my fear... That the rate limitation could be solved for a bridge but the buffer still must be defined","",""
"867075936054149191","rickbullotta","2025-04-18T19:58:02.0220000+08:00","Yup. Either the broker or the Node.js MQTT client seemed to just toss them away.","",""
"839874991355985981","ralf05700","2025-04-19T01:48:06.6260000+08:00","I think we solved the problem by setting inflight_window = 1 and worker_pool_size = 1","",""
"1195361146564263967","william_vanbus","2025-04-19T03:04:09.1510000+08:00","anyone use Arduino's MQTT / Arduino Cloud? Working on a demo with this, but seems I'm limited to using their proprietary broker (Can't publish to any broker like HiveMQ via an open source client like Paho). seems I have to use a webhook to route data from Arduino Cloud to other sources. Poking around today... looking for a better option.","",""
"867075936054149191","rickbullotta","2025-04-19T07:09:07.1810000+08:00","Arduino's MQTT libraries utterly suck if you need TLS over Wifi.  Suck is being generous. Arduino needs to take connectivity for more seriously and create libraries that ""just work"".  My advice?  Don't use an Arduino - use a Raspberry Pi, with a real operating system and a real runtime.","","ü´° (1)"
"1195361146564263967","william_vanbus","2025-04-22T20:36:38.8240000+08:00","RisingWave (Streaming database) had a decent overview of MQTT; curious if anyone thinks it will help with storing historical data from the mqtt broker (https://www.linkedin.com/posts/risingwave_the-evolution-of-mqtt-activity-7311065185463549953-LcCE?utm_source=share&utm_medium=member_desktop&rcm=ACoAAA4DiOkBOkB2kmVImiKE-tCTzmFWaRYoNpY)","",""
"867075936054149191","rickbullotta","2025-04-22T20:50:09.2870000+08:00","""The Future Of MQTT"" - literally LOL.  From a progress forward POV, MQTT has gone to the nursing home to die (Oasis Open).","","üòÇ (3)"
"1195361146564263967","william_vanbus","2025-04-22T22:50:05.3710000+08:00","This thing? https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html

so no MQTT v6 anytime soon? üòâüòâ

Would Apache foundation be any different?","",""
"867075936054149191","rickbullotta","2025-04-22T23:19:02.8350000+08:00","They're working on MQTT SN, which no one needed.","","üò¢ (1)"
"1195361146564263967","william_vanbus","2025-04-25T01:03:02.7570000+08:00","so, @Walker Reynolds (And others) , after the MQTT linkedin post (loved it btw), you got me curious. Hypothetically, MQTT v6 gets announced tomorrow; what would you love to see in it? (Curious on top features people are looking for out of MQTT in the future)","",""
"867075936054149191","rickbullotta","2025-04-25T02:13:51.3410000+08:00","- Decision to use 4 bits for message type. Short sighted and now a major limitation
- Multi-publish is essential (publish more than one topic in a single message)
- Topics should have durable metadata (could be passed as headers in publish or as its own message type)
- Payloads should have a data type (mime type) to enable parsing/processing by subscribers or intermediaries
- Topic binding should be a built-in broker feature (like a symlink) - topic aliases are not this
- The lack of a capability to query topics is a huge flaw/gap. Ideally these queries should be able to include metadata filters as well
- MQTT's subscription patterns are hopeless limiting. They should support richer match expressions and also metadata filters
- MQTT should officially support a REST binding for request/response query/publish/read/subscribe/unsubscribe
- Handling of large payloads (e.g. file uploads, video content, firmware/software updates, method responses) needs a lot of work to improve reliability
- Handling of RPC/method invocations remains an awful hack. This MUST be addressed.
- Multiple priorities for ""channels""","","üëç (1),üëè (1),üíØ (1)"
"867075936054149191","rickbullotta","2025-04-25T02:14:25.1250000+08:00","And for sparkplug:

- The rigid Node/Device format does not fit real world models. Do away with one of them and allow more flexible topic hierarchies.
- The handling of *BIRTH messages and the intermingling of data and metadata in them is a poor design
- The process for requesting *BIRTH messages is terribly inefficient. Metadata should be retained, not requested each time by each client.
- There should be *METADATA messages to deal with metadata
- The opaque/multi-value nature of *DATA messages makes it impossible for client(s) to subscribe to individual metrics. Huge issue.
- The ""primary client"" stuff is unnecessary and should be removed
- Any device commands/methods should be fully declared (inputs and outputs fully typed)
- Naming of metrics/commands needs to be locked down to a more restricted character set
- Add a few more top level data types (Location, BLOB (w/mime type), 
- Support other encodings besides Protobuf (e.g. plain JSON, zipped JSON, BSON, etc.)
- Millisecond resolution for timestamps is inadequate for modern systems where accurate event sequence is critical (e.g. power grid)","","üëç (1),üëè (1)"
"742752935947010118","busch1974","2025-04-25T21:17:48.7440000+08:00","For folks that are Microsoft shops we can now publish to a mqtt topic data source connected to Microsoft Fabric via Real Time Event Hub.    Basically, you can Transform live data with Microsoft Fabric from Ingestion to Visualization. Transforming Live Data with Microsoft Fabric From Ingestion to Visualization","",""
"742752935947010118","busch1974","2025-04-25T21:18:11.0920000+08:00","https://learn.microsoft.com/en-us/fabric/real-time-hub/add-source-mqtt","",""
"742752935947010118","busch1974","2025-04-25T21:18:44.2920000+08:00","https://youtu.be/pEI7FbsFIn4","",""
"686612416196640790","dezemand","2025-04-30T04:28:41.6100000+08:00","This has been on my mind a lot quite recently. We're struggling to find a right topic structure in our organisation as there's many different ways of doing this and sadly we lack the authority to decide (politics ü•≤ ), so rather than a hierarchical structure, querying would be much nicer. It really feels like there should be a much better way of doing this, especially when talking about having more than just a few brokers in place in the organisation. I'm thinking of functionality like what HiveMQ Pulse offers, but it would be much better if this was included in the protocol. Then it would be possible to use things like framing (like HTTP/2) for more data-intensive applications, and possibly exposing an MQTT v3/5 compatibility layer for more lightweight clients and devices.","",""
"686612416196640790","dezemand","2025-04-30T04:33:55.0640000+08:00","The MTRs would still apply for the clients","",""
"686612416196640790","dezemand","2025-04-30T04:36:30.4710000+08:00","Anyone here working on things like this or willing to work on it?","",""
"867075936054149191","rickbullotta","2025-04-30T20:33:03.4790000+08:00","I've prototyped some stuff but no plans to commercialize it or pursue it further - it was mostly a thought experiment and a way to communicate my ideas to others.  I'm counting on companies like HighByte, Litmus, HiveMQ, TwinThread and others to make it happen.  I gave up on PTC doing it.","",""
"867075936054149191","rickbullotta","2025-04-30T20:43:32.0500000+08:00","I'll help you feed yourself into a wood chipper. ü©∏","","üòÇ (1)"
"742752935947010118","busch1974","2025-05-01T21:13:54.7580000+08:00","The initial testing of MQTT MicroSoft Fabric MQTT data source (in preview) appears to be working well for Real-Time hub to both  KQL and Fabric Lake If anyone is interested in the Microsoft stack.","","üëè (1)"
"873009180938743828","sim_sam3","2025-05-02T22:14:38.5760000+08:00","Admittedly I could dig more, but anyone know of a good free Mqtt client utility that also supports sparkplugb? I‚Äôm told that unf Mqtt.fx has security vulnerabilities that will not be patched, and I‚Äôm getting corporate pushback on use","",""
"898217314741280828","hobbes1069","2025-05-02T22:27:12.7750000+08:00","Still need better options there unfortunately. MQTT Explorer has an unreleased version that supports it. Some people have built it from source to obtain that feature.

There‚Äôs a new app mentioned on the discord somewhere but it‚Äôs still very new.","","üëç (1)"
"873009180938743828","sim_sam3","2025-05-02T22:29:09.3520000+08:00","Thanks Richard! üôè

I‚Äôm poking around with untangling protobufs (for SPB) in JS without external libs üôÉ and wanted easy source data. I may just have to use Node-RED SPB publisher nodes.","",""
"354587225859686411","mikethecore8690","2025-05-02T23:40:15.0740000+08:00","may be able to just roll with the Eclipse Foundation project... https://github.com/eclipse-tahu/tahu","","üëç (1),üôè (2)"
"766684226455207996","bright_hummingbird_31342","2025-05-05T12:41:17.5440000+08:00","HighByte. The UNS client automatically decodes protobuf. One can view JSON and SpB payloads side-by-side. This feature can be used unlicensed.

It's also browser-based. A team can view the contents of a broker without necessarily having a direct connection to it. Exposing access the message brokers (and other backend systems) to networks with user PCs can be non-trivial in some orgs. IH can be added to an internal catalog of web apps and users can use their SSO identity to access it. This reduces the complexity of providing access as well as distributing credentials and endpoint info.","","üêò (2),üî´ (2),ü™∞ (2)"
"1073312001788477471","sparkylarks","2025-05-05T17:34:24.9330000+08:00","Is there a material difference between MQTT.Fx and MQTT Explorer from a vulnerabilities Point of view.??? 
you could reach out to Jens Deters and ask him 


https://www.hivemq.com/blog/mqtt-toolbox-mqtt-fx/

https://github.com/vogler75/sparkplugb-printer by the excellent @Andreas Vogler 

and  https://github.com/Ambre-io/sparkplugui , which seams to work well, but is hard to look at.

I use MQTT.fx normally","","‚ù§Ô∏è (1)"
"1073312001788477471","sparkylarks","2025-05-05T20:05:57.6100000+08:00","I reached out and got this reply","https://cdn.discordapp.com/attachments/1166016853991235594/1368921662002561024/image.png?ex=68df1365&is=68ddc1e5&hm=4575940e354babbb31c6043f4230de0584758a86a552558f4acb675e87da160c&",""
"873009180938743828","sim_sam3","2025-05-06T00:57:56.1660000+08:00","Thank you Mark! Yes I‚Äôm told it‚Äôs an issue with SoftBlade‚Äôs lack of maintenance as we were forced out of license contract with them when it came up for renewal in 2024. That‚Äôs about all I know - I will poke our internal buyer to see if I can find more specifics.","",""
"873009180938743828","sim_sam3","2025-05-06T00:59:41.7830000+08:00","Wow thank you so much. Is there a way to obtain the UNS client outside of IH container?","",""
"766684226455207996","bright_hummingbird_31342","2025-05-06T01:38:46.4050000+08:00","It's packed together, but it's pretty lightweight. The whole thing can be downloaded and installed quickly. It can be deployed as a container or without. It's an easy a setting up an MQTT connection and navigating to the UNS Client. The other functionality (e.g., models, pipelines) can be ignored.

Here's a video of Skellig playing around with it:
https://youtu.be/ox2NTFl_0_M?si=OBZAwDGWUhWe3C2V&t=1340","","‚ù§Ô∏è (1),üëç (2),üôè (1)"
"1031940518730543106","thunt.career","2025-05-08T06:44:20.8680000+08:00","Does anyone have any good reference material for planning the topic hierarchy? I'm primarily interested in deciding around additional properties to include in the topic hierarchy such as /ent/site/line/area/work order/{status=started,stopped,completed,scheduled}","",""
"794020366536146977","mparris","2025-05-14T11:47:24.7840000+08:00","Well @everyone‚Ä¶. EMQx looks to be going the way of NATS license-wise‚Ä¶. Changing from Apache to BSL starting with version 5.9.0

Permissive use will allow a user to run ONE emqx broker in production for free, as long as it‚Äôs not being commercially resold/embedded in commercial products. Multi-node clusters and all nodes after the ONE will require a license. 

https://www.emqx.com/en/content/license-faq","",""
"693309801589112862","_dyland","2025-05-14T13:45:08.8930000+08:00","If it goes the way of NATs they will reverse this decision and remain open source. Though that seems unlikely here...

https://www.cncf.io/announcements/2025/05/01/cncf-and-synadia-align-on-securing-the-future-of-the-nats-io-project/","",""
"1031940518730543106","thunt.career","2025-05-14T19:17:32.8290000+08:00","~~Redis~~ ~~NATS~~ EMQX ...","","üòÇ (1)"
"794020366536146977","mparris","2025-05-14T19:29:24.3990000+08:00","Have you seen any articles from Synadia on why they reversed course?","",""
"693309801589112862","_dyland","2025-05-14T19:41:25.1930000+08:00","Nothing official but I would assume the personal death threats to the CEO played a part.","",""
"693309801589112862","_dyland","2025-05-14T19:54:29.7310000+08:00","My speculation is that from the NATs side it was all about the Brand and the trademarks. But in trying to retain the brand they destroyed it... They must have felt that the only way to salvage it was to reverse course and use a different brand for their commercial version. I would be surprised if they don't fork it quietly after a cooling period. 

But I still maintain that CNCF had more to lose here than Synadia did...","",""
"693309801589112862","_dyland","2025-05-14T19:55:39.4590000+08:00","Ironically, NATs maintains a fork of Benthos...","",""
"867075936054149191","rickbullotta","2025-05-14T20:04:27.1020000+08:00","I think what gets confusing here is licensing vs pricing - two different things.","","üíØ (1)"
"867075936054149191","rickbullotta","2025-05-14T20:04:47.7900000+08:00","So you're saying that this is an effective mechanism for change?","","üò• (1)"
"794020366536146977","mparris","2025-05-14T20:08:42.3160000+08:00","Yeah...they not be handing out licenses for free...","https://cdn.discordapp.com/attachments/1166016853991235594/1372183843645427732/image.png?ex=68df140a&is=68ddc28a&hm=af056e97efc273e9cb8d88a2ba0d960e18931d1919bfea89848355c824221020&",""
"867075936054149191","rickbullotta","2025-05-14T20:30:19.6590000+08:00","Did you see that the new(ish) United Health CEO stepped down?  I wonder if the same factor is at work there.","",""
"693309801589112862","_dyland","2025-05-14T20:33:41.0480000+08:00","Probably. It's a pretty big issue right now in a lot of things. Even Magic the Gathering had some issues where a volunteer group had to step down because the ""Fans"" sent them death threats... It's getting scary out there.","",""
"1073632885153730621","vaughnturner","2025-05-14T23:07:51.7840000+08:00","Yes, I saw that. He's getting out for ""undisclosed personal reasons"" ü§î","",""
"753688565807841492","ravil1","2025-05-15T06:03:32.0620000+08:00","If not perpertual, then it is not a real license, just trial.","",""
"794020366536146977","mparris","2025-05-15T06:28:33.9320000+08:00","I agree with your sentiment about the trial, but what about subscriptions? Are those considered licenses or trials?","",""
"753688565807841492","ravil1","2025-05-15T06:33:14.9950000+08:00","Then it is a license with a condition attached: will be suspened if certain amount payment is not done in time üôÇ","",""
"794020366536146977","mparris","2025-05-19T00:28:39.0580000+08:00","@RickBullotta did you know Cedalo includes this?

""The Sparkplug Decode plugin automatically decodes all Sparkplug messages arriving on topics matching spBv1.0/#, decodes them into JSON and republishes them to spJv1.0/#. broker to be usable for Sparkplug.""

https://docs.cedalo.com/mosquitto/advanced-features/sparkplug/sparkplug-decode/","",""
"794020366536146977","mparris","2025-05-19T00:29:36.0030000+08:00","A nice feature...until Sparkplug comes out with their own ""spJv1.0"" definition... but we should have some time üòâ","",""
"697343364542103653","portainer.io","2025-05-19T05:33:40.1980000+08:00","anyone used https://nanomq.io/ much? looks quite interesting..","",""
"693309801589112862","_dyland","2025-05-19T09:19:11.2660000+08:00","No but I'm curious to check it out based on a cursory glance of the website.","",""
"867075936054149191","rickbullotta","2025-05-19T19:55:57.2010000+08:00","Or just don't use Sparkplug in the first place.  Problem solved.  Maybe if it ever gets fixed.  Not holding my breath.  I was, and I turned Smurf blue.  Gave up.","",""
"721948711126827009","jaylinyu","2025-05-20T08:25:41.3260000+08:00","I am the maintainer of this project. Feel free to fire any question to me.","","üî• (1)"
"794020366536146977","mparris","2025-05-20T17:17:29.8210000+08:00","This statement from emqx:
""For Our Community Users: This is a major upgrade! You now gain access to the full suite of EMQX features, including previously Enterprise-exclusive capabilities like advanced data integration (50+ connectors), enhanced security (SSO, RBAC), the visual Flow Designer, and more, directly within the core platform. ""

Actually, all I care about is an MQTT broker.  With a release history of at least one per month, I'm not looking forward to having to parse release notes only to see improvements to the bloatware around the broker, including all those 50+ connectors üò©   It's a steep price to pay in exchange for a webGUI to visualize the broker.

Who else gets weary from wading through release notes trying to figure out whether a given release will improve things?","",""
"867075936054149191","rickbullotta","2025-05-20T19:13:31.8190000+08:00","Well, you SHOULD care about SSO and RBAC though.  Those are essential capabilties even if you're just using the MQTT broker functionality.  If you're not using access control in your MQTT broker, you're probably doing it wrong.","",""
"742752935947010118","busch1974","2025-05-20T21:22:17.7620000+08:00","https://blog.fabric.microsoft.com/en-us/blog/mirroring-in-fabric-innovations-at-microsoft-build-2025?ft=All","",""
"742752935947010118","busch1974","2025-05-20T21:27:52.7070000+08:00","Simple ETL solution from Ignition SQL database (Trans Groups)","",""
"867075936054149191","rickbullotta","2025-05-20T22:34:22.7990000+08:00","Though I never really understood this rationale in a lot of industrial use cases.  Replicating all your data (read: copying and paying to process and store it multiple times, which cloud vendors love) doesn't always make sense.","","üíØ (3)"
"693309801589112862","_dyland","2025-05-21T00:27:02.1800000+08:00","It makes a lot of sense to the people who want you to pay for storage, Ingress, egress, compute, and queries.","","ü§£ (3),üíØ (1)"
"711239814241845259","milanhurban","2025-05-29T04:52:11.1510000+08:00","So recently I thought about making my own MQTT client/visualizer, mostly to get more familiar with Golang and some lightweight web UI frameworks. I know many here use MQTT Explorer, but I always thought perhaps one could do better, both in terms of UX and performance.

Anyway, while researching the topic and looking into the tech stack I wanted to use, I saw that some Australian dude already pretty much started doing exactly that (down to using Wails to package a web app as a desktop app) and put it on GitHub like two months ago, calling it MQTT Viewer. Anyone here wanna check it out? I wonder how you'd compare it to MQTT Explorer, especially if you have a larger broker/UNS running that could really test its performance, which I don't. And if I'm looking right, it already has some SpB support as well.

https://github.com/mqtt-viewer/mqtt-viewer","","üí° (2)"
"898217314741280828","hobbes1069","2025-05-29T19:59:36.3070000+08:00","I want to try it but he's having some issues working on the appimage package for Linux.","",""
"711239814241845259","milanhurban","2025-05-30T04:01:20.1480000+08:00","Yeah I saw that, I only quickly tried the Windows version and connected to the HiveMQ public broker. Worked without issues, shows topic payload history and such, shows the diff between the last two payloads, generally seems pretty nice.","",""
"1203544412462776404","oranges0728","2025-06-03T23:12:48.6160000+08:00","When trying to connect MQTT client in highbyte with HiveMq topic to receive the messages, we are unable to get messages although the topics subscribed. Anyone faced such issues earlier? Both Highbyte and HiveMq are on same machine and connected through 1885","",""
"898217314741280828","hobbes1069","2025-06-03T23:54:59.4260000+08:00","Are you sure you're connecting to HiveMQ? The default MQTT port is 1883. Highbyte uses 1885 for their internal broker to not conflict with an external broker.","",""
"867075936054149191","rickbullotta","2025-06-04T00:00:05.1410000+08:00","Wrong port, as Richard suggested.  Also, in a production scenario I'd recommend using TLS/secure communications.","","üëç (1)"
"794020366536146977","mparris","2025-06-04T03:31:20.1730000+08:00","Yeah, my guess is that you have the HighByte client connecting to the HighByte broker instead of the HiveMq broker‚Ä¶

Let us know what you find out","","üíØ (2)"
"1203544412462776404","oranges0728","2025-06-04T22:08:38.5790000+08:00","Will update soon","",""
"1328448347375403060","jpower19","2025-06-10T18:47:08.2810000+08:00","How do people recommend handling MQTT client authentication in production environments? TLS with username and passwords or TLS with certificates? Username and passwords seems easier to implement in our case.","",""
"867075936054149191","rickbullotta","2025-06-10T22:33:25.8330000+08:00","Whichever you choose, it would still be good ""hygiene"" to expire/rotate credentials regularly.","","üëç (2)"
"1203544412462776404","oranges0728","2025-06-12T22:07:21.9850000+08:00","Certificate is better option on physical device and remote located","","üëç (2)"
"1328448347375403060","jpower19","2025-06-12T22:08:18.1220000+08:00","Why is that?","",""
"867075936054149191","rickbullotta","2025-06-14T23:12:10.7630000+08:00","But you need a mechanism to be able to rotate/update certs too","",""
"890244048739270656","brianpribe","2025-06-17T03:08:08.7280000+08:00","Much more secure and automated. Sucks having to rotate passwords.","","üëç (1)"
"1173270244291264535","andreasvogler","2025-06-18T04:37:40.5640000+08:00","MonsterMQ üßå  with MCP-Server + Claude-Desktop, see what claude has made with just some questions about the data.
Dashboard: https://claude.ai/public/artifacts/97ab356a-e146-40a9-9877-561d9295f70c 
How I made it: https://youtu.be/l9SI3eNkAso
Feel free to publish data to test.monstermq.com and try to use Claude, here is the claude_desktop_config.json:
{
    ""mcpServers"": {
        ""MonsterMQ Remote"": {
            ""command"": ""npx"",
            ""args"": [""mcp-remote"", ""https://test.monstermq.com/mcp""]
        }       
    }
}
**Highly experimental! So, be careful and be nice to the monster, don't kill it.**","","üî• (3),üëç (2),üëå (1)"
"1203544412462776404","oranges0728","2025-06-19T16:29:34.7400000+08:00","Yes, that was the issue . Highbyte uses 1885 default for their broker and if the HiveMQ broker needs to be run on same machine, re-configuring it to 1885 is required ,","",""
"812295088348200960","patanj2","2025-06-19T18:01:04.3030000+08:00","If  they are running on the same machine,  why do you need the Highbyte built in broker to be enabled?","",""
"794020366536146977","mparris","2025-06-19T18:07:02.7620000+08:00","Or‚Ä¶even if you are going to be rubbing both brokers on the same machine, why can you not reference port 1883 for the MQTT connection?","","üíØ (1)"
"1144415465687482398","jprocess","2025-06-25T03:57:56.3920000+08:00","Can MQTT be used completely unidirectionally, or do I need bidirectional comms to establish the client to broker connection initially?","",""
"1031940518730543106","thunt.career","2025-06-25T06:00:21.7380000+08:00","What do you mean unidirectionally? Most mainstream brokers don't support UDP. HiveMQ Edge does have a UDP listener.

Assuming you are using the standard MQTT over TCP, then yes you will need bi-directional communication. However with stateful firewalls you can allow just the client to establish connection to be able to both publish and subscribe.","",""
"1144415465687482398","jprocess","2025-06-25T07:48:46.0920000+08:00","My scenario is my publisher will be behind a unidirectional gateway, so data can only go one way. It wouldn't need to subscribe to any data, just publish.","",""
"1031940518730543106","thunt.career","2025-06-25T08:07:39.6410000+08:00","@JProcess What's the product? Yes, there is hardware that supports this. 

Attached is image from Waterfall Security. MQTT isn't providing unidirectional support as it requires the broker/server to acknowledge the connection and payload with standard TCP. 

This gateway supports it by having a broker on the ""inside"" that picks up the topic on the ""Rx"" side then sends over their single fiber optic link to the ""Tx"" side that has a client to publish it out.","https://cdn.discordapp.com/attachments/1166016853991235594/1387222677080506418/image0.png?ex=68df13cb&is=68ddc24b&hm=034536a7e7cba76cfeae08b44874d68d3f8d5b072d26b15feea64d3aae8255ec&",""
"1144415465687482398","jprocess","2025-06-26T14:19:44.7540000+08:00","Cool thanks Travis!","",""
"1212245669558100021","tyler092335","2025-06-30T08:20:02.1060000+08:00","Anyone have a decent way of pulling computer statistics like cpu usage, ram usage and Ethernet connection. I found psmqtt on GitHub but I haven‚Äôt started the config file yet. Just seeing what‚Äôs out there","",""
"835805702228410378","johanscheepers","2025-06-30T12:54:49.1640000+08:00","What OS?","",""
"812295088348200960","patanj2","2025-06-30T20:15:47.2580000+08:00","Have you looked into any of the telegraf plugins?","",""
"693309801589112862","_dyland","2025-06-30T21:29:32.5080000+08:00","I like Glances, https://glances.readthedocs.io/en/latest/docker.html","",""
"1212245669558100021","tyler092335","2025-07-01T02:47:09.1450000+08:00","It‚Äôs Ubuntu 24","",""
"1212245669558100021","tyler092335","2025-07-01T02:50:01.9880000+08:00","I haven‚Äôt yet. I was trying to do a small project where push my desktop stats to a mqtt broker then node red pushes them to influx and then grafana displays the data from influx. Just to get more familiar with those tools","",""
"1212245669558100021","tyler092335","2025-07-01T02:50:12.4480000+08:00","I check this out. Thanks","","üëç (1)"
"839874991355985981","ralf05700","2025-07-02T19:33:42.0090000+08:00","Hivemind. I look for an MQTT broker that can run in bridge mode and when the local broker looses connection to the cloud broker, the local broker needs to buffer the data. Once connection is back up, the local broker should send the buffered data in a rate limited mode. Tried with EQMX but it‚Äôs not possible. Which other, preferably open-source broker can do this?","",""
"783917475128410112","geoffnunan","2025-07-03T08:21:47.3260000+08:00","a message queue like rabbitMQ","",""
"697134502148964423","trentc","2025-07-03T18:27:26.1600000+08:00","What part of this was not possible? Because i am certain it supports bridging‚Ä¶ is it the rate limit?","",""
"794020366536146977","mparris","2025-07-04T09:11:50.0410000+08:00","I‚Äôm assuming it‚Äôs the buffering‚Ä¶

Usually that would be handled by an application sitting outside of the MQTT broker","","üëç (1)"
"1212245669558100021","tyler092335","2025-07-04T09:39:01.0130000+08:00","Question for you. I have the below for my config file but for some reason it dont see any topics popping up in my broker. I can how ever go to localhost port 61280 and see that glances is running

[global]
check_update = False

[export]
export = mqtt

[mqtt]
host = localhost
port = 1883
tls = false
topic_prefix = glances
client_id = glances-client","",""
"693309801589112862","_dyland","2025-07-04T09:43:06.9880000+08:00","I haven't set it up for MQTT In quite a while, I probably won't be able to help more than the standard docs but the config you shared is different than what the docs call out. I would start there?

https://glances.readthedocs.io/en/latest/gw/mqtt.html","",""
"693309801589112862","_dyland","2025-07-04T09:44:03.6390000+08:00","https://glances.readthedocs.io/en/latest/config.html","",""
"693309801589112862","_dyland","2025-07-04T09:47:16.0600000+08:00","https://github.com/nicolargo/glances/blob/develop/conf/glances.conf","",""
"1212245669558100021","tyler092335","2025-07-04T10:09:42.6470000+08:00","no problem, ill mess around with if for a bit more. See if i can get it to work.","",""
"1031940518730543106","thunt.career","2025-07-04T11:25:47.6150000+08:00","It looks like password is required and username will default to 'glances' if not defined.","",""
"839874991355985981","ralf05700","2025-07-05T15:25:59.7420000+08:00","Yep. After the reconnection it would not rate limit the transmission but send everything at once","",""
"839874991355985981","ralf05700","2025-07-05T15:28:02.8200000+08:00","We were going for a lightweight approach and wanted to use the inbuilt buffering","","üëç (1)"
"1063829764164563026","mariano.beracochea","2025-07-15T04:12:54.6640000+08:00","In your plants you have a full time MQTT consultant?
What would be expected of a consultant like this?
 Configure the platform?
 Build the semantic structure? 
Configure the security permissions depending on the ID of the clients?","",""
"867075936054149191","rickbullotta","2025-07-15T04:52:50.5080000+08:00","I can't imagine anyone having this role.","","üíØ (2)"
"957775996856180737","evjakec","2025-07-15T06:18:00.6590000+08:00","Have not heard of this either. Architects typically own it. Once it‚Äôs configured, it should be pretty low touch.","","proveiticon (3),üíØ (1)"
"657361690379288596","du5tins","2025-07-19T06:15:10.2970000+08:00","Agree with this. For the brokers we have setup so far my team keeps forgetting the admin passwords because we log in so infrequently.","",""
"957775996856180737","evjakec","2025-07-19T06:19:38.6810000+08:00","Isn‚Äôt the password just ‚Äúadmin‚Äù? üòâ","","ü§£ (4),üíØ (1)"
"657361690379288596","du5tins","2025-07-19T06:22:43.7930000+08:00","No comment... haha","","üòÇ (1)"
"721948711126827009","jaylinyu","2025-07-23T16:00:37.7900000+08:00","Try NanoMQ, this is the specific scenario we target, has been massively deployed on vehicle","",""
"721948711126827009","jaylinyu","2025-07-23T16:02:07.5250000+08:00","Even with SQLite persist cache(open-source) and MQ rolling update(commercial ver)","",""
"1214242167640424619","zack.scriven","2025-08-16T11:12:43.9140000+08:00","That post today on LinkedIn is pretty interesting","",""
"1214242167640424619","zack.scriven","2025-08-16T12:35:15.7470000+08:00","This is a masterclass on MqTT https://youtu.be/pPddIsZW4T8?si=tZ8TKYaFHJzf6cnl","","üëç (1),üíØ (1)"
"867075936054149191","rickbullotta","2025-08-16T22:34:13.3110000+08:00","As I posted in response earlier: 

TL;DR: MQTT good, Sparkplug bad.  And not getting fixed anytime soon.  Time to move on from Sparkplug.","","üëç (5)"
"230441548653789184","r.pop","2025-08-19T00:13:22.6910000+08:00","And not or!","",""
"867075936054149191","rickbullotta","2025-08-19T00:31:02.9350000+08:00","Not in this case. Sparkplug adds negative value.","",""
"230441548653789184","r.pop","2025-08-19T00:34:41.7020000+08:00","I would disagree in some use-cases. I think there is value if you are an Ignition heavy shop and you want to leverage that infrastructure for some agentic workflows","",""
"230441548653789184","r.pop","2025-08-19T00:35:10.1860000+08:00","Because I know exactly what the topic structure will look like, it's easier to build adaptable/dynamic workflows","",""
"867075936054149191","rickbullotta","2025-08-19T00:58:27.8320000+08:00","TBH you have NO IDEA what the topic structure will actually look like since you don't know the node names. Mixing metric values in a single message and topic is bad voodoo for interop.  Then layer in having to decode protobuf and it's all bad.  JSON payloads on individual topics if you are about interop and if you want it to be consumable by something externally.  Even Ignition can deal with that happily.","",""
"867075936054149191","rickbullotta","2025-08-19T00:58:56.5210000+08:00","And the birth/discovery mechanism is really bad.","",""
"230441548653789184","r.pop","2025-08-19T01:02:28.0970000+08:00","Thats why I prefaced with saying if you're a heavy ignition user, because the structure is essentially your folder structure in Ignition.","",""
"230441548653789184","r.pop","2025-08-19T01:03:08.3170000+08:00","Im not saying it's better - just useful","",""
"693309801589112862","_dyland","2025-08-19T03:17:30.1420000+08:00","Sparkplug is just Ignition's fieldbus - Prove me wrong. ü™ß","","üíØ (5)"
"1304716553450688544","nemanjaglisic_21601","2025-08-22T03:02:36.1710000+08:00","Hello, maybe I missed some past post, I am wondering is there any story which explain MQTT vs AMQP ? In one moment, let's say 10 years ago it was looking that AMQP will be the protocol of choice for IIoT, I assume because of Microsoft and RabbitMQ. Accenture was also pushing AMQP. I saw few applications where Accenture was consultant, all were based on AMQP as internal bus between different services in the application. 
But now it looks like it is not popular anymore? Does AMQP still have a place in OT/IT stack?","",""
"1119420672138022962","jeffeweizen","2025-08-22T04:00:23.6890000+08:00","There are some good resources here for the AMQP vs MQTT for IoT question. They answer better than I could myself: https://www.hivemq.com/blog/mqtt-vs-amqp-for-iot/

and 

https://www.cloudamqp.com/blog/amqp-vs-mqtt.html

The short story is: AMQP supports more advanced routing and message delivery strategies, where MQTT is simpler with lower overhead.

To the second part of your question, AMQP certainly still has a place in the stack but I haven‚Äôt personally seen it much in the ‚ÄúOT‚Äù side. It is used heavily in software and ‚ÄúIT‚Äù applications with RabbitMQ, Azure Service Bus, and others.","",""
"1310949009246126155","symonschess_84515","2025-08-27T19:58:59.3050000+08:00","Hi everyone, I work for a small manufacturing software company and we are looking to make our software compatible with MQTT for our clients. Following Walker Reynolds, we have heard a lot about Sparkplug B, and this question came up in our discussions, so I figured I would bring it here:

Do we want to follow Sparkplug or define a custom topic structure? What is the industry standard for subscribing to shift or metric updates?
I don't see how we would fit the updates to sparkplug topic structure. There seems to be no way to subscribe to individual metrics (production_metrics), so every consumer has to subscribe to every update of a given device. If e.g. a service wants to receive shift updates, it can't, without also receiving all part, job, and team updates.","",""
"898217314741280828","hobbes1069","2025-08-27T20:10:48.7060000+08:00","SparkplugB is best for telemetry, you didn't mention what your software does so the usual answer ""it depends"" applies üôÇ In general, I would recommend supporting plain MQTT first, OPC UA second, and SparkplugB third.","","üëç (2)"
"1310949009246126155","symonschess_84515","2025-08-27T20:11:37.2960000+08:00","Gotcha, our software mostly displays and interacts with data from vorne products, and handles things like alerts and integrations with erp systems.","",""
"867075936054149191","rickbullotta","2025-08-27T21:00:22.3050000+08:00","It's not even ideal for that.","","üòÇ (1)"
"754022474617978971","jessedahirkanehl","2025-08-27T22:54:40.0190000+08:00","I'm the owner of the company and I'll add that our software is HMI and MES mostly. What I wanted to do with MQTT is give options for clients that want to use MQTT to integrate with current systems, and don't want to figure out the IoT hardware API which is a bit niche.
So I could see them building their own dashboards with it like Walker recommends. 
We're also making the backbone of our alerting system either NodeRED or Apache Nifi (still deciding), so that would get information from MQTT. So if downtime for a particular reason code is greater than 30 min then send an email. If quality drops below 90% on 2nd shift then send a text message. Stuff like that
We have a partner (friend of mine) that makes the OPC integration, but he said he doesn't want to get into the MQTT part. And from listening to the MQTT vs OPC debate it sounds like Sparkplug is great way to add functionality to MQTT, but I'm pretty new to this","",""
"696134466057273384","slamber12","2025-08-28T13:10:32.1830000+08:00","Now that I‚Äôve decided MQTT is not going to work for large volumes of historical data loading‚Ä¶the architect who argued with me many times we can only use the platform for real time data streaming is questioning what our technical limitation is üòê","",""
"794020366536146977","mparris","2025-08-28T16:24:51.8680000+08:00","In terms of moving data, there likely is not any limitations with using MQTT.

Note: there is a difference between MQTT the Protocol and MQTT-based systems.

I would argue that MQTT is best used as telemetry infrastructure when distributing the function of an application across multiple devices, where all  ends of this distributed function can be controlled.

It is possible to author an application that implements an MQTT server and also has a SQL backend, where clients can connect to the MQTT server, publish some query to‚Äú/select‚Äù and the application would pass through the query to the database and then stream back the results to client over /select/results.

Maybe some benefits of this are a front end proxy for a database, but I bet you that there are better technologies to use than the MQTT protocol.","",""
"696134466057273384","slamber12","2025-08-28T18:33:02.8750000+08:00","Inmation gets the history from our historian because of course it is aspentech and has proprietary query. They do have a good query/buffer mechanism for getting historical data which is better than using custom sql+ scripts. This produces our MQTT events to the broker which is perfectly capable of handling the volume, the problem is processing & contextualizing that data and writing it back to the correct ISA95 hierarchy topic","",""
"696134466057273384","slamber12","2025-08-28T18:34:03.0220000+08:00","We use highbyte but the write function over so many topics seems to be limited, there is a reference solution using some logic to split the writes up into multiple threads but it‚Äôs difficult to scale","",""
"794020366536146977","mparris","2025-08-28T19:44:21.6470000+08:00","What‚Äôs the purpose of writing historical data to MQTT?

What defines how much history to publish? Time-based or most recent X rows?

How often is the history published? Every time new values come in or on some polling schedule?

I‚Äôve not deplored that, so want to understand the use case","",""
"867075936054149191","rickbullotta","2025-08-28T21:02:18.8880000+08:00","Yikes.  I would never do RPC over MQTT.","","üëç (1)"
"254777321788145664","terrancesmith","2025-08-28T21:35:22.2840000+08:00","The fever around mqtt has some cognite customers thinking they want to move data from databases into Cognite Data Fusion using mqtt middlemen instead of using much more fit for purpose etl tools, cdc etc. I love mqtt for broadcasting telemetry, but I did not think it's potential applications would get to this..","","üíØ (1)"
"898217314741280828","hobbes1069","2025-08-28T21:35:40.7370000+08:00","The only way I see historical data being published to MQTT is for analytics... Meaning if you run a job that trends open orders for the last 30 days, you could publish that to the broker so that all people who are interested in that can get the data event based instead of everyone hitting the DB individually.","","üíØ (1)"
"754022474617978971","jessedahirkanehl","2025-08-28T23:00:43.1080000+08:00","sorry if this is off topic, but I'm confused as to what is considered the current telemetry? most of our metrics (counts, times, cycles, and summary metrics like quality, availability, mttr, etc) are calculated for some period of time like the current down period, job, shift, day, week, etc. does that all go out over MQTT? or does that belong in a historian and I should be thinking about it more as just the changes in count or cycles since the last time it was reported (+11 good count)?
so then when I'm talking about building alerting and wanting to know if the total downtime for the shift is over 1 hr so I can get an email, am I looking at the historian? Or an mqtt topic of .../device/shift/status and then that gives me the payload with all these calculations aggregated to the shift level. 
sorry if this is a bad question or I am asking in the wrong place","",""
"867075936054149191","rickbullotta","2025-08-28T23:23:21.3110000+08:00","Such a horrible idea.","",""
"138867775354437632","jonathan08947","2025-08-29T01:06:55.6390000+08:00","I like to treat the retained messages in mqtt as current state only. Any historical metrics like downtime on Aug 20th should be in a relational database to make it easier to query. Sometimes there's metrics like ""downtime last shift"" that you could make the argument is also considered current state, but I'm not a fan of those. Because now the metric is stored in the database and the retained mqtt message so you have to remember to update it in both places if there's any corrections that need to be made.","","üëç (2)"
"138867775354437632","jonathan08947","2025-08-29T01:13:49.7700000+08:00","Downtime for the current shift would be current state though. I think the main difference is it's more likely that a consumer will need to access downtime for current shift than for a past shift and therefore is more likely to benefit from Mqtt's pub sub pattern than a database's request pattern.","",""
"696134466057273384","slamber12","2025-08-29T01:33:12.0560000+08:00","The only purpose is to put data in the cloud which is currently only accessible through proprietary interface (IP21) for more advanced analytics‚Ä¶there is no good reason I can come up with to send it through the UNS‚Ä¶it‚Äôs like shipping an oversized plane on a highway - you can technically do it - but there are easier ways üòê","",""
"867075936054149191","rickbullotta","2025-08-29T02:40:01.2330000+08:00","I'd seriously recommend getting a HighByte trial license.  It'll ""just work"".","",""
"696134466057273384","slamber12","2025-08-29T04:18:56.3910000+08:00","Highbyte is part of our solution and we have the limitation of writing to many MQTT topics‚Ä¶.one thread seems to handle about 500msgs spread across many topics (dynamically defined by isa95 hierarchy enterprise/site/area/cell/unit/telemetry/<tag>)","",""
"696134466057273384","slamber12","2025-08-29T04:20:04.9610000+08:00","The suggestion is to use round robin and spread the workload but it‚Äôs a lot of configuration when the ‚Äúload‚Äù is infrequent and steady state is <200msgs/sec which we can do in 1 pipeline","","üëçüèΩ (1)"
"898217314741280828","hobbes1069","2025-08-29T07:46:21.7490000+08:00","Can't say I've tested that, but I have pushed 500k tags/s through highbyte using their pump simulation. Maybe I need to do a topics pressure test as well.","",""
"756543760028139720","aronsemle","2025-08-29T21:40:16.2360000+08:00","500/second does sound low, even for a single pipeline. When you write back out do you have ""ignore write result"" enable on the write stage? If you dont and youre trying to use the wrtie result, the pipeline will block waiting on each MQTT write to complete before processing the next write. If you disable that, you'll still get failure feedback but the pipeline hands off the writes to the MQTT connection thread, which can bundle them, and will be a lot faster.","",""
"1242074290510368854","jeffo_mt_90697","2025-09-04T18:24:25.1130000+08:00","Mettler","",""
"696134466057273384","slamber12","2025-09-05T10:15:29.9290000+08:00","Ooh this is a good tip I‚Äôll have to look at where it‚Äôs configured.","",""
"1173270244291264535","andreasvogler","2025-09-20T04:52:49.8480000+08:00","Hi, haven‚Äôt been active here for a while‚Ä¶ I have built a open-source broker based on Vert.x, PostgreSQL, MongoDB, or CrateDB. For a single instance, SQLite can also be used. It comes with a GraphQL interface, an integrated MCP server, integrated archiving of topics into a database or to Apache Kafka, an integrated OPC UA client to pull in OPC UA data (server is on the way), and a web admin page where you can also query the topic trees. Would be happy if some of you could test it and leave a star on GitHub üôÇ
https://monstermq.com","","üëçüèΩ (4)"
"867075936054149191","rickbullotta","2025-09-20T05:02:23.0020000+08:00","This looks really, really good!","","‚ù§Ô∏è (1)"
"711239814241845259","milanhurban","2025-09-21T03:50:01.9190000+08:00","I really like your projects and I've been meaning to check out MonsterMQ for a while, seems you've been busy adding features. What's your goal with it btw - is it a hobby side-project, is it a technology demonstrator or is there a concrete use-case for every feature, who is it for, do you have some ambition of achieving wider adoption?","",""
"711239814241845259","milanhurban","2025-09-21T03:51:10.7280000+08:00","And not surprised Rick likes it, seeing as it's heading in the Uber-broker direction.","",""
"1173270244291264535","andreasvogler","2025-09-21T18:25:27.4530000+08:00","As of now, it‚Äôs a hobby project and Open Source. I don‚Äôt have concrete plans for it yet ‚Äî apart from waiting for that (huge) investment offer üôÇ

Some functionalities can be really useful, though ‚Äî like being able to query the current state and history of a topic with GraphQL, having data logging built in, or integrating OPC UA directly. Another big one is being able to store an unlimited amount of retained messages, since they‚Äôre kept in a database.

And yes, a few of Rick‚Äôs ‚ÄúUBER Broker Ideas‚Äù have found their way in.

Of course, it also has to be clear that some of these features come with trade-offs. So, in the end, it must always fit the use case.","",""
"867075936054149191","rickbullotta","2025-09-21T19:39:47.0020000+08:00","A couple additional ideas I had: 

1a) Define some well known user properties that publishers can include in messages that MonsterMQ will recognize as metadata and also persist along with the topic.  X-DATA-FORMAT, X-DATA-TYPE, X-MIN-RANGE, X-MAX-RANGE, etc...or maybe just use a simplified type system such as DTDL or a ""lite"" version of OPCUA information models
1b) Enable querying of that metadata over HTTP/GraphQL
2) Enable publishing to a topic in MonsterMQ over HTTP/GraphQL (no need for MQTT)","",""
"1173270244291264535","andreasvogler","2025-09-21T20:00:40.2350000+08:00","Thx Rick! At least point 2) is already available. Also read/query and subscribe by GraphQL. For MCP I added a special ‚Äûsub‚Äú topic (retained) to have metadata for MCP. If you have a topic plant1/sensor1 then you can add a retained message on plant1/sensor1/..meta with a json payload to have metadata for the sensor1 topic which is read by the MCP. I do not have properties because haven‚Äôt yet implemented MQTT 5 üôÅ","",""
"794020366536146977","mparris","2025-09-22T01:17:31.8030000+08:00","I think ultimately, @RickBullotta wants you to implement I3X ü§£","",""
"794020366536146977","mparris","2025-09-22T01:18:58.1500000+08:00","It‚Äôs on my TODO list to look through the OPC UA Information Modeling and define which of those seem relevant to the I3X initiative","",""
"711239814241845259","milanhurban","2025-09-22T02:00:16.1650000+08:00","What about multi-publish (to an array of topics) and topic symlinks, @Andreas Vogler ?","",""
"1173270244291264535","andreasvogler","2025-09-22T02:09:30.4580000+08:00","You can do a multi publish with GraphQL. But with MQTT Protocol, this is not possible (due to the protocol). Also subscribers will always get single messages. Topic symlinks, interesting idea, will put this on my feature list. 
publishBatch ( inputs [PublishInput!]! ) [PublishResult!]!
Publish multiple MQTT messages in a single atomic operation Useful for bulk data ingestion and reducing API call overhead All messages must pass ACL checks or the entire batch will be rejected","",""
"1173270244291264535","andreasvogler","2025-09-22T02:10:50.2530000+08:00","@MParris what is the I3X initiative?","",""
"711239814241845259","milanhurban","2025-09-22T02:20:29.5360000+08:00","It's the CESMII API thingy, I think it got branded I3X not too long ago.
https://github.com/cesmii/API/blob/main/RFC%20for%20Contextualized%20Manufacturing%20Information%20API.md","",""
"794020366536146977","mparris","2025-09-22T02:23:55.1140000+08:00","Milan is correct

https://raw.githubusercontent.com/cesmii/API/refs/heads/main/images/data-access-model.PNG","",""
"711239814241845259","milanhurban","2025-09-22T02:25:37.5870000+08:00","What's the MQTT limitation on multiple topics? As far as I know it's just a string, you can use whatever separators you want, as long as the client and broker agree on it. And then publish as individual messages to subscribers. But yeah it would have to be done at the application level at the client.","",""
"794020366536146977","mparris","2025-09-22T02:33:30.3180000+08:00","3.3.2  Variable header
The variable header contains the following fields in the order: Topic Name, Packet Identifier.
3.3.2.1 Topic Name

The Topic Name identifies the information channel to which payload data is published.
 
The Topic Name MUST be present as the first field in the PUBLISH Packet Variable header. It MUST be a UTF-8 encoded string [MQTT-3.3.2-1] as defined in section 1.5.3.
The Topic Name in the PUBLISH Packet MUST NOT contain wildcard characters [MQTT-3.3.2-2].
The Topic Name in a PUBLISH Packet sent by a Server to a subscribing Client MUST match the Subscription‚Äôs Topic Filter according to the matching process defined in Section 4.7  [MQTT-3.3.2-3]. However, since the Server is permitted to override the Topic Name, it might not be the same as the Topic Name in the original PUBLISH Packet.","","üëç (1)"
"794020366536146977","mparris","2025-09-22T02:34:08.3380000+08:00","The limitation in MQTT is one topic per PUBLISH packet","",""
"1173270244291264535","andreasvogler","2025-09-22T02:55:32.3410000+08:00","sure you can encode multiple properties and values in one message and on one topic (one topic!). But that you can do with any broker. But then you loose the ability to subscribe to single properties. Always the same story üôÇ","",""
"711239814241845259","milanhurban","2025-09-22T03:04:06.2470000+08:00","What I meant was, what is stopping me from telling a client to publish a message to ""topic1/subtopic1\topic2/subtopic2\topic3"" and implementing the broker so that it recognizes ""\ "" as a separator and then publishes the same message to the subscribers of topics ""topic1/subtopic1"", ""topic2/subtopic2"", and ""topic3""?
You could actually do the same then with the message payload and publish different messages to different topics at once.
I'm not saying it's a good idea to deviate from the spec, just wondering.","",""
"1173270244291264535","andreasvogler","2025-09-22T03:09:36.0540000+08:00","Ok, got it, interesting idea.","",""
"711239814241845259","milanhurban","2025-09-22T03:28:30.9250000+08:00","It's definitely a hack and to be honest I've only ever seen the request for multi-publish from others here (like Rick) and thought this is what they meant. Haven't needed such a feature yet myself.","",""
"1405866167494774886","chrismisztur_43648","2025-09-22T06:46:51.0100000+08:00","This might help https://github.com/cesmii/API/issues/108","","üëç (1)"
"794020366536146977","mparris","2025-09-22T07:54:08.0810000+08:00","You are now leaving the realm of MQTT and building a protocol on top of MQTT, similar to how Sparkplug came to be.","","üëç (1)"
"867075936054149191","rickbullotta","2025-09-22T20:46:07.6390000+08:00","Nope - you can only publish a single topic at a time.  Major design flaw/limitation.","",""
"753688565807841492","ravil1","2025-09-24T05:32:20.9550000+08:00","Its like calling a function with scalar arguments, instead of arrays. Like reading one value at a time, instead of array/list of values.","",""
"867075936054149191","rickbullotta","2025-09-24T21:18:14.0360000+08:00","It's more like calling a function that can only have one argument!","",""
"753688565807841492","ravil1","2025-09-24T22:43:22.2150000+08:00","ü§£","",""
