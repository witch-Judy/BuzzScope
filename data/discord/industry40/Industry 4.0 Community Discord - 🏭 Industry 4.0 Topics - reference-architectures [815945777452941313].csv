AuthorID,Author,Date,Content,Attachments,Reactions
"194289793905983489","zackscriven","2021-03-03T21:54:12.9340000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/816669796270604348/unknown.png?ex=68df2cc4&is=68dddb44&hm=56572c109859b0b584ea88277143cdfc9db8527fb60284ba7ebd2c2029b0807a&","üëç (4)"
"194289793905983489","zackscriven","2021-03-04T08:58:59.1410000+08:00","Thank you @MParris we should just bring you on next week to ask your question in person... After we have @Omar  on for the Community Spotlight üî¶","https://cdn.discordapp.com/attachments/815945777452941313/816837090876325908/unknown.png?ex=68df1fd2&is=68ddce52&hm=48f5622959b9d606e20b7174b0f17a4c0706f6fa75c4532c8399034c997754ba&",""
"767678812699361310","henning8936","2021-03-08T02:46:49.3630000+08:00","@MParris I love that list + annotations. It really helps to break down a complex topic. To point 7: I never thought about that point and want to see if I get it right. You write ""[...] After beeig normalized, standardized and contextualized in the UNS"".  Does the UNS really provide normalization and standardization? I can see that the UNS provides the context, but I would have thought that I would have a separate node or service, that loads the values from the historian, in order to normalize and standardize them and  then push them into a datalake? If that is so, would this node push the normalized/standatdized data through the UNS or just directly into thr data lake?","",""
"817835202746253344","IIoT#4707","2021-03-08T02:46:49.6620000+08:00","GG @henning, you just advanced to level 4!","",""
"794020366536146977","mparris","2021-03-08T02:52:54.2260000+08:00","@Martin Jakobsen is who summarized the UNS with annotations from @Walker Reynolds  Props to them!","",""
"767678812699361310","henning8936","2021-03-08T02:55:02.0280000+08:00","Pressed enter to early... Great job @Martin Jakobsen","",""
"794827518170497045","martinjakobsen","2021-03-08T05:05:36.6770000+08:00","Thanks Henning. It is a great question that I think @Walker Reynolds  could shed some clarification to. When I wrote point 7. it was with HighByte in mind that has those functionalities. To my understanding HighByte does not act as a broker and therefore might, as you say, push it through the actual UNS afterwards.","","üëç (2)"
"382941357699760129","walker.reynolds","2021-03-08T10:14:28.6040000+08:00","Correct... We should see HighByte broker functionality in the next couple months... Its on the road map.","","üëç (1)"
"767678812699361310","henning8936","2021-03-08T13:51:40.1310000+08:00","@Martin Jakobsen  So Highbyte is providing an additional node for normalization and standardization in order to preprocess the data do be used in AI applications?! I don't want to nit-pick, I am just trying to get a clear understanding what the UNS itself is providing (e.g. structure and events)  and what is happening on the node level.","",""
"767678812699361310","henning8936","2021-03-08T15:24:31.0520000+08:00","Addition: I will try to answer my question myself: Part of Highbyte's inteligence hub is the transformation engine, that allows to standardize and normalize data. That means if we use Highbyte as a gateway e.g. for OPC-UA machine data, Highbyte can simultaneously provide UNS structure as well as above mentioned mathematical operations.  If my data is provided via some other gateway or if my machine is natively publishing its data under the UNS structure, than I might need an additional node for standardization and normalization?","",""
"745796393855352953","thedavidschultz","2021-03-08T18:38:20.6350000+08:00","Yes that is what HighByte does. It will connect to multiple data sources to normalize the data and publish it in a UNS structure. Data can be published to multiple places as well. I did a demo publishing to an MQTT broker and Azure IoT Hub.","","üëç (3)"
"767678812699361310","henning8936","2021-03-08T19:35:47.2840000+08:00","thanks @DavidSchultz","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2021-03-09T11:57:25.8940000+08:00","In a federated multi-UNS environment, where is everyone deploying their various applications and where are they integrating them?

There has been discussion about the UNS as being omnipresent, but what about the applications that connect to it?  I bring this up because I noticed a set of historians at the local UNS's in this drawing.

When there are multiple sites and UNS's, how are things like historians or HMI/SCADA approached?  Does it become arduous maintaining local and enterprise deployed versions of applications?  Or, is it just easier to keep everything in one place at the enterprise level?

What's the user experience like?  Is there a seamless experience ""hopping"" around the enterprise?  Or, must one awkwardly open different projects or versions of apps when they need to switch context (e.g., Enterprise, Site A, Site B)?

I've also wondered about the role of applications running in the cloud.  For example, ERP and even MES can be multi-tenant cloud apps.  Cloud is not necessarily limited to analytics or AI/ML.  Is it best to integrate once at the Enterprise UNS and federate down everything to the site-level UNS?  Or, is it better to maintain a set of integrations at each site-level UNS?

I recognize there are no hard-and-fast rules here, but it would be helpful to discuss different scenarios and their pros/cons.","","üî• (1),üëç (1)"
"194289793905983489","zackscriven","2021-03-09T14:25:59.7110000+08:00","Pinned a message.","",""
"745009912160976977","marioishikawa","2021-03-09T18:21:10.6980000+08:00","Ontology, UML and data model. This is a topic I love as much as the more I learn the more it feels I need to learn. ISA-95 solves a lot, but there is still a lot to be done. https://blog.iiconsortium.org/2021/03/understanding-the-ontology-of-iiot-information-models-can-help-you-begin-to-address-the-challenges-o.html","","üëç (3)"
"745009912160976977","marioishikawa","2021-03-09T18:21:28.4460000+08:00","full document here https://www.iiconsortium.org/pdf/Characteristics-of-IIoT-Information-Models.pdf","",""
"750468087761076244","ejmilly","2021-03-10T11:04:18.9630000+08:00","Hi David where is the demo you did?","",""
"745796393855352953","thedavidschultz","2021-03-10T19:38:01.2790000+08:00","https://youtu.be/Cu36vtvnJuw","","üëå (4),üëç (3)"
"767678812699361310","henning8936","2021-03-13T14:03:53.9220000+08:00","From the blog post: ""Traditional methods such as database schemas and XML schemas provide limited expressivity in modeling knowledge, which forces business logic that should really be part of the knowledge model to be embedded into applications.""

If that really is true, it would also be true for SpB, wouldn't it. SpB structure can be represented in JSON and JSON is not that much different from XML? So is SpB lacking modeling capability I would want or not?","",""
"373852732424978442","daniel_hirsch","2021-03-13T16:25:02.7800000+08:00","I don't quite understand why XML should have limited use for modeling onthologies when the W3C standardizes Notation3 (N3) as a XML-based representation for RDF. Or am I getting something mixed up?

https://www.w3.org/TeamSubmission/n3/","","‚ùì (2)"
"767678812699361310","henning8936","2021-03-13T17:03:25.2050000+08:00","I don't get it either. I modeled complete assembly processes in XML and never felt that limitation.","","ismile (1)"
"373852732424978442","daniel_hirsch","2021-03-13T17:13:32.5100000+08:00","In my opinion XML-based representation is the most open and flexible way to represent Data und Information, for both humans und machines. Data modeling is an I4.0 topic on its own and could deserve its own #thread, maybe?","",""
"194289793905983489","zackscriven","2021-03-13T21:48:02.2210000+08:00","Talking about IIoT at 2:00 AM ü§£","",""
"487658368492896257","benveenema","2021-03-13T22:31:52.7700000+08:00","I think that, in general, JSON is lighter weight than XML. XML is also less human readable than JSON and probably more effort to parse. It has just fallen out of favor. If the internet was being re-designed today, it would probably use JSON or YAML or something else instead of HTML.","",""
"794020366536146977","mparris","2021-03-13T23:08:54.5410000+08:00","Within XML, you can specify the structure of data and organize it in a way that mostly makes sense to a developer trying to interface to equipment or an application.

This article is bringing up the point that this is not sufficient for machines to understand about other machines.  The human developer is doing a lot of inference that a machine can't do. A machine needs to know how all the data is related.

For example, if you have a model that represents a valve and pump, you would typical organize these together in a hierarchy to show their true dependency/relationship in world (part of the same fluid circuit, and valve before pump) But a machine needs to be told the relationship. XML doesn't offer a standard way to express these higher-level modeling concepts. You could implement something, but that would only be your encoding scheme, and then we are back to the beginning: how can a machine understand your encoding.

OPC-UA includes a framework to create and expose relationships between objects, whereas XML doesn't.","","üëç (4)"
"767678812699361310","henning8936","2021-03-14T00:19:20.7140000+08:00","That guy models! üòÄ","",""
"794020366536146977","mparris","2021-03-14T01:22:07.6610000+08:00","Lol. In full transparency, I have never actually done it. I have gone so far as to look at the standard, watch a few videos, and use Beeond's UMX Pro as a GUI to define a nodeset file. The next step is to convert the nodeset file to source code classes to embed within the application. Then the source code of the application can hook into the variables and methods.

It's a very clunky process, and if you ask any developer to follow it for an agile project, you'll get a big eyeroll.

To bring it full circle, the OPC-UA nodeset file that defines the model is written using XML :laughing:","","üëç (4)"
"373852732424978442","daniel_hirsch","2021-03-14T01:50:34.9500000+08:00","For those who are interested, I found a paper on OPC UA and ontologies:
""Ontology-Based OPC UA Data Access via Custom
Property Functions"" https://publik.tuwien.ac.at/files/publik_286028.pdf","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2021-03-14T01:52:27.4920000+08:00","To reinforce Matt's point, here's a visual depiction.  

Notice how it's more than a simple hierarchal model of ""waterfall"" or ""parent/child"" entities.  There are attributes that describe what an entity is and their relationship to other entities.  This might all seem daunting and complex, but this approach is what enables the plug-and-play experience we're accustomed to with consumer electronics.

To enable holy grail outcomes with ease (e.g., plug and play, prescriptive analytics, discovery, awareness), semantic modeling is required.  A descriptive object name is just that... a descriptive object name.  A machine or application only interprets this as an object with text.  It requires, as Matt mentioned, a human to make inferences.  This might take the form of constructing UDTs and some accompanying logic.

This is an area where I think OPC-UA, conceptually, has a ton of potential and could solve a lot of problems.  Unfortunately, the execution is not there.  There are tons of working groups that attempt to ""boil the ocean"" with companion specs to model literally everything.  The resulting published specs are in no way ripe for market adoption and no one involved in drafting them are required to make a good faith effort to implement them.  They might generate a proof-of-concept, but it's just that.  They're generating a reference architecture without any reference products.  There's no go-to-market strategy.

OPC Foundation blog post on semantic modeling:
https://opcconnect.opcfoundation.org/2015/12/why-semantics-matter/","https://cdn.discordapp.com/attachments/815945777452941313/820353633254113310/whysemanticsmatter_fig1.png?ex=68df649b&is=68de131b&hm=8e8bdfab199008b2a84bab97bc615485eb95e4b7d4003faa8cb4469a79a309ac&","ishocked (1)"
"766684226455207996","bright_hummingbird_31342","2021-03-14T02:06:52.5880000+08:00","I've also attempted to play around with Beeond's modeling tool.  At some point, I joked ""F@#$ it.  Let's just use Modbus.""

The modeling is seriously so cumbersome that one could simply mandate a naming convention, deal with all inevitable discrepancies, and the team would probably still be ahead.  It's very awkward when a methodology or technology designed to make things easier actually makes things much harder.","","ü§£ (1)"
"456226577798135808","Deleted User","2021-03-15T06:12:20.2890000+08:00","I watched it today, good video! Did a similar thing with HighByte and Ignition (separately as test trying to get similar results with both setups). I find highbyte a nice tool but if you already have something like Ignition it feels redundant?","",""
"456226577798135808","Deleted User","2021-03-15T06:16:42.1940000+08:00","Also if you only have highbyte you still need a broker to be able for others to subscribe to the data? So the broker is always the UNS and highbyte a tool for the helping with the U (unifying)?","",""
"745796393855352953","thedavidschultz","2021-03-15T19:26:31.8380000+08:00","You can use both HighByte and Ignition to build a UNS. It all depends on the problem you are tying to solve and how you intend to use the data (making no assumptions on how the data will be used). If you already have Ignition, it certainly makes sense to use it, but if you do not, HB should be considered. It is a bespoke tool for creating a UNS. To clarify, the broker is the connection technology between nodes. The UNS is both the information/events and the structure.","",""
"456226577798135808","Deleted User","2021-03-15T19:53:41.8950000+08:00","Thanks for the clarification. The thing that confuses me is that sometimes I read HB is just a node and other times it is the UNS. I just did some simple tests with it but can you create those folder-like structures of an enterprise in it? (Enterprise, site, area,...)","",""
"817835202746253344","IIoT#4707","2021-03-15T19:53:42.2820000+08:00","GG @Deleted User, you just advanced to level 1!","",""
"456226577798135808","Deleted User","2021-03-15T19:54:16.4140000+08:00","Nice bot!","",""
"745796393855352953","thedavidschultz","2021-03-15T19:59:48.4670000+08:00","Yes you can create a folder structure in HB. That is one of the powerful features of the tool. I can define as many structures I need all from the same dataset.","","üëç (1)"
"456226577798135808","Deleted User","2021-03-16T00:14:01.8900000+08:00","Oh seems I need to take another look - thanks for the quick response!","",""
"745796393855352953","thedavidschultz","2021-03-16T00:20:08.1090000+08:00","The Output is where you would configure this.","",""
"745009912160976977","marioishikawa","2021-03-16T03:55:02.8280000+08:00","I'm late here but @MParris and @js came with great answers. Sometimes you need more context. For example: if you have a counter and it is simply a continuous variable for your system, your application will need to understand that a counter is a specific type you can use to calculate OEE while temperature not.","","üíØ (1)"
"815267392905150465","venkyiaf753280","2021-03-16T19:23:38.4240000+08:00","It was great to watch the video. Thanks for sharing David.","",""
"745796393855352953","thedavidschultz","2021-03-16T19:24:11.9070000+08:00","üëç","",""
"194289793905983489","zackscriven","2021-03-16T21:11:40.3300000+08:00","@DavidSchultz is an OG!","",""
"805482126170259498","mazensalhi","2021-03-16T21:38:28.2440000+08:00","Very good video. Very informative and clear. Thanks for sharing, David.","",""
"805482126170259498","mazensalhi","2021-03-16T22:06:07.4470000+08:00","What would alternative tools to Microsoft Stream Analytics and Power BI be, would you say? For example, Canary Labs and Axiom might be an alternative? Any others?","",""
"745796393855352953","thedavidschultz","2021-03-17T03:27:31.5020000+08:00","HB offers an AWS connector as well. My demo was based on a demo Aron did which connected to both IoT Hub and AWS. You can see watch it on the HB YouTube channel. You could use Axiom Asset Models to do this as it will connect to a OPC server. You could use also use the MQTT connector and subscribe to the broker to do the same thing. Depending on what you were trying to, Flow-Software could use the data or model from Canary. As always, lots of ways to skin the cat.","","üëç (2),flow (1),canary (1)"
"805482126170259498","mazensalhi","2021-03-17T03:30:04.9140000+08:00","Concepts and architectures slowly beginning to crystallize. Thank you, David.","","üëç (1)"
"745009912160976977","marioishikawa","2021-03-17T18:43:52.7990000+08:00","Google PubSub with BigQuery and Looker. Basically for the alternative you need something to manage the stream, like Kafka, something to process real time data, think of python scripts, for example, something to store the data, a database and finally a front end to present the data, what is Power Bi in the scenario, or Looker as I mentioned.","","üëç (2)"
"805482126170259498","mazensalhi","2021-03-17T21:07:59.4070000+08:00","Thanks, Mario","","üëç (1)"
"194289793905983489","zackscriven","2021-03-23T00:02:13.0710000+08:00","@Martin Jakobsen this is a more updated version of the one Walker was referencing.","",""
"820097580665929808","pvmagacho","2021-03-24T21:41:47.3260000+08:00","Hello, I wonder if this architecture is really Industry 4.0. It's from Gartner. By reading and looking at the videos shared by @zackscriven and @Walker Reynolds, the image below doesn't look right.
https://pbs.twimg.com/media/DK1QXmsXUAIbmCG?format=png&name=medium","","üòÜ (1)"
"820097580665929808","pvmagacho","2021-03-24T22:13:00.2040000+08:00","A similar one. https://www.missionsecure.com/hs-fs/hubfs/Graphics/Blog/Images/gartner-iot-reference-architecture.png?width=1954&name=gartner-iot-reference-architecture.png","",""
"820097580665929808","pvmagacho","2021-03-24T22:13:16.0350000+08:00","Looks like this doesn't have any relation with UNS","",""
"766684226455207996","bright_hummingbird_31342","2021-03-25T00:03:23.8330000+08:00","It looks like elaborate digital thread.  It looks like a research analyst that has not worked in industry for decades designed this.

I'm not sure why a digital twin would reside at a device layer without any context of everything else.

The broad classification of ""operations"" and ""business systems"" is bizarre.  It's like saying ""Oh yeah, that's just like some MES or ERP apps or whatever. Stuff just happens there, I guess.""  They have some sort of data processing fetish that has nothing to do with how real world apps work or how a business actually runs.  I'd like to see them try to apply logos at each of the functional layers.

I could see some of the architecture working for services of IoT products in the field (e.g., support, maintenance, performance management, consumption-based monetization), but not for producing products in an IIoT / Industry 4.0 context.","",""
"194289793905983489","zackscriven","2021-03-25T00:25:13.5350000+08:00","I think you are correct. Something oddly Purduish about that drawing.... ü§î","",""
"820097580665929808","pvmagacho","2021-03-25T00:35:04.3600000+08:00","> I'd like to see them try to apply logos at each of the functional layers.","",""
"820097580665929808","pvmagacho","2021-03-25T00:35:17.9460000+08:00","@js I think I found an image with apps for each layer.","",""
"820097580665929808","pvmagacho","2021-03-25T00:35:21.7600000+08:00","Hang on, üôÇ","",""
"820097580665929808","pvmagacho","2021-03-25T00:35:48.4980000+08:00","https://sofia2about.wordpress.com/2017/07/31/gartner-report-use-open-source-to-jump-start-iot-projects-and-make-iot-vendor-decisions-2/amp/","",""
"820097580665929808","pvmagacho","2021-03-25T00:35:54.6320000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/824320633050628147/image002.png?ex=68df52aa&is=68de012a&hm=bc53a3caa4902d928c774d6c8f672b21058b070c7e1f96eeca0143961f5993b8&",""
"820097580665929808","pvmagacho","2021-03-25T00:36:20.7430000+08:00","Is that what you mean?","",""
"794020366536146977","mparris","2021-03-25T06:10:37.6110000+08:00","Looking closely at the arrows...

""Enterprise: where plant data goes to die""","","ü§£ (3)"
"820097580665929808","pvmagacho","2021-03-25T06:16:05.1690000+08:00","And this is the source of information people that doesn‚Äôt know the OT world is looking at","",""
"794020366536146977","mparris","2021-03-25T06:17:31.9460000+08:00","I'm in awe how this group is an expert at so many open source devices and protocols üôÑ","",""
"794020366536146977","mparris","2021-03-25T06:24:13.1320000+08:00","Yes, @Walker Reynolds did a nice job covering that in the community Q&A yesterday.

Those graphics are nothing but buzzword soup. People study it and then feel educated, but then still have no idea how it works.

The first giveaway is that ""PLC"" is not listed on any of these... the devices that actually make money for any manufacturing business would be lumped in the category of ""things"".","",""
"657040065540915231","marcthepunk","2021-04-01T22:36:49.8600000+08:00","Hello community, I'm pretty new to this ecosystem. I was wondering if you can point me in the direction to documented references for managing PLC code repositories and best practices for a centralized versioning control system. I have one of my engineers doing research into ACM but I believe we're partially solving any type of optimized change management workflow. Any insight will be appreciated, thanks.","",""
"194289793905983489","zackscriven","2021-04-02T03:02:10.9270000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-04-02T03:02:17.4940000+08:00","Great question Marc!","","üëç (1)"
"487658368492896257","benveenema","2021-04-03T08:37:39.8450000+08:00","The sad thing is there is no good solution for this. There are a couple of version control systems for PLCs that cost a fortune and lack the features of modern VCSs like git. We had a conversation about them here a little while ago. It was in the edge channel starting March 24th. I'm on my phone, otherwise I'd link to it here.","",""
"194289793905983489","zackscriven","2021-04-03T22:22:00.5440000+08:00","@tbonola@circonenergy.com reference Architecture shared here https://discord.com/channels/738470295056416930/740564843710382080/827771843368583212","","üëç (1)"
"832550246961512479","beng1740","2021-04-18T17:02:10.8280000+08:00","Hi Team. Has anyone done anything with asset information being linked into the UNS? For example having a topic for links to drawings or manuals, Latest plc code revision, Etc? Potentially have something like Microsoft flow linked to a onedrive to push updates into the UNS automatically? Feels like this asset info could compliment the ecosystem of data for plant floor users. Interested to see if someone has an example of this in practice.","",""
"194289793905983489","zackscriven","2021-04-19T03:07:26.0150000+08:00","Pinned a message.","",""
"382941357699760129","walker.reynolds","2021-04-19T04:00:34.9310000+08:00","We take two approaches here -- one is to include a topic at the asset level that contains just the string name of the current drawing(s), the other is to include a topic(s) that contains the file path the drawing(s) file.  Its quite common to include these topics in the namespace as we get into later iterations... maybe 12 - 18 months into the transformation... however, we have included these topics far earlier in the engagement if capabilities like digital work instructions are a requirement early on.","",""
"832550246961512479","beng1740","2021-04-19T04:08:43.4950000+08:00","Thanks @Walker Reynolds. Makes sense that this would come later in the journey. I like the idea to think how it could potentially work at the start to give us a decent roadmap. üëç","","ismile (2)"
"794020366536146977","mparris","2021-05-17T20:36:32.7960000+08:00","Good info regarding the scope and state of TSN (Time Sensitive Networks):
https://www.na.hilscher.com/fileadmin/user_upload/Hilscher_TSN_Tech_Brief.pdf","","ishocked (1)"
"756247672637358181","sherylmccrary","2021-05-18T01:16:27.4740000+08:00","Excellent. TY","",""
"817835202746253344","IIoT#4707","2021-05-22T09:47:25.6250000+08:00","GG @MParris, you just advanced to level 14!","",""
"794020366536146977","mparris","2021-05-22T10:47:31.7220000+08:00","Corrected some typos, and added a top-level broker to demonstrate one of the greatest weaknesses of Sparkplug.  To federate the data up the enterprise, you have to itemize each possible combination of E, S, A, and W, those that exist now, and needs to be modified to accommodate new ones in the future.  Not very Edge-driven.

If Sparkplug could be extended to allow more than 1 topic level for ""groupID"", then all the statically defined pub/subs for Site1 would be replaced with just one dynamic pub/sub: ""spBv1.0/E1/S1/#"" and this one pub/sub would accommodate any future Area or WorkCenter added in the future.","https://cdn.discordapp.com/attachments/815945777452941313/845493048372101130/unknown.png?ex=68df3943&is=68dde7c3&hm=75ba7f6e451ee1e1ddfd5ca6654c2d0a0565cf042bcedda1d6fdc77b9a0dc57f&","üôå (7),highbyte (2),üëç (10),üëä (5),üíØ (1),üî• (1)"
"194289793905983489","zackscriven","2021-05-22T12:13:21.8490000+08:00","Amazing. I want to shoot a video on this slide.","",""
"194289793905983489","zackscriven","2021-05-22T12:13:54.2590000+08:00","This is amazing","",""
"744564195173073048","miklosbath123","2021-05-25T21:19:40.2260000+08:00","Can anyone point in the direction of Open source Edge architecture both open source edge hardware architecture and  open source edge software architecture based that will facilitate UNS, Edge drive, report by exception etc. If there are any links or designs, the closest Open source edge software i have come to see is Eclipse Kura or something similar along the lines?","",""
"817835202746253344","IIoT#4707","2021-05-25T21:19:40.5160000+08:00","GG @miklosbath123, you just advanced to level 2!","",""
"744564195173073048","miklosbath123","2021-05-25T21:23:28.5440000+08:00","I did create this part, I am trying to identify different hardwares and softwares(both open source and proprietary) that'll support. Any advice, thoughts or critical reviews welcome.","https://cdn.discordapp.com/attachments/815945777452941313/846740252747890738/unknown.png?ex=68df258f&is=68ddd40f&hm=904d664894f6b3cca1c3430bc7757d823d81b02acc1c4f47d52526efb18e085b&","üôå (3)"
"744564195173073048","miklosbath123","2021-05-25T21:25:48.2680000+08:00","This is at a High level","",""
"744564195173073048","miklosbath123","2021-05-25T21:26:05.5160000+08:00","Now trying to drill it down to details","",""
"794020366536146977","mparris","2021-05-25T21:26:54.0480000+08:00","BalenaOS and ioFog (https://iofog.org/docs/2/getting-started/quick-start-local.html) may also be solutions you're looking for?","","üëç (2)"
"744564195173073048","miklosbath123","2021-05-25T21:27:34.0560000+08:00","Thanks will check","",""
"194289793905983489","zackscriven","2021-05-25T22:38:56.6450000+08:00","Thank you for sharing!","",""
"585011139767959553","ekion_","2021-06-02T00:47:50.7310000+08:00","@miklosbath123 This could be useful! It's an open connected factory specification and framework that we pulled together last year based on Sparkplug/UNS: https://factoryplus.app.amrc.co.uk","","üíØ (3),üî• (4)"
"744564195173073048","miklosbath123","2021-06-02T01:44:20.7390000+08:00","Thanks, I have been following AMRC you guys do some really good work.","","üëç (1)"
"585011139767959553","ekion_","2021-06-02T01:52:10.3440000+08:00","Thanks! We‚Äôll be sure to keep you up to date with new developments coming out of the centre.","",""
"194289793905983489","zackscriven","2021-06-02T16:16:37.4730000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-06-02T16:17:08.4920000+08:00","I'm going to have Walker comment on your architecture drawing here during the next Live Q&A if you would like feedback","","üëç (1)"
"744564195173073048","miklosbath123","2021-06-02T16:37:07.4690000+08:00","Yes thanks Zack, I would like that and who are the right partners that will fit the architecture and any feedback and comments are excellent","","üíØ (1)"
"812295088348200960","patanj2","2021-06-13T00:16:59.1590000+08:00","If source files are text based,  you can run your own git server.   I have seen some controls teams not wanting to put their code into cloud based tools like GitHub or Bitbucket.  The downside that you‚Äôre missing is a platform like GitHub is quite adaptable to different workflows for how you want to manage reviews,comments,  merging code into  a release/production branch, etc.","",""
"260594842093092864","y_u_no_python","2021-06-19T06:16:10.7610000+08:00","https://tenor.com/view/say-what-now-anchorman-say-what-what-gif-15786157","","üòÜ (2),üëÄ (1)"
"830193224504705035","marc.jaeckle","2021-06-28T16:14:42.0320000+08:00","If you don't mind a dependency on a cloud provider you can use Azure IoT Hub or AWS Greengrass for the edge gateway. Depending on the amount of resources you have available on the edge gateway, k3s in combination with either Rancher or D2iQ Kommander (or similar) to manage your k3s clusters can be a great solution. k3s also has the advantage that you can easily build and edge cluster with multiple nodes if you want to do some more complex processing on the edge or want a HA setup. If you are already using some form of Kubernetes in the cloud it's also nice to have the same deployment mechanisms (and same security mechanisms, monitoring, logging, governance policies, ...) for the egde with k3s. It's also extremely helpful if your edge device offers Lights Off Management and PXE Boot support so you can manage it completely from your sofa including OS provisioning (at least after someone plugged in the cables).","",""
"519283075507814400","mariopoetazus","2021-06-28T17:10:12.0260000+08:00","if you like k3s, you need to check KubeEdge or Anthos from GCP","",""
"830193224504705035","marc.jaeckle","2021-06-28T18:02:41.0990000+08:00","Do you mean Anthos also as replacement for k3s or just as management plane for k3s through Cluster API? Last time I checked it didn't support one-node clusters yet and also didn't offer the same ""one binary"" approach with reduced resource requirements as k3s but it would be great if Google now offers something similar out-of-the-box.","",""
"519283075507814400","mariopoetazus","2021-06-28T18:09:09.7540000+08:00","To replace k3s","",""
"805550636481118208","jonnywright4","2021-07-05T16:56:28.8740000+08:00","@Y_U_NO_Python?   interested to hear your (and other members) expanded thoughts on that Factory+ spec https://factoryplus.app.amrc.co.uk/ by the AMRC... Thanks","","üëç (4)"
"260594842093092864","y_u_no_python","2021-07-08T00:34:10.7940000+08:00","@Jonny Wright. Curious if you are associated with this project (Assumption by your question)

I looked at their website, thought about their approach and I wanted to get my thoughts out after looking at the implementation:

Pro's:
    ‚Ä¢ Containerization of both the edge node deployment and Server deployment allow for repeat ability across plants.
    ‚Ä¢ Concept of defining structures and using the definitions on the incoming data.
    ‚Ä¢ I really like their walkthrough (Implementation guide)
    ‚Ä¢ All config files and docker-compose files are readily available on GitHub (free and open source)
    ‚Ä¢ Running the containers this way is a closer approach to a micro-service type architecture. 
    ‚Ä¢ https://github.com/AMRC-FactoryPlus?tab=repositories


Con's:
    ‚Ä¢ Steep learning curve -> Docker and then Docker Swarm / Kubernetes
    ‚Ä¢ High cost of defining Tag structures up front (Excel tag setup)
        - Need to know the address for polling
        - I assume this only applies to protocols that are not available for Ignition edge (SpB)
    

Improvements:
    ‚Ä¢ Needs more Common Data Structures Definitions (CDS)
        - Current use case for them only includes Robot (generic), CNC, AGV, Tool.
        - Could definitely use some open source help from community (Manufacturer specific Data maps for robots, PLCs, Etc)
    ‚Ä¢ Did not see an accompanying video or diagram overview of architecture?

I expect that @js or @MParris will have more specific utilization questions


I would like to attempt this on a smaller scale, but I would need to find 2 Suitable PCs for ""Server1"" and ""Server2"", since only the edge devices can be Raspberry Pis (hardware requirements)","",""
"194289793905983489","zackscriven","2021-07-14T08:09:15.8890000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659776465534976/unknown-2.png?ex=68df142b&is=68ddc2ab&hm=b2f6bf884509f4d3b1210a0d6cb091f17662b208b8980035f1ebd7676ca75947&","üëç (2)"
"194289793905983489","zackscriven","2021-07-14T08:09:16.5740000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659778549841930/unknown-3.png?ex=68df142b&is=68ddc2ab&hm=3321a39327f6b9623880a01297f5bdfb6c9d365b0cd318e9dc109c9489caa883&",""
"194289793905983489","zackscriven","2021-07-14T08:09:17.1000000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659781428314142/unknown-4.png?ex=68df142c&is=68ddc2ac&hm=6840dfcb9a38d46d06cb6753dea5ca1124b9bf8a8f2dec384650f75bf08691bd&",""
"194289793905983489","zackscriven","2021-07-14T08:09:17.5280000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659782765641729/unknown-5.png?ex=68df142c&is=68ddc2ac&hm=98fa0e4f1104f2146a3384a75443f441bbf7806ddace37eb45a9fbe7d97966c0&",""
"194289793905983489","zackscriven","2021-07-14T08:09:17.8120000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659784736964618/unknown-6.png?ex=68df142d&is=68ddc2ad&hm=0dc203b112a1460d98de1fa0d91be82f2ac386edf077866df259cef7434c9491&",""
"194289793905983489","zackscriven","2021-07-14T08:09:18.0590000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/864659785948725248/unknown.png?ex=68df142d&is=68ddc2ad&hm=322c25e231f6987bce1bb89c0107b6cca067ae1a86f77c1ad712b81536ee220d&",""
"756247672637358181","sherylmccrary","2021-07-14T08:21:35.2630000+08:00","Thanks for these! I was just thinking about asking for them. You read my mind.","",""
"756247672637358181","sherylmccrary","2021-07-14T08:30:33.5120000+08:00","Wait, didn't you say these were McKeon's creations? Even if he doesn't want  Gallarus  on them, at minimum, you should probably add a 4.0 Solutions attribution or logo.","","üëç (1)"
"690557931720015872","rikki7436","2021-07-14T17:36:47.3140000+08:00","Hi, I'm one of the architects of this specification. Thank you for your interest and I completely agree with your comments. We were only 5 people last year, so there were certain things that we couldn't quite achieve in v1.0. In particular, we are not totally satisfied with the CDS's and the limitations of basing these on the OPC UA Information Models. This year, we are rebasing these are looking to establish a central repository of models similar to Eclipse Vorto. Included in this, we want to improve the tag population process and move away from Excel so that populated models can be reused and a lot of defaults pre-populate to minimize the onboarding effort.","",""
"690557931720015872","rikki7436","2021-07-14T17:40:53.4270000+08:00","This year, we are also expanding the deployment of the framework across our organisation in order to improve the scope of device and device type support. This includes involvement of our industrial partners which comprises end users and OEMs - many of whom are keen to implement it and to provide native Sparkplug support from their devices. We hope to open source this model repository once we've fleshed it out a bit and would heartily welcome any collaborators to improve and expand it. Also, message received regarding a clear video or diagram of the overall architecture. I'll ensure we get this added!","",""
"690557931720015872","rikki7436","2021-07-14T17:45:06.4560000+08:00","With regards to the translation app, we initially developed this to fill in the gaps of missing device support in Ignition Edge (especially as we have no Java developers!). However, we think that we can completely replace Ignition Edge in our implementation particularly as we can add support for the model repository mentioned above and keep the whole thing open source (public github release pending).","",""
"690557931720015872","rikki7436","2021-07-14T17:50:41.0280000+08:00","By the way, I'm thrilled to see our work shared here and I'd be delighted to discuss anything about it üôÇ","",""
"817835202746253344","IIoT#4707","2021-07-14T17:50:41.2860000+08:00","GG @Rikki, you just advanced to level 1!","",""
"329780110704246790","rkwadd","2021-07-15T06:03:58.2400000+08:00","@Rikki The Sparkplug mapping is far enough along with MTConnect now that we need input from more users to guide the rest of the development roadmap. We are progressing rapidly and discussing weekly thanks to @Mr IIoT and his company‚Äôs contributions. LMK if we need to move the meeting time to accommodate","","üëç (4)"
"194289793905983489","zackscriven","2021-07-15T11:28:41.2250000+08:00","Yeah it was on there... I should put it back on.","",""
"740383178279354388","mriiot","2021-07-15T21:04:21.4710000+08:00","For sure, real world examples of current SpB use cases are best to guide the roadmap.","","ishocked (1)"
"260594842093092864","y_u_no_python","2021-07-16T00:24:39.0500000+08:00","I think that I am the most curious about this. I didnt see an outline of what you do with the ignition platform other than convert protocols to push up to main server. 

Did you have any visuals of the data or just monitoring node health and throughput?","",""
"690557931720015872","rikki7436","2021-07-16T05:11:11.7770000+08:00","Yes that was principally our use case. In parallel we developed our  own translation app (github repo pending). It was only a small team so we focused our efforts on the nuts and bolts rather than the visualisation. This year, we're building visualisations of our data but using 3rd party software. At present, our visualisations are mainly operational like health and throughput. We did a lot of this work over lockdown and we're not a production facility, so we didn't have reams of meaningful data to visualise.","",""
"194289793905983489","zackscriven","2021-07-20T07:40:09.1360000+08:00","Nice","",""
"767678812699361310","henning8936","2021-07-20T15:39:04.8640000+08:00","@zackscriven Factory+ has popped  up a a couple of times here on the discord. I like their specification and implementation guide. I think this is what a lot of people are looking for: A step-by-step description how to build your I4.0 Ecosystem. Wouldn't it be nice to bring some of the Factory+ guys on the live Q&A do give the community a live demo?","","üëç (4),üíØ (2)"
"194289793905983489","zackscriven","2021-07-20T22:31:12.3660000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-07-20T22:50:03.8670000+08:00","Anyone from Factory+ in here?","",""
"821044538709114900","ianskerrett.","2021-07-20T23:24:19.2160000+08:00","If not, I can find a contact via the Sparkplug working group","","uns (1)"
"194289793905983489","zackscriven","2021-07-20T23:32:24.5290000+08:00","Thank you!","",""
"794020366536146977","mparris","2021-07-20T23:38:59.6090000+08:00","@Rikki Coles from AMRC is here","",""
"585011139767959553","ekion_","2021-07-20T23:59:49.3330000+08:00","@Rikki and myself are co-authors of the framework.","","üëç (3),üëã (3),üßô‚Äç‚ôÇÔ∏è (1)"
"194289793905983489","zackscriven","2021-07-21T00:10:42.1790000+08:00","Thank you!","",""
"588366549203550210","aamer7282171","2021-07-22T09:11:32.4180000+08:00","Hi @henning could you please help to post the link to this guide here ?","",""
"767678812699361310","henning8936","2021-07-22T12:40:02.1640000+08:00","https://factoryplus.app.amrc.co.uk/docs/implementation-guide/about","","üëç (2)"
"588366549203550210","aamer7282171","2021-07-22T22:24:40.0470000+08:00","Thanks","",""
"194289793905983489","zackscriven","2021-07-24T05:06:17.1810000+08:00","Thanks for sharing Henning!@","",""
"194289793905983489","zackscriven","2021-07-25T00:49:29.9130000+08:00","OPC-UA integration into the Azure stack https://youtu.be/QJ1DWTvGQxo","",""
"194289793905983489","zackscriven","2021-07-25T00:49:39.9840000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/868535414410084352/image0.png?ex=68df55e3&is=68de0463&hm=13740b79e07e23370a45aeb1f21a78272868c2f74118262437b0aa7e9b911f4e&","üëÄ (3),üëç (2)"
"753688565807841492","ravil1","2021-07-29T00:08:31.7900000+08:00","The OPC Publisher does not have a configuration GUI and does not have persistent local storage for the messages (that is implementation of the Store and Forward feature is very limited, uses in-memory buffer, which has limited by RAM capacity and is lost when the application restarts ).
ogamma Visual Logger for OPC is a  better alternative, has a Web-based configuration GUI, advanced Store and Forward feature, and great support with responses within hours. 
It is certified by Microsoft as Azure IoT Edge Module and is listed at Azure Marketplace: https://azuremarketplace.microsoft.com/en-us/marketplace/apps/one-wayautomationinc1621632712369.ovlm
With it, you can store data from OPC UA servers not only in Azure IoT Hub but also to other cloud platforms, like AWS, GCP, IBM IoT Hub. 
Or popular time-series databases like TimescaleDB/PostgreSQL, InfluxDB, Apache Kafka/Confluent.","","üòÉ (2)"
"866588009774972928","pyrygronholm","2021-07-30T17:20:01.0900000+08:00","I definetelly have to take a look of this once I'm back from vacation. Store and forward gateway for OPC UA to Azure integration is something I would have needed a couole of times already.","",""
"698244484302897323","lmtx","2021-07-30T17:24:23.6700000+08:00","#deleted-channel everyone is welcome to provide a serverless architecture üôÇ","",""
"753688565807841492","ravil1","2021-07-31T05:37:03.7730000+08:00","This is one of the most often cases of how our customers use our product.
Question: can InfluxDB (optionally complemented by Grafana) be considered as UNS conformant?
Note that using measurements and tags data is organized hierarchically, so it is easy to drill down from top to bottom. And InfluxDB provides stream analytics and notifications capabilities.","https://cdn.discordapp.com/attachments/815945777452941313/870782067473023076/unknown.png?ex=68def07f&is=68dd9eff&hm=c8f26dbce887756cb69f709fca0832c58bfb442783c1a56a7bae31db59eee6da&",""
"194289793905983489","zackscriven","2021-07-31T05:40:19.4530000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-07-31T05:40:25.4070000+08:00","Thank you for sharing!","",""
"753688565807841492","ravil1","2021-07-31T07:12:02.0930000+08:00","This is another deployment case of the ogamma Visual Logger for OPC. 
MQTT topics can be either generated automatically using OPC UA variable attributes,  or configured for each logged variable individually via web-based GUI.","https://cdn.discordapp.com/attachments/815945777452941313/870805968169091112/unknown.png?ex=68df06c1&is=68ddb541&hm=d4aff0ff831fd4b9385f14dd142efad9ef9930a17a2b958c2f06848bc89fe0b2&",""
"753688565807841492","ravil1","2021-07-31T07:17:15.0760000+08:00","Screenshot of the MQTT Explorer - variables from different OPC UA servers published under topics Pump 1 and Pump 2,
Please note also ServerStatus- this is a complex type variable, converted to JSON value.","https://cdn.discordapp.com/attachments/815945777452941313/870807278457065472/unknown.png?ex=68df07fa&is=68ddb67a&hm=b2e89a1cedfb8738e81de816785e9d5c2579eafbc177ca6cddfdceb159fbd9fe&",""
"820097580665929808","pvmagacho","2021-07-31T22:37:08.7890000+08:00","@Ravil I think it cannot be considered an UNS. UNS is the current state of data while Influxdb will hold the history of the data. You need something on your architecture that provided the data to any other system in real time. Your second architecture seems to get closer on implementing an UNS. Just hook influxdb into the MQTT broker and that should be it. With Grafana 8 you can plug into the MQTT broker and the influxdb as well.","","üôÇ (1)"
"820097580665929808","pvmagacho","2021-07-31T22:37:35.6670000+08:00","Also, you will need data structured in your UNS","",""
"753688565807841492","ravil1","2021-08-01T00:21:41.8590000+08:00","@Paulo Vitor, thank you for sharing your thoughts!
Also, another data flow path from OPC UA Servers to Grafana is possible: via ogamma Visual Logger for OPC. With its REST endpoint for Grafana, you can read real-time values or history from OPC UA servers.
Grafana also has its own OPC UA plugin being developed.","",""
"817835202746253344","IIoT#4707","2021-08-01T00:21:42.1670000+08:00","GG @Ravil, you just advanced to level 3!","",""
"801561312861618236","jon.forbord","2021-08-03T21:16:36.6390000+08:00","An example of a UNS architecture utilizing both OPC UA and sparkplug.","https://cdn.discordapp.com/attachments/815945777452941313/872105675784847410/unknown.png?ex=68df23f4&is=68ddd274&hm=42150e58fd9e156035d581b4ba3dda3f69da403618b78fab59b01cc91cab986c&","ishocked (3)"
"830193224504705035","marc.jaeckle","2021-08-03T21:41:41.0330000+08:00","Started a thread.","",""
"753688565807841492","ravil1","2021-08-04T02:16:26.7460000+08:00","@Jon Forbord, thank you for sharing! 
I see that PLCs are not connected directly to the MQTT Broker. I saw somewhere PLCs were connected only to the UNS, and SCADA only connected to UNS, so they would communicate via UNS (in this case MQTT Broker?). Or PLCs could be connected to both SCADA and UNS. Why in your diagram it is not so?
If I am not wrong, Industry 4.0 is also about smart machines, communicating with each other. How machine to machine communication would happen? Would they connect directly to each other, or everything will go via MQTT Broker?","",""
"801561312861618236","jon.forbord","2021-08-04T02:27:24.8850000+08:00","My diagram is typically brownfield. It‚Äôs also a concept drawing, not fine grained or detailed. Just to show how OPC and sparkplug both can have a place in an architecture.","",""
"753688565807841492","ravil1","2021-08-04T03:18:50.9340000+08:00","@Jon Forbord, Does your SCADA already support publishing to MQTT? Or you use some separate connector?","",""
"801561312861618236","jon.forbord","2021-08-04T04:23:04.0250000+08:00","Yes, it supports mqtt/sparkplug out of the box, but that should be fairly easy to deduct, so I sense you have another underlying question/inquiry behind the question?","",""
"801561312861618236","jon.forbord","2021-08-04T04:24:53.5360000+08:00","E.g. are you really wondering if there‚Äôs a market for OPC UA to sparkplug gateways?","",""
"753688565807841492","ravil1","2021-08-04T04:33:13.7510000+08:00","Hi @Jon Forbord, yes, I definitely would like to know is there a market for OPC UA to SparkPlug converter. And not only that - any pain related to OPC UA. 
Also, trying to understand, if OPC UA is not the best option to be a backbone for the UNS,  then, at least, is there any place for it in Industry 4.0 overall and particularly in the  UNS ecosystem as it is visioned by the majority in the community here?
I wonder, can this be qualified as a business development activity here? If so, admins, please let me know.","",""
"766684226455207996","bright_hummingbird_31342","2021-08-04T04:39:25.2860000+08:00","There all sorts of ways to handle brownfield.  Sometimes SCADA is the native driver gateway, UNS, and broker together.  Sometimes the functions are broken out with dedicated tools.

[S7 PLC] <- native S7 protocol -> [KepServerEx] <- OPC-UA -> [HighByte IH] <- MQTT SpB -> [CL Chariot (Broker)]

[AB PLC] <- native E/IP protocol -> [KepServerEx] <- OPC-UA -> [HighByte IH] <- MQTT SpB -> [HiveMQ (Broker)]

[Modicon/Schneider PLC] <- native Modbus TCP -> [Ignition SCADA driver module] <- MQTT SpB -> [Ignition Distributor Module (Broker)]

[Fanuc Robot] <- native GE-SRTP -> [Maple Systems CMT SVR] <- MQTT SpB -> [Factory Studio]","","üëç (3)"
"766684226455207996","bright_hummingbird_31342","2021-08-04T05:06:24.8050000+08:00","OPC-UA could theoretical serve as a backbone of a UNS, but there are virtually no products available on the market that support OPC-UA pub/sub.  99% of connections would be OPC-UA client/server.  I don't even think there are pub/sub gateways on the market that would enable one to move client/server to the edge.  One would probably want to stand up an OPC-UA discovery server too.  And, for a lot of applications (e.g., ERP, MES, CRM, HCM, SCM), they don't have UA interfaces.  And when they do, they're often incomplete.  They don't necessarily expose everything in the data model that one might need.  Thus, one will need to develop their own UA interface.  One is stuck either self-implementing advanced information modeling (e.g., companion specs, methods) or trying to ""shoehorn"" these complex apps into the Data Acccess (DA) data model.  Either way, it's cost prohibitive.

One would be better off leveraging a REST client within something like HighByte or Ignition to facilitate integration to publish/subscribe into the UNS + Broker.  Yes, there is some engineering effort involved organizing a node's namespace to publish into the UNS.  But, it only has to be done once.","","üíØ (2),üëç (1)"
"382941357699760129","walker.reynolds","2021-08-04T20:12:12.9550000+08:00","We have built this gateway already... you may have seen us discuss it a few months back.  We stopped talking about it publicly because HighByte is almost certainly going to develop the functionality.  The gateway is consumes a full OPC-UA namespace and converts it to SPb or an MQTT 3.1.1 or MQTT 5 namespace and publishes to a broker -- it literally has just 4 fields to fill out and its off and running.","","üòÄ (2),highbyte (3),üëç (1)"
"801561312861618236","jon.forbord","2021-08-04T20:22:26.4580000+08:00","mhm.. I saw it. It sounds awesome. I'm very curious to hear more details about it.","",""
"382941357699760129","walker.reynolds","2021-08-04T20:35:55.0900000+08:00","Great answer -- great examples -- 100%","",""
"382941357699760129","walker.reynolds","2021-08-04T20:42:38.9650000+08:00","Ravil -- there is a place for OPC-UA, yes, but as it stands right now their place is limited to the edge.  There are flaws with Part 14 (Pub/Sub) that can be tied directly back to the technical debt inherent in the original UA standard that limit OPC-UAs impact in IIoT without a re-visiting of the standard.  OPC-UA tries to be everything to everyone and, as such, it really isn't any specific thing to any specific user.  We need changes to Part 14, we need wider adoption of the complete standard (once it gets 'fixed') and then maybe we will see a broader place for OPC-UA in I 4.0 applications.  Until then... companies early on in their DT journeys will start with OPC-UA as their backbone and then hit critical mass (like everyone does) and be forced to pivot to edge driven, lightweight, OA standards and protocols like MQTT SPb.  @MParris does a great job in LinkedIn long-form posts of breaking it down and suggesting improvements.","",""
"382941357699760129","walker.reynolds","2021-08-04T20:47:44.7910000+08:00","I've also shot several videos on our channel that break it down as well, but at a high level for a broad audience.","",""
"753688565807841492","ravil1","2021-08-05T01:20:30.5860000+08:00","Hi @Walker Reynolds, 
Thank you for sharing your feedback! Glad to hear that there is still a place for OPC UA, as an OPC UA guy, that is important for me personally for my future career planning.
Would be great if you could share what changes in Part 14 would make it better. I can convey them to the working group.","",""
"194289793905983489","zackscriven","2021-08-13T13:41:58.1610000+08:00","We cover this in the video series we shot for covering OPC-UA in detail.","",""
"194289793905983489","zackscriven","2021-08-13T13:42:06.6320000+08:00","Stay tuned üëç","",""
"753688565807841492","ravil1","2021-08-13T13:47:59.2660000+08:00","Thanks, Zack!
I am leaning towards the conclusion that actually the question is not ""which one is the best: OPC UA regular subscriptions or OPC UA Pub/Sub, or MQTT with plain payload, or MQTT with SparkPlug"".  They are not mutually exclusive.  It all depends on the specific project requirements.
I see that Siemens PLC S7-1500 supports both MQTT publisher and OPC UA server features. It confirms that there are different use cases when one or another or both are required.","","‚ù§Ô∏è (1),packiot (1),üëè (1)"
"382941357699760129","walker.reynolds","2021-08-13T20:10:03.5440000+08:00","Agreed -- OPC-UA has a place in IIoT and it is best on the edge.  Where OPC-UA starts to struggle is as you move up the stack, RE: scalability, security, time to value, impact on infrastructure, total cost of ownership.  For the executive, OPC-UA becomes difficult to scale, makes us vulnerable (client/server, even in a Purdue stack, requires inbound ports to be opened up), takes too long to integrate, has a bigger impact on our network performance and it costs a lot.  For the engineer, OPC-UA creates technical debt and puts limitations on what we can build at scale as we move it up the stack.  The closer to the edge you get, the more the strengths of OPC-UA have impact (assuming product developers actually build the stuff Industry 4.0 engineers need leveraging the strengths of the standard -- eg. information modeling).  I don't like pitting OPC-UA and MQTT against one another and I don't recommend people do that... (even though I sometimes do this myself).  I prefer we say they are siblings in an ecosystem -- siblings who know their place.  I think the OPC Foundation and the members of the group who treat OPC-UA as a religion do themselves a great disservice (and the community at large) when they simply dismiss objections and alternatives of OPC-UA as simply a function of an ignorant group of engineers who don't 'really understand' OPC and its power.  I believe this for two reasons -- its fairly simply to empirically validate all of my positions here (and we have many, many, many times) AND there isn't a single example of a previous OPC-UA evangelist (for Industry 4.0 and IIoT) who has not done the deep dive on OPC-UA and MQTT use cases and come to the exact same conclusions the brilliant engineers and developers in this community (and thousands more across the globe) have.","","aws (1)"
"794020366536146977","mparris","2021-08-14T01:08:45.2930000+08:00","@Ravil I agree with your conclusions.  Industry 4.0 (on the plant floor) is made up of two protocols at this time: OPC-UA DA and SparkplugB.

When @Walker Reynolds states that OPC-UA is not the future of IIoT, it should be understood with the following perspective:

IIoT is a new ecosystem running at the enterprise level and can be included at every layer of the manufacturing business (PLC, HMI, SCADA, MES, ERP, other). 
 Think of IIoT as a bubble, where a device/application can be inside the bubble or outside the bubble, AND it is perfectly acceptable for devices/applications to be outside the bubble; not everything will be in the bubble.   This bubble is truly the internal Internet of the business with Things intercommunicating in a scalable manner.

Given this vision of IIoT, will OPC-UA Client/Server Data Access serve as the backbone of this new ecosystem?  The answer is no (and I think you would agree).  Is OPC-UA DA obsolete because of Sparkplug?  The answer is ""absolutely not"".  In my opinion, OPC-UA DA is the preferred protocol to get data into the IIoT bubble through gateways and those OPC-UA servers should live as close as possible to legacy devices/applications.  Some PLCs include Sparkplug support natively, but even this does not mean that it must be part of the IIoT bubble for a given architecture; a deployment maybe is better served using the OPC-UA interface of the PLC instead of sparkplug for various reasons.  This is where architecting solutions comes into play and there are a lot of variables that will drive the designs one way or another.","","üíØ (3)"
"753688565807841492","ravil1","2021-08-14T01:47:13.7440000+08:00","@Walker Reynolds,@MParris, thank you for your posts! 
BTW, who asked this question at the very beginning: ""will OPC-UA Client/Server Data Access serve as the backbone of this new ecosystem""? And who said ""Yes""?
And who stated that ""OPC UA is the future of IIoT""?
I mean, did OPC Foundation or any OPC UA expert say ""never use MQTT or SparkPlug, because OPC UA is superior""?","","ismile (1)"
"382941357699760129","walker.reynolds","2021-08-14T01:54:24.7040000+08:00","Yes... Microsoft, Rockwell, et al communicate this time and time again to clients... We were forced to respond to some of the things they were telling their (and our) customers.  The very first video, way back when, was a public response to that.  These companies are still designing architectures built on OPC-UA that do not scale (and the client finds out when it's too late) and we are still coming behind and re-architecting with IIoT MTR and protocols/standards to get them over the hump.","",""
"753688565807841492","ravil1","2021-08-14T02:52:08.6730000+08:00","Yes, I agree that if a project was won by giving wrong, misleading information to the customer about competing technologies/products/companies, and by false promises about the offered products, this should have consequences.
In turn, customers should do their due diligence on making strategic decisions and selecting the right partners and technologies. I thought they do that, they consider multiple possible architectures and then select the one suitable best up to their requirements.
I see now the reason for your statements and the response. 
I think it triggered something in my mind and I ended up in this discussion forum because you used the same alleged tactics and started doing exactly the same, just replacing OPC UA with MQTT and vise versa.","",""
"756247672637358181","sherylmccrary","2021-08-14T03:13:11.2820000+08:00","So after all of your coversations in this forum, do you still feel @Walker Reynolds and the 4point0 Solutions community are giving out false information about OPCUA?","",""
"382941357699760129","walker.reynolds","2021-08-14T03:22:24.8100000+08:00","Great point, Ravil.  I had an epiphany 8 or 9 years ago in my career.  It became more and more clear to me that as Industry 4.0 was emerging, end-users were less and less equipped to complete due diligence on their own and that is one reason they were bringing in consultants to steer them in the right direction.  Some consultants saw themselves as brain surgeons with a moral obligation to tell the client was is the best option for prolonging their life, and some consultants saw an opportunity to capitalize on their client's ignorance.  This community is made up of professionals who consider themselves the former (the Brain Surgeon).  We focus on best in class, optimal architecture, long-game approaches to manifesting digital strategies... As the community grows, the industry will invariably shift its mindset as well.  I appreciate your contribution to this conversation, I really do.  The architectures we advocate for are based on results, experience and theoretical analysis.  I find that anyone who does the same deep dive that we have, always comes to the exact same conclusions -- and clarity ensues.","","üëç (4),üíØ (1)"
"753688565807841492","ravil1","2021-08-14T04:03:52.9970000+08:00","@SherylMCertainly, discussions here helped me realize that a lot of nice features that OPC UA has as a specification are not used due to the lack of real products available in the market. And I see that there are many use cases when MQTT with or without SparkPlug is preferred over OPC UA.
At the same time, I strongly don't agree that OPC UA is not open, is not reported by exception.
And although MQTT is lighter than OPC UA, it does not mean that OPC UA is prohibitively heavy in most cases. 
About not being ""Edge driven"": this is not completely true, considering that in OPC UA, there is a ""reverse connection"" feature when the TCP connection is opened by OPC UA Server, so there is no need to open a single port in the firewall. I have to admit though that it is not always supported. In the latest version 1.04 of the spec, it must be supported by clients and servers of all profiles (even in Nano).","",""
"753688565807841492","ravil1","2021-08-14T04:33:51.6680000+08:00","@Walker Reynolds, 
In the case of my small company, customers contact us when they have already decided to use OPC UA. Discussions here give me a lesson - perhaps I have to ask the customer why they choose OPC UA in the first place and verify if it is really best suited for their use case.","","üòä (2),ismile (1)"
"756247672637358181","sherylmccrary","2021-08-14T04:36:00.0690000+08:00","Thank you for your full and honest response, Ravil. This is helpful to those of us communicating with customers as to how we can communicate better relative to their needs. 

Ultimately, we want to help people, not make a sale at any cost.","","üíØ (1)"
"382941357699760129","walker.reynolds","2021-08-14T05:32:08.2340000+08:00","@Ravil  RE: ‚ÄúAbout not being ""Edge driven"": this is not completely true, considering that in OPC UA, there is a ""reverse connection"" feature when the TCP connection is opened by OPC UA Server, so there is no need to open a single port in the firewall. I have to admit though that it is not always supported. In the latest version 1.04 of the spec, it must be supported by clients and servers of all profiles (even in Nano).‚Äù
‚ÄîCould you expand on this a little bit?  When we say edge driven, we mean that the ‚Äòthing‚Äô where the data originates (eg. PLC) is simply configured to point to the broker/server and report its data by exception to a location in the namespace for other nodes to consume.  The ‚Äòthing‚Äô can also subscribe to topics in the namespace through that same stateful outbound connection it instantiated.  How do we do that same thing with an available tool with the OPC label on it?  I am familiar with the reverse connection feature but that requires an edge opc client to instantiate which doesnt currently exist on-board with many industrial hardware (maybe Beckhoff?) devices and would require pub/sub to be implemented to get the same results.  I agree that 1.04 took some great strides forward, fyi, but Im still not seeing the tools I need via OPC to implement the solutions we build‚Ä¶ even if I were willing to accept heavier overhead and paying a premium for the OPC tool.","",""
"329780110704246790","rkwadd","2021-08-14T06:05:43.1190000+08:00","Customers who standardize on OPC, or on MTConnect (my employer), or on anything else very often want to be able to say that they‚Äôve picked a standard so now they are done. but it doesn‚Äôt work that way, which is why there are #reference-architectures in the first place.","","üëç (1)"
"753688565807841492","ravil1","2021-08-14T06:21:08.2720000+08:00","The OPC UA client application UA Expert and OPC UA Demo Server, both from Unified Automation, support the reverse connection feature. Prosys OPC UA products support it too. 
In this scenario, the OPC UA client (UA Expert in this example) acts similar to what the MQTT broker does - listens on some port. 
You configure in the server-side the address of the OPC UA client, similar to how you configure the publisher. 
When the new server is configured, the client detects it, and it does appear in the list of servers. 
What is different than MQTT, in UA Expert you need to select that server node and initiate a connection, create a subscription, and monitored items.
The UA Expert is a demo application. In a real application if you want it is possible to automatically discover all tags and subscribe to them and start getting data values automatically, at the rate as you want, with deadbands as you want, etc. Also, you can use the same connection for bidirectional communication too, each side can be a server and client at the same time, that is the server can send requests, why not. The spec perfectly allows that. 
This way you can build OPC UA federating/aggregating server, which potentially can have all the features you would have with MQTT Broker. 
Would you or not, that is a different story :).","",""
"753688565807841492","ravil1","2021-08-14T06:24:10.1580000+08:00","Here is UA Expert screenshot.","https://cdn.discordapp.com/attachments/815945777452941313/875867352053456946/unknown.png?ex=68defb89&is=68ddaa09&hm=1706ff40b37757ff415ab4106151db0b3325ca97742142bb29b685c8f30df838&",""
"382941357699760129","walker.reynolds","2021-08-14T06:33:08.1660000+08:00","Right‚Ä¶ server on the edge?  Thats what I thought you were saying.  What you have described is not an optimal architecture for all of the reasons Ive listed above in previous posts.  I would recommend conversion at the edge.  Optimal here is conversion of OPC-UA to MQTT on the edge for integration to the UNS.  Costs less, short time to value, less overhead, lighter weight, can use free tools and it scales while supporting self awareness.","",""
"382941357699760129","walker.reynolds","2021-08-14T06:34:18.1830000+08:00","We leverage UA Expert in legacy infrastructure ‚Äî I like the tool.","",""
"817835202746253344","IIoT#4707","2021-08-14T06:34:18.4540000+08:00","GG @Walker Reynolds, you just advanced to level 13!","",""
"382941357699760129","walker.reynolds","2021-08-14T06:42:09.0290000+08:00","@Ravil I was an OPC guys for the first 13 years of my career ‚Äî Matrikon, Kepware et al.  I hadn‚Äôt heard of MQTT until 2013.  Since that time, I have architected some of the largest systems in the world and have been awarded accordingly, leveraging MQTT and a Unified Namespace (a term I coined) for the enterprise infrastructure.  I think its important to keep in mind that at scale, optimal becomes critical.  Small deltas in samples (like 120kb every 5 minutes) becomes critical mass at scale.  Industry 4.0 means that there is no such thing as a standalone project, siloed architecture‚Ä¶ all projects (iterations  in Industry 4.0) are one part of a bigger whole.  To achieve scale, 1. Define digital strategy 2. Design enterprise architecture 3. Pick PoC 4. Build UNS 5. Iterate.","",""
"382941357699760129","walker.reynolds","2021-08-14T06:42:34.3550000+08:00","I think its important to keep in mind the types of solutions we are building","",""
"753688565807841492","ravil1","2021-08-14T06:42:43.3060000+08:00","The OPC UA server (for example PLC) stays wherever it is. Instead of publishing data from over MQTT to the broker, you use the Gateway OPC UA server (which is also the client), instead of the MQTT Broker. I believe the gateway server from Unified Automation supports the reverse connection. 
So, no open ports to the lower level server, just like with MQTT. 
And then you can install gateway servers in layers, up to the cloud. Whatever level you can get outbound connections from the network where OPC UA Server is running, there you can put the gateway server.
I agree this might be more complicated, more configuration than MQTT. 
In return, you might not need any additional integration tools from the consumers. For example, most SCADA/HMI systems can consume data over OPC UA, so they would be already integrated without any additional programming. 
On another hand, they often have MQTT connectors too.","","üëç (1)"
"382941357699760129","walker.reynolds","2021-08-14T06:45:28.2170000+08:00","Over time, the bifurcation between localized automation projects and enterprise class digital transformation projects will close tightly.  Its important we design architectures now that dont need to be refactored when that happens.","","üëç (2),üëè (1)"
"382941357699760129","walker.reynolds","2021-08-14T06:45:52.3930000+08:00","Have a great weekend, brother.  Great back and forth.","",""
"753314779883503618","arunsinha","2021-08-14T07:16:18.5900000+08:00","We have this new tool online for building reference architectures (granted the h/w graphics are Opto-specific...). Handy tool, please check it out and feedback is welcome: https://www.opto22.com/support/resources-tools/demos/groov-epic-groov-rio-architecture","","ismile (1),üëç (2)"
"817835202746253344","IIoT#4707","2021-08-14T07:16:18.8980000+08:00","GG @Arun Sinha, you just advanced to level 2!","",""
"801561312861618236","jon.forbord","2021-08-14T15:11:35.1100000+08:00","Anyone here familiar with TOGAF, Gartner or other enterprise architecture frameworks? Are these useful to study for an industry 4.0 professional? 

https://youtu.be/Bd4LH_nTaAw","","ismile (1)"
"740383178279354388","mriiot","2021-08-14T20:20:56.9760000+08:00","I think understanding of enterprise architectures is essential because some of the topics discussed here will have fundamental business impacts.  I have always found this to be a good resource https://caminao.blog/about/","",""
"820097580665929808","pvmagacho","2021-08-17T20:12:34.1580000+08:00","Hello. It's often said that Tesla is a benchmark in I4.0. Is there any documentation on how it was implemented? I remember someone saying that Tesla has this information available to anyone. If I am wrong, please let me know as well. Thank you","",""
"818886317403668492","kirtanderson","2021-08-18T00:24:16.0940000+08:00","Go find Colin Breck on Linked In. He was instrumental in much of it and is generally pretty available.","",""
"194289793905983489","zackscriven","2021-08-18T00:31:37.0070000+08:00","Pinned a message.","",""
"820097580665929808","pvmagacho","2021-08-18T20:16:31.0170000+08:00","Hi, was this an answer to my question? If yes, there are many Colin Becks in LinkedIn.","",""
"820097580665929808","pvmagacho","2021-08-18T20:20:31.5480000+08:00","Sorry. my mistake. I just misspelled it ü§£ .","",""
"820097580665929808","pvmagacho","2021-08-18T20:20:37.9770000+08:00","Thank you @Kirt Anderson","",""
"571815818308878347","binyameen_980","2021-08-19T01:20:00.2680000+08:00","Only one of them mentioned Tesla in his profile","",""
"795178288330440704","youri.regnaud","2021-08-19T14:12:42.8830000+08:00","Is anyone using or thinking of using Litmus and Highbyte in same architecture?","",""
"766684226455207996","bright_hummingbird_31342","2021-08-19T22:51:55.4540000+08:00","Great question for @Omar.","",""
"740365995419631736","omarazizahmed","2021-08-19T23:10:43.3200000+08:00","I've worked at both companies. üòÇ .","",""
"740365995419631736","omarazizahmed","2021-08-19T23:10:58.2240000+08:00","Both great products but we haven't come across customers using both.","",""
"740365995419631736","omarazizahmed","2021-08-19T23:12:08.2690000+08:00","Litmus has great capabilities with Edge ML and Edge Analytics...I would recommend people to look at Litmus for Edge Calculations.","",""
"382941357699760129","walker.reynolds","2021-08-20T03:31:38.9670000+08:00","One step further on Omar‚Äôs recommendation‚Ä¶ Litmus uses some really cool technology to develop new hardware drivers faster than anyone else in the market‚Ä¶ its a very interesting solution.","",""
"795178288330440704","youri.regnaud","2021-08-20T12:11:38.1410000+08:00","My fear is to not have enough flexibility with this solution in case the driver is not available and Litmus has no interest to develop it because it is very specific equipment (watch industry devices) Any recommendations on this subject?","",""
"740383178279354388","mriiot","2021-08-20T19:16:31.9670000+08:00","Now I am curious to know how watches are made.","",""
"519666539436310529","aristotelestn","2021-08-20T19:26:13.4080000+08:00","Hi Guys, I would like some help from you. In electrical automation, when you have IEDs on a 61850 network without an RTU, how do you collect the data? Direct in SCADA or have I inserted a gateway on the 61850 network for MQTT? (I think I sent it to the wrong channel before, sorry about that)","",""
"820097580665929808","pvmagacho","2021-08-20T21:24:32.0950000+08:00","Use KepwareEx to read IEC61850 MMS data","","üëç (1)"
"329780110704246790","rkwadd","2021-08-20T21:39:56.1800000+08:00","The manufacturing or assembly task for watchmaking can be specialized but still use mass market controls. Can‚Äôt address the driver support concern without knowing more about the equipment.","",""
"329780110704246790","rkwadd","2021-08-20T21:43:35.1200000+08:00","For example a 6 axis industrial robot arm might use custom built end of arm tooling but the robot arm is still an off the shelf product with corresponding level of driver, software, and connectivity* support


*these robots have horrible connectivity support üòî","",""
"795178288330440704","youri.regnaud","2021-08-20T22:03:49.3400000+08:00","The manufacture of luxury watches is a mixture of standard industrial technologies (machining, turning, stamping, ...), advanced know-how in the field of polishing and precision in the assembly of movements and watches. The richness of this activity is to mix advanced technologies and traditional know-how","","ishocked (1),ü§ô (1)"
"519666539436310529","aristotelestn","2021-08-20T22:34:00.2970000+08:00","Thanks, I'll take a look.","",""
"795178288330440704","youri.regnaud","2021-08-23T12:42:13.1100000+08:00","Is AWS Outposts can be use to host Highbyte at Edge https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/highbyte-intelligence-hub-industrial-dataops-on-aws-ra.pdf?did=wp_card&trk=wp_card?","",""
"817835202746253344","IIoT#4707","2021-08-23T12:42:13.3890000+08:00","GG @youri.regnaud, you just advanced to level 4!","",""
"821044538709114900","ianskerrett.","2021-09-02T19:52:34.9310000+08:00","Netflix recentlty published a technical article describing their new device management platform for remote testing. The architecture is based on MQTT and Kafka. There are often questions about MQTT and Kafka here so I thought it might be of interest. https://netflixtechblog.com/towards-a-reliable-device-management-platform-4f86230ca623","",""
"579012995154182163","stuxnetza","2021-09-04T00:02:09.8160000+08:00","Hi All, I remember there were some discussion or even a video from @Walker Reynolds about API calls vs. MQTT / Event driven approach, can someone please point me in the right direction? I am in discussions here about why we should use MQTT if we already have discrete APIs between our applications.... I can list a few advantages, but some other opinions also help... Thanks","",""
"745796393855352953","thedavidschultz","2021-09-04T00:59:39.9000000+08:00","API calls require knowledge of the data available. If new information is available at the endpoint, all API calls need to be updated. API calls are also poll/response which means data may not be in real-time. Because MQTT and the payload is defined by the client, all data is published and is always current.","","üíØ (2),üëç (3)"
"756247672637358181","sherylmccrary","2021-09-04T01:04:04.6060000+08:00","This video may be useful to you, too. https://www.youtube.com/watch?v=4yG-wWpONJE","","üëç (2),üíØ (2)"
"801561312861618236","jon.forbord","2021-09-04T06:02:18.0010000+08:00","My 2p: APIs are point to point, and as David mentioned not automatically updated if new data points are added to the nodes. When you‚Äôre transforming a business, you also need to build an architecture than can scale and keep up with the business as it changes (and new use cases). You may not start by replacing all discrete API connections, but over time you should replace most of them, if you want to build the business of the future. Example, you add another system to your business, and it needs data from 3 other systems, with APIs that‚Äôs three more discrete connections. With UNS you just point the new system to the UNS and subscribe to the relevant topics, plus publish back any new data created by the system for other systems to consume.","","üíØ (3)"
"382941357699760129","walker.reynolds","2021-09-04T06:03:23.6860000+08:00","Spot on","",""
"579012995154182163","stuxnetza","2021-09-04T06:26:18.0780000+08:00","@SherylM @Jon Forbord @DavidSchultz Thanks for your input. It will be an interesting discussion moving forward. We are using Mulesoft for all of our application API management, perhaps as a starting point I can convince IT to use Mulesoft to publish to MQTT when an API call was made, this would avoid us to change any applications right now, and slowly migrate towards MQTT in future releases. Let's see... üòâ","",""
"194289793905983489","zackscriven","2021-09-08T05:08:15.9100000+08:00","Any advancements on this?","",""
"579012995154182163","stuxnetza","2021-09-08T05:27:30.6830000+08:00","Not yet, been facing pushback, but will just demonstrate how MQTT works in the next couple of weeks, that should get their attention :). Keep you guys posted...","","4point0 (1)"
"740317294584004680","vaughnturner8478","2021-09-08T05:28:23.0650000+08:00","Awesome thanks","",""
"814834194278645760","damiansmektala7371","2021-09-10T22:57:16.8800000+08:00","Hey Youri. Damian here, I head up the Litmus sales team. RE your question on drivers - providing easy connectivity to all industrial assets was the core technology this company was built on! Whenever we run into something we don't have a driver for, we develop it and integrate into the next release of the product so all customers can take advantage of it. On the rare occasions where it is truly a one-of-a-kind application, we will charge a small fee to create the driver for the customer. Hope that helps üôÇ","","4point0 (1)"
"795178288330440704","youri.regnaud","2021-09-10T23:01:50.3440000+08:00","Why don‚Äôt let your customer build custom/niche drivers with SDK, ‚Ä¶ if there is no interest for over customers?","","üëç (1)"
"194289793905983489","zackscriven","2021-09-12T00:15:57.6690000+08:00","Thanks for sharing Ian!","",""
"194289793905983489","zackscriven","2021-09-12T00:16:35.0450000+08:00","Thanks for chiming in!","",""
"783917475128410112","geoffnunan","2021-09-13T12:58:48.7300000+08:00","Hi @Jon Forbord  I am certified with TOGAF and use it extensively within Industry 4.0, particularly as a consultant. Happy to help if you have specific questions","",""
"817835202746253344","IIoT#4707","2021-09-13T12:58:48.9530000+08:00","GG @GeoffNunan, you just advanced to level 2!","",""
"783917475128410112","geoffnunan","2021-09-13T13:04:16.1810000+08:00","All of the challenges you mention with APIs are addressed by GraphQL, which also has the benefit of being queryable, which MQTT does not.","",""
"745796393855352953","thedavidschultz","2021-09-13T19:44:15.1670000+08:00","With MQTT supporting a UNS architecture, I don‚Äôt need to query. I already have the answer. üòâ","","üíØ (2)"
"801561312861618236","jon.forbord","2021-09-13T22:41:32.5930000+08:00","As I understand TOGAF very high level and abstract and basically ensures that software dev/ integration within very large companies are according to the goals of the business. It says nothing about architecture itself, nor technology. Would you recommend it for small to medium sized manufacturers?","",""
"836165501989945345","billliu4646","2021-09-14T03:14:16.8660000+08:00","I am not an expert in GraphQL, but you can subscribe and publish an object like in Sparkplug B. It's probably not as ""light weight"" as MQTT but more powerful with its query language than the wildcards in MQTT. Not sure if there is a ""last will"" mechanism in GraphQL, but I think the same can be achieved through an extension of the protocol.","","üòÄ (1)"
"817835202746253344","IIoT#4707","2021-09-14T03:14:17.1980000+08:00","GG @Bill Liu, you just advanced to level 1!","",""
"783917475128410112","geoffnunan","2021-09-14T12:07:06.0060000+08:00","Thanks for the question @Jon Forbord. You are right, TOGAF does not specify specific architecture patterns or technology. It's an Enterprise architecture framework, not a reference architecture. Enterprise architecture is the umbrella that covers 4 different architecture viewpoints, Business Architecture (What, why and how is my business serving it's customers), Information Architecture (What information drives by business ), Application Architecture (How do the various applications work together enable business capabilities) and Infrastructure Architecture (What foundation infrastructure are my applications built on). TOGAF then wraps those 4 viewpoints with some guidance on managing the various different types of requirements, governing the architecture and managing change. 
Businesses don't realise that they need Enterprise Architecture, and it often feels intangible specifically when used to specific project work.
TOGAF is a framework for Architects, not for developer. Think about Architects who design buildings to work for the owners or people who have to live in the building. They will approach their work with a different set of needs to the builders who construct the building. Builders have codes they must follow, whereas Architects have a vision they strive to realise.

Remeber: You cannot decide to not have an #architecture for your system. If you don't actively create it, be prepared to live with the one that emerges.","","üëç (2)"
"783917475128410112","geoffnunan","2021-09-14T12:13:46.1820000+08:00","GraphQL is not a replacement for MQTT, they are different but complimentary. MQTT (Message Queue Telemetry Transport) was specifically designed as a light-weight publish/subscribe integration for small messages (Telemetry). GraphQL was designed to solve the problems of REST API by providing one single API that allows the consumer to define the data they want to access or change.
MQTT provides basic topic filtering with wildcards, but is a rigid structure that provides access to a payload that is determined by the producer.","",""
"783917475128410112","geoffnunan","2021-09-14T12:16:14.2840000+08:00","GraphQL provides a query language to access and subscribe to data where the consumer decides which data they want, and what should be included in the payload.

GraphQL is not for device connectivity, it is the API that sits between the front-end application and the backend application. MQTT sits between backend applications.","",""
"783917475128410112","geoffnunan","2021-09-14T12:18:25.9490000+08:00","This article provides an example of how MQTT and GraphQL should work together in an IOT Application https://medium.com/swlh/chasing-drones-with-mqtt-graphql-497ed8c90e32","","üëç (3)"
"836165501989945345","billliu4646","2021-09-14T16:41:38.5590000+08:00","Correct me if I am wrong. My understanding is GraphQL can fallback to standard HTTP(S) for compatibility with older browsers or restrictive network environments. There are plenty of GraphQL libraries around for every popular web framework. MQTT client libraries for the browser exists but are hard to find. HiveMQ has a demo: http://www.hivemq.com/demos/websocket-client/","",""
"756247672637358181","sherylmccrary","2021-09-15T02:09:21.8200000+08:00","""You cannot decide to NOT have an #architecture for your system. If you don't actively create it, be prepared to live with the one that emerges."" True, true. Also true of business processes. They are rarely designed or reviewed but emerge as the steps people have to go through to do their jobs, however inefficient.","","üëç (3)"
"756247672637358181","sherylmccrary","2021-09-15T02:34:29.8310000+08:00","This---Enterprise Architecture umbrella---is a really useful framework for thinking about #digital-transformation  because Industry 4.0 effects and requires radical changes in all four of these areas: 
- how you serve customers, 
- the info that drives your business, 
- how your apps interact, 
- the infrastructure you need.

Think of the impact on the Information Architecture question alone (What info drives my business?). The answer to that is the very definition of Ind 4.0, the now possible availability of single source of truth, state of the business, in every moment and in predicted near future. This information is not possible or even imaginable with 3.0 technology.","","üëç (4)"
"783917475128410112","geoffnunan","2021-09-16T05:18:33.1890000+08:00","üíØ","",""
"219966967480582144","richardphi1618","2021-09-16T20:41:59.7210000+08:00","> If Sparkplug could be extended to allow more than 1 topic level for ""groupID"", then all the statically defined pub/subs for Site1 would be replaced with just one dynamic pub/sub: ""spBv1.0/E1/S1/#"" and this one pub/sub would accommodate any future Area or WorkCenter added in the future.
This would be my ideal. Is there an argument against doing that today. (outside of it doesnt adhere to the standard 100%)","",""
"794020366536146977","mparris","2021-09-16T20:52:29.5610000+08:00","The only argument is that it wouldn't work with spBv1.0 devices   So if you go that route, you shouldn't use that keyword as your first topic.

Also, the challenge you will have to overcome going that route is how will your applications know how far down the topic tree to go before it hits the true payload, and can then start to parse it for data.

The current topic structure is fixed so subscribing applications know to expect 4-levels to encounter a Node's payload and 5-levels to encounter a device payload. So subscribing applications are hardcoded how to get the data.","",""
"794020366536146977","mparris","2021-09-16T20:53:27.4720000+08:00","Do you have any ideas how to overcome the challenge of applications knowing the number of topic levels before encountering the payload topic?","","üëÄ (1)"
"219966967480582144","richardphi1618","2021-09-16T21:23:44.3580000+08:00","knowing what level you are in the ISA stack should help with this some, but having nested topics is not the end of the world from a programming standpoint. Why have wild cards as a feature if you are not going to use them (security being its own topic of discussion and the risk wildcards bring there I think is the only valid argument I have heard so far, but again if managed shouldn't be a problem).","",""
"219966967480582144","richardphi1618","2021-09-16T21:24:46.2750000+08:00","I would want to be able to pull all of my data based on where in the ISA stack I want to pull from. something like e/s/w/#","",""
"219966967480582144","richardphi1618","2021-09-16T21:31:40.0780000+08:00","also the programming I have done here the json object comes over looking like this:
```json
{""topic"":""e/s/w/machine"",""payload"":""1631799075324"",""qos"":0,""retain"":false,""_msgid"":""46c25e2ccd7e9ae8""}
```","",""
"794020366536146977","mparris","2021-09-16T21:32:15.1080000+08:00","So if an application subscribes to the entire new namespace (spCv1.0/#)  when a two publishes come in:

1) spCv1.0/e/s/w/NDATA/<nodeID>
2) spCv1.0/e/NDATA/<nodeID>

That your idea is for the subscribing application to parse the topic of any incoming publish until it hits the NDATA keyword, then know the next level below that is the <nodeID> with the actual data?","",""
"219966967480582144","richardphi1618","2021-09-16T21:32:21.0920000+08:00","you would just need to interpret the topic on the application side. Not exactly a nested json object with traversal issues","",""
"219966967480582144","richardphi1618","2021-09-16T21:33:43.1180000+08:00","If I was developing an application that was looking at the entire enterprise (or specific enterprise) in your example. yea. More specifically though if I wrote an application to only look at a site or workcenter I can just change the subscription accordingly and I'm not having to manage the traffic of everything coming in on spCv1.0/#.","",""
"219966967480582144","richardphi1618","2021-09-16T21:35:36.0560000+08:00","the data pipeline would be cleaner to setup imo. I'm not trying to pretend I know better. I'm just trying to get an idea on why is it the way it is.","",""
"219966967480582144","richardphi1618","2021-09-16T21:36:21.8150000+08:00","but my thought would be topic == where did this come from and payload == what is it (modeled data with value+ machine model)","",""
"219966967480582144","richardphi1618","2021-09-16T21:39:04.6340000+08:00","your original description of a topic as ""spBv1/e1-s1-w1/nodeID"" seemed like the samething while not letting you leverage wildcards. (again whether or not wildcards are the devil as some cyber security professionals would say I will stay out of it)","",""
"794020366536146977","mparris","2021-09-17T02:41:10.1410000+08:00","I don't know why the static groupID came from, but the fact that this was developed primarily for a local scada system likely provides the context for why some of it is the way it is.

Even subscribing to the site, your application for spCv1.0 would have to parse the topic dynamically and lock onto the keyword to know how to handle the payload.

Don't know if the designers thought parsing was too expressive computationally?

I am totally on-board with trying to leverage wildcard subscriptions to get only the data that is needed.

This is done today with sparkplug, but each groupID has to be enumerated, which implies that there is some knowledge ahead of time of what groupIDs exist today and also requires manual integration for future groupIDs.

A huge pain if deploying it across the Enterprise. Not as simple as saying subscribe to spCv1.0/e1/s2/# and you'll get ALL current devices and devices added in the future without manual integration","",""
"329780110704246790","rkwadd","2021-09-17T08:12:52.7870000+08:00","Efficiency at a node/machine/workstation/cell/line/facility versus scalability to the entire enterprise is a sort of ever-present tension","",""
"740383178279354388","mriiot","2021-09-17T10:01:06.3330000+08:00","Maybe it‚Äôs time to stop polluting the topic and have a broker that can filter on mqtt5 user properties?","",""
"740383178279354388","mriiot","2021-09-17T10:02:27.6330000+08:00","When I issue an http request for an xml representation, I don‚Äôt get json back, but I‚Äôm still hitting the same uri.","",""
"740383178279354388","mriiot","2021-09-17T10:07:56.8290000+08:00","Having discovery (birth) of all nodes and devices would be helpful in a case where you want to track processing of a particular product, let‚Äôs say.","",""
"753688565807841492","ravil1","2021-09-17T14:11:35.0260000+08:00","Hmm, if every consumer subscribes to all topics on a site, would not it flood the network with too many messages? Then no matter how light is your payload, there is a danger of creating too much load on the network, as well as on a consumer application. Maybe this can be mitigated by implementing access rights on MQTT Broker, so only consumers who really need data from specific topics, have access to them.","",""
"795178288330440704","youri.regnaud","2021-09-18T12:54:42.0880000+08:00","Do you know if AWS Greengrass and IoT Core can use another MQTT Broker between Greengrass gateway (for OT/IT protocol) and IoT Core (Devise Registration, Devise Shadows, ‚Ä¶) ?","",""
"846417580804669450","damaniaaditya","2021-09-20T13:12:19.8640000+08:00","Hello! Yes you can use it, however I advise against using the pre-built services. It definitely helps in reducing development time dramatically, however there are huge cost implications which may leave you troubled when there is competition in the market and price reductions.","",""
"846417580804669450","damaniaaditya","2021-09-20T13:13:10.4050000+08:00","Most importantly IoT core charges implications are definitely not sustainable at scale. I had to re-architect my entire system to make it more cost effective.","",""
"883725522977325098","benderunit5347","2021-09-28T08:12:32.7950000+08:00","Hello. I‚Äôm looking to get data from our AB PLCs to AWS in spark plug B format. It seems I have 2 ways to approach this.  Kepware and HighByte so I can talk to the PLCs and send in spark plug B to AWS. 

Or go with Ignition edge using cirrus link to send to AWS.  Am I on the right track?  I want to do a proof of concept and since this is all new I want to go the best route first.  I use Kepware a lot but not sure from a cost perspective its the right choice.","",""
"740975015247478946","chrisgele","2021-09-28T09:42:28.7800000+08:00","@benderunit Take a look at the Maple Systems cmt-svr-102. Cost around $400 US.  https://www.maplesystems.com/product/modelname/cmt-svr-102","",""
"740975015247478946","chrisgele","2021-09-28T09:43:10.2650000+08:00","@benderunit Walker has used this product quite a bit.","",""
"830193224504705035","marc.jaeckle","2021-09-28T15:00:26.4860000+08:00","Third option would be to write your own service using PLC4X (or the underlaying libs) to access the PLCs and send the data to AWS via MQTT/Sparkplug. Please keep in mind that AWS IoT is still not fully MQTT 3.1.1 compliant. More details can be found here: https://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html#mqtt-differences For example it still has some limitations around Retained Messages that might be relevant to you. Also QoS 0 still means that a message is delivered **zero** or more times. Apparently the compatibility has improved a little bit and an update to https://www.hivemq.com/blog/hivemq-cloud-vs-aws-iot/ might be needed @Ian Skerrett. For example I also think that you can connect to AWS IoT with a standard MQTT lib for some time now and not just with the AWS SDK. Can you confirm this @Michael Brown?","",""
"830193224504705035","marc.jaeckle","2021-09-28T15:02:19.4220000+08:00","Another thing: Looking at the software layer is one thing but you should also think about how your deployment platform should look like. Where will those services run that access the PLCs? How do you deploy and operate them? How do you automate the infrastructure? ...","",""
"876880919988957205","ryankershaw","2021-09-28T21:08:05.9730000+08:00","What are you looking to do with the data overall?  Does it have to transmit via SpB?  We have some pretty good resources on pushing data to the cloud including this one: https://litmus.io/resource/how-an-edge-to-cloud-data-platform-works/

Also, if you're looking to put together a PoC, we can help with it.  Send me a message and we can have a look at the application.","",""
"753688565807841492","ravil1","2021-09-28T23:46:36.8350000+08:00","I Marc, I can confirm that it is possible to publish data to AWS IoT Core with standard MQTT Library (I used Eclipse Paho C library).","","üëç (1)"
"883725522977325098","benderunit5347","2021-09-29T08:12:10.0270000+08:00","I‚Äôm not looking to write my own code and hardware isn‚Äôt a problem. Just looking for the best setup and functionality with the 2 options I‚Äôve described.  Has anyone else done this or is it that people are still writing code to get this to work correctly?","",""
"883725522977325098","benderunit5347","2021-09-29T09:44:02.1840000+08:00","I‚Äôm open to ideas on how to automatic the the infrastructure if you have any","","üëç (1)"
"830193224504705035","marc.jaeckle","2021-09-29T15:44:57.5540000+08:00","Use servers and edge devices that support LOM & PXE Boot (e.g. HPE or DELL) so you can provision them remotely. Then you only need someone to ""plug in the cables"" on premise. I would use Flatcar Linux (CoreOS) as container-optimized Linux and then install Kubernetes on top of it. You can also use Metal3 (https://metal3.io/) to provision the on prem servers incl. Kubernetes. For the cloud I would use Terraform (or the installers that distributions provide). In general using something like Rancher or D2iQ DKP is very helpful because they provide good multi-cluster management tools and Rancher is even fully OpenSource. For Edge Devices I would use k3s as Kubernetes distribution (which can be managed both by Rancher or DKP).","","üëç (1)"
"769436583753416706","jman444","2021-09-29T22:39:10.5430000+08:00","wouldn't be easier to have some sort of device that converts the PLC data and publish it on a MQTT topic?  the device should get his configuration automatically from an API endpoint","",""
"769436583753416706","jman444","2021-09-29T22:44:25.1820000+08:00","I'm a bit scared of connecting my main Kubernetes cluster network with these devices from the field..","",""
"830193224504705035","marc.jaeckle","2021-09-29T23:50:39.2720000+08:00","I'm not entirely sure what you mean by ""connect"". Maybe this quick drawing helps illustrate what I mean.You would have separate Kubernetes environments for the cloud, the fog (meaning on prem in the plant here) and on the edge devices. On the edge devices you would run k3s as a independent one node Kubernetes. Multi cluster management could be done e.g. via Rancher or DKP (or similar products, I just wouldn't use OpenShift). You could put the management cluster into the cloud or the corporate network (could be the same one in the cloud that you run your regular workloads on). When I say cloud, I mean private cloud on AWS or Azure without internet connectivity / public IPs. Depending on what's possible in your plant you would either connect the PLCs to the edge devices and do the ""translation"" to MQTT/Sparkplug there or connect them to PLC4X services (or Ignition or ...) running in the fog cluster that do the translation or directly to an MQTT broker in the fog cluster if they speak MQTT or come with Ignition Edge (like the Opto 22 EPICs). From there you would connect the MQTT broker via bridging to an enterprise level broker cluster in the cloud. You can then deploy any workload to each environment in the same way and operating them would be identical in each environment. If you don't won't to run the Kubernetes clusters yourself you could also get a managed solution like GiantSwarm, although you would have to talk to them on how to integrate the edge devices).","https://cdn.discordapp.com/attachments/815945777452941313/892800549722943508/Kubernetes_Example.png?ex=68df480e&is=68ddf68e&hm=76730a3ecab2f79f4cc738492309ead4a98e2f32f4ad7ba560003a11445facb0&",""
"830193224504705035","marc.jaeckle","2021-09-29T23:56:06.2280000+08:00","But how does the device or the application running on top of it know who it is? Meaning which node and device ids to use for the UNS? For example what happens when you restart the application or the device after a crash? How do you make sure that it gets the same node and devices ids again from that endpoint? You have to store this somewhere. Either the application stores it locally in some way or you keep it in its deployment configuration or the endpoint for the identity has some kind of IP-identity mapping or some other way to determine the identity of the device/application.","",""
"769436583753416706","jman444","2021-09-29T23:59:07.7830000+08:00","got it, so you are separating the environments, basically you're having multiple Kubernetes environments","","üëç (1)"
"769436583753416706","jman444","2021-09-30T00:00:58.0910000+08:00","the edge server might store locally his ID and a secret to access the configuration","","üëç (1)"
"830193224504705035","marc.jaeckle","2021-09-30T00:21:53.8070000+08:00","And for managing the Kubernetes environments, many Kubernetes products come with multi-cluster management that make your live a lot easier when you run multiple Kubernetes environments/clusters. If you're on Azure: Azure also provides a multi-cluster management tool called Azure Arc that let's you manage any Kubernetes clusters that supports the Cluster API so you can also manage your on prem clusters with it. The cool thing about Arc is that Azure also offers some managed data services (e.g. Postgres) for any Arc managed cluster which means you can get managed services on prem as well and I'm sure they will add more services because it's a great selling point. I'm especially hoping they will support serving Azure ML models in Arc managed clusters. So far you can only train them there. In contrary to Rancher or D2iQ DKP we haven't used Arc in a project yet but it's definitively on my list of things to check out. The other hyperscalers also work on improving their hybrid cloud products. AWS recently released EKS Anywhere as GA and Google offers Anthos.","",""
"769436583753416706","jman444","2021-09-30T00:39:34.1170000+08:00","the hardest parts of managing Kubernetes on premise is to solve the networking between nodes (the data should be encrypted and it should allow new nodes to be added quickly), then you will have to find a good storage driver (I'm testing Longhorn), then you will need a good backup system, and finally a Load Balancer driver. In a cloud environment it's pretty easy because most of these things are managed by the cloud provider.","",""
"830193224504705035","marc.jaeckle","2021-09-30T15:50:43.7490000+08:00","Depending on what you need the storage for exactly, another option might be to use min.io for S3 compatible object storage. min.io also has a distributed mode. Just using the min.io operator might need a bit of time to get used to. In general I would try to store most of the data in a managed service in the cloud and just use local SSD storage for things like Kafka, Elastic (and to a lesser extend HiveMQ) and rely on their internal replication mechanisms. Especially Kafka and Elastic don't have a good performance if you don't run them on local SSD storage. Let me know how things are going with Longhorn. We haven't gone beyond playing with it so far.","",""
"769436583753416706","jman444","2021-09-30T16:01:18.4390000+08:00","what is the records throughput you've reached using managed databases?","",""
"830193224504705035","marc.jaeckle","2021-09-30T17:12:54.3260000+08:00","Scalability was never really an issue with the managed services. The problem was that it usually got too expensive before we hit a limitation so we switched to self-managed solutions at a higher scale (e.g. Elastic clusters on AWS i3 instances). For storing really all raw data for data analytics, we usually first store the data in a Kafka cluster and then write it in batches to AWS S3 or Azure Data Lake / Azure BLOB storage. In our largest project we currently get about 4 billion messages per day. In Industrial IoT settings the throughput of your connection to the cloud can be a limitation though, which is one of the cases when edge computing absolutely makes sense. Sometimes it's just not an option to move all the data to the cloud either because it would take too long or be too expensive. In a non IIoT project we had the problem that the devices created about 20 petabytes per 30 days. Regarding costs at a larger scale it's important to keep the data transfer costs in mind. For example AWS data transfer costs can be very nasty. Even things like replication over 3 availability zones can become very expensive.","","üëç (1)"
"817835202746253344","IIoT#4707","2021-09-30T17:12:54.6760000+08:00","GG @Marc J√§ckle, you just advanced to level 5!","",""
"769436583753416706","jman444","2021-09-30T17:46:48.6450000+08:00","wow, 4 billion messages, that's impressive. Do you analyse the data in real-time and save the analyisis output in a ""queryable"" database (SQL/noSQL)?
In our infrastructure (which I've described it a bit on the #iiot-edge channel - https://discordapp.com/channels/738470295056416930/742458745031884921/893067776040763402) we're kind of limited by the throughput of TimescaleDB so we might need to move all the raw data out of the SQL DB and use a real-time data workflow to save just the aggregated data in the SQL DB (I might have to look into how Unified Namespaces work..)","",""
"830193224504705035","marc.jaeckle","2021-09-30T20:06:31.6920000+08:00","We often have Flink or Spark Streams that do real-time or near real-time processing and we store the processed data (at least cleaned, normalized and maybe extended with some other data) in Elastic (or it's OpenSource fork). Elastic is great for analytics use cases because it does two things really well: filtering and aggregating. Regarding TimescaleDB: If you are really limited to it then I also would just store the processed data and maybe the current state for each device / machine / PLC in it. Everything else I would write to an object store. We started to do a comparison of some scalable databases for IoT use cases which you can find here: https://github.com/MaibornWolff/database-performance-comparison/ Originally we only wanted to test YugabyteDB and CockroachDB but then added ArangoDB and Cassandra for the fun of it. So far we only measured insert performance on an empty database. We already did some tests on how insert performance behaves with increasing number of rows already stored in the databases but removed the results again because we changed the test setup considerably. We also want to do some other tests like typical aggregations but just don't find the time for it.","","üëç (2)"
"884665155642875954","arnesvendsen","2021-10-18T16:40:24.6010000+08:00","https://intechdigital.isa.org/publication/?i=723525&_ga=2.115034247.1845163717.1634545659-1513424498.1618254060
An article from ISA's newsletter on extending isa95. Even if it's written by Dennis and Charlotta, who I have known since I started the 95 journey in July 2000, it is still not sufficiently addressing what we are doing with iIoT ... Have  look anyway...","",""
"456226577798135808","Deleted User","2021-10-19T11:44:45.8830000+08:00","Thanks for mentioning this name. Looks like he has a great blog as well - https://blog.colinbreck.com/shared-nothing-architectures-for-server-replication-and-synchronization/","",""
"194289793905983489","zackscriven","2021-10-19T23:40:39.3810000+08:00","LOL Thanks Arne!!!","",""
"745796393855352953","thedavidschultz","2021-10-21T22:35:51.8810000+08:00","The ISA95 article may not be the best, but the article on Page 8 is pretty good üòÄ","","üî• (1),üëè (3),üëç (1)"
"487658368492896257","benveenema","2021-10-22T15:50:20.0190000+08:00","Lol!","https://cdn.discordapp.com/attachments/815945777452941313/901014594816970762/Screenshot_20211022-034738.png?ex=68df803b&is=68de2ebb&hm=182bf52398e8c4065ebd57d2b8e8a792f9952556f90de5ffdee63be718402075&","üòÇ (4)"
"194289793905983489","zackscriven","2021-10-23T00:19:47.3460000+08:00","LFG!","",""
"795178288330440704","youri.regnaud","2021-10-23T02:39:39.3550000+08:00","what do you think of this simplified architecture diagram? Any comments to improve it? Thanks","https://cdn.discordapp.com/attachments/815945777452941313/901178002308747324/unknown.png?ex=68df6faa&is=68de1e2a&hm=d78c53aaedb2e00b775808e600ccb70e40f8ac8a163a677cd721781b79be1fb7&","üî• (1)"
"830193224504705035","marc.jaeckle","2021-10-23T16:32:49.4280000+08:00","First of all I would stop differentiating between OT and IT. This insinuates that two different worlds are involved. Instead an IIoT platform should be one consistent thing and this should also be supported by your org structure. The second thing I would not do under any circumstance is to put business logic like the transformation of data into the broker. This mirrors the failed ESB approach from 10-15 years ago. A message broker should only do one thing and do this well: broker messages. A message broker is not well suited to be a runtime / deployment platform for business logic. I'll have a look at the rest next week üôÇ","",""
"795178288330440704","youri.regnaud","2021-10-23T16:36:22.3900000+08:00","Thanks for your feedbacks","",""
"795178288330440704","youri.regnaud","2021-10-23T16:41:01.7790000+08:00","We call it UNS Event Hub to emphasize real time. Indeed a clearer separation between the business logic and the broker role will avoid parallels with the ESB. We are testing Solace today with Highbyte to play these 2 different  roles.","",""
"783917475128410112","geoffnunan","2021-10-24T06:58:07.2530000+08:00","Have you considered Master Data Management and Identity Management? Particularly with ensuring that your Event Hub contextualises data with consistent master data across other applications.","","üëÄ (1)"
"194289793905983489","zackscriven","2021-10-24T07:04:23.3780000+08:00","Great diagram.","",""
"801561312861618236","jon.forbord","2021-10-24T18:10:29.4830000+08:00","Master Data Management, would that be the practices and solutions to make sure overlapping master data is consistent throughout the business? Such as a Vendor‚Äôs address in one application in one business unit is updated/the same in all instances of that vendor in the business? If that is the case, could UNS function as a layer for Master Data Management?","",""
"783917475128410112","geoffnunan","2021-10-24T18:53:45.8460000+08:00","It could @Jon Forbord. In practice it's trickier than it sounds as each application (think ERP, MES, SCADA, PLC, CMMS, Quality Management System, LIMS) structure their master data to suit the particular needs of that application, so often Master Data Management is a mapping exercise, not because applications are silos, but because different application serve different purposes.","","üëç (3)"
"373852732424978442","daniel_hirsch","2021-10-25T18:31:10.9430000+08:00","What tools do you use, to draw architectures?","",""
"795178288330440704","youri.regnaud","2021-10-25T19:24:58.4210000+08:00","PowerPointüò©","",""
"795178288330440704","youri.regnaud","2021-10-25T19:25:21.9480000+08:00","But will test draw.io with a git behind for version control","",""
"373852732424978442","daniel_hirsch","2021-10-25T19:34:06.4950000+08:00","draw.io is my actual tool. It does its job well. But maybe someone has another tool, that might be worth a try.  ‚ò∫Ô∏èüòâ","","üíØ (1)"
"794020366536146977","mparris","2021-10-25T20:26:15.6400000+08:00","Lucidchart","","üôè (1)"
"329780110704246790","rkwadd","2021-10-26T03:30:44.4550000+08:00","Lucidchart, Omnigraffle, Draw.io, MS Office","",""
"329780110704246790","rkwadd","2021-10-26T03:31:44.7250000+08:00","or draw it by hand","",""
"794020366536146977","mparris","2021-10-26T05:46:17.8470000+08:00","Small, portable marker board is critical!","",""
"753688565807841492","ravil1","2021-10-26T05:50:42.3800000+08:00","Gliffy, with Confluence","",""
"795178288330440704","youri.regnaud","2021-10-26T13:42:58.4590000+08:00","Any other comments or advice?","",""
"830193224504705035","marc.jaeckle","2021-10-26T15:21:22.3900000+08:00","Miro works really well if you want to work with someone together remotely on an architecture.","","‚úÖ (1)"
"897154180001726494","koios6274","2021-10-28T01:39:09.4880000+08:00","Thoughts on this Enterprise Architecture for a company with multiple segments? Essentially adding an additional layer(Segment MQTT Broker)","",""
"897154180001726494","koios6274","2021-10-28T01:39:13.4710000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/902974733606326292/unknown.png?ex=68df6180&is=68de1000&hm=c66822beb855252d01f41eb290b86e677815542ff9d78d05a120c049b7c16ce1&",""
"897154180001726494","koios6274","2021-10-28T01:41:07.0550000+08:00","Or would you have all; of the ""Site MQTT Brokers"" publish directly to Enterprise ; even if they are in different segments","",""
"817835202746253344","IIoT#4707","2021-10-28T01:41:07.3310000+08:00","GG @Brent Wassell, you just advanced to level 2!","",""
"465984575450120223","galopingwombat","2021-10-28T18:57:25.3220000+08:00","It's just my thoughts because we are building a similar archi in my enterprise, but you may avoid the segment broker if you don't have a need to access the segment data at this location.","",""
"794020366536146977","mparris","2021-10-28T20:35:41.3420000+08:00","Agreed. Only connect the brokers if there is Equipment needing to know about each other.

A trade-off to spreading all traffic across the Enterprise vs having a handful of applications make a few connections to independent brokers.

There's a tipping point between those two options depending on the architecture needed","",""
"519666539436310529","aristotelestn","2021-10-28T21:55:17.8620000+08:00","Dear youri, great diagram. I have some doubts, what is the difference between data hub and event hub? would they be the same application? if not, would PIMS be the data hub or PIMS connect to the event hub? what would the connection to an IIoT platform look like? This cloud connection via VPN or using TLS?","",""
"830193224504705035","marc.jaeckle","2021-10-28T23:07:21.7270000+08:00","I would try to avoid avoid additional brokers for segments and only use one broker cluster per site. Additional brokers create a lot of operations overhead and make analyzing issues more complicated. You can represent segments as topic elements and use topic permissions to restrict publishing / subscribing to these topics. Unluckily if you are using Sparkplug this gets a bit more complicated because you can only use the ""Group ID"" topic element to represent your segments (e.g. ""site-area-cell"").","","üíØ (1)"
"194289793905983489","zackscriven","2021-10-29T01:23:40.0800000+08:00","Good advice.","",""
"900744649352826880","niravpatel4530","2021-10-29T08:47:36.7210000+08:00","So I have decided to share my IIoT reference architecture here. Comments are welcome. I have tested 70.00% of what is shown in this architecture. I was very happy with the results so far. It was very easy to implement with the listed software in my architecture. As well it was very efficient and significantly less effort to  implement when compared to traditional methods. Lastly, most of the  software and hardware I mentioned in my architecture are cost-effective solutions.","https://cdn.discordapp.com/attachments/815945777452941313/903444926312906842/drawoIO.drawio_1.png?ex=68df1d27&is=68ddcba7&hm=90c1853b77baf4ecb54245c7287681a2b127a4a3b85e7b474a6bcd7cc221d6e5&","üëç (5),üëÄ (3),uns (2)"
"329780110704246790","rkwadd","2021-10-29T10:11:49.6330000+08:00","On the Device/Sensor layer, if industry standard semantic models exist for the device then push the contextualization down. BACnet includes that, S7 has semantic data model(s) but it‚Äôs proprietary, MODBUS/EthernetIP don‚Äôt have one, MQTT does but only with Sparkplug, OPC UA includes it via Companion Specifications.","",""
"794020366536146977","mparris","2021-10-29T21:03:34.6090000+08:00","You must really like the Groov Epics... You have it on there twice under gateways üòâ

Looks like a great start!üëè","","üòÜ (1)"
"900744649352826880","niravpatel4530","2021-10-29T21:44:12.7540000+08:00","@Russ from the Internet, thank you for sharing the information. I am somewhat aware of those sematic. But what would be an ideal way to show them in architecture reference? Can the data be left as the source in those cases and simply publish to the broker?  I believe S7 and Modbus are absolute address-based. This will require context and modeling. I think EtherNet/IP you can obtain as tags if well-defined. I think the idea behind the DataOps is to standardize. As many vendors have different tags in their native PLC/Devices. Using DataOps we can set a standarization and then publish it to MQTT broker with SpvB.","",""
"817835202746253344","IIoT#4707","2021-10-29T21:44:13.0580000+08:00","GG @Nirav Patel, you just advanced to level 2!","",""
"194289793905983489","zackscriven","2021-10-29T22:03:22.3630000+08:00","Beautiful! I love what you did here.","","üëç (1)"
"329780110704246790","rkwadd","2021-10-29T22:23:51.9700000+08:00","A data model that includes things like IDs, time stamps, types, and addresses is still lacking context like ‚Äúthis is a robot arm and not an overhead crane.‚Äù You can get that level of definition from an OPC UA companion spec for example, but not from the core OPC UA spec.","",""
"329780110704246790","rkwadd","2021-10-29T22:26:14.2340000+08:00","The diagram isn‚Äôt wrong as is; there‚Äôs just the possibility for more detail on how contextualized the data will really be.","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2021-10-29T22:29:07.4820000+08:00","From my understanding, virtually nothing in that diagram will support any OPC UA companion spec.  What's the rationale behind bringing it up?  Just as like a theoretical example for semantic modeling?  Or is it something Nirav could actually adopt in that architecture?","",""
"329780110704246790","rkwadd","2021-10-29T22:31:12.7130000+08:00","Contextualization/Standardization/Modeling at the device layer versus centrally.","",""
"329780110704246790","rkwadd","2021-10-29T22:32:27.4590000+08:00","Doesn‚Äôt have to use a standard. Could be you standardize on one vendor, or standardize on an edge gateways for all data acquisition.","",""
"897154180001726494","koios6274","2021-10-29T23:28:51.4590000+08:00","@Nirav Patel nice architecture - thanks for sharing. Is this for a single site?","",""
"900744649352826880","niravpatel4530","2021-10-29T23:35:29.2320000+08:00","Thanks, Yes it is a single plant layout. But if your project requires a central hub. Then just add a central unified namespace broker which will subscribe to all these individual brokers.","",""
"795178288330440704","youri.regnaud","2021-10-29T23:44:27.8340000+08:00","Maybe Groove RIO for I/O?","",""
"795178288330440704","youri.regnaud","2021-10-29T23:46:08.8680000+08:00","Libre can be MES Layer and Historian (InfluxDB behind) Maybe a cloud broker between Edge and Cloud can be useful (compared to direct cloud injector)","",""
"900744649352826880","niravpatel4530","2021-10-29T23:52:40.6140000+08:00","There are many possibilities. My design was a bit of my learning experience and regulated industry mindset. We deal with a lot of validation and Life Sciences are a bit skeptical about the cloud. So I left the cloud as the last choice.","",""
"810171324764258326","luisn8316","2021-10-31T13:23:49.1040000+08:00","This is a great list and start! If you don't mind, I also have a few suggestions of some Siemens devices/solutions that can be added into your document:

Edge Gateway:
SIMATIC IoT 2040
SIMATIC IoT 2050
SIMATIC CloudConnect 7
SIMATIC Unified Comfort Panel (HMI)
SIMATIC IPC 227E (running Industrial Edge)
SCALANCE LPE9403

PLC with MQTT support:
S7-300 (via LMQTT library)
1200 (via LMQTT library)
1500 (via LMQTT library or via CP 1545-1)

Modern IIoT SCADA or HMI:
WinCC Unified Comfort panels
WinCC OA V3.17 or higher (current release is v3.18)","",""
"794020366536146977","mparris","2021-10-31T14:45:48.4820000+08:00","I'm wondering if any of these could be added to the product list I started.

Do any of those products support OPC UA pub/sub, or an OPC companion spec, or Sparkplug?

If so, I can add them to the list.

Thanks!","",""
"810171324764258326","luisn8316","2021-10-31T19:09:12.7210000+08:00","Do you have a link so we can take a look? 

I am only closely familiar with the PLCs..The S7-1200/1500 PLCs both support OPC UA DA incl. Companion specs. Only S7-1500 PLC supports pub/sub (and DA server/client, registered read/write, alarms & conditions, methods, diagnostics, etc.). SpB is possible, but not native in the LMQTT library. The CP 1545-1 also does not natively support SpB (that i know of yet?).

The Unified Comfort Panels have an edge runtime parallel to the WinCC HMI visualization runtime where you could run Siemens edge apps like FlowCreator (NodeRed), docker apps, or a custom (python) app.. My understanding is that there are libraries for NodeRed that allow you to publish SpB so this could work. There was a recent update to WinCC Unified this month and I'm not sure what protocols were added in as native drivers, but can get back to you once I find out more..

I'd also have to check the others products on specifics since I'm not as familiar with them. 

BTW, my hope is that someday soon we can get some of these (or all) into the hands of @Walker Reynolds  and/or @zackscriven's hands for demo for you guys üòâ. I'm mainly responsible for PLCs, but I try to keep a close eye on other products that support the i4.0 community, and I believe Walker already has an S7-1200 in his ""Mobile demo center""","",""
"794020366536146977","mparris","2021-10-31T19:16:26.3240000+08:00","Do you have documentation regarding which of the 35 companion specs the s7-1200/1500 naivety supports? Is it as a producer of the spec or a consumer?

CNC systems, Rubber and Plastic machinery, AutoID, etc.

A an example of a consumer if AutolD would be typing in the IP address of your RF600 product and having a register that the control engineer's logic could use.

Thanks!","",""
"794020366536146977","mparris","2021-10-31T19:22:13.5850000+08:00","List of OPC  companion specs is here:
https://opcfoundation.org/developer-tools/specifications-opc-ua-information-models","",""
"810171324764258326","luisn8316","2021-10-31T19:23:23.4710000+08:00","Technically, they support any (including custom information models). You can import/build the information model/companion spec and map the plc tags from your TIA Portal/Step7 project (engineering software for the S7 PLC) using a standalone/free software called SiOME (Siemens Object Model Editor). 

Here's a link with information on the tool: 
https://support.industry.siemens.com/cs/ww/en/view/109755133","",""
"794020366536146977","mparris","2021-10-31T20:20:36.6180000+08:00","If I'm understanding correctly, SiOME allows the PLC to expose its registers as an OPC-UA server via an information model (standard or custom even). Correct me if I'm wrong, but it appears to just be for simple data mapping.

 For example, to replicate the functions of the Machine Vision companion spec, an engineer would have to develop all the logic of the state machines and methods, and then map the internal registers to the imported companion spec?

Also, a similar question but going the other direction: Do you know if your PLCs can be an OPC UA client to interpret the information model of other devices? Such as connecting to the siemens rf600","",""
"810171324764258326","luisn8316","2021-10-31T20:45:31.0440000+08:00","Correct, the PLC logic has to be programmed accordingly. It would be difficult to write Operational logic for every type of machine according to companion specs, but I wouldn't be surprised if the respective companion spec organizations provide libraries at some point for common PLC platforms..SiOME helps map the companion spec tags with the S7 tags that are given ""access rights"" to the OPC UA server interface (not all tags/registers should be accessible to OPC UA servers/clients). 
S7-1200 can only operate as an OPC UA Server, but you can still ""write"" to tags from an OPC UA client if you allow this property to the tag (configurable in TIA Portal). See chapter 5 in the following document(this is for S7-1200 OPC UA server, but also applies if using S7-1500):
https://support.industry.siemens.com/cs/ww/en/view/109775168","",""
"817835202746253344","IIoT#4707","2021-10-31T20:45:31.4410000+08:00","GG @LuisN, you just advanced to level 6!","",""
"794020366536146977","mparris","2021-10-31T21:09:56.4390000+08:00","Thanks for your help.

Regarding libraries, if I had any influence, I'd require the foundation release PLC libraries with the companion spec... No libraries, no spec üòÅ","","üíØ (1)"
"766684226455207996","bright_hummingbird_31342","2021-11-01T04:03:55.1360000+08:00","This is great info.

What applications can consume these companion specs?  WinCC?  Any partner or third-party applications?

I saw a SiOME demo a couple years ago.  At the time, there was no modeling support for third-party devices.  I was hoping the product could also function as some sort of modeling gateway for legacy or third-party devices.  Has this changed?","",""
"810171324764258326","luisn8316","2021-11-01T09:59:49.0970000+08:00","SiOME is intended exclusively for Siemens' SIMATIC S7 PLC with OPC UA server and SINUMERIK CNC controllers only. 

I don't think there are plans to use this as some sort of soft gateway or interface with any 3rd party devices/software. We have software like SIMATIC NET that can sort of handle protocol conversions via hardware/software.. But it's fairly limited I think and don't think this is what you're referring to ü§î","",""
"810171324764258326","luisn8316","2021-11-01T10:01:32.3080000+08:00","Not sure I answered the right question, please clarify if I left something out","",""
"766684226455207996","bright_hummingbird_31342","2021-11-01T10:16:39.7610000+08:00","That answers the server side. Thanks.

My other question is on the client side. Once a server is up and running with a companion spec, what client applications can connect and make use of these UA information models?","","ü§î (1)"
"465984575450120223","galopingwombat","2021-11-02T16:32:19.1770000+08:00","It's very interesting and looks like what i'm trying to build here. However, after some tinkering I have doubts that Ignition can be the DataOps brick. Let me explain - Ignition is able to build a model and then push to MQTT using sparkplug, but once this is done, the model content cannot be updated by any other application, due to Ignition being the Node, and only the Node can update the published information in its context.  At this step I'm a bit confused with the all Sparkplug hype and I'm not anymore convince it can be used for UNS.","",""
"745796393855352953","thedavidschultz","2021-11-02T18:42:50.4920000+08:00","Why would you want another device to publish data to the same node? That's part of the reason SpB was developed.","","üëç (3)"
"465984575450120223","galopingwombat","2021-11-02T20:33:29.2410000+08:00","Maybe I'm missing something. For example say i'm publishing information about a plant floor from Ignition, like on the example attached. Then I need to add information in this structure from another software which is the digital interface of the equipment. I don't want to go through ignition because it would create useless forwarding of data. What would be the good way to do it ?","https://cdn.discordapp.com/attachments/815945777452941313/905072118406991872/unknown.png?ex=68df19d8&is=68ddc858&hm=8b6cdd664f6da67c2b4a0dee94ade60691d752598cae10669588f79d74db3b35&",""
"810171324764258326","luisn8316","2021-11-02T20:51:02.3780000+08:00","My understanding is that information models are just a way to ""harmonize"" data structures between different manufacturers so that someone building a client application (e.g. SCADA, MES, etc.) Doesn't have to know a specific tag name or structure for 3 different machine builders....the tag names and structures are the same so long as they follow the given companion specification. So ideally, I don't think the client NEEDS to explicitely support ""companion specifications"" since it really is just a way to have uniform OPC UA interface to data...does that make sense? I am not an OPC UA expert, just sharing my understanding, so I could be wrong ü§∑‚Äç‚ôÇÔ∏è","",""
"745796393855352953","thedavidschultz","2021-11-02T20:58:42.3520000+08:00","You need to create multiple namespaces and then a unified namespace. The DataOps tool is what is used to do this.","","üëç (1)"
"465984575450120223","galopingwombat","2021-11-02T21:13:25.0030000+08:00","Ok thank you for your answer. So it means that at some point, on the MQTT broker will cohexist the same data from the original equipment Node and data from the UNS Node.","",""
"817835202746253344","IIoT#4707","2021-11-02T21:13:25.4650000+08:00","GG @Cyril, you just advanced to level 1!","",""
"745796393855352953","thedavidschultz","2021-11-02T21:15:57.9420000+08:00","Exactly. Or another broker. It all depends on how you architect the system. It is common to have plant brokers and an enterprise broker. You may want to have area brokers as well. But you will end up with ""raw"" namespaces and then a UNS.","","üëç (1)"
"867075936054149191","rickbullotta","2021-11-02T21:36:37.5070000+08:00","...or something that is ""broker-esque""","","üíØ (1)"
"745796393855352953","thedavidschultz","2021-11-02T21:43:32.2790000+08:00","I only know how to spell MQTTüòÜ","","üëç (1)"
"897154180001726494","koios6274","2021-11-02T23:58:42.2170000+08:00","Which DataOps tool?","",""
"745796393855352953","thedavidschultz","2021-11-03T00:00:12.5610000+08:00","Depends on application and what else the solution requires. HighByte, Ignition and Frameworx are all good options.","","üëç (1)"
"867075936054149191","rickbullotta","2021-11-03T00:08:28.1120000+08:00","Those are all fine for sensor/telemetry data but not ideal for transforming other sorts of structured data, at least in their present incarnations.  Lot of apps can technically do it, but really aren't optimized for those types of cases where a lot of data transformation is needed, heterogenous blending of data streams is required, and so on.  Yet we also don't need the heavy capabilities (and pricing) of some of the more general purpose data ops tools not focused on industrial use cases.

Maybe give me your definition of ""data ops"" in this context?","",""
"903763641868910622","niravpatel4231","2021-11-03T00:23:20.7750000+08:00","Earlier, I shared some reference architecture. I am going to share them again with a few improvements that I receive from people here in the forum. I am still welcoming more comments and improvements.","https://cdn.discordapp.com/attachments/815945777452941313/905129963517280326/drawoIO-Page-2.drawio.png?ex=68df4fb7&is=68ddfe37&hm=3672b158a8656e54ec84898f914da8c62bf7515c438ca2eb9f5f8fab0dc7b7bc&","üëè (1)"
"903763641868910622","niravpatel4231","2021-11-03T00:23:26.4230000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/905129988183953438/drawoIO-Page-1.drawio.png?ex=68df4fbd&is=68ddfe3d&hm=6ed3d132b2d4cb48023ceb754cd5a630c16f9271a499cc91c13396f0fae07e53&","üëç (2),üëè (1)"
"867075936054149191","rickbullotta","2021-11-03T00:30:59.6330000+08:00","The big gap I see is the lack of any structured or semi-structured storage outside of MES/ERP.  A datastore (SQL or NoSQL) for this type of data is almost a necessity.  I also don't think the UNS should be the interface to ERP or MES - there's usually a better place for that (SCADA, IIoT platform/middleware, the data ops tier with some business rules).  The other gap I see if that there's no obvious place for unified visibility for operations support.  Analytics/reporting tools like PowerBI, Tableau, etc are NOT a good choice for this functionality.  Manufacturing intelligence/operational visibility tools need to be able to cross-data-stream drilldowns and correlation and actionability, not just viewing.","",""
"867075936054149191","rickbullotta","2021-11-03T00:38:45.6770000+08:00","I also think you need to rethink what ""Data Ops"" is - it's more than just the data flow from machines and devices.  There's another type of ""Data Ops"" needed above the UNS as well to correlate across many systems and data stores.","",""
"903763641868910622","niravpatel4231","2021-11-03T00:48:40.6110000+08:00","Have you taken a look at HighByte for DataOps? It definitely has more stream than devices.","",""
"867075936054149191","rickbullotta","2021-11-03T00:49:24.6420000+08:00","Yup - been giving feedback to Tony, Aron and team for a while and I run it in my lab setup.","",""
"898217314741280828","hobbes1069","2021-11-03T00:55:04.9230000+08:00","Out of curiosity, what did you create these in?","",""
"903763641868910622","niravpatel4231","2021-11-03T00:59:48.1770000+08:00","draw.io (free tool)","","üëç (1)"
"903763641868910622","niravpatel4231","2021-11-03T01:47:21.8840000+08:00","Thanks for the comments and feedback. For datastore type connectivity do you suggest connecting something like Canary, InfluxDB to ERP and MES? I don't understand the operations visibility support? Did you mean the SCADA connection with UNS lacks that visibility? Analytics and reporting with PowerBI I kept it because some Executive folks loves those things. So I won't be paying much attention there.","",""
"903763641868910622","niravpatel4231","2021-11-03T01:50:50.2470000+08:00","@RickBullotta  Did you suggest something like SQL, CSV, Flat Files to HighByte <=> Canary or Influx DB <=> MES or ERP?","",""
"817835202746253344","IIoT#4707","2021-11-03T01:50:50.4690000+08:00","GG @Nirav Patel, you just advanced to level 1!","",""
"867075936054149191","rickbullotta","2021-11-03T01:58:08.8880000+08:00","SCADA systems usually suck for interactive data analysis with supply chain data, QMS, EAM, ERP, and so on.  Conversely most BI tools don‚Äôt understand production data nor can they make it actionable in the ways we need.","",""
"867075936054149191","rickbullotta","2021-11-03T01:59:50.7870000+08:00","Regarding data storage, no not another time series database! The exact opposite. More like a SQL database, document/K-V database, graph database, etc.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:03:18.4750000+08:00","How do you suggest ERP, MES, EAM interact?","",""
"867075936054149191","rickbullotta","2021-11-03T02:23:48.2780000+08:00","Via some middleware/IIoT platform.  SCADA can interact with them via that middleware also.  It's a great way to standardize access control, manageability, API patterns, data formats, and so on.  It also keeps some aspects of SCADA/HMI ""pure"" in the cases where they are provided by an equipment OEM and modifying them might impact warrantees or performance guarantees.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:29:23.2240000+08:00","Is such middleware out there? I don't know of any. Hoping they are not OSI-PI or thingworx. üòÜ . With EoN or DataOps you aren't modifying any existing OEM equipment. You are only collecting data. In many cases, I don't even have to touch the OEM equipment or have to change anything on their validated machines. Besides a simple poll-response connection to Edge device.","",""
"867075936054149191","rickbullotta","2021-11-03T02:30:19.9910000+08:00","Literally hundreds of middleware platforms for manufacturing.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:31:20.7730000+08:00","?","",""
"903763641868910622","niravpatel4231","2021-11-03T02:33:45.9820000+08:00","When data is moved to OSI-PI or MQTT regardless, in life science companies you have to validate the data source as good GxP practices and regulation compliance.","",""
"867075936054149191","rickbullotta","2021-11-03T02:38:08.5890000+08:00","Yes, I'm well aware of GxP requirements. I've done many validated systems over the years.  A Google search will yield lots and lots of OT and OT/IT middleware options from ERP vendors, cloud vendors, general technology vendors, specialty OT middleware suppliers, IIoT platform vendors, and so on.  Many of the manufacturing intelligence vendors include some level of this as well.  At a minimum, these platforms can assist with data relationships, transformation, correlation, and heterogenous queries.  Many can also provide for event/rules-based transactional execution.  Some include AI/ML capabilities. And some include visualization as well.  There are even a few open source options.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:44:31.1490000+08:00","Excuse my ignorance. But what are the most common industrial protocols to do this? Another middleware could be another data silos? How do you handle absolute addressing and so many heterogeneous data silos to speak one common language?","",""
"867075936054149191","rickbullotta","2021-11-03T02:49:44.3250000+08:00","Magic, of course. üòâ","",""
"903763641868910622","niravpatel4231","2021-11-03T02:49:49.0750000+08:00","I took your advice and did a simple search on google and found services offered by companies who talk about OT/IT convergence. But nothing in the top 15 searches returned a product that can be true middleware.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:52:23.8240000+08:00","The key to such middleware is a common language that all can understand. We can write services, API, codes, and custom solutions to make it work but is it worth it for the client?","",""
"817835202746253344","IIoT#4707","2021-11-03T02:52:24.1910000+08:00","GG @Nirav Patel, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2021-11-03T02:58:22.0130000+08:00","ERP vendors like SAP, Oracle, and Infor all have some capabilities.  Microsoft, AWS, and IBM have some too.  GE, Honeywell, PTC, Rockwell, ABB, Siemens and most of the other major automation vendors have some.  Software AG, Mulesoft, and many other general tech vendors also do.  Crosser, Flow Director, Think Automation, RTI, Flow, Libre and others are in this space.  Some companies and integrators have used things like Node-RED and Apache's many offerings to achieve it.  There are also many research papers describing designs and requirements for manufacturing and IoT middleware.  Besides the list above there are probably 200+ more.  There's nothing wrong with writing a bit of code around the functional edge(s) of a platform to create adapters to proprietary stuff, add new algorithms, or extend with new visualizations.","",""
"903763641868910622","niravpatel4231","2021-11-03T02:59:28.0480000+08:00","From personal experience, our company made a decision to use OSI-PI as IIoT üòÜ with a hefty price tag by well-known integrator. Yet their solution was to provide a handful of tags for that price. Their architecture is way too complex and hard to manage. Their method is OPC-DA because OPC-UA doesn't support redundancy. The point I am trying to make is that those middleware-oriented service providers are well established and backed up by Rockwell, Siemens, and SE. Unfortunately, some big pharma believes in them.  Now, do you truly think that is the definition of IIoT, middleware, or even close to digital transformation? For me, that is a scam and another data silo waiting to happen in the corner.","",""
"867075936054149191","rickbullotta","2021-11-03T03:07:10.7710000+08:00","Yikes.  Sorry to hear that.  I've seen and been involved in many, many successful implementations of IIoT platforms/middleware and more importantly seen customers get substantial payback on those efforts.  Yes, there's a lot of hype, and yes this stuff can seem expensive.  But it can also work very, very well.","",""
"465984575450120223","galopingwombat","2021-11-03T16:55:01.1710000+08:00","I cannot help thinking the overall solution would be simpler if the edge devices which are MQTT capable could insert their updates directly at the right place in the UNS. Is it something avoided because of complexity to maintain model at multiple places ?","",""
"745796393855352953","thedavidschultz","2021-11-03T18:45:13.9700000+08:00","The best thing about flat MQTT is that you can publish to any topic. The worst thing about flat MQTT is that you can publish to any topic. You are correct in that if every edge device could publish to the same UNS is would make it much simpler. The risk, of course, is that different devices are publishing to the same topic. Consumer would not be aware of it and potentially act on incorrect data.","",""
"756565963520081950","andersgustav","2021-11-03T18:55:20.5480000+08:00","> The risk, of course, is that different devices are publishing to the same topic
Following the ISA-95 part2 strict, this should be next to impossible? Given that there are no human errors in the implementation. But that could happen anyway, right?

Most of my MQTT devices publishes directly into the UNS. I actually think the risk of topic duplication is less this way.

Any errors I have encountered has been 100% human (designed by yours truly, every single one of them! üòâ )","","üëç (1)"
"745796393855352953","thedavidschultz","2021-11-03T19:05:35.4800000+08:00","Understood. But on device checkouts it is a common occurrence to stroke a valve on Train 1 only to see the same valve on Train 2 move. I realize this is resolved before operation, but as more devices are added by more people, it can become unruly. 

If done correctly flat MQTT is a great solution. If SpB allowed devices to publish to the same namespace, albeit on different metrics, that would solve a number of problems. I am confident that MQTT 5 with Sparkplug ""C"" will account for some of this.","","üíØ (1),üëç (1)"
"830193224504705035","marc.jaeckle","2021-11-03T22:14:23.3100000+08:00","""actionable"" is a great keyword that I haven't seen being mentioned here yet. A good litmus test for any KPI/analysis that you are building is if the results are actionable. Otherwise people tend to build KPIs that are just interesting. Ideally KPIs offer direct functions in the UI so you can do something with the results (or even do something in an automated way). This is not always possible and often not that easy if you don't have a custom built frontend but some products allow this as well, at least to some extend (e.g. Grafana).","","üíØ (3)"
"867075936054149191","rickbullotta","2021-11-03T22:16:34.9040000+08:00","I used to call many KPI reports the ""We Sucked Yesterday"" charts.  The key is to be able to act in time!  Grafana is super limited in this regard IMO.  It's really intended for view only (and makes cross-data source drilldowns rather difficult).","","üòÜ (1),ü§£ (1)"
"766684226455207996","bright_hummingbird_31342","2021-11-03T22:24:19.9110000+08:00","""We sucked yesterday"" charts.  I'm dying.  üòÜ","","üìâ (1)"
"830193224504705035","marc.jaeckle","2021-11-03T22:34:05.8580000+08:00","That's why I wrote ""to some extend"" üôÇ Usually we build custom frontends for these types of KPIs.","","üëç (1)"
"867075936054149191","rickbullotta","2021-11-03T22:47:23.6070000+08:00","This is why I think that publishing ""commands"" or ""services"" in addition to ""data"" into the UNS provides a common repository for the capabilities that can be composed to make stuff actionable.","",""
"830193224504705035","marc.jaeckle","2021-11-04T00:04:39.3560000+08:00","I'd already be happy if the APIs would be published in a central developer portal. For example Gloo Portal uses a nice approach on how to publish APIs (but it still uses OpenAPI and presents APIs in a similar way to SwaggerUI which is always annoying).","",""
"812295088348200960","patanj2","2021-11-05T08:12:40.7930000+08:00","OK ""We sucked Yesterday"" charts ... I'm plagiarizing this (internally)","","üëç (2)"
"783917475128410112","geoffnunan","2021-11-05T17:36:11.2500000+08:00","Being able to act in time has two parts, the awareness that there is a need to act, and the ability to effect the action. Grafana does a good job of the first bit, and can be extended to do the second (although this takes some development effort). Do you think it's important that you can do both in a single environment?","",""
"894527802316046366","nickn5549","2021-11-09T09:46:56.8830000+08:00","Absolutely","",""
"830193224504705035","marc.jaeckle","2021-11-11T00:57:08.1180000+08:00","We recently added Elasticsearch (clustered) and TimescaleDB (single instance) to our database comparison for IoT and IIoT data. We couldn't find a good way yet to run multi-node TimescaleDB on Kubernetes with little effort and I can confirm that the TimescaleDB multi-node helm chart is üí© . We already knew what to expect from the two DBs but added them for completeness to the comparison: https://github.com/MaibornWolff/database-performance-comparison/
We did not draw a conclusion and leave this up to the reader as it really depends on your use case if something is usable or not. For example Single Node TimescaleDB might be just fine for your project/scale if you can live with short downtimes now and then and you have good external storage.","",""
"810171324764258326","luisn8316","2021-11-17T13:29:31.3800000+08:00","Sorry for the late reply on this, but I thought it would be worthwhile to come back to at some point..

My understanding is that ANY OPC UA client should be able to access the process tags. 

I don't believe the idea of companion specs was that the client supports it, but that the data structure is in a uniform format regardless of the controller and/or machine builder. 

So machine builder A provides the same data for their machine as machine builder B, and both with the same data structure (but obviously different process values). 

In an HMI/SCADA application, you only poll for the data/tags you need for your screen/application... Similar to how MQTT clients have to specify the topic namespace they want to subscribe to, UA clients have to specify the topic/namespace from the UA server...the companion spec describes what the structure of that namespace is depending on the process tag type. 

This is my understanding of how information models/companion specs are intended to be used, but I'm also no OPC UA expert... (I'm on here to learn more than teach)","",""
"794020366536146977","mparris","2021-11-17T17:25:11.9480000+08:00","Your understanding is correct and a very common use case when discussing information models.

What is missing, however, and what is typically the more difficult challenge,. It's not only standardized servers; the purpose of doing this is to then have standardized clients. The idea of the client is that I can connect some application or function and as soon as that connection happens, the client knows what type of object the server represents and then makes the appropriate accommodations for that object type, such as adding onto a dashboard, including in some aggregate calculation, etc. The client is the most difficult than the server because the client must be programmed to handle the full implementation of the companion spec, while at the same time detecting which options have been defined in the server and being able to properly handle the lack of data for options not being present.

It's one thing to look for a list of OPC UA servers supporting a companion spec, and that list is what the Foundation would typically tote around to conferences demonstrating market adoption. But then ask anyone for a list of devices or applications that can consume the information model and you'll hear crickets. So this begs the question, if nothing can consume it, why develop against the companion spec to begin with?","","üíØ (2)"
"810171324764258326","luisn8316","2021-11-17T20:07:34.4190000+08:00","Thanks for the explanation. That helps with my sanity üòÇ. I completely agree with your assessment of the CS requirements for clients, but my understanding is that there isn't a single protocol that supports this today...Does SpB have ""automatic detection"" of data or does a screen object (e.g. gauge, trend box, IO field..) for a dashboard still need to be configured to point to a specific tag within a manually defined topic namespace?","",""
"766684226455207996","bright_hummingbird_31342","2021-11-17T22:04:29.8540000+08:00","There other issue is that while clients may scan for these in the server‚Äôs namespace, the rest of client application will often consume it as a ‚Äúflattened‚Äù data model. It‚Äôs just name-value pairs with perhaps some hierarchy. The server‚Äôs model cannot be interfaced with intelligently. OPC-UA, to the vast majority of those embedding it into their products, means satisfying the basic DA use case and nothing more.

While SpB is not perfect, it works well in that it‚Äôs essentially publishing device UDTs into the IIoT infrastructure. It‚Äôs possible to have applications dynamically consume these. Whereas, with most implementations of OPC-UA, one must give the application explicit permission to consume components of each model instance. There are ways to leverage templates in applications to cut down on mapping efforts, but it‚Äôs often through aliasing via aggregating OPC Servers or within an application native namespace itself. This is an example of where OPC-UA, setting aside security, does not fair much better than a modern native protocol with support for automatic tag generation.

The goal isn‚Äôt necessarily to have a better namespace to manually map from, but to eliminate the mapping all together. This is why consuming a model is just as important as producing one.","",""
"867075936054149191","rickbullotta","2021-11-17T22:56:44.3110000+08:00",""" It‚Äôs possible to have applications dynamically consume these"" - sort of.  This is where I find Sparkplug on its own to be a PITA.  I don't like opaque topic names - that's one of the areas we complain about with the cloud vendors' MQTT IoT brokers - yet some happily accept it with Sparkplug.","",""
"766684226455207996","bright_hummingbird_31342","2021-11-17T23:10:04.7500000+08:00","For basic SCADA and telemetry applications, it suffices.  But, yes, it requires a degree of shoehorning for more advance applications.  The topics can be opaque and their contents get bloated.  But, is one better off with these compromises than the currently-available OPC-UA alternatives?","","üëç (1)"
"867075936054149191","rickbullotta","2021-11-17T23:12:51.0740000+08:00","Obviously that's an ""it depends"" answer.  With some tweaks to MQTT and Sparkplug we can address the shortcomings and make it a non-issue altogether.  I ended up using my ""uber broker"" that I created as part of the solution for my 3D printer integration experiment, and I'm more convinced than ever that a solution isn't that difficult technically - it's getting through all of the standards committee BS.  Or maybe don't even bother, and just start building more non-standard but standard extensions to MQTT outside of the domain of OMG.","",""
"194289793905983489","zackscriven","2021-11-19T02:00:40.8060000+08:00","Wow! Just wow! DA for the benefit of redundancy! That‚Äôs genius. Why didn‚Äôt I think of that. ü§£","",""
"830193224504705035","marc.jaeckle","2021-11-23T01:30:50.7640000+08:00","I also don't understand why Sparkplug does not allow the topic structure at least to be configured to some extend (with the default the way it is now in the spec). Then you could just configure it for your enterprise accordingly in all your applications. Without having thought about it much, I have the feeling that you could probably make it much more flexible without a too strict structure (even more so with MQTT 5). There should be a new official draft version of the Spec out in the not too distant future. Probably a good time to give some feedback.","",""
"795524195458220082","almukhtar","2021-11-23T08:41:06.1290000+08:00","Luis take a look about the demo project arlen did   i think you will appreciate it as i did
https://www.linkedin.com/posts/arlen-nipper-42281057_industrial-data-management-supports-scada-activity-6864264107047092224-V6A5","",""
"794542235676180500","akoscs","2021-11-26T21:22:35.5140000+08:00","If we compare pub-sub to request-response communication obviously there are differences due to the architecture. If we compare useful payload and overhead for messages that is another thing, but if we compare purely information availability, there is no reason why OPC-UA could not be consumed exactly as dynamically as SpB. What is the machine readable information, that you have n the fly available for SpB and not for OPC-UA that prevent a fully dynamical consumption on the client side?","",""
"794020366536146977","mparris","2021-11-26T22:06:28.3480000+08:00","@Ravil Can you confirm that if a OPC UA Server is exposing a custom structure or data type, that a Client cannot decode this data type unless it has a nodeset file ahead of time?","",""
"753688565807841492","ravil1","2021-11-27T01:46:18.7760000+08:00","No, the client does not need a nodeset file ahead of time, in order to decode custom (complex) data structures. Description of such data types can be retrieved from the server over OPC UA Session.
But in the case of PubSub, subscribers might be not able to connect to the server and create a regular OPC UA session. Can be due to being the server behind a firewall, or, just the client is not OPC UA one, can be some regular MQTT subscriber. For such cases, the concept of the Cloud Library was created. The service in the cloud will implement standard REST API, connecting to it, servers can publish their data model, and subscribers can get the model and use it to decode custom structures.","","üëç (1)"
"756247672637358181","sherylmccrary","2021-11-29T12:02:02.8390000+08:00","Good advice. And more reason to consider a UNS architecture.  https://youtu.be/DELV-3irclA","",""
"766684226455207996","bright_hummingbird_31342","2021-11-30T07:41:44.6720000+08:00","Great question.  This helps emphasize what I believe is a useful distinction when discussing OPC technology.  That is, there is OPC-UA in theory and OPC-UA in practice.  The spec has a ton of features to satisfy all sorts of use-cases, but it's not necessarily available or practical to adopt.

For those that build and sell OPC-UA SDKs, this is not much a concern.  If a feature is missing and an opportunity presents itself, it can be added.  And sure enough, that feature will be working as-designed in a debug console.  Whether this can be practically utilized in an application or device is an entirely different story.  For those responsible for digitally transforming manufacturers, this makes all the difference.  Missing features and interoperability issues are a huge concern.  It adds risk and engineering cost.

Manufacturers and integrators have to piece together what is available on the market. They do not have the luxury of phoning up, say, SAP or Siemens to address the gaps on this quarter's roadmap. They're in a stringent supply chain that demands a solution to be up and running right away. The gaps must get filled regardless of what a product manager may think or their org is prepared to commit to.

In the case of OPC-UA clients, dynamic consumption is absolutely possible.  But, in practice, the clients in most applications consist of an interface to explicitly manage connections and subscriptions.  Occasionally, if the application sophisticated enough, it might be possible to programmatically manage subscriptions.  But, in most cases, it's just a tag browser for manually mapping name-value pairs into a native namespace.  For the majority that embed OPC-UA in their products, this appears to be the extent that they understand the technology or are willing to invest in it.

While we could claim this is fault of the application and not the OPC spec itself, it doesn't make a difference to the manufacturer. They have a desired outcome and it's still not being met.","",""
"794542235676180500","akoscs","2021-11-30T16:57:57.9060000+08:00","Really interesting topic! Thanks for the long explanation. 

I think this is where the open source OPC-UA libraries can make a huge difference! For one, buying a stack might be priced based on features, so...smaller companies  (producing devices with an OPC-UA server) might be inclined to spend the minimum amount for the stack, for the SWE integration training of the staff (i.e. how to use the stack) and implementation effort, but with open source libraries catching up with more and more OPC-UA features this cost barrier to more advanced  functionalities might improve substantially. 

Another factor might be market pull. If the market wants these features and has alternative solutions, sooner or later, OPC-UA library features might just catch up to marked demand and to the standard specifications, enabled by the open source implementations. 

Furthermore, I know that the Comp Specs are not popular on this forum, but I think the Comp Specs are exactly what will (re)fuel the OPC-UA adoption after they are finished/established. There is no other initiative that is even comparable to comp specs (e.g. eClass is borderline unusable) and in the machine tool community or in the robotics community this is unheard of and there is huge interest for it. I can have a client using the same interface, syntax and **semantics** with robots (or CNCs or any other device which has a comp spec) from different manufacturers is an extremely important step forward for all system integrators!","",""
"794020366536146977","mparris","2021-11-30T18:14:05.7780000+08:00","I would be interested to hear your thoughts on this article:
https://www.linkedin.com/pulse/opc-ua-vaporware-matthew-parris/","",""
"794020366536146977","mparris","2021-11-30T18:22:51.5770000+08:00","I think this community is open minded to try any available products. The talk around OPC UA is mostly what COULD be done if someone developed applications. This type of discussion, though, will fall in deaf ears. Integrators want to integrate, not develop from scratch.

So when discussing OPC UA architectures, providing the names of products that can realize that architecture is required to have any credibility... Otherwise, it's just talk about words on paper.

@Ravil, after hearing the use cases of Sparkplug on this community, is working to have his product behave similar to an MQTT broker, and enable discover ability through OPC-UA. His challenge will be identifying a consuming application/destination to make use of the data dynamically.","",""
"794020366536146977","mparris","2021-11-30T18:28:04.7320000+08:00","One of the oldest companion specs, AutoID, had been released over 6 years. With all the hub-bub surrounding it, you would think that there would be one PLC that could natively consume that companion spec without manual integration.

I'm engaging the AutoID working group to describe this use case, but the fact that it would be considered novel for a PLC to consume autoID has me worried that the people developing the specs do not have the end user or integrator in mind as the customer","",""
"794542235676180500","akoscs","2021-11-30T18:39:57.4940000+08:00","OPC-UA in its current form was never meant to be consumed by a PLC. OPC-UA is meant to be used ""upwards"" of the PLC in the classical pyramid.  So, no you would not expect a PLC to implement an OPC-UA Client. If it implements an OPC-UA client, then obviously you can use it to connect to the barcode reader.

The role of the companion spec is not really to ease the implementation of a specific AutoID client (although that definetly would be possible and should be done), but to make sure that if you buy a barcode reader from a different manufacturer, which also implements AutoID you can ""plug and play"" exchange the old barcode reader with the new one (given that you are using only functionalities described in the comp spec and not vendor specific functions). It has the ability to eliminate vendor locking for basic features of a barcode reader. This is in my opinion huge!

The FLC working group (Field Level Communications) is what addresses PLC (or CNC, MC, RC) to sensors, drives, IOs, etc.  type of communication currently. It is still in the works an TSN is a great enabler for this to work also as a real-time fieldbus for motion control (i.e. instead of Profinet/EtherCAT/sercos/CanOpen)","",""
"794542235676180500","akoscs","2021-11-30T19:09:31.8220000+08:00","I read through the article. I agree with your frustration towards OPC-UA as described in the article and I very much support a better understanding of OPC-UA both at vendors and system integrators. I do not agree with some of the aspects which you would expect from OPC-UA. First of all backwards compatibility was never a goal. let's just leave it with that and not touch an horrible naming practices. To address your points in the why is OPC-UA vaporware section:

1. Spec development is extremely complex and an immense effort. 
Optional components are the way to keep it simple. What if all aspects would be mandatory? That is not keeping it simple. Identify core functionality, make that mandatory and make more complex scenarios optional is the way to make sure that there is a set of core functionalities which are simple to use and implement and the complex stuff is used for use cases where it is actually required. Also, see point 3 for further relevant details.

2. You are probably right here. 

3. Exaclty! How do you get commitment form OEMs? Logitech mouses have extra buttons and extra functionality which differentiates them from MouseBrandX. How do you get Logitech to commit to make USB mouses which BrandX can also make? By allowing them to make custom drivers for their mouse which supports their differentiating unique feature, e.g. an extra button. That is a vendor specific function. In this analogy USB is OPC-UA, but the HID-Compliant device profile (the generic usb keyboard/mouse) which already includes a semantic defintion, that is the OPC-UA CompSpec. Plug in your Logitech mouse and it will work as a HID compliant device. Do you have the special logitech driver (aka. vendor specific part) then have fun with the extra buttons on the mouse! There is no alternative to the CompSpecs. SpB does not have a strict semantic defintion. If device profiles made USB successful, an in essence that is what you are claiming your best bet are the CompSpecs.","",""
"867075936054149191","rickbullotta","2021-11-30T21:16:45.0260000+08:00","...same with MQTT - it was intended primarily to send telemetry to another system, not as a means for command and control or writing data (the open ended nature of subscriptions being a clear indicator of this).  As I've said a zillion times - it's all flawed - OPCUA, MQTT, Sparkplug, etc...

And honestly, who cares?  Instead of trying to define a ""winner"", let's design a proper software layer on top of this stuff that abstracts it away as well as any of the zillions of other protocols and ""standards"".  And someday, someone else will have to abstract this away.  Call it a UNS, a Digital Twin, an Optomorphic Quantum Clone, or whatever - let's just do it.","",""
"794020366536146977","mparris","2021-11-30T21:28:11.1560000+08:00","@DavidSchultz What do you think we call this effort the Industrial Standard for Applications?","",""
"867075936054149191","rickbullotta","2021-11-30T21:33:18.8730000+08:00","Functional Utilization of Component Knowledge - Technical Hierarchy of Abstract Types","","ü§£ (1)"
"867075936054149191","rickbullotta","2021-11-30T21:33:38.6370000+08:00","Yes, I just made that up.","",""
"794020366536146977","mparris","2021-11-30T21:42:45.0890000+08:00","Have you heard of GenICam? It is a standard that abstracts away various machine vision transports such as GigEVision, USB Vision, Coax Express, etc.

Sounds like this would be a more general effort, but along the same lines?","",""
"867075936054149191","rickbullotta","2021-11-30T21:46:58.9710000+08:00","I'm thinking something more like a mashup of the best bits of OPCUA, Sparkplug/MQTT, DTDL, ThingWorx, Actor and Event-based models, a unified data format that can be rendered as JSON or binary, all wrapped up in language, transport and OS neutral implementation(s).  ü¶Ñ","","üî• (1)"
"794020366536146977","mparris","2021-11-30T21:49:38.3840000+08:00","I say we start a working group, and just start listing the features we like of each.

Keep the scope small, purposeful, and flexible.

It may have a chance to go further than other bloated or limited specs.","",""
"794020366536146977","mparris","2021-11-30T21:52:09.7300000+08:00","Have the team small, but represent the full stack... Device up to cloud. Actually have a use case defined from the start that demonstrates simple capability at all levels.","",""
"794020366536146977","mparris","2021-11-30T21:53:13.7320000+08:00","OEM, integrator, and end user represented","",""
"867075936054149191","rickbullotta","2021-11-30T21:53:19.2520000+08:00","...and actually have working code.  Spec-based standards suck.","",""
"867075936054149191","rickbullotta","2021-11-30T21:53:46.5720000+08:00","You already bloated it with ""OEM, integrator, and end user"" representation. üòâ","",""
"794020366536146977","mparris","2021-11-30T21:56:12.4880000+08:00","No word documents allowed...

Write the spec using Test-Driven-development methodology... Define the compliance test first, then the function","","üëç (1)"
"867075936054149191","rickbullotta","2021-11-30T21:56:50.6680000+08:00","We do need some docs, but it needs a reference implementation also.","",""
"794020366536146977","mparris","2021-11-30T21:57:39.1730000+08:00","Docs are ok... Just no MS Word docs...","",""
"766684226455207996","bright_hummingbird_31342","2021-11-30T21:57:49.1480000+08:00","And a commitment for those involved to actually go to market with it.","","üíØ (1)"
"794020366536146977","mparris","2021-11-30T22:02:13.6800000+08:00","This group would provide feedback at various points of the spec.  Use Agile development...basic function, get feedback from the users, then add more.

Don't do waterfall approach and drop the binder on the desk of the OEM and then say: ""Implement this!""","",""
"745796393855352953","thedavidschultz","2021-11-30T22:02:51.2110000+08:00","Naming is not my fort√©, but it seems Rick has a great handle on it. These are hilarious.üòÇ 

I am not as concerned with the standards/specifications/layers as I am the functionality. The goal is to enable problem solving within all areas of a company and provide tools to solve them. Why I like MQTT/SpB is that it creates a lightweight method to provide all of my data. But it has it limitations, as we have discussed.

The approach of a mashup and drawing from benefits of all is a good place to start. But we need to heed the advice of Occam and not make it too complex.","",""
"867075936054149191","rickbullotta","2021-11-30T22:02:54.8320000+08:00","Agreed with an asterisk: User feedback is *HIGHLY* overrated unless they're the right users.","","üëç (2),üíØ (1)"
"867075936054149191","rickbullotta","2021-11-30T22:03:07.3750000+08:00","Elegant in its simplicity!","",""
"745796393855352953","thedavidschultz","2021-11-30T22:03:22.3220000+08:00","I just want a faster horse üòÇ","","üíØ (1)"
"329780110704246790","rkwadd","2021-12-01T03:46:11.0290000+08:00","I think a lot of people see same opportunities @RickBullotta and @MParris are enthusiastic about and are just getting on with building it. I‚Äôm not sure any new collective body or consortia are needed.","",""
"329780110704246790","rkwadd","2021-12-01T03:46:21.4420000+08:00","Ad hoc industry round tables would be good.","",""
"756247672637358181","sherylmccrary","2021-12-01T03:53:59.1320000+08:00","This conversation is exciting.","",""
"817835202746253344","IIoT#4707","2021-12-01T03:53:59.4230000+08:00","GG @SherylM, you just advanced to level 14!","",""
"329780110704246790","rkwadd","2021-12-01T03:59:39.8650000+08:00","Agree. It‚Äôs sort of crazy that just a few years ago my conversations were often about ‚ÄúWhy would I want data out of my machinery?‚Äù","","üòÄ (1)"
"766684226455207996","bright_hummingbird_31342","2021-12-01T04:20:57.9200000+08:00","I don't know about you, but I think it's about time for a Plattform Industrie 5.0.  It's imperative that we define the Metaverse Administration Shell.","",""
"329780110704246790","rkwadd","2021-12-01T04:28:12.7740000+08:00","It‚Äôs already official. https://ec.europa.eu/info/research-and-innovation/research-area/industrial-research-and-innovation/industry-50_en","","ü§Æ (2)"
"766684226455207996","bright_hummingbird_31342","2021-12-01T04:55:47.5230000+08:00","Industry 7.0, courtesy of Liquidtool

*It‚Äôs not hard to link the industrial revolutions to the megatrends. In our hypothesis, Industry 5.0 will lead us from the information age to the age of health and experience, with new experience expectations leading to an increased demand for customization and individualization. Industry 6.0 will introduce the ‚ÄúEmotional Machines,‚Äù opening up new possibilities for psychosocial health care. The second half of the age of health and experience will then be dominated by Industry 7.0, which will usher in the age of life science and completely redefine the relationship between man and machine. This brings us to the end of our ‚Äújourney through the industrial revolutions‚Äù in which we considered one possible future.*","https://cdn.discordapp.com/attachments/815945777452941313/915345388872032356/unknown.png?ex=68dee6d3&is=68dd9553&hm=441a7c95dd586e2216cb30361478e436195bb3ff936284ecbcc294d15bd8843f&",""
"766684226455207996","bright_hummingbird_31342","2021-12-01T04:58:06.4880000+08:00","Industry 6.0.  My head hurts.
https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cmu2.12284
https://www.alliedict.fi/wp-content/uploads/2021/08/Industry-X-White-Paper-3.5.2021_Final.pdf","",""
"867075936054149191","rickbullotta","2021-12-01T08:05:42.2100000+08:00","Bah.  All that warm and fuzzy ""we are the world"" and ""let's save the planet"" bullshit.  Ha ha.  JK","",""
"329780110704246790","rkwadd","2021-12-01T08:16:31.4220000+08:00","I just try to distinguish between a bunch of random companies, professors, or individuals talking Industrie 9000 or whatever and the official European Commission position. Industrie 4.0 for example isn‚Äôt vague or ill defined, no matter how many talking heads say ‚Äúeveryone has their own definition‚Äù: it‚Äôs an industrial policy written by and for Germany. Doesn‚Äôt make the definition better or more useful or less tedious per se but it‚Äôs absolutely traceable to a single specific source.","",""
"329780110704246790","rkwadd","2021-12-01T08:18:00.8950000+08:00","It‚Äôs like if you look up ‚Äús***posting‚Äù on urban dictionary and the top result has a billion likes. We can safely say that‚Äôs the consensus definition. Thanks, Web 2.0!","",""
"766684226455207996","bright_hummingbird_31342","2021-12-01T08:42:19.3570000+08:00","So, Industrie 5.0 is ~~search engine optimization~~ s***posting?","","ü§î (1),ü§≠ (1)"
"794020366536146977","mparris","2021-12-01T16:12:24.0020000+08:00","What makes you think that OPC UA in its current form isn't appropriate for PLCs as a client? I seen to recall some marketing regarding OPC UA being able to scale down to embedded devices.

If the purpose of a companion spec isn't to improve the speed of integrating compatible products through plug and play, then that is a complete failure of designing specs/products with the customer in mind. Or maybe the customer that OPC UA working groups have in mind is, in fact, someone else besides industrial integrators?","",""
"794020366536146977","mparris","2021-12-01T16:17:17.7580000+08:00","To say that having options in the spec simplifies things is to speak from the server/producer perspective and also from the developer perspective.

It most certainly does not simplify for the end user, especially over trying to purchase a client/consumer. For example:

Software A includes the core plus feature 1
Software B includes the core plus feature 1 and 2
Software C includes the core plus feature 2

Feature 3 is actually needed...

How simple is it for the end user to wade through all the possible products, read the fine print of each, and potentially locate that one product that supports an optional feature?","",""
"794542235676180500","akoscs","2021-12-01T16:22:00.1050000+08:00","There is no special thing that makes it inappropriate, just that it was not designed to be used at that level of the pyramid. Yes, scale down to embedded with an OPC-UA Server (not client), so that it is easy to integrate with an MES system. The purpose of a companion spec is to provide a common semantic understanding to a commonly accepted information model, which will make devices interchangeable. I.e. I make a nice dashboard for my CNC machine with a Fanuc Controller, I change only the IP address it connects to and it can show the same things for my CNC Machine with a Siemens controller. Your mouse analogy was really good, but did not take into account that the key to using mouses form different manufacturers with the same driver is a commonly accepted information model, which are the comp. specs. Plug and play comes after you implement something. Then you can plug and play a different device instead of your original one.","",""
"794542235676180500","akoscs","2021-12-01T16:23:48.3990000+08:00","What is the alternative you are arguing for? SW-A includes all bells and whistles and it is extremely expensive due to all bells and whistles, but you only use the core features. Embedded device B does not implement OPC-UA beacuse it has no computational power to support all functions so it cannot implement OPC-UA. Would that be better?","",""
"794020366536146977","mparris","2021-12-01T16:25:57.3010000+08:00","How confident would a system integrator make an optional feature as part of the architecture without some reasonable guarantees that many products will implement it?


The spec with many options places a heavy burden on the developer of a client/consumer. To make it full-featured, the developer must accommodate ALL options, all the while wondering while writing the code: ""is anyone going to use this stuff anyway?"" So most developers don't do the options since there isn't strong market support, so then the options become irrelevant for three industry as a whole. 

 Time spent developing the spec for the option, time spent for developers to learn the options and decide whether it makes sense to implement, all wasted churn, in my opinion.","",""
"794542235676180500","akoscs","2021-12-01T16:30:25.6160000+08:00","Exactly! One company can decide which are the parts I can make money with. The key is to describe very well which options are here and which are not. But codeing an optional feature means that someone decided that we will have clients for it. That is better then coding a mandatory feature where you know that you never make money with it. You can argue for system integrators needing all features, to spend less time on selecting SW/HW, but can they afford products with all OPC-UA bells and whistles which they will then not use? Would that be a cost effective approach? I think not!","",""
"817835202746253344","IIoT#4707","2021-12-01T16:30:26.0290000+08:00","GG @akos, you just advanced to level 2!","",""
"794020366536146977","mparris","2021-12-01T16:36:24.1290000+08:00","The analogy for the USB mouse holds.

Imagine the consumer electronics industry sold PCs stating USB support, and after inspecting the hardware it does reveal a USB port, but after bringing home the PC and plugging in the mouse, you discover an ""unknown device"" message.

Oops... The fine print of the mouse says you have to write your own driver. But the OEM doesn't think this is problem, because once you write the driver, you'll be able to use any USB mouse after that.

This is why OPC UA companion specs won't succeed in the market... The working groups are failing to have products lined up to consume the model without each customer having to write the ""driver""

For example, how many products exist that can connect to an AutoID device or of the box... Just an IP Address and security credentials. It's been out 6 years and it's a very simple and obvious use case... And even despite this, no products have been produced.

I cannot say why this is happening, just from the perspective of an end user, that it is happening.","",""
"794020366536146977","mparris","2021-12-01T16:40:41.5810000+08:00","My proposal would be for the spec to be agile-like in its development.

Be laser-focused on the functions that cover the 85% of use cases, keep it slim, then spend the effort getting so many OEMs on board across all parts of the automation stack that you won't need a tag line that it is the Industrial Interoperability Standard, because the results in the market will speak for themselves.

Then continue to add extra features that have similar effects across much if the market.","",""
"794020366536146977","mparris","2021-12-01T16:44:29.6030000+08:00","The worth of a product manager is not defined by what he says ""Yes"" to, but what he says ""No"" to","",""
"794020366536146977","mparris","2021-12-01T16:55:32.4170000+08:00","Also, many think that companion specifications are just data structure definitions, but this is a narrow view. Specifications like AutoID and Machine Vision specify the means to manage state machines of the device, options to connect to the device to get data, etc. These are all functions that have to be developed in a""driver"" if the end user is going to make use of that companion spec.

There fact that OPC Foundation member OEMs are not doing the heavy lifting here is not a good sign that these will proliferate in the market.

If I, as an end user, am responsible to develop a driver for an OPC-UA bar code scanner in a PLC as has been demonstrated at OPC UA events, then it is a hard sell why an end user would want to lock themselves into the small ecosystem of devices with the additional burden to develop the driver, VS using Modbus/TCP where am integrator may need to spend 10mimutes learning the register map, but after that, it's done.","","üíØ (1)"
"794020366536146977","mparris","2021-12-01T16:59:47.3820000+08:00","Those in the OPC Foundation would consider it anathema to be compared to Modbus/TCP, but in my opinion, if market execution is so poor that people can seriously consider the PROs and CONs of OPC vs Modbus, then it is seriously failing... If the spec is doing its job, there would be no serious discussion/consideration of using Modbus over OPC UA in there market with devices... It would be an obvious choice... Just as nobody considers using a serial mouse  over a USB mouse.","",""
"794020366536146977","mparris","2021-12-01T17:02:46.8650000+08:00","But as you said, there is the Field Level Communication coming out.

This will be another opportunity for the Foundation and it's members to deploy a spec to the market. I'm curious to see if they have learned lessons from over the past 15 years to get the technology more widely adopted and useful for end users.","",""
"794542235676180500","akoscs","2021-12-01T17:10:37.5540000+08:00","Let me be clear, there is a lot that could be improved with the whole OPC-UA situation, but I think there is no alternative which is better in **all aspects** and trying to give credit where credit is due. To continue your mouse analogy, your plug and play mouse has a driver which can be used on exactly one platform. Luckily there are only 3-4 platforms for your mouse. Try using the advanced features of your fancy Logitech mouse on FreeBSD...The mouse only works with the bare minimum of functions with a driver someone (not Logitech) wrote. Does the fine print say that you need to write a driver for FreBSD? No it says works with win/mac/linux.  ...

What is the basis for creating a product which can communicate with a large number of the similar devices from different manufacturers? A common understanding of what core functionality and an implementation from the manufacturers. If you do not start with device manufacturers and a common core functionality you cannot make any steps forward in any directions. Then you have a landscape which is so fragmented and so application specific that you have no chance to make anything that is plug and play. Without comp. spec there is no start in any favorable direction.

So...you mentioned agile. Why not make an agile spec...well quite frankly if you are arguing against optional components how can you argue for agile? In agile you implement the first iteration release your product, then comes the next iteration, which your product does not support. You start developing the new firmware version, this takes time, so for a while you are in a state where you have to compare spec integration versions between components to asses compatibility. I think that is way worse then optional components. Furthermore it adds advantage to large manufacturers, which have a large team and disfavors smaller teams of small manufacturers which cannot afford fast reaction times.","",""
"794542235676180500","akoscs","2021-12-01T17:17:16.0550000+08:00","Modbus is an alternative for extremly simple usecases. If you can do it with modbus...then do it. You spend 10 mins and you are done. OK. Then you buy a new device. Now you have to add a new feature to a running system, you need to test it, etc. With AudoID this is a very easy change if you have the ""driver"". So do you invest initial dev time to ease your tasks later on, or do you invest less time and hope for the best. OPC-UA and comp specs gives you this decision, without it you do not have the l uxsury to decide for your self. Then your first device brakes, there is no drop in alternative. With AutoID you have a **chance** of a drop in alternative (I agree, there is a slim chance, but at least you are in control of making a decision). If that chance is high or low....depends on the market, but that chance comes from the manufacturers! So if you cater to the manufacturers you might just get devices which are autoID compatible. If you cater to system integrators...you will have even less manufactures...so if you want devices you have to cater to manufacturers.","",""
"794542235676180500","akoscs","2021-12-01T17:19:39.2640000+08:00","You do not have a serial port, so nobody is considering a serial mouse. If you had a serial port, you would not see any serious gamer with a USB mouse (ok maybe keyboard not mouse, but this is only an analogy)! Reaction time on a serial port (which is NOT a USB connected one with a converter would be faster)","",""
"794020366536146977","mparris","2021-12-01T17:23:44.5790000+08:00","Here is the difference with OPC and USB:

To get core functions of the USB mouse, I can reasonably assume that all operating systems will include a driver to provide core functions (3-buttons and x-y movement). If my mouse has extra features (business, gyroscope, etc), the OEM includes a driver to be installed on one of more operating systems. If buying a device with optional functions, the burden placed in the consumer is simply to verify that the supplied driver will work with the intended operating system.

With an OPC UA barcode scanner and PLC there are many hurdles:
1) Consumer must find a barcode scanner that supports OPC US
2) consumer must find a PLC that includes an OPC UA client
3) the consumer cannot assume that these two products will work out-is-the-box. In fact, the consumer is expected to write the""driver"" for core functions
4) if there are extra features of the bar code scanner, then the consumer cannot assume that the OEM will supply drivers. In fact, the consumer must write the""driver"" to make use of the extra functions","",""
"794020366536146977","mparris","2021-12-01T17:35:36.7860000+08:00","I agree with you... In theory.

If there were more products supporting AutoID (many major OEMs are not convinced of the technology since they haven't deployed to any products. And the OEMs that ARE convinced haven't committed to deploying to all of their products.)

So the future of AutoID can't be assumed. The risk of the future, in addition to the lack of OPC products available today are the boat anchors.

I think the market would look different if the OPC UA feature set was as simple as modbus. But instead, the strategy was to include so many features that one could never exhaust all the great benefits of OPC.

Except these statements are mostly rooted in what is possible, or what could be available if some company would choose to use it. These statements are rarely what is available on the market today.","",""
"794542235676180500","akoscs","2021-12-01T17:36:23.5950000+08:00","I will just assume that instead of PLC you worte system, because, again....OPC-UA  was not meant to be used at that level. You are right, in these steps. 
1) yes
2) yes
3) Consumer can look for a ""driver"" for any AutoID barcode scanner, does not have to be exact same make and model. After, if a driver cannot be found he/she can write his own adn publish it as an open source component. So next time anybode does any basic stuff with an AutoID barcodescanner already has a driver, without any additonal programming or configuration. This is unprecedented in the automation world! Is it perfect? No absolutly not! is there any alternative to this? No. There is no commonly agreed upon information model other then the comp spec which does this!
4) Yes, vendor specific functions are custom and are optional. If your barcode reader happens to measure temprature and humifity also, you can access this information probably only for this make and model. What is the alternative? No access to this? Well if you need it form some reason, then you have to access it. Make it mandatory for all barcode readers? Well you only need it for your 1 custom very special application, why force everyone to add extra stuff","",""
"794542235676180500","akoscs","2021-12-01T17:39:45.7640000+08:00","Marked adoption is problematic. What can help with that? Convincing more and more manufacturers to add OPC UA to other products. e.g. one OEM is producing barcode readers and scales. He considers  adding AutoID, but decides that it is not worth the investment. Now comes the opcua comp spec for scales. Now the decidion to add OPC-UA to both scales and barcode readers can be beneficial because the costs can be spread around more devices and not it may just be worth it.","",""
"794020366536146977","mparris","2021-12-01T17:42:24.9500000+08:00","I have only identified one product that exists in any level of the automation stack that advertises support for consuming AutoID. For one of the simplest and oldest companion specs, this is not good news for OPC Foundation.

Regarding his to improve market adoption, I'm not clear what the hurdle is.","",""
"794542235676180500","akoscs","2021-12-01T17:45:01.6420000+08:00","OK, so you are arguing for a simple Modbus like protocol. I assume you want to add machine readable type definitions, security, and at least some other modern features. Someone else wants alarms. What to do with all of these? Make all things mandatory or get a list of core features and make those mandatory and the rest optional? Now we can argue about what goes on the mandatory list, but that always differs form person to person. I think the approach is right, maybe not the right granularity, but I do not see a better alternative to the approach of core and optional.","",""
"794542235676180500","akoscs","2021-12-01T17:45:50.1270000+08:00","EDIT: (Changed any to many....) Many OPC-UA client can consume AutoID. You just have to set the nodes up and you are done. The difference is that one OPC-Ua client set up for AutoID can plug and play talk to all AutoID barcode readers (wihtout any change). You might see an advanage here, or you might say the initial setup is not worth a **chance** or a supposed less workload later on. That is OK, but there were no other promises made which were broken.","",""
"794020366536146977","mparris","2021-12-01T17:49:16.7770000+08:00","For a bar code scanner, it doesn't have a vested interest in one protocol or another. So for them, I imagine it is technical capability of the hardware and investment of development time.

An OEM is out to make money, so one that hasn't implemented the AutoID is likely not convinced that it will help sell barcodes or significant improve the user experience, or the requirements of the spec are too heavy to implement on the existing hardware.

So there has to be value for the end user, and the spec needs to be implementable on embedded devices: both client and server.","",""
"794542235676180500","akoscs","2021-12-01T17:50:14.2080000+08:00","Or that OEM just wants to preserve vendor locking, which AutoID fights against.... Server first, client can already work when set up. Specific AutoID clients can follow as open source if someone ha sinterest or can follow as payed modules once ther is a market of AutoID servers","",""
"794020366536146977","mparris","2021-12-01T17:52:33.8750000+08:00","With a bar code scanner that supports modbus/TCP, Ethernet/IP, profinet, and raw TCP sockets, I don't think vendor lock is on their mind. I think it's more likely they don't want to spend the effort to develop these features when nobody will immediately benefit","","üíØ (1)"
"794542235676180500","akoscs","2021-12-01T17:54:06.1240000+08:00","Vendor lockin due to a non standard informaiton model. If you implemented their special dirver once you are incentivised to but the same thing form the same manufacturer","",""
"794020366536146977","mparris","2021-12-01T17:54:12.0910000+08:00","I would argue the client should come first to reveal the killer function that everyone is missing out on, then the servers will follow.

The OPC roll out has been in reverse... Get a bunch of servers and try and convince integrators to build up applications to use them","",""
"794542235676180500","akoscs","2021-12-01T17:55:18.8460000+08:00","SO what do you do with your killer client which has no server to connect to? How would you sell that? Who would be interested in implementing open source software which does not have a server to connect to?","",""
"794542235676180500","akoscs","2021-12-01T17:56:16.5360000+08:00","I might just chage my name to OPC-Ua fanboy at this point, but I am really not a fanboy...I know it comes off otherwise","",""
"794020366536146977","mparris","2021-12-01T17:56:48.3700000+08:00","I don't know of any controls engineers that complain about different devices using different registers in Modbus or Ethernet/IP or Profinet for bar code scanners.

Is that a common pain point you hear about from controls engineers?","",""
"794020366536146977","mparris","2021-12-01T17:59:29.7080000+08:00","1 purchasable client with an obvious use case that anyone can understand the benefit paired with 1 servers is all you need.","",""
"794542235676180500","akoscs","2021-12-01T17:59:42.2260000+08:00","I hear that they have too much work because you again bought something that is not compatible with what we already have. I hear MES Project costs skyrocket because the 1000 variables need to be mapped to a data model form 70 CNC machines wich have 7 different controlles, that meaning 7x1000 mappings instead of 1x1000 mapping. I hear people complain that it would be great to do one dashboard for my robot and just duplicate it change the IP and use ti form my other robot from a different manufacturer.","",""
"794542235676180500","akoscs","2021-12-01T18:03:10.6470000+08:00","How about one open source client, which you only configure once and instantiave 70 times and just pushes all your data to <insert data platform here> instead of having to confiugre it for all the different controllers that you have? Or being sure that that controller cna deliver spindel coolant temprature because the standarized information model includes it?","",""
"817835202746253344","IIoT#4707","2021-12-01T18:03:10.9650000+08:00","GG @akos, you just advanced to level 3!","",""
"794020366536146977","mparris","2021-12-01T18:06:25.1560000+08:00","That sounds like a great deliverable that should be required with release of a companion specification from the OPC Foundation. Not just words on paper, but actually a reference design for a usable product.","",""
"794020366536146977","mparris","2021-12-01T18:11:11.0950000+08:00","With AutoID, there is logic required to make use of it... Standard OPC client functions are not sufficient:
1) Determine what type of devices it is: barcode scanner, RFID, OCR, etc
2) determine what mechanism this particular device uses to expose its data: a) call a method and get data back, b) subscribe to an event and get data, c) subscribe to an event then have to call a method, d) subscribe to a data tag
3) call a method to start the bar code scanner process.
Etc","",""
"794020366536146977","mparris","2021-12-01T18:12:11.9150000+08:00","I was a fan boy, too. Then I tried to start using it. Now I'm a recovering fan boy üòâ","",""
"794542235676180500","akoscs","2021-12-01T18:23:52.6560000+08:00","Using OPC-UA was a far better experience then using anything else. It had its learning curve, but I am using it to connect PLCs (and other stuff) to SW which I write, run and deploy..so I guess I am their ideal usecase.","",""
"794542235676180500","akoscs","2021-12-01T18:25:54.4110000+08:00","Yes, OPC-UA Foundation currently is working on open source libraries as reference implementations and mocked use-cases (so you can run the whole thing attached to a mocked device and not need a device)","",""
"794542235676180500","akoscs","2021-12-01T18:42:55.2480000+08:00","This is what I mean, by it was not meant to be used at the PLC level. I downloaded the spec. You have 4 options to read data. Using an OPC-Ua Client library with python/.net/c++/java etc. you can implement all 4 options of scanning stuff in about an hour (ok...probably 3 with a high test coverage and debugging) and your application can conform to the device capabilities with minimal effort.  On a PLC this is way harder.","",""
"794020366536146977","mparris","2021-12-01T20:45:28.3840000+08:00","I can see why you would think OPC clients are not intended for PLCs, but the president of the OPC Foundation doesn't agree. When presented this very use case, he pointed out the fact that much work had been done to define OPC UA Client function blocks through the PLCopen companion specification. 

Mission accomplished.","",""
"867075936054149191","rickbullotta","2021-12-01T22:03:16.0530000+08:00","Generally I would write *to* the PLC as part of supervisory logic rather than having PLCs read *from* some other data source.  I don't want to be modifying PLC code in general, particularly with legacy PLCs or OEM PLCs.","","üëç (1)"
"794542235676180500","akoscs","2021-12-01T22:10:03.5230000+08:00","OK. I give up. I still think that OPC-UA is not meant for this, and the fact that there is work done to make it somewhat usable is great! If it is not exactly what you wanted, it is just a generic client. Nobody made  a specific AuToID client for you yet. Well make one and make it open source and then everybody has one... That is the whole point of it.","",""
"794020366536146977","mparris","2021-12-01T23:05:51.8570000+08:00","Maybe others use software middleware to connect ID devices to PLCs, but it seems common to have a PLC connect to one over Modbus or it's native protocol.

My hope has been that OPC UA would be able to completely displace Modbus, just as the USB flash drive did the floppy. But I don't think that the OPC Foundation is trying to do this, just looking at how things are moving.

Then there is the Field Level communications. So will the Foundation punt on pushing devices like bar code scanners to support traditional OPC UA client/server and instead encourage them to support FLC? And will devices be more willing to implement AutoID over FLC, or will it also struggle in the market?","",""
"867075936054149191","rickbullotta","2021-12-01T23:07:42.9170000+08:00","I was specifically referring to the use of OPC UA.  Of course PLC peer-to-peer communications is common, but rarely using OPC UA in the real world that I've seen.

I think part of the goal of OPC UA over TSN was to enable it to move towards field level communications with I/O and for more deterministic peer comms like you'd see in a classic DCS system.","",""
"794020366536146977","mparris","2021-12-01T23:09:30.6130000+08:00","Looks to me that they want to have OPC UA be everywhere...

https://opcconnect.opcfoundation.org/wp-content/uploads/2021/09/OPC-UA-for-Field-in-FA-and-PA.jpg","",""
"794542235676180500","akoscs","2021-12-01T23:14:25.2840000+08:00","Look at the arrow, initative for FLC","",""
"794020366536146977","mparris","2021-12-01T23:14:30.2160000+08:00","I agree. The companion specs of AutoID, Machine Vision, and Robot are ripe to have ""drivers"" baked into the PLC or other SCADA system to exchange data directly in a plug and play fashion.

This is a hole that I'm surprised had not been filled by the Foundation to promote their specification.

And everything @akos is saying that the integrator should develop the companion spec interface since the Foundation didn't convince their members OEMs to include them is true... That is the state of things.  I just think it doesn't have to be that way.","",""
"867075936054149191","rickbullotta","2021-12-01T23:17:15.2350000+08:00","Though I still wonder in the ""big picture"" if the OPC UA model is the right one in the sense that it (usually) creates a shit ton of point to point connections versus a broker model.  There are lots of advantages to a broker model (at least one that is properly implemented), and of course some disadvantages too (potential performance or availability choke point).  But I'm generally not a fan of a 1950's style telephone switchboard, which is what you kinda need to implement, don't you?","",""
"794020366536146977","mparris","2021-12-01T23:17:59.5450000+08:00","Yes, that diagram does answer my question about where the Foundation plans to go for FLC vs the traditional client/server. The question is whether they will get better producer/consumer adoption among OEMs saying they are supportive of OPC UA, and whether the existing companion specs will be revised to map to FLC as well.","",""
"794020366536146977","mparris","2021-12-01T23:20:04.9070000+08:00","They are purposefully vague by just putting ""OPC UA"" across the whole Enterprise. Technically speaking, you could use Part 14 Pub/Sub and get that broker functionality.

Don't forget...""OPC UA loves MQTT""","",""
"794020366536146977","mparris","2021-12-01T23:21:03.0070000+08:00","It just would be very difficult to implement what the spec writers have in their head using readily available products","",""
"766684226455207996","bright_hummingbird_31342","2021-12-01T23:21:18.4810000+08:00","Precisely.","https://cdn.discordapp.com/attachments/815945777452941313/915623600906731530/OPC-UA_Vertical_Integration.png?ex=68df412d&is=68ddefad&hm=92d7aabe8db570f5d82c9fcad4477772706eb05fb1c884ade4907a222039c275&",""
"817835202746253344","IIoT#4707","2021-12-01T23:21:18.7580000+08:00","GG @js, you just advanced to level 16!","",""
"794020366536146977","mparris","2021-12-01T23:25:36.0790000+08:00","I think this diagram says a lot... That the authors of the spec were so used to the pyramid models, that the most popular reference architecture was cascading OPC aggregating servers. Then Pub/Sub was released a couple years later.","",""
"867075936054149191","rickbullotta","2021-12-01T23:29:02.1550000+08:00","Worse, they just show the single black line connecting the clients/servers to the layers when in fact you're effectively connecting each client to each server (or the ones that it needs to).  That would be one messy diagram!","",""
"794020366536146977","mparris","2021-12-01T23:31:50.3860000+08:00","I drew that diagram for our own systems to help others understand the difference between OPC client/server and MQTT.  one of the two diagrams is unequivocally prettier üòâ","",""
"766684226455207996","bright_hummingbird_31342","2021-12-01T23:32:36.3030000+08:00","I would venture to say that there was an emphasis on methods (i.e., ""configuration"") in addition to data access.  It's cool having everything exposed to be remotely interfaced, but this point-to-point approach seems impossible to standup and lifecycle.

It's not even clear how this would work in pub/sub architecture.  But, few nodes support methods anyways, so why bother.
https://opcfoundation.org/forum/opc-ua-standard/calling-method-in-pubsub-infrastructure/","",""
"766684226455207996","bright_hummingbird_31342","2021-12-01T23:52:36.7200000+08:00","And imagine doing it all without any sort of orchestration or directory (e.g., Global Discovery Services).  Need to make a change to a node?  Good luck propagating the change through all the layers to other nodes.

This architecture is like pouring glue into a company.  It will lock it up for years and make change painful.","","üíØ (1)"
"867075936054149191","rickbullotta","2021-12-02T01:05:07.5210000+08:00","In a weird and twisted way, over the years we sort of figured this out and intentionally or unintentionally realized that the historian and the SCADA nodes were the ""brokers"" and UNS.  This approach also ensures that comms traffic to/from the PLCs, controllers and sensors was minimized and optimized and easier to manage.  I still find it baffling to understand why people still want to talk directly to the PLCs in scenarios where the data is already in a SCADA system or historian.  Just don't do it!","",""
"766684226455207996","bright_hummingbird_31342","2021-12-02T01:09:54.6020000+08:00","I don't think convincing is going to work.  Many of us know this from first-hand experience.  It's very challenging to convince someone to take on a bad deal.  And if it's mandated, one will conspire to pass on all the cost and then some or walk away entirely.  A good standard is one that encourages adoption and fosters a valuable ecosystem.

This is why execution is so important.  Taking a Metcalfe's Law view, the OPC Foundation has been perpetually spinning its wheels in the early stage.  If we take the narrow view that OPC-UA (in ""base"" DA client/server form) been widely adopted, we could concede that it's a valuable network.  But, at the same time, we could argue that it's not much more valuable than alternatives (e.g., native protocols, fieldbus, http).  OPC-UA, in-practice, allows us little more than protocol normalization of name-value pairs with security and without  Windows DCOM.  Theoretically, it does not much more than this.  In fact, it's purported as more than a protocol and the UN of Automation.  But, the value of this ecosystem is quite low.  There are few nodes.  Investing  in it is so costly that most determine it's just not worth it.  And this is not just traditional or small firms.  Even blue-chip firms with top-tier corporate memberships and board seats at the OPC Foundation have elected not to.","https://cdn.discordapp.com/attachments/815945777452941313/915650930748313600/OPC-UA_Metcalfes_Law_Market_Execution.PNG?ex=68df5aa1&is=68de0921&hm=fe5a3de05d8b4e45c1bab10a425fab46cf26c4c30c7cf4948f401b37377d412f&",""
"766684226455207996","bright_hummingbird_31342","2021-12-02T01:36:23.8150000+08:00","You're right.  Perhaps this is function of how these solutions are being sold.  Is it gullible buyers?  Is it herding behavior?  If I were to look at all the demos I've seen the past few years, I could naively conclude that all one needs with PLC data is a state indicator overlaying Google Maps or a trend it in Power BI.","",""
"766684226455207996","bright_hummingbird_31342","2021-12-10T04:21:29.4300000+08:00","Maximum Technical Requirements:
-Client-driven
-Heavyweight
-Report-by-subscriptions
-Membership-based Architecture","","üòÑ (8)"
"745009912160976977","marioishikawa","2021-12-10T05:36:12.8780000+08:00","Report by request, tag per tag üòÑ","",""
"745009912160976977","marioishikawa","2021-12-10T05:36:24.4670000+08:00","you could make that brain meme","",""
"745009912160976977","marioishikawa","2021-12-10T05:36:41.9570000+08:00","https://tenor.com/view/brain-who-whom-gif-13818655","",""
"923367369965994034","brendanrice4710","2021-12-31T07:07:05.5260000+08:00","Did this video ever come to fruition?","","‚ûï (1)"
"867075936054149191","rickbullotta","2022-01-08T02:23:47.9170000+08:00","‚ÄúOpen Standard‚Äù. Lol. How awful.","https://cdn.discordapp.com/attachments/815945777452941313/929077878648361060/IMG_0803.png?ex=68df6bf3&is=68de1a73&hm=2714cd3ecd3405659008d6d4e58f80446dd9d416895784cd483c9fdf0c1f7cd1&","‚ùó (2)"
"194289793905983489","zackscriven","2022-01-11T07:01:45.8080000+08:00","LOL!","",""
"329780110704246790","rkwadd","2022-01-11T10:49:28.8700000+08:00","I have no love for paid standards held for ransom by alphabet soup orgs, but ‚Äúopenness‚Äù doesn‚Äôt mean free. It just means that you can‚Äôt exclude stakeholders. The idea is to prevent scenarios like creating a standard that user will bake into their requirements, building in a feature that leads to a single vendor holding the implementation, then excluding competitors or customers who won‚Äôt pay up from the development activities.  Or scenarios like ‚ÄúRick can‚Äôt be on this standards committee because we hate his stupid face.‚Äù","","üòÇ (1)"
"329780110704246790","rkwadd","2022-01-11T10:53:55.3870000+08:00","charging for a framework like this really helps no one though. RAMI 4.0 and the IIC Reference Architecture are more thorough and freely available.","",""
"538677655000842260","na23909","2022-01-12T05:20:52.8490000+08:00","Hi there Namur ist displaying a new unifed Architecture called NOA https://m.youtube.com/watch?v=iVC_9qriM5A&feature=emb_logo","",""
"891563487241842699","jbonhage155","2022-01-13T03:46:15.2410000+08:00","Has anyone used Snowflake? 
Thoughts on it strengths / weaknesses in regarding to OT data?","",""
"867075936054149191","rickbullotta","2022-01-13T04:23:47.4530000+08:00","High latency between ingest and availability for query, potentially very pricy depending on how long you retain data and how many analytics jobs you run.  Not what I'd recommend for your primary data store - maybe for a transient analytics store.","","üëç (1)"
"794020366536146977","mparris","2022-01-22T03:56:05.1610000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/934174533764669500/unknown.png?ex=68df8194&is=68de3014&hm=807d892f8e9c8372f5afefdfebaebb4b581fb848478ec025755a48829c6322dd&",""
"794020366536146977","mparris","2022-01-22T04:15:25.2850000+08:00","""OPC UA vs MQTT"" is always too general for a meaningful discussion.

It depends on what is meant by ""MQTT"" and ""OPC UA""","",""
"794020366536146977","mparris","2022-01-22T04:35:25.1340000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/934184432376610897/unknown.png?ex=68dee20c&is=68dd908c&hm=185e739e4cdf0b714f4c4fd004da2d1c73c7851b3795085c16cb578cbd85606f&","üëè (5)"
"690187418376208506","dzimmerman","2022-01-22T09:03:49.0880000+08:00","That is really good is that something you can share? Can't save the file","",""
"794020366536146977","mparris","2022-01-24T21:43:10.0650000+08:00","In the mobile Discord app, do you see a download icon in the top-right off the screen when you tap the picture?

When you download it, it is titled ""unknown.png""","",""
"690187418376208506","dzimmerman","2022-01-25T02:51:29.2380000+08:00","Interesting yes on mobile it's downloadable. Did not know that","",""
"571815818308878347","binyameen_980","2022-01-25T03:00:30.4090000+08:00","On desktop you can click on file to open it. Then right click and hit ""Save Image""","",""
"801561312861618236","jon.forbord","2022-01-25T03:07:11.9480000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/935249394654130236/image0.jpg?ex=68df761f&is=68de249f&hm=bda64ef4612951ddaccf1f20a98b7108cb470932613be176def7de8315a3b8ef&",""
"690187418376208506","dzimmerman","2022-01-25T04:54:48.8010000+08:00","Yes tried that but for some reason it doesn't work. I can download it from a mobile device but not desktop","",""
"801561312861618236","jon.forbord","2022-01-25T05:13:30.6440000+08:00","Sorry, I misread it üôÇ","",""
"571815818308878347","binyameen_980","2022-01-25T13:59:47.7310000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/935413626108534804/Screenshot_2022-01-25_105846.png?ex=68df6653&is=68de14d3&hm=3c34f7f26cc66f27a82460b41534d4bac9c801afafcfbe810214d1551ea23404&",""
"690187418376208506","dzimmerman","2022-01-25T20:58:01.7630000+08:00","I know how to do it but have you actually tried to save image?","",""
"571815818308878347","binyameen_980","2022-01-25T20:59:25.9030000+08:00","Yes I have","",""
"690187418376208506","dzimmerman","2022-01-25T21:00:43.4660000+08:00","Interesting my computor at home and at work give me a image can not be saved error","",""
"571815818308878347","binyameen_980","2022-01-25T21:30:00.4950000+08:00","That is weird. I often save useful images. I have saved this one too","",""
"794020366536146977","mparris","2022-01-25T21:49:11.8100000+08:00","Try to click ""Open Original""

That should open a new tab with nothing but the image.  Then you should be able to right-click and save the image, just as you would on any other website","https://cdn.discordapp.com/attachments/815945777452941313/935531753106448394/unknown.png?ex=68df2b97&is=68ddda17&hm=0a68b2106170cc116d854136472fb9869364074b98290d8efdba72289c96367a&,https://cdn.discordapp.com/attachments/815945777452941313/935531753303576627/unknown.png?ex=68df2b97&is=68ddda17&hm=db22607600d6b3d5b8c3feef37cff912a6e3f09436d64e14362a5f39a9e238a2&,https://cdn.discordapp.com/attachments/815945777452941313/935531753521700914/unknown.png?ex=68df2b97&is=68ddda17&hm=61493c21b16ba71db50f2bc05f20ddada8fc413e21fd474f9a787856e3413f5c&","üëç (1)"
"846202449953554463","gamify6891","2022-01-26T00:04:43.1270000+08:00","On a desktop you get an option to open or copy the link. From there you are able to save it.","",""
"794542235676180500","akoscs","2022-01-26T18:42:16.6010000+08:00","I think it would be important to specify what real-time is. For motion control it is always time determinism and a specified cycle time (sometimes lower then 100 microseconds) but probably never higher then 20ms. The stacks you put together will all struggle with time determinism and I doubt that the cycle times can be in as low as 20 ms sustained.","",""
"794542235676180500","akoscs","2022-01-26T18:49:31.4820000+08:00","This is a really cool representation. What would you thingk about swithcing up Grammar and Dictionary? In my mind, these relate to lexers and parsers, Dictionary includes the tokens and Grammar is the syntax. How about serialization? Do we need an alphabet to speak the language? Is there something other then Old English / Modern Latin for the Voice-Sound stack? Wouldn't sound be the alphabet and air the Material (the physical layer)","",""
"794542235676180500","akoscs","2022-01-26T18:52:07.0930000+08:00","Is there a free standard from any of the non-software exclusive international bodies (like ISO / EN)?","",""
"329780110704246790","rkwadd","2022-01-26T21:05:51.7430000+08:00","If it‚Äôs an international standard that‚Äôs officially sanctioned, then it is going to be paid access.","",""
"783917475128410112","geoffnunan","2022-01-28T14:47:55.6510000+08:00","This is a great outline @MParris 
I note that the Applications you have considered are typically informational. That is, they are presentations with limited or no feedback from users. When you move into more transactional applications, there is a need for a common data model that extends beyond the equipment centric models in your diagram.","",""
"903763641868910622","niravpatel4231","2022-01-31T01:29:18.4900000+08:00","Sharing my new improved connectivity diagram for IIoT architecture.","https://cdn.discordapp.com/attachments/815945777452941313/937399085852414042/IIoT_Architecture-Page-3.png?ex=68df5f2e&is=68de0dae&hm=30ec86155a360ca686f5aaa82d5e0f73a21d700640c25e1e5bcb37d2493724df&","üëç (6)"
"929491385944510534","jxs9162","2022-02-12T04:11:23.4490000+08:00","I'm interested in any comments or recommendations of the following I4.0 Architecture with multiple solution options for historian, SCADA, etc.","https://cdn.discordapp.com/attachments/815945777452941313/941788529216856115/unknown.png?ex=68df852a&is=68de33aa&hm=1ed31b8ae1197bfdebf27674c0825e5354489a41ceb29bd2c75dbb00bb7a8ccc&","uns (3),üëç (3)"
"795178288330440704","youri.regnaud","2022-02-12T20:59:03.2190000+08:00","Nice, some questions : where do you normalize, contextualize your OT data? Are you sure about Node Red so high in your stack? Have you several plants?
I like Jira in the stack!","",""
"299680406595305472","scamananak","2022-02-12T22:45:06.5950000+08:00","This is really nice, very clear and easy to understand.
Im curious as to why you use both mqtt vanilla and sparkplug B? Why not all SpB and use a converter (e.g. highbyte) if the receiving program needs another format? Am I understanding correctly that you are sending both vanilla and SpB messages to your MQTT broker, as some programs need vanilla and you didn't want to convert the encoding or format perhaps?","",""
"923710333758087208","amyw0048","2022-02-16T05:17:30.9870000+08:00","Great diagram! Apologies if this question is very un-informed, but would you say this is based on the Purdue Model ?","",""
"745796393855352953","thedavidschultz","2022-02-16T05:47:58.4020000+08:00","ISA-95. They are similar but not the same.","","üëç (1),üëÜüèº (1)"
"929491385944510534","jxs9162","2022-02-17T21:52:25.7840000+08:00","Thank you.  It's a good question and I think it is a question everyone, including myself, is struggling with on merging the established architectural standards vs disruption from new technology.   But one thing I like to view Purdue and ISA 95 is they both provide a great reference on how different application types should be broken down based on many years of experience from a lot of smart people.  The new technology and protocols, like MQTT and SpB, are giant leaps to integrate these applications with many to many connections.    Using the best fit application for the right use cases is where S95 provides the best guidance, even for today's cloud vs On-Perm discussions.   Too many times I experience confusion between application teams and users where they didn't separate use cases/requirements from applications or technology they are familiar with.   There are just no single silver bullet that will solve everything.    And the first principles of supply chain and manufacturing really hasn't changed, just the tools used to solve the same problems.","","üëç (1)"
"158997520167600128","jasperlouage","2022-02-17T21:53:28.2650000+08:00","Nice diagram, Just couple of questions from my side. 
1. Why is the broker on the OT network? Doesn't this mean you need to have an inbound connection on the ot network? 
Why 
2. Why are you using all these different historians? Wouldn't it make more sense to go all-in on influxdb, canary or OSI PI? Why all three of them? 
3. And would it not make more sense to have your data going through an Ignition, so that Ignition screens can access historians data easily? You could attach influxdb and canarylabs on it quite easily
4. Do you have multiple sites? If so, are you not a little scared for you connection to break occasionally, so your Ignition SCADA will be blind during that time? Or is Ignition like not so important in your architecture?
5. How did you put ERP on MQTT? is that not very far from home for most ERP softwares?","",""
"929491385944510534","jxs9162","2022-02-17T21:53:37.7120000+08:00","Thank you Youri, I replied back on a separate post by mistake.   Moved the reply to here, where it should be.  Still learning how to use discord.

Thank you, the topic is complex so I'm glad this diagram makes sense to someone other than me.  Normalization of the OT data will depend on the use case.   I imagine there are multiple destinations for OT data, for example: process/time series data would be captured in one of the historian products leveraging UNS to take full advantage of nosql so data are captured as soon as they are exposed by the OT team.   Alternatively, UNS with message type/action keywords would drive data collection for OEE or machine state alerts.   The main goal of the architecture is really take advantage of the technologies and methodologies being discussed for Industry4.0 and expose the data to IT systems with minimum impact to OT (OT focus should be keeping the production systems running to make more wedges)","",""
"929491385944510534","jxs9162","2022-02-17T21:53:54.7620000+08:00","Thank you George, I replied back on a separate post by mistake.   Moved the reply to here, where it should be.  Still learning how to use discord.

Thank you, I'm glad this is clear to others.   The reason for including the different MQTT protocols is to provide different native options and their capabilities when considering architecture options in relation to use cases.   But your point on using a converter is noted.   There is a trade-off on capability/functionality vs the number of different components needed to accomplish the same task.   There are some low level benefits of using MQTT without SpB (ex. some device limits for UNS/topics to identify machine/device are only 3 levels with SpB).   This really can be a limiting factor to implementing SpB.   If there is a device or native function to MQTT broker that runs configurable logic to convert topic based on mqtt client ID and original topic would be one way to eliminate that limiting factory to use SpB in more use cases.","",""
"929491385944510534","jxs9162","2022-02-17T22:05:33.7750000+08:00","Thank you.   I will try to answer the best I can.

1.  The broker on the OT side is to limit the number of new rules needed on the firewall to isolate OT and IT for ICE environment.  As the plant grows or as the digital transformation expands in a factory, OT projects can run asynchronously.   Depending on the architecture and implementation on the IT side and UNS standard established, machine process data collection on new data sources with no additional work needed after OT has published the data into the broker.   Also, any existing or new implementation only needs to connect to the broker for the majority of their data.   I'm working on different use cases where additional brokers are needed on the IT side but OT side should be kept as simple as possible.   The goal is still to keep OT as simple and straightforward as possible so the equipment does what they need to do physically.

2. The different historian was just my need to show the same architecture can apply to the same solution from multiple vendors without any changes in the architecture.   I needed to show we can move from using InfluxDB for a proof of concept project then migrate to Canary or OSI PI as the digital transformation get more mature/support, there is no changes needed on the OT side or the rest of the architecture.

... continue on the next post ...","",""
"817835202746253344","IIoT#4707","2022-02-17T22:05:34.0690000+08:00","GG @Jack Shum, you just advanced to level 1!","",""
"929491385944510534","jxs9162","2022-02-17T22:30:32.8510000+08:00","3. Thank you for pointing that out, the presentation layer was a bit complex to represent on the architecture because the connections could become a spaghetti diagram.   But using just ignition would simplify the scalability of the architecture.    This is exactly why we should all share ideas to help each other.

4. Handling use cases for multiple sites is definitely not clear in this architecture.  Ignition is a great solution for a lot of use cases but the architecture is not trying to be specific solution-focused.   My thought process for multiple sites is the data persistence layer could have a mix of On-Perm/Cloud(either private or WAN)  based solutions.   But to your point on the lost of connectivity, this architecture doesn't address it very well.   So the issue here is how the data can be buffered/queued then recovered with correct timestamps.    I'm still researching on this but my initial view is SpB with the right broker solution can meet this use case.  I just need more time and create a test environment to understand this fully.

5. Yes and no.   There are some use cases, ex. in-process test results or integration of scales, that would benefit ERP in receiving data from OT.   Having an architecture to simplify the orchestration of data could reduce complexity and increase supportability.

I hope this helps in understanding the reasons behind my madness.","",""
"867075936054149191","rickbullotta","2022-02-17T22:56:01.6840000+08:00","Just to be clear, you can also use InfluxDB as your digital transformation gets more mature!  Not sure the point you're trying to make here.","",""
"158997520167600128","jasperlouage","2022-02-17T23:01:02.1990000+08:00","@Jack Shum thanks for sharing!","",""
"820097580665929808","pvmagacho","2022-02-17T23:59:24.1660000+08:00","Continuing from last YouTube video. @Walker Reynolds  mentioned we should connect the industrial network to the business network and forget about the Purdue piramid. I wonder how would that work. Anyone has any experience on that or a reference architecture to share.","",""
"929491385944510534","jxs9162","2022-02-18T01:05:17.9990000+08:00","Totally agree, it was just a possible scenario.   Sorry if the reply had implied something else and it wasn't meant to direct anyone to that exact path, it was just a scenario that I had experienced with non-technical requirements from a customer and sales team.   InfluxDB is very feature-rich and well supported.","","üëçüèº (1)"
"929491385944510534","jxs9162","2022-02-18T01:05:55.8410000+08:00","No problem.  Thank you for your comments.","",""
"829232781414236212","jcena5856","2022-02-24T16:43:29.4830000+08:00","hi folks, has anyone reviewed the Kafka platform? how would you fit it in the solution stack for DT?","",""
"829232781414236212","jcena5856","2022-02-24T16:45:21.6600000+08:00","or place it in the reference architecture?","",""
"830193224504705035","marc.jaeckle","2022-02-25T00:19:27.3110000+08:00","I would use it only as managed service in the cloud for
1. Stream processing / analytics: For stream processing you need something like Kafka to be able to do checkpointing & replaying / reprocessing data.
2. Persist data in batches to object storage & timeseries DBs: It's better (i.e. much faster) to write data in batches to objects storage like S3 or timeseries DBs. You need Kafka to replay data in case your services crashes with data in flight that hasn't been persisted yet.

Do **not** use it as a UNS.

If you use HiveMQ or EMQX for your UNS, you can connect to Kafka using their bridge extensions. Otherwise write a small service that does the forwarding. You can use MQTT manual acknowlegements to make sure you don't lose any data in case a forwarding service instance crashes with messages in flight. This will reduce your throughput though. 

Avoid running Kafka on your own. Use the Confluent offering, AWS MKS or Azure EventHubs via Kafka API.","","üíØ (1),üëçüèº (2),ü§ü (1)"
"914993398526656542","mikebartlett_nh","2022-02-25T00:45:27.6330000+08:00","We've baked it into our platform, which is a dockerized collection of microservices.  It works well as a pub/sub protocol moving streaming data between the other components in our platform (persisted storage like @Marc J√§ckle described - InfluxDB, Parquet, etc) and we can distribute services between edge and cloud.  But our root edge data collection starts with the standard stuff like OPC, MQTT, etc.  Quartic.ai is built for operationalized AI & ML so Kafka is necessary.","","üëç (1)"
"890244048739270656","brianpribe","2022-02-25T02:26:51.1210000+08:00","This is a gem","",""
"801561312861618236","jon.forbord","2022-02-25T04:03:21.9040000+08:00","Nailed it!","",""
"277515221885779970","jermuk","2022-03-26T01:04:09.5370000+08:00","bit late to the party, but I need to disagree. 

As the United Manufacturing Hub we worked with MQTT and various brokers for the past years and we are currently moving to Kafka to the sake of Reliability. MQTT is designed to connect and hold millions of low-throughput connections and it is not designed to be a central message broker in a microservice architecture. it works in small setups, but as soon as you have high availability setups, multiple microservices, devices being turned off and on and a unrealible internet connections, messages started to get lost. we actually tested multiple MQTT broker around a year ago and none of the tested were able to reliably hold messages in buffer during device or connection downtimes.

with the log based approach kafka is using we can ensure that no data gets lost, even during device restarts (e.g., some operator turning off the production machine) or internet connection failures. disadvantage is the additional complexity as it is an IT tool, so in our reference implementation in the United Manufacturing Hub we still use MQTT as an interface for automation engineers","",""
"830193224504705035","marc.jaeckle","2022-03-26T01:21:40.7370000+08:00","It's really hard to say what went wrong in your case regarding the reliability of the MQTT brokers that you used and I can't speak for all brokers. We have used HiveMQ in large scale projects and I have seen it being used in many more and HiveMQ has been extremely reliable, including setups with many microservices. There are multiple car manufacturers that run their entire fleets with multiple million vehicles on HiveMQ without problems, especially in the scenarios in which you have frequent connection downtimes (e.g. due to tunnels, parking garages or just bad internet connectivity). If you look at service to service communication it depends a bit on your specific setup if MQTT is a good solution. If messages may not get lost under any circumstances and you have a high throughput, then using manual acknowledgements can become disadvantageous as they reduce throughput which means higher infrastructure costs as you need more service instances.","","üíØ (1)"
"830193224504705035","marc.jaeckle","2022-03-26T01:27:48.3610000+08:00","If you are mainly doing stream processing and just want to store all data safely in a timeseries DB (and object storage), then using Kafka directly is a better fit. MQTT is really not very useful for doing stream processing due to it's lack of replay capabilities and checkpointing ""support"". That is exactly what Kafka was build for and is really good at. Regarding storing the data, Kafka does allow you to store data much faster with less resources than MQTT as you can write the data in large batches without having fear of losing in flight messages as you can always go back and reload them from Kafka after a service instance crashed.","","üëç (1)"
"867075936054149191","rickbullotta","2022-03-26T01:30:19.8310000+08:00","I have to once again suggest that the correct answer in cases like this is often ""AND"" nor ""OR"".  By choosing Kafka, you've basically eliminated interoperability with a broad range of industrial software tools that know how to subscribe to MQTT and for whom Kafka is a non-option.  While you might want to use Kafka for your internal data pipeline, you should still consider using an MQTT broker as an optional (or built-in) pub/sub interface for the increasing number of applications that support it.

And I want to echo @Marc J√§ckle 's comments on the reliability and robustness of HiveMQ.  It's a very viable solution for mission critical applications.","",""
"830193224504705035","marc.jaeckle","2022-03-26T01:30:42.3440000+08:00","Because of their different strengths I have used both MQTT and Kafka (or something with a Kafka API like EventHubs) together in all IoT projects over the last 7 years. I think they complement each other well.","","üëç (1)"
"830193224504705035","marc.jaeckle","2022-03-26T01:35:11.4340000+08:00","And of course you can also use Kafka for you UNS, it just might cause you some more effort and pain compared to using HiveMQ for it specifically.","",""
"830193224504705035","marc.jaeckle","2022-03-26T01:38:06.6930000+08:00","If you only need something in the cloud, are able to use managed Kafka services and don't have bandwidth issues or issues with Kafka's shortcoming regarding the support for reverse proxies / load balancers, then the difference is probably not as big.","",""
"277515221885779970","jermuk","2022-03-26T01:59:56.2660000+08:00","Thank you for the answer! Our setup was to have an edge MQTT broker and a cloud MQTT broker with a MQTT bridge between it. Then we recorded data, turned off internet connection, then the device (and various variations) and of the tested MQTT brokers none were able to handle that properly (HiveMQ was not in there, but other known brokers). I think this case is also a pretty edge case that usually does not happen for cars, etc. (MQTT bridges). 

Also our stack is more focused on stream processing, so this is why we chose MQTT and Kafka, but Kafka as the single-source-of-truth for the UNS and MQTT only to replicate and connect with other applications.","",""
"830193224504705035","marc.jaeckle","2022-03-26T03:25:35.0830000+08:00","I forgot to add one more thing: Another issue with problems like this can also be the MQTT library you are using. For example the Java Paho library has (or maybe had. haven't used it in a while) the problem that it sometimes looses the connection to the broker but thinks that it is still connected. If you don't notices this in time, the queue in the broker may run full and it will start dropping messages. Before the HiveMQ MQTT library existed, we had to implement a workaround for that meaning that all services sent themselves pings via MQTT and checked if they still received it. Theoretically fixing the paho lib would have been an alternative but looking at the messy code we decided against it.","","üòÇ (1)"
"801561312861618236","jon.forbord","2022-03-26T05:52:12.4150000+08:00","UNS != Kafka. 
UNS > MQTT
Kafka & Microservice == True
MQTT + Kafka = ‚ù§Ô∏è","",""
"801561312861618236","jon.forbord","2022-03-26T05:57:50.2140000+08:00","Kafka for unreliable connections seems to contradict most of the stuff I‚Äôve read about Kafka, as Kafka is famously reliant on reliable and high throughput  networks, and MQTT is famous for low bandwidth and unreliable networks.. ?","","üëçüèº (2)"
"821044538709114900","ianskerrett.","2022-03-28T20:49:00.7720000+08:00","FWIW, one of HiveMQ's largest customers has HiveMQ deployed in factories around the world that bridge to a cloud broker. The use case you described works perfectly fine for them.","",""
"277515221885779970","jermuk","2022-03-28T20:52:40.6290000+08:00","Could be the case that it works with HiveMQ, we tested several others and struggled with it (and ended up writing our own MQTT bridge)","","üëç (1)"
"277515221885779970","jermuk","2022-03-28T20:55:51.2310000+08:00","we are not using Kafka for unrealiable connections, we are deploying a kafka broker for each isntance (e.g., factory) and then bridge them with a self-written service. with the self-written service we can ensure that no messages get lost, but performance in high-throughput setups might be not so great. we will definitely report.","",""
"277515221885779970","jermuk","2022-03-28T20:56:38.3350000+08:00","because so many people recommended HiveMQ we will also check it out and report our findings for it","",""
"277515221885779970","jermuk","2022-03-28T20:59:55.9410000+08:00","can confirm, finding a good MQTT library is a pain. especially paho in python is difficult üòÑ","",""
"795598602772414485","kskblr07","2022-03-30T02:12:14.3490000+08:00","Is verbosity the only reason why one would prefer mqtt over amqp? otherwise both are report by exception; pub-sub and open?","",""
"867075936054149191","rickbullotta","2022-03-30T03:00:21.2110000+08:00","Much broader support in the industrial community, layered protocols like Sparkplug, ""ready to use"" QoS and persistence.","","üëç (2)"
"884665155642875954","arnesvendsen","2022-04-08T20:40:25.3470000+08:00","Hello @Jermuk  we seem to be on parallel tracks here. I am architect in a DTMA with 40 sites, where it was chosen to use Kafka-clustered with central + site-instances. So far no MQTT, but it will come. I totally agree with @RickBullotta  it is AND (not OR). As  PLCs, equipment etc  start coming with MQTT built-in, a gateway to Kafka will be inserted. It will work out.  The MORE interesting thing is how to manage/document the Unified Data Model (=UNS) - and we just started. On top of Kafka, I think the default is AVRO schemas (are there other options?). 
Fine but: We aim to have ALL enterprise data moved through Kafka over time, i.e. our UNS must describe not JUST the Equipment model, but all models (material.,product-specs, orders, warehousing, etc..)  
My current challenge is to find the good tool to hold all the data-models/descriptions in one repository. Just now looking for that tool, where we could e.g. draw all the datamodels in UML, show how they relate etc.. and then make them available for all projects/applications going to use them to connect.  Input most welcome ..","",""
"867075936054149191","rickbullotta","2022-04-08T20:54:58.4790000+08:00","This is why I believe that topic discovery and (durable) topic metadata are absolutely essential to add to MQTT.  Sparkplug can help, but only partially.","","üíØ (2)"
"277515221885779970","jermuk","2022-04-08T23:15:56.8270000+08:00","if you find a tool, feel free to share! we've been searching for one as well to document the data model of the United Manufacturing Hub. there is https://www.asyncapi.com/ but we have not used it yet. 

if you want a starting point incorporating equipment, (some) product information and orders (and a example for documentation), you can take a look here: https://docs.umh.app/docs/concepts/mqtt/ would be great to get your current data model as well (if that is allowed)

from my perspective the real challenge is not the data in the MQTT broker ""UNS"", but keeping it consistent across the entire stack (REST API, variable names and database). Example: a product is often traced through the production using a barcode and you have the same barcode for multiple stages of that product. So to model it properly in databases with prodyuct parents and childs you need an additional unique identifier. then on the REST API / frontend leven you need to have the barcode and the unique identifier. I hope I managed to get my point over. if you are interested how we handle product track & trace there is an article on our page explaining just that: https://docs.umh.app/docs/concepts/digitalshadow/","",""
"884665155642875954","arnesvendsen","2022-04-08T23:47:13.8780000+08:00","Thank you, I am checking out all on your site www.umh.app.  E.g. your mention of TimeScaleDB as a better choice than Influx, was new to me. I will check you ""MES"" solution. You remind me a bit of LibreMfg - maybe room for sharing efforts .. 
The first tool we came across in the project - to manage UNS documentation is BoUML, but it is a ""small product"" and NOT the final solution. My colleague is checking the UML->IDL ""compiler"" which is - part of - what we look for..","",""
"181876985369329672","j_1342","2022-04-11T20:39:26.9430000+08:00","Guys any comments on this architecture?  The background is that the company have a lot of facilities and the goal is for a central cloud based place for data scientists to implement ML and bring back information to optimise processes. For example if we find something interesting on Site1 to implement optimisations on SiteN. Each facility will have local data base with for example 1 month worth of data to help local operations and as a ""backup"" and the cloud will collect all of it. The core Machines and lines will be mixture of Siemens and ABB PLC's, and for the rest I'm still looking at different options inc. Kepware, HightByte, Ignition and others.","https://cdn.discordapp.com/attachments/815945777452941313/963055679696937060/Reference_architecture__3th_party.jpg?ex=68df1b3e&is=68ddc9be&hm=4ddc92156a6690ddc4937d635679bbbd77b4424ceddd7fd867f3154b36e7508e&",""
"867075936054149191","rickbullotta","2022-04-11T21:01:25.7370000+08:00","Give TwinThread a look too.","",""
"958521736029155338","iiotdev1804","2022-04-11T21:02:16.5420000+08:00","it looks pretty standard - other than it appears as though your machine  sensors are going to communicate directly to stream.. and a broker might be helpful to represent","",""
"890244048739270656","brianpribe","2022-04-11T21:44:49.3320000+08:00","Is your SCADA mqtt capable? Or does it need a gateway as well for it to connect to the broker?","",""
"181876985369329672","j_1342","2022-04-11T22:10:33.8780000+08:00","my SCADA is non existing üòÑ","",""
"890244048739270656","brianpribe","2022-04-11T22:13:17.1820000+08:00","Oh lovely üòÖ  Well what platforms have you been looking at for your MES and SCADA. If that's what you guys will be building up to.","",""
"181876985369329672","j_1342","2022-04-11T22:15:58.6440000+08:00","Im most familiar with Siemens, but Ignition looks more suitable for the job. Also been looking around for Honeywell, ProLeIT and so on","",""
"890244048739270656","brianpribe","2022-04-12T00:14:09.9350000+08:00","I'm biased towards Ignition and FrameworX. They meet my technical requirements and I've worked with the more than other (really at all).","",""
"795178288330440704","youri.regnaud","2022-04-12T01:39:40.0910000+08:00","Maybe show Edge broker per plant and a cloud broker with a bridge between Cloud Broker and Edge brokers","",""
"890244048739270656","brianpribe","2022-04-12T01:54:42.6490000+08:00","Pretty common architecture","",""
"890244048739270656","brianpribe","2022-04-12T01:57:45.1270000+08:00","However, connecting to your cloud UNS directly is preferred.","",""
"795178288330440704","youri.regnaud","2022-04-12T02:03:33.8310000+08:00","Why?","",""
"890244048739270656","brianpribe","2022-04-12T02:08:15.0680000+08:00","Scaling and the design of the architecture itself. It's where all of your nodes connect to. The more gateways, the more barriers, the harder its going to get connected and scale.","","üî• (1)"
"890244048739270656","brianpribe","2022-04-12T02:10:31.2840000+08:00","In a perfect world, there is always a stable and strong connection, your cloud UNS will be infinitely scaleable, and there are no malicious actors to compromise your system.","","ü¶Ñ (3),üí© (2),üç¶ (1)"
"890244048739270656","brianpribe","2022-04-12T02:12:27.2800000+08:00","You could connect the smallest iiot device to your UNS, and have that data be consumed by all applications effortlessly in the shortest amount of time.","",""
"867075936054149191","rickbullotta","2022-04-18T08:12:30.6910000+08:00","And unicorns will poop  ice cream and money will come out of faucets. Better to plan for unstable and weak connections, deal with the scale/performance/reliability/cost balance, and assume that there are a ton of bad actors who want to mess with your stuff.","","ü§£ (1)"
"890244048739270656","brianpribe","2022-04-18T08:29:23.1890000+08:00","You forgot about the Easter bunny bringing us a solution stack to digitally transform us all into an ISA-95 enterprise using OPC-UA and OEE!!!","","üò© (1),ü§£ (3)"
"891705751016452146","leightaylorf1","2022-04-30T17:38:22.8160000+08:00","Had a Few Conversations this week with SE and AVEVA. We are getting closer to support in GeoSCADA for MQTT SpB (Production Ready Driver being worked on at least) But also from AVEVA the attached Document showing at Least a Broker architecture that will enable a UNS to be setup with some of these products. Small Steps but in January the same people told me they had no demand for MQTT Broker architecture. Things are moving.","https://cdn.discordapp.com/attachments/815945777452941313/969895482224701500/Aveva_Reference_Architecture_Details.pdf?ex=68def0ce&is=68dd9f4e&hm=d8c38aa2f66429a0bc24bdd1c81d566f6da1c9ef4a5fa2cdcd11207b77c683a5&",""
"867075936054149191","rickbullotta","2022-04-30T23:57:44.6660000+08:00","Aveva has so many different SCADA and HMI solutions though - not a lot of consistency in capability or product strategy.","",""
"745796393855352953","thedavidschultz","2022-04-30T23:59:57.7840000+08:00","AVEVA Edge is nothing more that rebranded InduSoft which was acquired by Wonderware/SE a decade ago. The lawsuit against Tatsoft makes for an interesting read. OSIsoft PI has a connector that supports SpB after an oil company demanded it (OSIsoft stood to lose a lot of money if the company went to Canary). AVEVA now realizes that the MQTT/SpB is gaining traction as the number of competitors supporting it grows. But this continues to be a unified architecture. AVEVA will consume SpB data, but does not publish SpB data. You will continue to be locked into their ecosystem, despite their claims of being open.","","üëç (1)"
"891705751016452146","leightaylorf1","2022-05-01T00:00:33.7760000+08:00","My personal preference is to keep clear of them and the solutions, unfortunately some of the people I work for are struggling to break free. I feel like this is a step in the right direction though. A complete turnaround in story in 3 months means they are getting the message.","",""
"891705751016452146","leightaylorf1","2022-05-01T00:03:09.7460000+08:00","They say the GeoSCADA driver will be both ways, let‚Äôs wait and see.","",""
"867075936054149191","rickbullotta","2022-05-01T00:15:51.1810000+08:00","I don‚Äôt blame them for not going ‚Äúall in‚Äù on SpB (or MQTT) in their current incarnations.  As we both agree, plenty of room for improvement and functionally inferior to some proprietary approaches. Someday we might actually be able to achieve both - ideal functionality AND open/interoperable.  Someday.","",""
"745796393855352953","thedavidschultz","2022-05-01T00:18:50.5390000+08:00","I don't fault them for not going all in. There are plenty of companies who continue to use AVEVA. And new licenses are being sold. At this point, they really don't have to. But where I get sideways with them is when they claim to be open and that SP is a UNS.","","üíØ (3)"
"891563487241842699","jbonhage155","2022-05-11T06:43:20.8600000+08:00","Thoughts on a future architecture ----. Currently we have an appliance reading PLC data and sending to SQL. Reports are then generated against that data and been that way for 10 years, all good.

We have a new MES wanted to consume that data. Would you tell the new MES just to query the existing database to get the data it needs and call it a day?

Another thought is to use Ignition to full replace the existing appliance and allow a future UNS. Ignition would read the current PLC, scale/convert the data, publish that data into an MQTT broker, then the new MES can consume from there.

Now to keep the legacy system alive, we could have Ignition do SQL inserts into that application for the same data it serves up to the MQTT broker ---- or is there a way a SQL table could subscribe to a broker when new data is pushed?","",""
"277515221885779970","jermuk","2022-05-11T16:20:31.8680000+08:00","in general it sounds very good to send the data to a message broker like MQTT before consuming them. if it works with ignition and the MES has only this SQL interface I think this would be a good approach. alternatively, you could write your own microservice doing just that. If i would be you I would check whether the MES has something like a REST endpoint hwere you could push the data into it as it would take out an additional component (SQL server) from the list of potentially failing systems","",""
"487658368492896257","benveenema","2022-05-11T16:34:24.5440000+08:00","What is your digital strategy?","",""
"783917475128410112","geoffnunan","2022-05-11T19:24:29.6480000+08:00","It can be done. there are many tools you can use to subscribe to MQTT and write the changes into SQL Server like NodeRed, Telgraf (From InfluxData), about 10 lines of python or golang would also do it. 
The bigger challenge is how to do it with 100% reliability. What happens if you need to restart the SQL Server, or the thing you are using to subscribe to MQTT, or your MQTT broker? Is it critical that you don't loose any messages, or is loosing messages acceptable?
It's really easy to get something simple working that works most of the time. It's really difficult to get something that works 100% of the time while still allowing you to upgrade each of your components without taking everything down for maintenance.","","üëç (7)"
"867075936054149191","rickbullotta","2022-05-11T22:05:34.0650000+08:00","I'd take a look at HighByte for sure - it can be your solution for the current scenario and has the flexibility to adapt as you change it/evolve it.  It also has high availability and data integrity (store and forward) built in.","","üëç (1)"
"891563487241842699","jbonhage155","2022-05-12T00:44:04.6830000+08:00","Yeah I'm going to chat with Omar.","",""
"891563487241842699","jbonhage155","2022-05-12T00:44:13.1200000+08:00","That is a great question!!!","",""
"891563487241842699","jbonhage155","2022-05-12T00:46:56.6970000+08:00","our strategy is to put in a new fancy MES to fix all our problems.... lol.
But seriously we need to get to an MQTT/UNS model, it just how to get there will some legacy system that will want to keep living on....","",""
"891563487241842699","jbonhage155","2022-05-12T00:58:16.7220000+08:00","Interesting. It seems like to not go down the route of an MQTT-SQL connection due to complexity and instead from our smart gateway, do the SQL inserts at the same time we publish data to the MQTT broker. Really the getting data to SQL portion is short term solution until we can get the plant off the legacy system. Lots to ponder and like Rick said maybe a HighByte type product would work here. Don't know much about it so now time to learn!","",""
"891563487241842699","jbonhage155","2022-05-12T01:02:11.4680000+08:00","Like you said the more parts and piece, not good.... that's why I really like to go full Ignition as maybe it doesn't do everything the best but a lot can be accomplished under 1 roof.
In addition I think it's a world of pain to get vendor/software approved from a corporate level so that factors into the decision a little bit. 
Corporate IT/security/compliance, supposed to be a support partner to OT, right? ha ha","",""
"867075936054149191","rickbullotta","2022-05-19T00:42:05.5800000+08:00","It will be interesting to see how large joins perform on this: https://www.apollographql.com/blog/announcement/backend/the-supergraph-a-new-way-to-think-about-graphql","","chadlennythink (1),üëç (2)"
"867075936054149191","rickbullotta","2022-05-19T00:42:23.4440000+08:00","Any thoughts on this @GeoffNunan ?","",""
"783917475128410112","geoffnunan","2022-05-19T14:41:08.3150000+08:00","Many thought. I've been testing the new federation 2 and rust based apollo router for a while.
Your question about large joins is still more to do with the underlying database and how the resolvers are implemented rather than the router.

The rust based apollo router is a huge step forward over the old node.js stuff,  which actually wasnt old, it was only released last year.
Goes to show how fast this space is moving","",""
"867075936054149191","rickbullotta","2022-05-19T23:45:58.6690000+08:00","The database‚Äôs join performance isn‚Äôt the choke point for heterogeneous joins across subgraphs.","",""
"783917475128410112","geoffnunan","2022-05-20T00:46:02.6910000+08:00","That depends on how your subgraphs handle the n+1 problem","",""
"867075936054149191","rickbullotta","2022-05-20T02:34:46.7260000+08:00","I would think that it‚Äôs a combo of the query plan and the capabilities of the resolver, plus the limits on memory at the aggregation level.  In either case, it‚Äôs gonna be slow at scale - latency of the calls to each subgraph compounded by the potential for a worst case subquery of ‚Äú1‚Äù.","",""
"817835202746253344","IIoT#4707","2022-05-20T02:34:47.1440000+08:00","GG @RickBullotta, you just advanced to level 22!","",""
"783917475128410112","geoffnunan","2022-05-20T08:41:16.8890000+08:00","GraphQL federation works a bit differently to how you might think. It does not do any aggregation, that's done in the resolvers in the sub-graphs. You can think of Federation more like an API Gateway that routes calls to backend services with the difference being that a call to the federation router can orchestrate calls to subgraphs and assemble a single response. It's actually very light-weight in what it's doing, It's not at all comparable to an SQL Query engine.
GraphQL federation by design is mostly concurrent calls, so latency is not as big an issue as you might imagine.","","üëç (1)"
"795598602772414485","kskblr07","2022-05-23T12:56:09.7090000+08:00","Picking this up a bit late - but why do we say SP cannot be UNS? - is it because it does not support data integration/fluidity across IT-OT ie no pub-sub pipes?","",""
"745796393855352953","thedavidschultz","2022-05-23T23:25:59.0800000+08:00","The Unified Namespace is both a technology standard and a design architecture. The community talks mostly about MQTT/SpB, but other brokering technologies can be used (DNP3). But the technology needs to support the minimum technical requirements (open, lightweight, RPE, edge driven). SP does not meet these.

Where there is a disconnect is how people interpret the UNS through its visual structure. Since most companies use ISA 95 Part 2 to define their structure (ERP master data model), this becomes the structure of the UNS. SP uses a plant model, so it would appear to be a UNS, but it does not function like a UNS (see above). It has the potential of being a node within a UNS, but would need to be more open.","","üëç (1)"
"867075936054149191","rickbullotta","2022-05-23T23:27:44.9010000+08:00","Couldn't SP linked to an MQTT broker satisfy the requirements?","",""
"745796393855352953","thedavidschultz","2022-05-23T23:57:41.9780000+08:00","It's not as much connectivity as it is functionality. If SP is connected to a broker, but only communicates with other Aveva software, then no. But if it allows other systems to publish/consume data, then yes.","",""
"744671252605829181","jeff.rankinen","2022-05-29T03:06:36.4220000+08:00","No transparent pricing if we are talking about Aveva SP....","",""
"744671252605829181","jeff.rankinen","2022-05-29T03:10:30.7300000+08:00","We need to let companies with no transparent pricing know that this community will look to other companies with advertised pricing.","",""
"867075936054149191","rickbullotta","2022-05-29T04:10:39.4790000+08:00","Yeah, not a fan of companies that don't always share pricing, but coming from the other side of the fence, it's not always that simple.  And I wouldn't make that a deciding factor for my technology/product decisions.  Quite often when people use very binary decision matrices, they make poor choices in the end.  Even if it's inconvenient, I would never immediately disqualify a vendor just because of that.  In some cases the diverse set of use cases, customers, and applications requires some flexibility in pricing and licensing.  That said, I still like clean, simple, readily available price lists.","","üëç (2)"
"744671252605829181","jeff.rankinen","2022-05-29T04:56:14.6580000+08:00","Thanks Rick for that balanced approach. Seems like Inductive Automation and Tatsoft are exceptional in the transparent pricing area.","","üëçüèº (1)"
"745796393855352953","thedavidschultz","2022-05-29T05:45:47.5910000+08:00","One of the criticisms for lack of transparent pricing is due to complexity. This is certainly the case with Aveva.","",""
"744671252605829181","jeff.rankinen","2022-05-29T05:54:03.3460000+08:00","I like Elon Musk's response to complexity.","https://cdn.discordapp.com/attachments/815945777452941313/980227480654852116/Screenshot_20220528-175248.png?ex=68def47b&is=68dda2fb&hm=8095069a5c054222267fdfa033c906414443649f5213425d24f88813c86c4171&","üíØ (1)"
"867075936054149191","rickbullotta","2022-05-29T05:55:23.4310000+08:00","Absolutely. When I was an account exec for wonderware I had a massive multi page spreadsheet for pricing!","",""
"856535054972354601","tvidonja","2022-05-29T17:03:37.2130000+08:00","I'm not sure if this goes under #reference-architectures nevertheless I've just seen PPT from April 2022 by MIMOSA referring to slide number 6 as Open Industrial Interoperability Ecosystem (OIIE) and ISO 18101 Architecture. It looks pretty complex, and it opens a question how (in practice) the context and events on the shopfloor are related to data?! I'm okay with data accessed through pub/sub broker or DBs, but connecting those data to the context and events is not clear to me. I hope I'm the only one. üôÉ  More specifically ... where and how are events and the context written/stored and then related to data?","",""
"856535054972354601","tvidonja","2022-05-29T17:03:55.6440000+08:00","And the PPT ... https://www.mimosa.org/wp-content/uploads/presentations/2022/05/7948/MIMOSA-ISA-APR-2022.pdf","",""
"867075936054149191","rickbullotta","2022-05-29T21:03:27.5110000+08:00","Slide 7 is the only one you need to see.  And then you'll understand why there will never be seamless interoperability.","","üíØ (1),üëç (1)"
"898217314741280828","hobbes1069","2022-05-29T21:13:51.1600000+08:00","In general I like ISA, but some of this stuff is worthless. An eye chart and references to various specifications (ISA/ISO, etc) but it doesn't REALLY tell you how it work or how to implement anything.","","üëç (3)"
"898217314741280828","hobbes1069","2022-05-29T21:17:35.0210000+08:00","And at the same time too complex to convey anything useful to the non-technical executive level.","",""
"856535054972354601","tvidonja","2022-05-29T21:31:14.5750000+08:00","Interesting. (1) What's the point of such comprehensive architecture drawing if it doesn't help real case implementation? (2) Does it mean the drawing make sense (has a practical value) for the tech level executives? Hmm  üòé","",""
"817835202746253344","IIoT#4707","2022-05-29T21:31:15.0420000+08:00","GG @TomazVidonja, you just advanced to level 3!","",""
"898217314741280828","hobbes1069","2022-05-29T21:33:10.0890000+08:00","I saw a lot of colorful diagrams, but nothing that I personally would consider ""architecture"".","","üòã (1)"
"917925131261718558","jpmoniz","2022-05-29T21:33:54.1650000+08:00","I bucket it under organizational FOMO.","","üëç (1)"
"917925131261718558","jpmoniz","2022-05-29T21:38:44.0730000+08:00","Digital twins is an area where I personally think there will never be true interoperability any time in the near future. Sure they might generate standards to guide but ultimately your asking everyone to play nice in the sandbox.  When money is involved I think we know how that goes.","","üî• (1)"
"898217314741280828","hobbes1069","2022-05-29T21:40:25.3790000+08:00","Sometimes referencing standards is good and necessary, but I hate it it seems like they're trying to hide things, for instance I try to lookup IEC 62541 for ""Interoperability, and it's really for OPC/UA, and behind a paywall.","","üëç (1)"
"856535054972354601","tvidonja","2022-05-29T21:52:55.6120000+08:00","It seems like IT is more pragmatic and effective with regards to standards than OT. 

Only the IETF and ITU-T explicitly refer to their standards as ""open standards"", while the others like ISO and IEC refer only to producing ""standards"".
 https://en.m.wikipedia.org/wiki/Open_standard","",""
"794020366536146977","mparris","2022-05-30T11:32:50.0200000+08:00","Charts like these are created by people wishing that products will eventually implement their ideas.

Seems the better approach is to build a product to solve a problem, then standardize its interfaces so other products can help solve similar problems.

It sure seems that many of the standards never make it off the paper.

Sad to say that this article still seems relevant almost 1-year later:

https://www.linkedin.com/pulse/what-technologies-ready-your-iiot-architecture-matthew-parris","","üëç (3)"
"765617417140961280","jhisw","2022-05-30T14:15:33.5220000+08:00","OPC UA is specified under the IEC 62541, so you couldn't find anything else.

What did you try to find?","",""
"898217314741280828","hobbes1069","2022-05-30T20:19:20.0900000+08:00","Well, I specifically didn't like a bunch of spec references, and specially with 65241, why not go ahead and say it's related to OPC/UA in the presentation?","","üëç (1)"
"765617417140961280","jhisw","2022-05-30T21:04:40.5800000+08:00","Oh I didn't notice you were referencing the presentation. I had a look at it and now I understand you. The presentation is not understandable at all.","",""
"898217314741280828","hobbes1069","2022-05-30T21:08:01.8600000+08:00","Nope, lots of eye charts and bullet points, but really whenever I see something like this I always ask myself. How does this (assuming I can even understand it) change how I will go about implementing my digital transformation strategy?","","üíØ (1)"
"898217314741280828","hobbes1069","2022-05-30T21:08:08.0080000+08:00","For that presentation, it's zero.","","üòÜ (1)"
"938526937855443035","johndevenney","2022-05-31T22:08:36.9510000+08:00","I think if they hear about there opaque price model every time you talk to them it will sink in...","",""
"867075936054149191","rickbullotta","2022-06-01T22:05:08.5650000+08:00","Virtual Codesys PLC's from SDA:

https://www.digitaljournal.com/pr/software-defined-automation-releases-industrial-control-as-a-service","","üî• (4)"
"812295088348200960","patanj2","2022-06-01T23:33:16.8330000+08:00","So I just attended a conference and got a brief demo of Cognite platform.  They call it an Industrial DataOps platform.  This is also how HighByte describes itself.   Upon inspection though,  the two offerings don‚Äôt look all that similar.  For one thing HighByte is designed as a lightweight,  primarily OT first application,  while Cognite is SaaS only.  Just venting,  but I swear the IIOT space is somewhat confusing even for myself,  who has a decent amount of experience in the space!","","üíØ (2),üëç (1)"
"795178288330440704","youri.regnaud","2022-06-02T04:01:24.7790000+08:00","I met them in Hannover this week. The new version is pretty amazing with the management of both classic PLCs and vPLCs from a cloud platform with TechOps (deployment)et DevOps (version control)","","üëçüèº (2)"
"471331458087387137","amen.amaach","2022-06-02T20:02:11.9170000+08:00","Copia.io does the same, isn't it?","",""
"867075936054149191","rickbullotta","2022-06-02T20:04:37.5950000+08:00","No, SDA also provides  virtual PLCs.","",""
"471331458087387137","amen.amaach","2022-06-02T20:08:29.9610000+08:00","Got it, thanks","",""
"471331458087387137","amen.amaach","2022-06-02T20:22:24.6480000+08:00","This is really a game changer :
https://youtu.be/CiMUrBI4B8I","",""
"801561312861618236","jon.forbord","2022-06-04T00:27:46.5490000+08:00","Cognite data fusion has some overlap with Highbyte, but yea, the similarities stop there. Cognite data fusion is used to map data to models, and they use a knowledge graph based on their own schema (not ISA-95) to map relations between the data. On top of this they build tools to analyze and visualize the data. They‚Äôve got some pretty nifty stuff going on.","",""
"776645715341738015","jazzu2602","2022-06-16T20:17:58.3140000+08:00","Hello, I am looking for machine connectivity and data visualization architecture. Thinking of testing the following combos:  1. Litmus.io->Litmus Edge for IIOT platform (has prebuilt dashboards for OEE,SPC) , 2. KepServerEX+HighByte+Grafana (for data visualization) + AWS or GCP for Data Lake. not sure which one to choose. Appreciate if someone can help to list the pros and cons of each.","",""
"898217314741280828","hobbes1069","2022-06-16T20:30:08.7780000+08:00","Looks like you've done some homework. We trialed Litmus and really liked it but already had KepserverEX + Tulip and it's hard to beat Kepserver on price and the number of devices it can talk to is great but I hate having to RDP into a Windows Server VM to make configuration changes.","",""
"776645715341738015","jazzu2602","2022-06-16T20:53:58.4740000+08:00","Great. For KepServerEX+HighByte tech stack, Grafana is good for data visualization (OEE, SPC, Dashboard)?","",""
"277515221885779970","jermuk","2022-06-16T21:08:45.2140000+08:00","first you would also need a database to access the data from Grafana and you would need to configure highbyte to do that. Then additionally you would need to do your own OEE calculations (or you could leverage the free and open-source ""factoryinsight"" microservice of the united manufacturing hub to do these KPI calculations)","",""
"867075936054149191","rickbullotta","2022-06-16T22:48:49.9870000+08:00","There are a bunch of videos showing how to do this with InfluxDB and HighByte.","",""
"277515221885779970","jermuk","2022-06-16T22:50:36.0850000+08:00","alright, then I take back the statement üôÇ","",""
"277515221885779970","jermuk","2022-06-16T22:50:58.0690000+08:00","still need an additional database like influxdb though","",""
"277515221885779970","jermuk","2022-06-16T22:54:37.8540000+08:00","found the video: https://www.youtube.com/watch?v=i-n39NQ6x_w (this is what you mean right?)
from a first glance of it seems that you need to write it on your own using influxdb queries. in my opinion this is good for very easy interpretations of the oee, but it might get hard combining shifts, orders, products with varying speeds, etc. into that equation","",""
"867075936054149191","rickbullotta","2022-06-16T23:01:47.5780000+08:00","FYI InfluxDB  Edge is free.","",""
"277515221885779970","jermuk","2022-06-16T23:02:17.9420000+08:00","stuff that is hard to do when using influxdb in calculating the OEE (we did it at first also using this method, but then swtiched to a custom program). these points usually come up if you have a lean expert in your firm, which pushes for a ""correct"" OEE calculation (every company has their own interpretation of it)
- getting a list of OEE losses with their reasons, e.g., 56 min / day due to microstops when producting product ABC
- automated microstop detection
- integrating planned time into the equation (taking out maintenance tasks or night shifts out or moving it into a separate bucket)
- varying products with different speeds / cycle times
- flexible shifts, e.g., pharma packaging, where there is no fixed plan on using the machien and it is decided at the beginning of each shift
- correlating ""not running"" automatically with breakdown reasons, e.g., error codes on the machine, etc.","","üíØ (4),üëç (1)"
"867075936054149191","rickbullotta","2022-06-16T23:02:22.1320000+08:00","As long as you tag/contextualize the data on storage, you can do some very powerful stuff with Flux.","",""
"277515221885779970","jermuk","2022-06-16T23:04:32.6750000+08:00","we first started with chaining fluxdb queries and storing the results as a separate datapoint (do not know the InfluxDB term for that), but then shift supervisors would want to change the data (e.g., removing a shift) and we would need to manually trigger recalculation","",""
"277515221885779970","jermuk","2022-06-16T23:07:16.4730000+08:00","still here the voices of the lean experts in my ear, expplaining how easy OEE is (just multiply this availability, performance, quality), but then introducing a couple hundred edge cases where the calculation might not be that simple","",""
"795178288330440704","youri.regnaud","2022-06-17T00:34:55.7870000+08:00","We will have a look to Cybus. It really a OT solution with IT in mind (MQTT, API, K8, Security, ‚Ä¶) and can challenge Kepware with a more advanced stack","",""
"783917475128410112","geoffnunan","2022-06-17T13:20:52.7640000+08:00","That approach works if the data does not change, but fails quickly and @Jermuk has experienced.
Libre also took the approach of tagging/contextualizing the data on storage for our very first OEE proof of concept on InfluxDB 5 years ago. It works, but doesn't take long before it breaks.
What breaks it? When history changes. An operator changes their mind about a reason for a stoppage, or about when an order started or finished, or when the shift ended.
Yes, you can do some powerful stuff with flux, but changing the data that is stored, and the context of that data in how it is tagged is much harder.
We ended up with an approach where we store the stuff that does not change, and the stuff that can change in seperate measures, and then join these together with flux ( and sometimes we just use go code in microservices to do the complex stuff)
Store the sensor values in one measure. Running, Stopped, Speed, Blocked Sensor, Starved sensor etc. 
Then store the calculated machine state change timestamps in a different measure because the history of this does change. We use the PackML State Model of Stopped, Idle, Starting, Execute, Held, Suspended etc. Only store the state changes so that you can edit these events. You can then easily split downtime events by inserting a new state change. Store the reasons with the state change record.
Then store the planned rates in a seperate measure

There is then a bunch of smart stuff you need to do with Flux including:
- filtering out short stops
- handling the scenario where there is no state change in the time-window that you are querying
- interpolating for shift boundaries
- interpolation at time-window boundaries
- calculating the basic KPI values of availability, performance and quality
and many more","","üíØ (4)"
"894527802316046366","nickn5549","2022-06-17T16:20:45.9900000+08:00","I have at least 20 x Node-Red flows that calculate stuff for final OEE calculation for 4 x lines, 5 machines/line","",""
"867075936054149191","rickbullotta","2022-06-17T19:34:11.4060000+08:00","All great points! The boundary stuff remains a real challenge in pretty much any data store.  Like most apps, designing iiot stuff for the ‚Äúexceptions‚Äù (which we all know are really the rule, and are numerous) is indeed where the magic happens.  And when events span shifts, runs, days - and shifts run over the planned time - and someone forgets to record a changeover and - well, you know what I mean.","",""
"776645715341738015","jazzu2602","2022-06-17T20:12:27.2580000+08:00","thank you all for sharing your inputs. I will keep this in mind while calculating OEE. But first I need to select the tech stack, I feel Litmus.io is best suited for my use case. Anyone knows their commercials, is it costly compared to ""KepServerEX,HighByte,Influx,Grafana"" ?","",""
"776645715341738015","jazzu2602","2022-06-17T20:13:31.2270000+08:00","Thank you. will look into Cybus.","",""
"876880919988957205","ryankershaw","2022-06-17T20:19:58.8510000+08:00","With Litmus (and I'm from Litmus FYI), these sorts of calculations can be done right at the edge with the streaming data from the live tags.  These analyses can be centrally managed, so a central expert can have control over the calculations, making adjustments to bring in new considerations for one, that can be replicated throughout the organization.  This ensures that there is some central cohesion between the sites, which allows for benchmarking, which in turn greatly increases the usefulness of the equation.","https://cdn.discordapp.com/attachments/815945777452941313/987330767493414962/unknown.png?ex=68df16ae&is=68ddc52e&hm=60ce6944e1ebd752db686bc9bddbaae09e71556e9426d26b860c9cb2a3a33207&",""
"876880919988957205","ryankershaw","2022-06-17T20:20:40.6670000+08:00","All of the raw data, and the calculated data can then be transferred to whichever database you prefer.","",""
"894527802316046366","nickn5549","2022-06-18T11:17:24.9550000+08:00","My PoC is attempting to detect automatically ALL the events, including the changeovers at least for production lines that need setup, which is tracked by the MES system. So far, working well...still need to add a few more flows for some.....exceptions.","","üëçüèº (1)"
"917925131261718558","jpmoniz","2022-06-18T18:52:23.6410000+08:00","Great point. That‚Äôs exactly why I like the ability to record the raw data and then have the ability to adjust to reality of operations when needed. Sepasoft does this decently well with their OEE module. Not saying it‚Äôs perfect.  But having a system that understands nothing will be automated into perfection is a good approach.","",""
"867075936054149191","rickbullotta","2022-06-18T19:46:51.7980000+08:00","Doing it with streaming data only can lead to real challenges when you need to ""fix"" or ""correct"" history, or when some transient outage leads to missing events.","","üëç (3)"
"277515221885779970","jermuk","2022-06-19T21:07:22.3500000+08:00","@RickBullotta  we've spend really a lot of time on this issue and came up with the following architecture to efficiently fix history (while at the same time mass deploying OEE at our customers, which requires speed and flexibility). the stream processing part is then based on kafka, with reasonable assumptions about missing data so that we can handle all relevant exceptions","https://cdn.discordapp.com/attachments/815945777452941313/988067469723860992/Unbenannt-2022-06-19-1456.png?ex=68df21ca&is=68ddd04a&hm=7f7a42434ec9c709b7d581ebfb0f7c42163de25f3f3f9d227c633995aab413a4&","üëç (4)"
"876880919988957205","ryankershaw","2022-06-19T23:21:20.9140000+08:00","True, but can always present the real time data, while sending the raw data to a database for further processing (if needed) or archiving.","","üëçüèº (1)"
"329780110704246790","rkwadd","2022-06-22T06:09:04.8590000+08:00","Everybody asks for raw real time data then says ‚ÄúOh well that‚Äôs meaningless unless we do [random filters, aggregations, and transforms]‚Äù","",""
"917925131261718558","jpmoniz","2022-06-22T06:11:39.8020000+08:00","At one level your not wrong.","",""
"867075936054149191","rickbullotta","2022-06-22T06:16:55.5110000+08:00","Raw data maybe. But interesting events need to be available in real time to trigger actions and processes.  I think Rony is exploring some ideas around this area.","",""
"329780110704246790","rkwadd","2022-06-22T06:20:08.5000000+08:00","Raw data should 1000% be preserved at the lowest level of contextual definition that has an actual usage‚Ä¶also ‚Äúraw‚Äù doesn‚Äôt actually mean anything. Sometimes knowing a sensor voltage is critical, sometimes a PLC register, sometimes something further up the chain of abstractions.","",""
"817835202746253344","IIoT#4707","2022-06-22T06:20:08.8880000+08:00","GG @Russ from the Internet, you just advanced to level 12!","",""
"329780110704246790","rkwadd","2022-06-22T06:21:03.7590000+08:00","Composability is all about making it so you can logically stack up and down or traverse side to side.","",""
"329780110704246790","rkwadd","2022-06-22T06:22:02.7650000+08:00","These ideas aren‚Äôt new but it is cool seeing them actually progress in practice.","",""
"917925131261718558","jpmoniz","2022-06-22T06:27:28.3500000+08:00","Interested in hearing how you see Kafka fitting into such a strategy.","",""
"744671252605829181","jeff.rankinen","2022-06-22T11:09:03.7780000+08:00","Looking at your website for pricing. Please advise.","",""
"744671252605829181","jeff.rankinen","2022-06-22T11:10:18.7440000+08:00","Can't find your demo software either.","",""
"744671252605829181","jeff.rankinen","2022-06-22T21:18:40.3260000+08:00","Found the pricing - $300/mo.","",""
"876880919988957205","ryankershaw","2022-06-22T22:24:11.8990000+08:00","That's one of the tiers, but to be honest, our pricing varies significantly depending on the application.  We see anything from $2 - $6ish/tag/year depending on the size of the facility, what is being used (i.e. just connectivity, edge analytics, full ML/AI deployment), and even the customer type (OEMs with a high number of low tag count machines use a different model than facilities).  I know it's not straightforward, but this platform, and others like it, can be deployed to a wide range of applications and situations, so coming up with a singular model is difficult.  That said, the basis of any of our models is to provide a simple price based on size and capabilities, and leave the rest unlimited (i.e. unlimited users, connections, deployments, drivers, etc.).  It doesn't work for everyone, but I don't think any model does, and this one has served us well.","",""
"744671252605829181","jeff.rankinen","2022-06-22T22:34:45.8350000+08:00","I appreciate the quick response. As an educator, it makes it easier when companies have unlimited products. Is your software installed locally or is it on your hardware?","",""
"876880919988957205","ryankershaw","2022-06-22T22:44:45.5980000+08:00","Flexible on installation.  We use a cloud based VM for our sales instance (they keep it separate so when us sales guys break it, it doesn't affect the real ones), but can be deployed to bare metal systems.  We don't have any hardware, though we have certified certain ones.  That said, we also have a minimum spec that can be used to self-evaluate any other hardware out there, so we're not tied to any one manufacturer.  We used to have our own gateways, but those were dropped years ago.  Our experience was that everyone had their own preferred hardware solution, so found it easier to just deploy a software solution.","",""
"876880919988957205","ryankershaw","2022-06-22T22:53:12.5200000+08:00","Yeah, I look at ""raw"" being just that, the lowest level of contextualization that you can get.  As for whether something is important, with newer analytical methods, especially ML, the more raw data that can be kept, the better.  Let the algorithm decide on what is and is not important.  Could be that the butterfly flapping its wings was a voltage change in a sensor.","",""
"277515221885779970","jermuk","2022-06-23T04:51:12.0740000+08:00","i think most of the people asking for raw data want access to the raw data to apply those transformations and to be master of their own data. they do not need it actually stored.","","üëç (1)"
"277515221885779970","jermuk","2022-06-23T04:52:44.6480000+08:00","you could also use MQTT. we send all of our raw data to MQTT / Kafka, so that the customer can always apply those transformations if he wants it","",""
"917925131261718558","jpmoniz","2022-06-23T04:57:14.0480000+08:00","For sure. Was mainly asking past broker","",""
"657361690379288596","du5tins","2022-06-23T23:55:55.7310000+08:00","OK! I am looking for a reference broker architecture that is regional and feeds up into a corporate unified namespace. Customer wants this system to be highly robust and resilient. i.e. if they restart a broker at the regional level it is immediately backed by another broker (sounds like clustering).","",""
"817835202746253344","IIoT#4707","2022-06-23T23:55:56.2190000+08:00","GG @Dustin Symes, you just advanced to level 8!","",""
"657361690379288596","du5tins","2022-06-24T00:01:18.4450000+08:00","Any hints on which broker package might be helpful here?","",""
"657361690379288596","du5tins","2022-06-24T00:07:17.2590000+08:00","https://www.emqx.com/en/blog/mqtt-broker-clustering-part-1-load-balancing","",""
"657361690379288596","du5tins","2022-06-24T00:07:28.8520000+08:00","This is close to what I'm looking for I think.","",""
"657361690379288596","du5tins","2022-06-24T00:07:44.2400000+08:00","I might have to scroll up and see what other architectures are on the discord here.","",""
"821044538709114900","ianskerrett.","2022-06-24T04:04:41.6380000+08:00","HiveMQ published some reference architectures based on different use cases. It might be helpful.  https://www.hivemq.com/solutions/mqtt-based-manufacturing-reference-architecture-for-hivemq-on-azure/    Full disclouse: I work at HiveMQ.","","üëç (2)"
"755791126803251280","kevinhibbins","2022-06-30T00:30:43.6060000+08:00","Store data in a relational DB. Use layers of data constructs. Bring it all together upon consuming the data. Then there's no concern with time boundaries at all.","",""
"755791126803251280","kevinhibbins","2022-06-30T00:39:54.7270000+08:00","Most people cater for the ""happy path"". And forget the ""what if"". By the way, I don't think the ""boundary"" stuff is an issue, well at least not in the context of performance reporting.","","üíØ (1)"
"191987346734841856","eddiiee_","2022-07-07T03:43:01.2430000+08:00","Hi guys. In my company we have a project for implementing a light-weight MES for removing all paperbased quality tracking and digitalizing it. We are using ignition as an middleware to connect the machinelayer to the MES to integrate the quality figures that exists in current SCADA system. So basically, earlier Operators have manually taking information from SCADA system and writing into the ERP system (SAP). I have drawn the architecture to the best of my knowledge. I'm not sure why we are not using Ignition as a complete IIoT solution. When I've asked the answer been that it's simpler to do the integrations directly to MES and that SAP doesn't have a good direct integration to Ignition. I doesn't sound quite right to me. I'm thinking we have to redo integrations later on if we want to use Ignition as an IIoT, or it will be complex if we're gonna expand the MES to house all information.","https://cdn.discordapp.com/attachments/815945777452941313/994327631606583296/unknown.png?ex=68df7e85&is=68de2d05&hm=b417b252edc1f505201f813fddda485519965b893f33dd273b9fd0978b38ae94&",""
"891563487241842699","jbonhage155","2022-07-07T09:33:44.7270000+08:00","I would reconsider the Ignition IIoT to MES link via MQTT. If MES doesn't talk SparkPlugB then you are scripting your MQTT messages via another namespace. Ok for a few tag updates but don't think it will scale due to the amount of event script that will be triggered.
https://docs.chariot.io/display/CLD80/ME%3A+Python+Scripting","",""
"891563487241842699","jbonhage155","2022-07-07T09:41:50.6600000+08:00","Curious how does the  'seperate OEE system' communicate with the ERP ?","",""
"191987346734841856","eddiiee_","2022-07-07T13:35:59.4960000+08:00","Ooh it's just a flat-file integration. And the arrow goes only one way (To the ERP), as a reporting. Nothing is sent back unfortunately. You could think we adjust our plans up and down based on OEE data, which we are, but manually üòÑ","",""
"191987346734841856","eddiiee_","2022-07-07T13:49:44.9040000+08:00","Thanks, will look into that how it's exactly made. But then it makes sense to have everything go to the MES and not trying to center the architecture around ignition as a UNS","",""
"867075936054149191","rickbullotta","2022-07-09T15:11:23.1040000+08:00","Tulip. https://www.tulip.co","","üëç (3)"
"801561312861618236","jon.forbord","2022-07-13T08:19:23.4980000+08:00","There are SAP and business connectors for Igntion, but they‚Äôre fairly expensive
(Edit: I guess if you have SAP, and already spent 6-7 figures on that, these 10k modules of sepasoft are negligible üòÖ) 

https://www.sepasoft.com/products/interface-for-sap-erp/

http://www.inductiveautomation.com/resources/casestudy/arizona

The specific integration may or may not be cheaper in the short term, but in the longer term it is always better to build something that can easily be expanded to more use-cases than the specific project that‚Äôs in front of you now. And even if companies use Ignition as their SCADA system, doesn‚Äôt mean they have an architecture that will scale etc..","",""
"867075936054149191","rickbullotta","2022-07-13T18:58:05.4000000+08:00","The most useless certification ever is an SAP interface.  Literally means nothing. The hard part is the transaction mappings themselves. And modern versions of SAP are moving away from RFC‚Äôs and BAPIs. That‚Äôs a flashback to Y2K!","",""
"801561312861618236","jon.forbord","2022-07-13T20:41:44.6230000+08:00","Hehe.. I‚Äôll take your word for it üôÇ","",""
"783917475128410112","geoffnunan","2022-07-19T12:35:56.8530000+08:00","Not all 'At-least-once-delivery' guarantees are equal.
https://www.youtube.com/watch?v=QmpBOCvY8mY","","üíØ (4)"
"867075936054149191","rickbullotta","2022-07-19T17:24:14.4130000+08:00","That and DTC - it requires a huge number of ""watchers"" and then if you're doing it right you need to ""watch the watchers"", and then don't they need to be watched too?","",""
"801561312861618236","jon.forbord","2022-07-19T18:38:18.8370000+08:00","https://youtu.be/IP-rGJKSZ3s","",""
"801561312861618236","jon.forbord","2022-07-19T18:44:44.5480000+08:00","I.e there are no guarantees in distributed systems, only statistical improbability and error handling.","","üíØ (2)"
"801561312861618236","jon.forbord","2022-07-19T18:51:40.9820000+08:00","Great share! It popped up in my LinkedIn feed as well üòÄ","",""
"783917475128410112","geoffnunan","2022-07-19T21:07:29.6500000+08:00","Yes, but with some simple best-practices you can get close enough.
Where some can trip up is when the failure scenarios are not considered at all. 
Ashley Jeffs does a great job of implementing simple best practices for reliability. I'm a big fan of the patterns behind his Benthos project.","",""
"867075936054149191","rickbullotta","2022-07-19T22:50:50.5600000+08:00","""Close enough"".   Send a message to the engines *exactly once* to do a controlled burn to get us to Mars.  Oh, crap, it did it twice.","","üëç (1)"
"277515221885779970","jermuk","2022-07-20T02:35:59.5160000+08:00","that would have been me üòÑ","",""
"894527802316046366","nickn5549","2022-07-20T17:02:19.7710000+08:00","Neptune, here we come... üöÄ","",""
"908337053140394004","tonylatigre","2022-08-10T00:47:09.4990000+08:00","I think this is the best section to ask this question so here goes.  I built a technology stack that is sensors -> Arduino -> Rasp Pi - (node-red, InfluxDb, Grafana) -> Wireless Router for a local manufacturer.  It works as expected, getting my data in the DB and ultimatly on the dashboard.  Next step, I want to see it in the cloud.  I have my ""industrial network"" sitting behind thier router on it's own router, aka double nating my network.  The way we view the data now is connecting to the ""industrial network"" wifi router to see the data.  I want to run Grafana in the cloud and connect to it with my on Prem Influx instance.  I'd like to have my dashboard available in the cloud as a tabbed browser. I believe I need to write an API to do this, but would love to hear how others are doing it.  Thanks in advance.","",""
"867075936054149191","rickbullotta","2022-08-10T01:40:28.4410000+08:00","Or you could just use Influx Cloud and the new sync stuff Influx provides to sync an edge Influx to a cloud instance.  Maybe @Michael Hall can help.","",""
"633480462601420801","mhall119","2022-08-10T02:09:58.5790000+08:00","@TonyLaTigre you can use InfluxDB's replication feature to put a copy of that data in the cloud. You can even downsample, aggregate or anonymize it first using a Task","",""
"633480462601420801","mhall119","2022-08-10T02:13:44.6400000+08:00","Ultimate if you're going to visualize it in the cloud you're going to want the data in the cloud. By using tasks and replication you can limit it to just the data you need for security and performance reasons","",""
"633480462601420801","mhall119","2022-08-10T02:14:22.9650000+08:00","I work for InfluxData, in case that wasn't clear, and I'm happy to help you with your setup","","üëç (1)"
"277515221885779970","jermuk","2022-08-10T14:22:49.5570000+08:00","Having the databases on prem and using grafana from the cloud is something that i heard now a couple of times,  but might not be the best idea. Either move influxdb also into the cloud, or grafana on Premise.  The reason behind it is security, that you do not want to have open ports in your firewall","",""
"817835202746253344","IIoT#4707","2022-08-10T14:22:49.8690000+08:00","GG @Jermuk, you just advanced to level 8!","",""
"894527802316046366","nickn5549","2022-08-10T16:34:49.8310000+08:00","Google down yesterday for 30-40min, though, for half of the world...https://theconversation.com/todays-google-outage-was-brief-but-disconcerting-188452","","üòß (2)"
"894527802316046366","nickn5549","2022-08-10T16:39:26.8660000+08:00","explosion at Google? https://www.news.com.au/technology/online/internet/three-injured-in-explosion-at-google-data-centre/news-story/fb7f420d0ebcb0abbc6a9ff7c6d52032 just few sparkies playing with a screwdriver...","",""
"898217314741280828","hobbes1069","2022-08-13T03:30:15.7160000+08:00","Thoughts about ""encoding"" area/line/cell in Kepserver channel names? It would help with the namespace but creates other issues. The channels are driver specific for one. And for us, we like to reorganize equipment on a somewhat frequent basis. This would cause the tag names to change and then everything downstream of it has to be touched.","",""
"740383178279354388","mriiot","2022-08-15T03:50:31.8710000+08:00","I would rather apply transforms on IoTGateway egress.","",""
"741651574044098631","jerrylbc.","2022-08-23T05:36:27.9850000+08:00","what about Alias option in the Kepware, so you can change Channel and Device as you like, but the unigue Alias will always represent it whatever name you use for Channel/device","",""
"756247672637358181","sherylmccrary","2022-08-23T15:06:18.4350000+08:00","Pinned a message.","",""
"867075936054149191","rickbullotta","2022-08-23T19:55:02.8270000+08:00","I personally think more people should be looking to get this data from their SCADA/HMI or their historian, for myriad reasons - already contextualized/scaled, reduced comms load on devices, reduced security risk, etc...","","üíØ (1)"
"794020366536146977","mparris","2022-09-14T03:45:23.1140000+08:00","Regarding your statement that PLCs aren't meant to connect to AutoID devices using OPC UA, the OPC Foundation disagrees...","",""
"794020366536146977","mparris","2022-09-14T03:46:19.1820000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1019333225052647564/unknown.png?ex=68df7f4b&is=68de2dcb&hm=7231518d16b5990a9be55b21d3a2745b24ead0fda1125feef327b3a2b470ebe2&",""
"794020366536146977","mparris","2022-09-14T09:32:25.2710000+08:00","This is the gap that is most frustrating with their communications","",""
"794020366536146977","mparris","2022-09-14T09:32:56.8740000+08:00","What could be done VS what should be done VS what is being done","",""
"794542235676180500","akoscs","2022-09-14T14:19:55.6740000+08:00","I do not think that anyone with technical knodge at the OPC foundation would disagree.  I agree the image can be misleading, but it can just as well be interpreted as OPC is connecting PLCs to Scada systems, and so on, and you can pit your AutoID devices on this network. If the OPC foundation intended OPC-UA to connect sensors to a PLC from the start, then why would they create the FLC group years later? The existence of the FLC group is saying that we have now a new use-casa not covered before, field level communications.","",""
"794542235676180500","akoscs","2022-09-14T14:23:11.6690000+08:00","You can bash OPC UA all you want, but you never give a better alternative that is not subject to the same critisism. Is there any other alternative that is working on data modelli g on such a large scale as the comp specs? No. Is there any othere communication system supporting as many features as OPC-UA? No.","",""
"867075936054149191","rickbullotta","2022-09-15T02:28:20.0150000+08:00","The OPC UA information model is an abomination.  The verbosity, horrific node id approach, and lack of readability makes it so.  Sprinkle on the fact that it is still XML based, in 2022, and it‚Äôs quite ‚Äúbash worthy‚Äù.","",""
"794542235676180500","akoscs","2022-09-15T02:29:44.4580000+08:00","You know a better one? Same scale, same usecases?","",""
"867075936054149191","rickbullotta","2022-09-15T02:31:12.0440000+08:00","You make it seem that the proliferation of little used features is, itself, a feature.  I‚Äôd disagree as would most, including quite a few OPC UA insiders.  What was needed was a platform independent replacement for OPC DA, HDA, and A&E, with some enhancements to support richer discovery and metadata.  What we got is monstrosity-by-committee.","",""
"867075936054149191","rickbullotta","2022-09-15T02:32:50.8940000+08:00","They all suck. But let‚Äôs not fall into the ‚Äúwhich sucks less‚Äù trap that has led to things like horrible choices for political candidates.  Let‚Äôs fix it. And it might involve a clean sheet of paper.","","üëç (1)"
"794542235676180500","akoscs","2022-09-15T02:33:50.3350000+08:00","You have no chance of rallying that much support from companies in the next 10-15 years","",""
"794542235676180500","akoscs","2022-09-15T02:35:11.6800000+08:00","It‚Äôs not they all suck. It‚Äôs tell me 1 alternative which has the same scale as the comp specs.","",""
"867075936054149191","rickbullotta","2022-09-15T02:35:58.9540000+08:00","Again, I see that scale as a bug, not a feature.","","‚ù§Ô∏è (1)"
"867075936054149191","rickbullotta","2022-09-15T02:36:51.8230000+08:00","That‚Äôs exactly the problem! When ‚Äúthe companies‚Äù do this kind of stuff it takes 10-15 years and we end up with outdated, complicated junk.","","‚ù§Ô∏è (1)"
"794542235676180500","akoscs","2022-09-15T02:40:49.8660000+08:00","Does it take 10 years for a comp spec? I did not say that. I said you will not get support for a different project in the next 10-15y.","",""
"794542235676180500","akoscs","2022-09-15T02:41:33.4940000+08:00","So if scale is a bug, wide adoption is a bug also? How do you get wide adoption without scale?","",""
"867075936054149191","rickbullotta","2022-09-15T04:44:51.1760000+08:00","I'm just disappointed that the industry is so tolerant of mediocrity and half-assed-ness.  The emperor has no clothes, and too many are too scared (or too uninformed) to say so.  Good luck.","",""
"867075936054149191","rickbullotta","2022-09-15T04:48:32.5230000+08:00","For the record, I feel the same way about MQTT and Sparkplug.  They fall short on so many levels as a comprehensive IIoT solution.  Maybe the truth is that none of this crap has truly widespread adoption.  It'd be interesting to ask the big historian and HMI vendors what protocols are most commonly used to connect to control and sensing.  I suspect the majority answer is still native connectors, not OPC UA.  And there is still a LOT of OPC DA stuff being implemented and sold.","",""
"1003237589421137992","gregory.g.","2022-09-15T11:40:44.5710000+08:00","I have the same feeling for PackML, MTP, etc.","",""
"914993398526656542","mikebartlett_nh","2022-09-16T05:11:25.4010000+08:00","The number 1 connector we sold at OSI is OPC DA by a wide margin.  It was more than 50% of the total.","",""
"782154101122531328","yousufzubairi","2022-09-17T14:07:24.0630000+08:00","Writing an article on introduction to secure OT/ICS network architecture and segmentation to be published on linkedin later tonight, appreciate any quick feedback and any volunteers interested in reviewing draft and can provide comments today","https://cdn.discordapp.com/attachments/815945777452941313/1020576688800809110/image0.jpg?ex=68df681c&is=68de169c&hm=ab617103d1d293a94d414a9f9c78d265a57ba81c4aaa565ea45dca3229b97630&",""
"812295088348200960","patanj2","2022-09-17T21:12:55.9280000+08:00","Wow.  That is interesting to hear.  I personally haven‚Äôt used in years,  but functionally I liked it,  relatively simple,  did one thing well.  Only when you had to get into DCOM configuration and troubleshooting did it make me want to pull my hair out.","","üíØ (1)"
"794020366536146977","mparris","2022-09-17T21:20:42.9740000+08:00","Based on the image you posted, I'm not sure what you are trying to explain to the audience.

I suggest having smaller, more concise images that convey a particular point.","",""
"782154101122531328","yousufzubairi","2022-09-17T22:43:04.6280000+08:00","Thanks @MParris for input. Am introducing the concepts on building a secure OT/ICS network architecture with network segmentation b/w IT and OT environment and on conceptual Enhanced Purdue Model - in an Industry 4.0 / IIOT, with Wireless settings & where to set certain Security Enforcement Boundaries within the model. For UNS, am suggesting micro-segmentation and or zero trust security model.","",""
"1000180138325065800","bender_unit","2022-09-18T02:34:31.7830000+08:00","I think a lot of the people in charge don‚Äôt know about MQTT. Also I don‚Äôt think they know much about OPC UA vs DA. Does it connect? Then they are happy. I really think the lack of education and all the acronyms confuse people and they just do what‚Äôs easy.","","üëç (1)"
"794020366536146977","mparris","2022-09-19T18:54:30.2160000+08:00","At IMTS in Chicago, I spoke to Peter Lutz of the OPC Foundation about FLC.

He explained that PLCs supporting FLC will have to include an OPC UA Client to configure the other controller (or device when they release that specification).

I asked him that since so few PLCs implement an OPC UA Client over 16 years after the general specification was released, what would convince the OEMs to add OPC UA Client now to support the FLC initiative.

Peter's response was that the use-case didn't exist before, and that the market will pressure PLC OEMs to add this capability.

@akos what are your thoughts that PLCs will have to embed an OPC UA client to connect to other devices for FLC?","",""
"766684226455207996","bright_hummingbird_31342","2022-09-21T06:29:12.7770000+08:00","I know this question is directed to @akos, but I'd like to chime in.

Outside of a few of the PLC makers that are big on machine-to-machine over OPC UA, I don't see this really taking off.  The PLCopen Function Block was neat, but few companies wholeheartedly adopted it.  Also, not having to map in and out fieldbus payloads is a pretty good use case.

**Pretending to be interoperable**
If you look at TSN, which FLC relies on for determinism, many of the fieldbus orgs are using TSN to enhance their own competing fieldbus technologies.  Why would one create a new version of a fieldbus while also participating in working groups to consolidate them?

**Rockwell doesn't care**
If ODVA is working on a TSN implementation of EtherNet/IP and ODVA is largely influenced by Rockwell, why would Rockwell bother implementing an OPC UA client with the CIP companion spec?

**Mitsubishi doesn't care**
If CLPA is working on a TSN implementation of CC-Link IE and CLPA is largely influenced by Mitsubishi, why would Mitsubishi bother implementing an OPC UA client with the CC-Link companion spec?

**Siemens is confused**
If Siemens recently enhanced their controller firmware for OPC UA Client support and PI is largely influenced by Siemens, why would PI bother working on a TSN implementation of PROFINET?

**Fanuc doesn't even bother**
If Fanuc plans to continue using their range of native protocols (e.g., I/O Link, SRTP/SNPX, FOCAS) and support popular fieldbus protocols (e.g., EtherNet/IP, PROFINET) and not use OPC UA in any of their hardware, why would Fanuc implement an OPC UA client at all?","","üëÄ (2)"
"801561312861618236","jon.forbord","2022-09-21T23:29:16.6830000+08:00","I liked John Renaldi‚Äôs take on this. ¬´I love OPC UA, I hate OPC UA, I love MQTT, I hate MQTT¬ª. And you‚Äôre right, OPC UAs information model is the most comprehensive there is. Does anyone know a good demo that shows the power of these information models used in conjunction with comp specs?","","üòÄ (1)"
"794542235676180500","akoscs","2022-09-22T01:58:15.5230000+08:00","For field level communications we already have widely accepted data models (CanOpen has Device Specification, sercos has it‚Äôs data models, EtherCat uses CANOpen or sercos data models, ProfiNet has data models (Profibus also), most of these are standardized, some are open standards). Given a drive amplifier, I can switch out the drive amp for a different make and model and if I am not using any manufacturer/model specific functions, it will work (not quite plug and play, but plug, make sure it is configured right and play). Comp. Specs for OPC UA are currently the best option for something similar at the non field level. This is new for non field level communications and have a lot of positive effects. In field level communications OPC-UA FLC (on its own) does not bring anything new thing, comparable in novety to comp specs. (Maybe novelty is not the right word, but you get it). It will more or less be ‚Äúanother standard‚Äù which might do great stuff, but nothing so out of the ordinary. (To be continued)","",""
"794542235676180500","akoscs","2022-09-22T02:07:02.3950000+08:00","(Cont‚Äôd) TSN is an extreamly interesting technology, but it is not quite availabe for the general public (it is a collection of standards, some of them, related to the network controller still unfinished, commercially availabe switches lack important features). If the only new thing OPC UA FLC brings is ‚Äúover TSN‚Äù then it will still take a while until it can be actually used. Furthermore all other protcols can be ‚Äúover TSN‚Äù also. I think this is the reason why OPC UA FLC interest is somewhat underwhelming. There is one aspect where OPC UA FLC could differentiate itself and it might be its key to sucess. I am not quite sure what the difference will be for FLC, but, if contrary to EtherCAT, sercos and Profinet it will implement the IP layer it will be better usable in ‚Äúunified‚Äù ethernet network (where with TSN RT and NRT traffic will be mixed). It is still unclear how TSN will work (how replanning/reconfiguring a network will actually be carried out). This will be the thing that will make OPC UA FLC very useful in practice. How will TSN progress and if it will be available and adopted and how well can OPC UA FLC be ‚Äútailor made‚Äù for TSN. Its alternatives have legacy problems ‚Äúover TSN‚Äù.  I think we are still away from wide scale TSN use (not sire when or if it will happen) but after TSN can be actually used in an industrial setting, then we will see the shortcomnings of current fieldbusses (not necessarily their data models). OPC UA FLC‚Äôs chance of bringing something new to the table is eliminating those legacy problems. We could have a long discussion on what TSN will bring, I think, IF it will be as I imagine (not all of its parts are finished) and IF it will be widely adopted it will show the weaknesses of choreographed microservice architectures (and MQTT) and steer us towards orchestration (e.g. Zebee), but this is a different and very long discussion.","",""
"794020366536146977","mparris","2022-09-22T07:58:21.6380000+08:00","Before they can tackle TSN, PLCs must embed an OPC UA client to be compliant with FLC Controller-to-Controller or the in-progress Controller-to-Device spec.

@akos Do you think this requirement will be too large for PLCs to comply with the FLC specification?","",""
"794542235676180500","akoscs","2022-09-22T16:37:11.8420000+08:00","I do not think that you can speak of PLCs in general. There are PLCs which use cheap 8bit processors and there are PLCs using high performance x64 architectures. Definitely there will be PLCs which will not be able to implement this. There are PLCs which cannot implement other high speed fieldbusses for the same reason. As the cost of compute is getting cheaper more and more PLCs will be able to implement complex communication mechanisms. I am more worried about TSN+PubSub then about PLC compute performance. Current Siemens S7-1500 PLCs can handle 30 parallel incoming OPC-UA connections (I did test this) and run production line in parallel, why would an OPC client be a problem? Furthermore having a nodeset file from a PLC in controller to controller comms will allow unprecedented integration testing before deployment in the field!","",""
"794542235676180500","akoscs","2022-09-22T16:43:36.8970000+08:00","Furthermore, if and when TSN will work and will be widely adopted we will be able to rethink a lot of todays ‚Äúno alternative‚Äù controls architecures and have a more flexible approach to controls. I am not saying ‚Äújust use a PC‚Äù I am saying that there will be many new options for innovative products that can take the role of a PLC.","",""
"817835202746253344","IIoT#4707","2022-09-22T16:43:37.3190000+08:00","GG @akos, you just advanced to level 7!","",""
"795598602772414485","kskblr07","2022-09-25T20:10:37.6650000+08:00","Folks, What is the best way to store raw telemetry data on Azure Data Lake Storage Gen2? In my case I have 250k tags coming from PI every 5/10 minutes. Would I store every individual reading as a separate file? Or would I choose something like an append blob and append the reading, and possibly create a new blob every 24 hours? I will eventually be sending off this data for processing (no real time processing) to Azure Databricks to create a curated zone. Thank you.","",""
"743810005714600017","dep05d","2022-09-25T20:55:04.5010000+08:00","I would put each 5-10 minute batch of records into it's own blob rather than append to a daily file. This will allow you to trigger processing of those records in other Azure services based on the blob creation event.  One of those triggered services could always process that data into a more structured long-term historical blob format, if desired.","","üëç (2)"
"914993398526656542","mikebartlett_nh","2022-09-26T23:11:54.4660000+08:00","I'm very interested in how this is working out for your organization from a cost perspective, if you can share a use case, and if you are using ADL as your long-term storage or just as a transient stop for analytics.  Part curiosity (I was at OSIsoft for almost 15 years and helped customers with efforts similar to this for analytics) and part because we are working with a few AWS customers who are pushing, or are looking to push, time series data into S3 from our software.  TIA","",""
"795598602772414485","kskblr07","2022-09-28T01:30:26.5120000+08:00","For now yes thinking of using ADLS as long term storage (medallion architecture), but still in design/prototype phase Mike. Will keep you posted on how this goes.","","üëç (1)"
"1023339351834370089","rehenley","2022-10-03T23:01:38.2210000+08:00","I would like to learn more about the Structure / Architecture of unified name space and the visualization / dashboard / analytics platforms that drive it.  I know there are any endless variety of options but I would love to hear from folks who have moved in that direction and what it looks like for them.","",""
"745009912160976977","marioishikawa","2022-10-04T01:29:52.8710000+08:00","I believe that as for Visualization in Real Time, Ignition is the most used in this community. For stored data you can also use a BI system such as Power BI. The most common architecture most will mention here is HiveMQ and HighByte for the UNS. Anyway, I tried to make it possible to give you an answer, but this is a huge topic and is also covered on Mentorship and Mastermind.","",""
"898217314741280828","hobbes1069","2022-10-04T02:44:55.4040000+08:00","As Mario suggested, joining Mentorship and/or Mastermind would be beneficial. To try to answer your question as best as I can in a one-liner... Structure your UNS based on how you want/need to CONSUME the data, then you know how you need to publish it. Do the work on the front end instead of the back end.","","üëç (2)"
"1023339351834370089","rehenley","2022-10-04T05:43:47.2680000+08:00","Thanks, I know these are far reaching questions.  I am in the process of signing up for the mastermind + series.  Thanks for the replys.","",""
"894527802316046366","nickn5549","2022-10-04T06:14:47.6620000+08:00","Started it with FREE tools and still building on this FREE version....until get more traction. EMQX MQTT + Node-Red + Python + MySQL + InfluxDB + neo4j","",""
"894527802316046366","nickn5549","2022-10-04T06:17:11.2570000+08:00","one day I will add the fancy tools....Ignition, HighByte, Flow","https://cdn.discordapp.com/attachments/815945777452941313/1026618949309300756/unknown.png?ex=68def9e7&is=68dda867&hm=15911a9f27e59f121e8830c60ecd46e4612907f929697a0070da6b9be38121c4&","üëç (1),üëèüèª (1)"
"1023339351834370089","rehenley","2022-10-04T06:19:32.5570000+08:00","I am similar @NickN  - using python, MySQL, Ignition, then a couple of siloed departmental applications that I am trying to incorporate into the system.  Really focused on the MES side of the facility at this point but want to start thinking in terms of Business process automation.","",""
"894527802316046366","nickn5549","2022-10-04T06:30:31.4260000+08:00","Yep, I have 60+ apps that are used by manufacturing and engineering, UNS is the glue behind the scene that is unifying the backend and makes apps integration easier....still WIP though, at this stage I'm ALL IN ONE - architect, design, development, implementation, training, maintenance....you name it","",""
"894527802316046366","nickn5549","2022-10-04T06:37:17.3210000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1026624007946129418/unknown.png?ex=68defe9d&is=68ddad1d&hm=1c26a7f3baf478d3e81855eb5765b81a4e83517e4de9bec4514ed49b30a86a58&",""
"917925131261718558","jpmoniz","2022-10-04T07:01:24.3430000+08:00","OWI? Work instructions? Just caught my eye as we use same acronym","",""
"894527802316046366","nickn5549","2022-10-04T07:01:57.3060000+08:00","Yep, Online Work Instructions","",""
"917925131261718558","jpmoniz","2022-10-04T07:02:51.1190000+08:00","Lol. Ours is operator work instructions. But still online","",""
"894527802316046366","nickn5549","2022-10-04T07:07:42.1850000+08:00","What do you use to display the OWIs?","",""
"917925131261718558","jpmoniz","2022-10-04T07:10:14.6520000+08:00","Ignition but just for single pane view they are just word docs in SharePoint that I show via web services @NickN","",""
"894527802316046366","nickn5549","2022-10-04T07:15:42.9950000+08:00","And hardware?","",""
"917925131261718558","jpmoniz","2022-10-04T07:19:30.0030000+08:00","Whatever you want. Phone/tablet/desktop. Windows/Linux/ARM","",""
"894527802316046366","nickn5549","2022-10-04T07:28:54.6510000+08:00","Same here...but I'm trying to standardise the UX. Pi 400 + a screen are pretty good and cheap","",""
"917925131261718558","jpmoniz","2022-10-04T07:42:03.8410000+08:00","I get it. Design to your constraints.  I‚Äôll just say ignition perspective is a flexible way to deal with all of that.  Yes I am a fanboy that way.  I just haven‚Äôt seen anything that compares yet.","",""
"894527802316046366","nickn5549","2022-10-04T09:23:12.1220000+08:00","I played a bit with Perspective - looks all right, but I prefer a bit more freedom in building up the UI. I use PHPRunner as a framework and the results are cool. You can generate your OWIs directly online - in a web editor - add text, pictures, videos, files, ect -  skipping the Word Doc and Sharepoint stuff. Incorporated Revision Log and Training records directly in the OWI system...","https://cdn.discordapp.com/attachments/815945777452941313/1026665761017700382/unknown.png?ex=68df257f&is=68ddd3ff&hm=79b308feb6a03199daf8d8d62b9f0db03a230bacb992b7c65213ee5c9a1e7ac6&","üëèüèª (1)"
"894527802316046366","nickn5549","2022-10-04T09:26:16.8350000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1026666535969894400/unknown.png?ex=68df2638&is=68ddd4b8&hm=97c412f0af12285c057355f27370c7536932c5d20464c50900db46a09cb8dace&",""
"917925131261718558","jpmoniz","2022-10-04T09:36:35.2160000+08:00","For sure. One thing I am working today on is database driven work instructions so the UI/UXis driven off of the configuration and data in the db. Working towards the idea of paramtarized work instructions. I.e no more word.or XL. But also no more UI building based off that info.","","üëç (1)"
"876880919988957205","ryankershaw","2022-10-07T02:33:24.5790000+08:00","Where would everyone place the UNS in the Purdue/ISA95 model?  I'm looking at it more from an architectural standpoint, not a connectivity standpoint.  For instance, even if an ERP can talk to a process sensor, we still refer to the ERP being in Level 4.  I'm thinking a UNS would be there too, but want to get some other viewpoints.","",""
"1003237589421137992","gregory.g.","2022-10-07T02:50:59.9230000+08:00","I guess we should put it in the level 3.5 DMZ.","",""
"876880919988957205","ryankershaw","2022-10-07T02:57:33.2250000+08:00","Technically not a level.  For this exercise, need to stick to the standard 5 level system. üòÅ","","üòÜ (1)"
"898217314741280828","hobbes1069","2022-10-07T04:58:29.3490000+08:00","I agree with Walker that Purdue is dead... I'm working with IT to put each manufacturing building on different VLANs and then use firewall rules to allow/deny access.","",""
"876880919988957205","ryankershaw","2022-10-07T05:04:16.5220000+08:00","I half agree with him on that. I think from a connectivity standpoint, it‚Äôs definitely facing some challenges.  Not sure about dead, but getting to that point. However, from a naming convention standpoint, I think it remains quite useful.","",""
"917925131261718558","jpmoniz","2022-10-07T05:16:27.8960000+08:00","Level 3 and level 4.  You could have site namespaces at level 3 and enterprise namespaces at 4. That‚Äôs the flexibility with broker technology.","",""
"876880919988957205","ryankershaw","2022-10-07T05:54:18.8900000+08:00","Similar to the Manufacturing Service Bus/Enterprise Service Bus. Personally, with a UNS as a single instance, I would more see it sitting in Level 4 since it affects the entire enterprise, but split like that I think it makes sense.","","üëç (1)"
"894527802316046366","nickn5549","2022-10-07T06:04:23.8770000+08:00","UNS is trans-dimensional","",""
"917925131261718558","jpmoniz","2022-10-07T06:22:06.2260000+08:00","Yes In a simple form I would agree. Broker technology also enables many other use cases at site so I would expect to see site instances as things scale out.","",""
"867035383509024778","mattmigchelbrink","2022-10-07T06:48:03.1020000+08:00","jp well played on deliberately replacing UNS with broker. 

but to be clear for newer members... UNS is more than just a broker","",""
"917925131261718558","jpmoniz","2022-10-07T07:26:16.0560000+08:00","Sometimes we need to separate the two. UNS to me is a design concept for interoperability. Broker technology is a piece that gets you there. But also not the whole story.  Still needs to have a central API gateway as well.","","üëè (5)"
"812295088348200960","patanj2","2022-10-07T10:48:08.4060000+08:00","I was getting hung up on same question‚Äî if UNS lives on a broker as as a physical instance,How can it be 3 and 4 and not 3 or 4.   For my site architecture, UNS and broker live at level 3.","",""
"1003994033468747787","andreasbackman","2022-10-07T18:54:35.5760000+08:00","Could you shed some light on what that API gateway would mean in practice. How and where and to whom?","",""
"917925131261718558","jpmoniz","2022-10-07T19:20:25.9350000+08:00","Well I think the common use case would be ad-hoc query of data across nodes in the ecosystem. If the premise is don‚Äôt assume who or what needs access to data and the goal is to eliminate point to point connections then one would need an api hub to promote that.","",""
"894527802316046366","nickn5549","2022-10-07T20:02:24.0260000+08:00","at least add a layer of intelligence around the MQTT formed from microservices moving the data around - I use Node-Red for that - just linked today the ECN Portal to the Production Schedule to be able to check on the spot all the critical revisions (BOM, CAD, bare PCB) before we start running the products on the manufacturing lines","",""
"876880919988957205","ryankershaw","2022-10-07T20:38:55.3160000+08:00","That seems like a cheating answer. üòÇ","",""
"876880919988957205","ryankershaw","2022-10-07T20:41:36.0580000+08:00","Yeah, I think it's going to be different depending on the organization.  Not the answer I was hoping for, but the answer I got I suppose.","",""
"1003994033468747787","andreasbackman","2022-10-07T21:10:35.4700000+08:00","And that API hub would get data from where? And do you mean something like HTTP endpoint (Graph QL?) or somehing else?","",""
"917925131261718558","jpmoniz","2022-10-07T21:12:11.9890000+08:00","Depends on what the system of record is.  But generally yes it‚Äôs web services based.","",""
"794020366536146977","mparris","2022-10-08T06:25:22.0010000+08:00","UNS has at least two components: (1) connectivity/communication and (2) information.

If you are ignoring the connectivity part for this exercise, you are left with the information.

While you can't categorize UNS into the five layers, you can categorize a producer function feeding the UNS  and a consumer function reading from the UNS.

 In a mature organization, there will be many of these applications all up and down the stack.  In an ideal world, all devices, PLCs, SCADA, and ERP included, would produce and consume according to the information standards of the organization.","",""
"876880919988957205","ryankershaw","2022-10-08T06:39:49.4980000+08:00","I‚Äôm ignoring the connectivity part of the ISA95 model, not the connectivity part of the UNS. As for where it gets categorized, I agree that it feeds and consumes from many points on the stack, but is there a certain place in the ISA95 model that it should be placed?  With the UNS, the ERP should be able to gather information from up and down the stack as well, but we still classify it as a Level 4 system.","",""
"794020366536146977","mparris","2022-10-08T06:44:07.6490000+08:00","ERP is classified by the function it provides, not the data it provides or uses.

The function of UNS is connectivity, similar to Network infrastructure. So its categorization, by definition, has to be at all levels.

My prediction is within 10 years that just as there is network infrastructure devices (switches, routers, firewalls), there will be Data Access infrastructure devices, and each level of ISA 95 would house one of these Data Access Infrastructure devices.","","üíØ (1)"
"794020366536146977","mparris","2022-10-08T06:47:02.5330000+08:00","If there are data ops functions (transforming data, etc), then I'd use the scope of that Data Ops application to define what level it should be put at.

An org may have an Enterprise-level data ops application, while at the same time, a level 3 device gateway producing the information in exactly the format needed by the Enterprise, or a level 2 PLC doing the same.","",""
"894527802316046366","nickn5549","2022-10-08T09:11:53.5220000+08:00","it's Sci-Fi üôÇ  UNS evolves from a black hole to a white hole (opposite)...if we were to cite general relativity...","",""
"1003237589421137992","gregory.g.","2022-10-10T14:19:16.1840000+08:00","come across this one 
https://www.iiot-world.com/industrial-iot/connected-industry/mqtt-enables-iiot-security-best-practices-within-the-purdue-model/","",""
"876880919988957205","ryankershaw","2022-10-11T21:01:21.9880000+08:00","Yeah, even this one doesn't really put the UNS at a single layer.  Honestly, looking at it from a naming convention, I think Level 4 would be the most appropriate.  Also interesting in the article to see that SCADA is mentioned as both a Level 2 (in the paragraph) and a Level 3 (in the illustration) application.  I've seen that a few times, though I would typically slot it in as a Level 3 application.","",""
"1003237589421137992","gregory.g.","2022-10-11T21:02:40.5350000+08:00","UNS enterprise on Lvl4 and a local factory UNS in Lvl3.5/3","",""
"876880919988957205","ryankershaw","2022-10-11T21:06:28.7500000+08:00","Yeah, and there's the crux, should the UNS be considered a singular application (naming and data repository for the organization) or part of the network infrastructure (connectivity)?  In the case of the former, it gets assigned to a single place (again for naming purposes only), in the case of the latter it exists at all levels as part of the infrastructure.","",""
"876880919988957205","ryankershaw","2022-10-11T21:13:17.3200000+08:00","Honestly, at this point, I think there's a different way of structuring it for each organization.  Until ISA reopens the books on ISA95 and updates it, there's probably going to be a million and one different ways to look at it.  The split scenario you've described is more aligned to the MSB/ESB (Manufacturing and Enterprise Service Bus) architecture, but if we use @MParris 's version of the UNS, we could put parts of it at each level as part of the network infrastructure.  From a connectivity standpoint, I think there's been some agreement that the UNS does not fit into the standard ISA95/Purdue model, which I definitely agree with, but from a where to place it in the org pyramid, I think we're a ways off from consensus.","",""
"794020366536146977","mparris","2022-10-12T00:23:40.1110000+08:00","Given UNS has a connectivity/communication component and an Information component, connectivity can happen at any layer. Likewise, Information can be produced and consumed at any layer.

Maybe what lives at Layer 4 is the ""definition"" of the communication standards and the ""definition"" of a standard Information Model?  I don't seeing this as an application itself, but more like a word document or Confluence page that contains a common dictionary of terms, for example. But it is up to application to comply with the standard and take the theory of what has been defined on paper (even digitally) and make it a reality, and that actualization of communication and information can be implemented at any layer of the model.

Don't know if that aligns with what you have in mind...","",""
"876880919988957205","ryankershaw","2022-10-12T01:44:35.4680000+08:00","Yeah, I think that's a good way to look at it.  The standard would apply to the entire enterprise, so it would make sense that it would sit at that level.  I would say that aligns nicely.","",""
"876880919988957205","ryankershaw","2022-10-12T01:46:21.7060000+08:00","Btw, this whole thing came about because I was trying to figure out where to fit the UNS in a course I'm putting together for ISA.  So based on all of this discussion, I can now confidently put the UNS piece in slide ""x"", not slide ""y"". üòÇ","",""
"876880919988957205","ryankershaw","2022-10-12T01:48:23.9860000+08:00","Though I do think this highlights the fact that ISA should probably open up the standard and make some adjustments to it.  The changes in communication, the addition of Levels 3.5 and 5, the MSB/ESB/UNS question, etc.  Not sure if they're working on it at the moment, and am doing way too much to even think of inquiring.  That said if anyone here is interested in something like that, I can ask around to see if they've started that up again.","",""
"844671073827291156","yasirtuncer","2022-10-12T19:58:20.9880000+08:00","@MParris What are your thoughts on micro-services that pushes the intelligence from UNS to targets? Should the technologies that we construct UNS be responsible for event-driven triggers? In most of our engagements the customer asks if you have the current state of the business why don't you send related information to different endpoints? This is not sending the payload to several endpoints, rather since UNS is the company's collected intelligence why does not UNS become the rule engine to send related payload in case 1 to X endpoint and in case 2 to Y endpoint? The roles and responsibility of UNS should end at some point even though like self-aware SCADA the UNS has the intelligence, but in my opinion it should not be the responsibility of UNS to run application-level decisions? What are your thoughts?","",""
"794020366536146977","mparris","2022-10-12T20:18:36.3470000+08:00","Without knowing any specifics of what you have in mind, I think it's best to separate the communication and information from the application.

Certainly, there are proprietary platforms that combine all three layers, but keeping the communication and information isolated from what should be done with the information (the application) is a more flexible architecture for other applications to connect.

I suspect this space will evolve from monolithic applications towards micro services. The challenge will then be, how to manage all the micro services, and how to locate the one when it is not functioning correctly.","","üëçüèª (3),üí° (1)"
"917925131261718558","jpmoniz","2022-10-13T09:21:52.0330000+08:00","100%. On your last paragraph.I think that‚Äôs going to be the biggest struggle moving forward.  This is where some sort of unified management platform will be key. The question become what does that platform look like. To me the space is too confused right now to deal with issues like this. Early adoption of platforms that try to solve this right now I think is a bit too premature.","",""
"794542235676180500","akoscs","2022-10-13T14:43:17.0330000+08:00","Is site to site vpn on topic for reference architectures? Does anyone has experience with openvpn? For a very low cost approach, I found cheap but robust routers but these can only do OpenVPN server or client and L2TP. Is there an open source solution to host a site to site OpenVPN server? It seems that OpenVPN Access Server is not free/opensource and I am somewhat confused about the differences between an OpenVPN server and an OpenVPN Access Server.","",""
"794020366536146977","mparris","2022-10-13T19:44:04.7950000+08:00","Check out PFsense, or look at the Netgate commercial devices. 

Something to consider is network throughout as that is strongly affected by CPU power.

I think Lawrence Systems on YouTube may have some videos on site-to-site VPN","",""
"794020366536146977","mparris","2022-10-13T19:44:40.5940000+08:00","This topic probably fits better under the #machine-networks channel","",""
"794542235676180500","akoscs","2022-10-13T23:14:03.1900000+08:00","I know pf sense and netgate, but i want a very low price. I considered processing power and bandwithh. Only OpenVPN remains somewhat an open issue","",""
"898217314741280828","hobbes1069","2022-10-20T03:47:49.3140000+08:00","Where is the best place to make unlike machines like? Here's what I mean by that...

90%+ of our machines are Fanuc based CNC machines, so we use Kepserver to poll via FOCAS2 and then translate to OPC UA tags. Because some of the data is Fanuc/FOCAS2 specific, I tend to name the tags in kepserver to be similar to what FOCAS2 library uses.

Once mapped into Tulip however, we really would like to have consistent naming where possible regardless of machine type (assuming it's similar, i.e.: A CNC mill is a CNC mill). 

My current thought is to use the attribute mapping in Tulip to ""translate"" from FOCAS2 specific definitions to more generalized definitions.","",""
"917925131261718558","jpmoniz","2022-10-20T05:20:11.8910000+08:00","Personally I would try to do it as close to the source as possible but also considering scale issues.  If it was me I would probably put something on top of kepware.  Either ignition or highbyte.","",""
"477355192375967747","kiwimalice","2022-10-20T08:40:03.3710000+08:00","so whos going to bite the bullet and go through the below and see if its relevant for the UNS ?

IEC PAS 63441:2022 
Functional architecture of industrial internet system for industrial automation applications
https://webstore.iec.ch/publication/75170","",""
"817835202746253344","IIoT#4707","2022-10-20T08:40:03.7580000+08:00","GG @GavinD (EOT), you just advanced to level 3!","",""
"766684226455207996","bright_hummingbird_31342","2022-10-20T11:27:37.2560000+08:00","HighByte is very strong for this use case.  Instead of striving to be consistent across varied mappings in applications, HighByte is consistent through the use of models.  In your example, you could have a model govern the flow between KEPServerEX and Tulip.  With this approach, regardless of the heterogeneity in or across plants, Tulip will always ingest data consistently.  It's not a function of how disciplined one mapped attributes or followed a naming convention in an application.

One of the most powerful features are the global JavaScript functions.  This enables one to essentially create and maintain library of reusable transformations.  The biggest issue I've encountered with CNC isn't necessarily the variation in tag names, but the variation in how the underlying registers are used and the meager documentation.  So, suppose there exist registers that are tedious to clean up and make fit for use as tags in applications.  One can build specific ""cleanup"" functions once and run tags through them in a model instance.

At scale, it's just as important to have consistency in data transformations/mappings as it is in the organization of a namespace itself.

I believe it's much more sustainable to either ""get it right"" in the device itself or model in the infrastructure.  When I've tried modeling in an application, I've found myself running into issues.  First, it may not be capable of handling all the use cases.  This may necessitate additional solutions or custom apps to stand up and maintain.  Second, it may not do so efficiently.  Keeping up with changes or training others can be limiting.  Third, it's not ideal when another application introduced and needs to consume that data.  This necessitates another mapping project or a bespoke application-to-application integration.  Tightly coupling nodes makes lifecycling much more challenging.","","üëç (5),ü•∞ (2)"
"795178288330440704","youri.regnaud","2022-10-20T11:43:02.8890000+08:00","We plan to normalize our tags in Highbyte (after Kepware) in a semantic model. This semantic model will be use to create a machine type in Tulip. In short term our Solace broker will push data in Tulip Machine API. We are waiting MQTT features to publish data with MQTT protocol. I already ask Tulip to enable machine type and machine creation from API or import to be Edge Driven. By doing this, normalize data are available for all applications and Tulip is just a node connected to UNS","","üëç (1)"
"795178288330440704","youri.regnaud","2022-10-20T11:48:31.9560000+08:00","Is there a ¬´¬†packML¬†¬ª like specification for CNC machines?","",""
"740383178279354388","mriiot","2022-10-20T20:32:51.2810000+08:00","MTConnect information model would be the place to apply structure and semantics.  And then MQTT as the transport.","",""
"898217314741280828","hobbes1069","2022-10-20T20:40:04.8360000+08:00","Yeah, internally we've talked about eventually making all machines API machines and move the state calculation out of Tulip and into something like Highbyte. We're working on a PoC with them now (dealing with all the fun stuff with a bigger company, onboarding, getting approval from the category manager, etc.)","",""
"766684226455207996","bright_hummingbird_31342","2022-10-20T22:29:04.8800000+08:00","There are too many (e.g., MTConnect, VDMA, NCLink) and not enough apps/assets that support them [well].

@Russ from the Internet would be a good person to discuss this with. He knows MTConnect and Tulip well.","","üëç (1)"
"795178288330440704","youri.regnaud","2022-10-21T01:37:46.5920000+08:00","Interesseting question if machine state should be done in real time or store all tags data and have capabilities to calculate and recalculate machine states.","",""
"898217314741280828","hobbes1069","2022-10-21T01:39:11.4060000+08:00","That is one of the things that bother me. I have access to the attributes in real time, but they're not historized, so I have no ability to go back and reinterpret the data if I find a better way to classify machine state.","","üëç (1)"
"898217314741280828","hobbes1069","2022-10-21T01:41:06.4670000+08:00","I think you need to store machine state because a lot of my analytics are based on the machine state. If I didn't, it would have to calculate machine state on the fly so it could produce the final analytic. I'm not sure how responsive your system is, but we're a big enough site that Tulip can get pretty bogged down already.","",""
"329780110704246790","rkwadd","2022-10-21T02:10:37.2710000+08:00","So machine state here is one layer of abstraction higher than tags from the equipment or controller?","",""
"329780110704246790","rkwadd","2022-10-21T02:13:55.6110000+08:00","Conventional wisdom and most common approach for the last ~10 years was semantically define at lowest layer possible. Carry those definitions along through subsequent transformations and aggregations.","",""
"329780110704246790","rkwadd","2022-10-21T02:17:06.7150000+08:00","Significant caveat here: The vast majority of data collection and analysis projects mostly just didn‚Äôt apply semantic definitions anywhere and survived by ad hoc attempts to contextualize retrospectively, or accepting that a very small number of data items would suffice and therefore just working from small and simple tag libraries.","",""
"898217314741280828","hobbes1069","2022-10-21T02:32:19.3780000+08:00","Yes, it's bascially:
CNC (FOCAS2) -> KepserverEX -> Tulip (OPC UA)
Currently all the machine state calculations are performed in Tulip Triggers and then written to the MAT (Machine Activity Table).","",""
"898217314741280828","hobbes1069","2022-10-21T02:33:19.3680000+08:00","The current (and sometimes pervious) attribute values (tags) are available, but not historized.","",""
"329780110704246790","rkwadd","2022-10-21T02:41:13.7140000+08:00","Per my bad history lesson above the theory is that machine state is best defined one of these ways:
-In FOCAS2, by FANUC
-By Kepware‚Äôs FANUC driver","",""
"329780110704246790","rkwadd","2022-10-21T02:45:05.3250000+08:00","PackML, MTConnect, etc might have a state definition that‚Äôs more accurate,  complete, or applicable to other brands than what FOCAS or Kepware driver would include. That lets you push state calculation closer to the device layer, reduce duplication, potentially reduce resources on the OPC UA+Tulip layers","",""
"329780110704246790","rkwadd","2022-10-21T02:46:35.7010000+08:00","The performance implications can be pretty profound though and I don‚Äôt have a good sense of pitfalls and chokepoints.","",""
"795178288330440704","youri.regnaud","2022-10-21T02:49:54.6920000+08:00","I think you need to store both : Machine states for analysis and Machines Tags to recalculate machine states?","","‚ûï (1),üëç (2)"
"740383178279354388","mriiot","2022-10-21T04:38:03.4740000+08:00","What machine state are you even talking about ?","",""
"740383178279354388","mriiot","2022-10-21T04:39:43.2180000+08:00","Execution of the g-code program as it relates to modifying a work piece ?","",""
"740383178279354388","mriiot","2022-10-21T04:40:01.2520000+08:00","Thats a calculation across 5+ data points.","",""
"740383178279354388","mriiot","2022-10-21T04:41:27.8040000+08:00","Execution across multiple independent paths or multiple workcenters on a cell?","",""
"741114711550066709","john.harrington","2022-10-21T05:06:52.0270000+08:00","I think of the ISA95 stack as an application stack.  The UNS and communications infrastructure needs to be pulled out of the layers and be thought of as a different dimension.  It has to be able to span multiple layers and let data move smoothly across layers and skip layers.  There is too much data to move it up the stack loading down each layer as it moves through.  
Out of curiosity, where are you putting cloud based analytics in the ISA 95 pyramid?","",""
"817835202746253344","IIoT#4707","2022-10-21T05:06:53.1570000+08:00","GG @john.harrington, you just advanced to level 2!","",""
"741114711550066709","john.harrington","2022-10-21T05:23:04.0270000+08:00","@Richard Shaw  though I am biased (I work at HighByte), I agree with @youri.regnaud and @js that you should use HighByte to standardize and contextualize your data. This is exactly what HighByte Intelligence Hub was designed to do.  Doing it in Kepware is not advisable.  This will take you a lot of time and it doesn't have the concept of a model that gets instantiated for each similar machine.  I met a company just this week who wrote a custom application to sit on top of Kepware and standardize the naming of tags in it to solve this problem.  It is not going well for them.  
Doing it in HighByte also provides you the flexibility that if machines get swapped out or data needs change you have a solution to simply make the adjustments.  You can leverage the same model structures across multiple locations while giving the local domain experts a solution to perform the mapping.","","üëç (1)"
"329780110704246790","rkwadd","2022-10-21T08:09:25.6590000+08:00","I don‚Äôt work at HighByte and still agree with John.","","ü§£ (2),üëç (1)"
"898217314741280828","hobbes1069","2022-10-21T09:14:59.6250000+08:00","Good thing we're already working on a PoC with HB üôÇ","","‚ù§Ô∏è (2)"
"277515221885779970","jermuk","2022-10-22T00:53:00.0510000+08:00","If anyone has questions on integrating Tulip with Unified Namespace / MQTT, free to ask! We even wrote a small tutorial on how to connect it: https://learn.umh.app/guides/external/tulip/tutorial/connect-umh-with-tulip/

Right now, we are combining UMH and Tulip at a customer, so that we can leverage the Historian and Unified Namespace functionalities of the United Manufacturing Hub together with the great interactivity of a Tulip dashboard. From a technical side we are using a REST API, so that Tulip can fetch high frequency data, OEE, etc. from UMH / TimescaleDB, and then again a REST API, to push data back to MQTT.","",""
"876880919988957205","ryankershaw","2022-10-22T02:53:22.4330000+08:00","Good question, most newer publications are calling anything cloud based Level 5, but since I'm sticking to the standard model, it's going in Level 4.  That said, I am including a section that talks about some of the new unofficial levels like Level 5 and Level 3.5.","",""
"891563487241842699","jbonhage155","2022-10-27T12:28:35.3440000+08:00","Interesting! Curious to how UMH queries equipment PLC/controllers? Looks like in the example an IPC was used to connect to the controller, what protocol does it use? (I see NodeRED called out but not failmiar with it)","",""
"277515221885779970","jermuk","2022-10-27T17:53:16.4660000+08:00","I think for that example in the assembly cell, we used barcodereader to read out the quality test station (it acts as a USB keyboard and will print the measured parameters), and then used Node-RED to contextualize it. For one of the machines we used retrofitting using sensorconnect and ifm IO-link gateways (+ again Node-RED to contextualize). Another machine was done via OPC-UA in Node-RED if I remember correctly. In some cases with more complicated protocols we just use Kepware as an interface between MQTT and the machines. If it is avoidable (because Kepware only runs on windows, does not scale well, etc.), we use other methods.","","üëç (1)"
"875748535503573002","rv8938","2022-11-24T04:23:23.5830000+08:00","Hello all, question about GCP. Is MDE comparable to a MQTT broker where UNS resides? Is MDE the single source of truth? Also, is MDE similar to IoT Hub, that is: it is a black box and not a true MQTT broker? I am referring to ""Open architecture"" piece that Walker mentions in his philosophy. Does MDE support publish and subscription to MQTT 3.1.1 and SPb payloads? Thank you again for considering these questions!","",""
"794020366536146977","mparris","2022-11-24T06:10:01.7710000+08:00","I'm hoping to get the answer to some of these questions in the next few weeks","","üëç (1)"
"1044299684803530832","willemrs","2022-11-24T10:44:25.8000000+08:00","Hi all, not sure if this is the place for this but considering it‚Äôs architecture related we‚Äôll see.  I‚Äôm looking to bring the UNS architecture to our facility,  10+ main production lines, lots of smaller machines, Mostly AB plc‚Äôs and Rockwell HMI, and Ignition SCADA.  Given the idea that we don‚Äôt want to make assumptions as to what data is necessary, what is the best practice for bringing all the PLC tags to the UNS.  Thinking we would use Ignition to form the structure but that still requires secondary tags to be built in ignition aliasing to the PLC tag, say for baseline there are 5k tags per PLC.   Then if we really were to browse all 5k tags per PLC with ignition on a 1sec scan time we could easily overload the coms.  Am i missing some key way to link the PLC‚Äôs to a software based UNS or would we need to install hardware per line?","",""
"867075936054149191","rickbullotta","2022-11-24T22:01:37.2010000+08:00","MDE is really about driving consumption of GCP services like DataFlow (streaming analytics), BigQuery and the various AI/ML assets.  A variant of Litmus is the edge component here.  I would be cautious going ""all in"" on MDE at present - mostly because there's no longer an executive leader for manufacturing at GCP.  If it was strategic, that role should have been quickly backfilled (Dominik Wee moved to Microsoft).","","üëç (1)"
"991852688574779392","hutcheb","2022-11-24T22:33:51.6610000+08:00","Reading 5000 tags at 1 sec on L7X controllers is pushing the controllers ability (increasing the time allowed for comms from 20% improves this, but only slightly), on L8X controllers you should be fine.
However the quicker you can get the tags to be reported by exception the better, Softing make an OPCUA module that should be capable of it. I would really like to see an MQTT module for the logix platform though.","",""
"876880919988957205","ryankershaw","2022-11-24T22:35:01.6390000+08:00","Yeah, MDE is a bit of a closed ecosystem, especially compared to Azure and AWS.  GCP is really trying to be the one-stop shop in that area, which has it's positives and negatives.  On the plus side, things just work together, but on the negative side you're pretty tied to GCP.  From what I remember, they do have multi-cloud support, and you can bring in external applications, so there is a way to spread out the risk.  I have to say, I do like the platform, but I think it's going to come down to personal preferences and the capabilities of your organization.","",""
"867075936054149191","rickbullotta","2022-11-24T23:26:03.1830000+08:00","I'm curious what those 5000 tags per PLC entail.  What's the breakdown of them discrete vs analog, sensors vs memory, purpose and type of them?","",""
"1044299684803530832","willemrs","2022-11-25T00:03:53.3720000+08:00","Had to look to be honest.  looks like about 1k analog/Real. 4k discrete Dints/bools.  Lots of TC modules so looking at fault bits and temps, 6 + Servo Axis so all of the tags associated with those as well.    In reality the majority of these would not be interesting/important and we currently bring in only about 1/5 of them into either our HMI's or Ignition, however I feel like one of the key concepts here is the idea of pushing everything to the UNS, then picking what's important from that to pull for either and HMI or history.","",""
"1044299684803530832","willemrs","2022-11-25T00:19:23.6070000+08:00","Yep when we first picked up Ignition I overloaded a few of our processors, ended up slowing down our HMI's which were RSView at the time.  Then started being very selective as to what we looked at.  I definitely like the idea of standardizing the scan times and publishing everything to a single source, I'm just not sure how its technically done.","",""
"991852688574779392","hutcheb","2022-11-25T00:34:37.1240000+08:00","Ideally you'd have every tag being pushed every time it changes. But when you start to look at the realities, you'll be limited by your hardware and platform selection. An example would be if your PLC tag changes every 1 ms, Can your broker handle that? Can any clients make use of it? 
Your view on what data is required will also change when you look at standardizing device models, getting input from all the stakeholders you might realise the vast majority of tags won't be useful without some sort of context.","",""
"867075936054149191","rickbullotta","2022-11-25T03:14:56.5920000+08:00","I don't think there's much value in bringing everything honestly.  Everything of value, yes!","",""
"801561312861618236","jon.forbord","2022-11-25T07:12:32.4510000+08:00","I disagree, as how would you know for sure what holds value in the future? For me pulling everything has transformed my job when I‚Äôm programming PLCs and troubleshooting them. We used to historize what was conceived as valueable/important metrics, and when we started to historize everything during a run of development on new functionality, it was nothing short of transformative. Rather than adding tags to historize or start scoping after an incident hoping it would happen again to capture the data, or trying to replicate it, or staring endlessly at PLC code trying to figure out how it COULD fail based on human observations of what happened, you‚Äôd actually be able to see the sequence of events. But! You can‚Äôt always pull everything due to technical limitations, but I do think there are many good reasons to pull everything if you can, and at least use this as your shiny leading star when you can‚Äôt.","",""
"894527802316046366","nickn5549","2022-11-25T07:16:11.3490000+08:00","you need to 'borrow' an AWS datacenter to do all these....","",""
"894527802316046366","nickn5549","2022-11-25T07:18:30.0130000+08:00","I have the same issue with some very verbose machines - AOI - automated optical inspection - they send XMLs and also a sqlite database for each processed board - with embeded pictures of the faults and lots of paramaters.....to get all that, need to 'rent' a datacenter...","",""
"801561312861618236","jon.forbord","2022-11-25T07:31:26.5230000+08:00","This obviously depends.. and for the record we‚Äôre nowhere near to pulling literally everything, but it is the shift in mindset when you think about data to pull. It‚Äôs not ‚Äúdo we need this for the use-case?‚Äù, it‚Äôs ‚Äúcould this possibly ever hold value?‚Äù As an added benefit it‚Äôs easier to manage everything when you grab chunks of data, rather than handpick everything. Then there are of course other circumstances that can force you to make concessions..","",""
"894527802316046366","nickn5549","2022-11-25T07:46:04.5900000+08:00","agree","",""
"1044299684803530832","willemrs","2022-11-26T02:03:54.5160000+08:00","Yes I agree with this as well.  This is one of the main reasons I really like the UNS architecture.  The idea that only one source pulls from the PLC and publishes to the UNS then everything else would just pull what's needed.  Its always frustrating when the one tag that could help troubleshoot an ongoing issue isn't in the log...  After troubleshooting I end up trying to grab all the values that would have helped but at slower scan times to balance our the load.  If we were able to pick and choose what values to log without any affect on PLC load it would be a game changer.","","üëç (1)"
"917925131261718558","jpmoniz","2022-11-26T03:37:48.5740000+08:00","There is a point where your just pulling in garbage as well. I agree to a point. Really depends on how well structure is applied within logic. I don‚Äôt need scratchpad crap if there is a well architected structure to pull in.","","üíØ (1)"
"867075936054149191","rickbullotta","2022-11-26T03:46:50.6880000+08:00","Well, a lot of memory registers are typically used for internal state, logic, and calculations that, if I want to see that data, I'm doing to use my PLC programming software to look at it in proper context.

Also, bringing in too much garbage clutters your namespace and makes it hard for users and applications to actually find what they want.

And just hope you aren't using Sparkplug or you'll have almost no chance of finding what you need in those crowded payloads.","",""
"801561312861618236","jon.forbord","2022-11-26T03:47:31.7550000+08:00","You just need a couple of experiences where your assumptions about the usefulness of some data were incorrect to understand how little you know about the usefulness of data and hence should always try to at least pull as much as practical into the namespace. To avoid clogging the functional/contextualized namespaces you separate this  into a raw namespace and pull from the raw to make your functional / contextualized namespace. I see this as one of the really ground breaking aspects of this UNS concept. Again there are technical / cost reasons you can‚Äôt always do this.","",""
"867075936054149191","rickbullotta","2022-11-26T03:48:32.9370000+08:00","If you're sending this ""maybe I'll need it someday"" data to the cloud and historizing it, you could be facing a MASSIVE surprise when you get your cloud invoice!","",""
"917925131261718558","jpmoniz","2022-11-26T03:50:03.3480000+08:00","There is also the fact if you can even capture the data in the first place. Some things are best left to do in PLC and tracked through other mechanisms","","üíØ (1)"
"867075936054149191","rickbullotta","2022-11-26T03:51:41.7690000+08:00","Have I ever mentioned how much I hate cluttered namespaces? üòâ","",""
"917925131261718558","jpmoniz","2022-11-26T03:56:00.8480000+08:00","Me too. I‚Äôd rather see better engineering and structures from the start. More and more as I progress through this journey to me I‚Äôm landing on data centricity. I find if you shift your view point to data then you start to describe things better from the start and negate some of these type of discrepancies","",""
"801561312861618236","jon.forbord","2022-11-26T03:56:53.0890000+08:00","As said. Cost/practicality/technical limitations.. etc. Massive cloud costs would be a good reason to not historize everything.. but that doesn‚Äôt mean it can‚Äôt still be part of the namespace. And yes, we‚Äôre using sparkplug B, and we separate the raw from the structured in its own DDATA topic.","",""
"867075936054149191","rickbullotta","2022-11-26T03:58:08.7920000+08:00","I'd also make a case that namespaces/data/protocols can be different for machine operators (HMI/SCADA), machine programming (PLC/DCS configuration and monitoring) and enterprise data sharing (OT/IT bridging, analytics, etc).","","üíØ (1)"
"867075936054149191","rickbullotta","2022-11-26T03:59:05.8970000+08:00","Do you also expand the DDATA stuff (even the structured stuff) into finer grained topics to enable easier access for subscribers?","",""
"917925131261718558","jpmoniz","2022-11-26T04:00:28.9890000+08:00","100%. What you need for you HMI to be functional is totally different than what you will use for analysis. Is there some overlap. Yes. But the exercise is the same when developing structures in my view.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2022-11-26T04:05:54.9370000+08:00","And what you need to monitoring/editing control logic is yet another completely different set.","",""
"801561312861618236","jon.forbord","2022-11-26T04:07:14.2450000+08:00","Not yet, is what I‚Äôll say to that ü§òüèª Have no plan of using sparkplug for everything.. just SCADA and the lower layers.","",""
"867075936054149191","rickbullotta","2022-11-26T04:08:54.3110000+08:00","If you want to use my ""Sparkplug Expander"" just let me know.  Happy to share the code.  It's basically a Node.js task that will automatically expand Sparkplug B payloads into a more consumable namespace, and also includes the metadata in a retained message/topic.","",""
"917925131261718558","jpmoniz","2022-11-26T04:11:35.3760000+08:00","Yep.  Good example is our overhead code for motion axis parameters that tie the HMI to the plc. We have tons of code so HMI templates can allow the user to update a servo position parameters. Things like acceleration velocities position and what not.  Why would I ever log that underlying code when I can just monitor the data it‚Äôs modifying and infer something or someone has changed it.  To me those are the types of things that have no value in tracking when your can logical make inference on what you actually need to track.","",""
"801561312861618236","jon.forbord","2022-11-26T04:12:28.0060000+08:00","Hell yeah, I‚Äôll take you up on that offer! I‚Äôve done a sparkplug B decoder with Tahu, but that didn‚Äôt include properties or anything yet.","","ü§òüèº (1)"
"867075936054149191","rickbullotta","2022-11-26T04:14:32.9000000+08:00","DM me a good email for you.  I haven't put it in Github yet.  I have a couple variants I can explain to you.  Some are just the expander, some add a REST API to it, and some even add automatic historization to InfluxDB.","","ü§òüèª (1)"
"867075936054149191","rickbullotta","2022-11-26T04:31:28.5420000+08:00","This picture is a great example of my angst with Sparkplug B:

https://www.hivemq.com/img/blog/real_world_mqtt_for_industry_40_part_2/real_world_mqtt_for_industry_40_35_prepare_mqtt_messages_on_node_red.png","",""
"795178288330440704","youri.regnaud","2022-11-26T23:35:09.9660000+08:00","Is it a real problem between devices and broker, or more between broker and client that want to consume only specific metric?","",""
"867075936054149191","rickbullotta","2022-11-27T21:03:18.6890000+08:00","For clients that are only interested in specific metric(s).  Also, if MQTT simply added a ""multi-publish"" capability (which would be trivial), Sparkplug's *DATA intermixed metrics format wouldn't be needed.  Sparkplug could then be used simply for metadata definition/discovery (with some fixes) and for payload format(s).","",""
"795178288330440704","youri.regnaud","2022-11-27T21:18:22.0300000+08:00","What do you mean by ""Multi-publish""?","",""
"794020366536146977","mparris","2022-11-27T22:05:48.8940000+08:00","Change the MQTT packet structure so that data from multiple topics can be published without significant overhead from the MQTT protocol","","üëç (1)"
"794020366536146977","mparris","2022-11-27T22:14:11.6290000+08:00","For example, the topic paths are strings so they do not compress on the wire. And when you have multiple subtopics within one topic that is being published the upper level topic appears in the packet as many times as there are subtopics. So an optimization would be to include the upper level topic once and then the subtopics be able to reference that.","","üëç (1)"
"794020366536146977","mparris","2022-11-27T22:15:02.1590000+08:00","I'm thinking relative path vs absolute path","",""
"867075936054149191","rickbullotta","2022-11-27T22:54:31.6920000+08:00","Simply being able to include multiple string topic/value pairs in a single message saves overhead and latency, particularly with higher QoS levels, but in all cases.  And when combined with MQTT 5's topic aliases, it becomes even more efficient.  The ""relative topic name"" idea is good too.","","üëç (2)"
"795178288330440704","youri.regnaud","2022-11-28T02:41:04.4520000+08:00","thanks for you clarification. Like batch request in REST but for MQTT","","üíØ (2)"
"1044299684803530832","willemrs","2022-12-07T10:03:21.6390000+08:00","Thanks for the info everyone.  So given that its currently not possible to pull EVERYTHING into the UNS, what is the next best thing?  It sounds like using software like Ignition or direct to PLC MQTT modules, to push specific controls data direct to the UNS.  If done in Ignition would this be through UDT's?  And considering were still doing the intermediate step of bringing tags into Ignition to then push them to the UNS, is there really a benefit of utilizing a rack mounted MQTT module?  I have no experience using any of the rack mounted controllogix MQTT modules.","",""
"627696721903878156","dvy___","2022-12-14T14:38:03.5430000+08:00","Does anyone have one or more examples of a reference architecture that includes UNS, PLC/HMI/DCS, Historian, MES (managing production orders from the ERP, executed at least partlially by the PLC's). I have seen some proposals to put the UNS central and let all other systems communicate through the UNS.  For example illustrated by HiveMQ here: https://www.hivemq.com/blog/what-is-unified-namespace-uns-iiot-industry-40/ . But is that realistic? I've already seen some discussions here struggling with the historian. How about the ERP sending production orders to te MES and the MES executing them on the devices (PLC's)? All over a central UNS? Or is this architecure more suited to some specific use cases/industries? Shouldn't the UNS in some cases be limited to the literal meaning of the name: Unified Names (address/hierarchies) accross all applications instead of also trying to contain/route all data?","",""
"867075936054149191","rickbullotta","2022-12-15T05:10:34.4770000+08:00","That's one of the things ThingWorx tries to do.  In the SAP world, SAP DM (which is a bunch of products) tries to do that.  Process integration from ERP <-> MES <-> PLCs is about considerably more than a UNS though, in most cases.","",""
"627696721903878156","dvy___","2022-12-15T06:52:58.9220000+08:00","I agree it's about considerably more. So it feels like UNS is a pillar sitting next to the typical purdue architecture. Then where there's no tight vertical integration between ERP-MES-PLC this might work fine. But when UNS is braught into a company where they do need this integration then people are starting to scratch their head. That Hivemq architecture won't work in that case, at least not in the near future.","",""
"627696721903878156","dvy___","2022-12-15T06:53:47.4840000+08:00","So anyone who did have some level of success in integrating UNS with the classical PLC/HMI/DCS/Historian/MES stack?","",""
"685604620810322017","mattventer.","2022-12-15T18:26:05.7380000+08:00","The ERP generally wouldn‚Äôt send production orders to the UNS. The data would need to be pulled. You would then publish to a specific topic in the UNS by taking into account the Asset/EquipmentID. The MES would then be subscribing to this topic to get work order information.","",""
"627696721903878156","dvy___","2022-12-15T19:22:55.5670000+08:00","Pulled by what some intermediate software? And then it would have to be cyclic pulling because you don't know when an order is available.  And at a high update rate if the user wants to immediately see it in the MES. That sounds more complex than the MES just pushing the orders the moment they are released like it's mostly done today.","",""
"685604620810322017","mattventer.","2022-12-15T19:28:53.4090000+08:00","It also depends where the scheduling is done (MES/ERP). But yes, you would need intermediate software to periodically check if a new order has been released. It works for us as we have allotted times when scheduling + production takes place.","",""
"627696721903878156","dvy___","2022-12-15T19:37:49.7370000+08:00","Right there can be a scheduling layer in between. (Which might be part of the ERP, or the MES, or standalone). In this case indeed the orders for one period are prepared together. So you have a scheduling solution that can publish to MQTT?","","üëç (1)"
"745796393855352953","thedavidschultz","2022-12-15T20:53:43.3600000+08:00","At present you will need software to request WO updates to publish to a UNS. While this can be integrated directly into the MES, there may be other systems that want to consume the information. Same thing for scheduling and status updates. The intent is to architect nodes in an ecosystem that publish and subscribe to information with a consistent, unified approach. I can solve a business case in many ways. But making it scalable and extensible is more challenging.","","üëç (1)"
"867075936054149191","rickbullotta","2022-12-15T21:31:13.0280000+08:00","And anyone who thinks you can take a WO unmodified or undecorated and ""run it"" in your MES or automation system is in for a very rude awakening...","","üòÇ (1),üíØ (1)"
"794542235676180500","akoscs","2022-12-17T02:56:31.7830000+08:00","Here is a question that is bugging me for a few years now‚Ä¶we are aiming for single source of truth for our data. What about workflows or processes? Why do we not have a single source of truth for workflows and processes? What happens to the data is basically as important as the data, right?","",""
"867075936054149191","rickbullotta","2022-12-17T03:14:11.9640000+08:00","Data is just the exhaust from those workflows and processes, right?  Or are you referring to the dataops themselves?","",""
"794542235676180500","akoscs","2022-12-17T03:53:02.9480000+08:00","Exactly data is the exhaust of those processes. What defines the process? Currently in an event driven arhitecture with coreography, every service is responsable only for one step in the process. We have all the data, but we do not have an actual blueprint of the process (you can recreate it feom the data, but only post priory, there is no a priory blueprint to see what will happen to this datapoint when it ‚Äúenters‚Äù the UNS.","",""
"867075936054149191","rickbullotta","2022-12-17T05:54:08.2180000+08:00","Most MES, ERP, and workflow systems have a process definition environment though.","","this (1)"
"627696721903878156","dvy___","2022-12-17T07:05:12.3100000+08:00","Like when the workflow started and ended, or even how it progressed in detail for every step?","",""
"627696721903878156","dvy___","2022-12-17T11:08:50.7320000+08:00","So thanks to the people who already gave feedback to my original question about reference architecture examples based on UNS. Since I couldn't find an example that could apply to all the possible systems in a typical batch-based process I made a quick drawing myself. I went to the extreme to let all data pass over the UNS like some are advocating. I'm doubtful about a lot of things in this architecture, but let's first see what the opinions here are.","https://cdn.discordapp.com/attachments/815945777452941313/1053509049523654776/image.png?ex=68df3e42&is=68ddecc2&hm=c343fa4d7893b34c44cf685e29595a54bc777673e5123dd177a3efb28bd17764&",""
"898217314741280828","hobbes1069","2022-12-17T12:08:23.6710000+08:00","That's actually pretty nice. With more time I could make more suggestions but I'll work through a couple of points.
1. The Cloud (or more likely data lake) can be directly connected. The purpose of the historian and data lake are separate (with some grey area). The historian is there to provide historical context to manufacturing signals. The cloud is there to store massive amounts of data for AI/ML use. I know Azure does, and I ASSume AWS has a way to directly ingest MQTT  (or Kafka) streams. 
2. The UNS is not just an MQTT broker (but that's the heart of it). It can also be whatever you need to describe your enterprise (or site, etc.) and can include databases and other sources of data needed to completely contextualize your business.","","üëç (1)"
"627696721903878156","dvy___","2022-12-17T12:52:43.8970000+08:00","So today a plant that has this kind of set-up will already have the two main single sources of data: first of all in the historian for the time series data, and secondly the MES database. If the historian is properly set up it will already have the data organised according S95. Same for the MES. Are you saying that this is basically the same as the UNS concept, even though people don't call it that?","",""
"898217314741280828","hobbes1069","2022-12-17T20:41:34.4680000+08:00","Well, I didn't mean to overly download the broker part. That is a huge difference. It allows nodes that care to subscribe to the parts of the UNS that it cares about and get notified in real time about information and events. Poll/response is slow and expensive, even in an enterprise grade database if you have enough clients.","",""
"627696721903878156","dvy___","2022-12-18T03:45:13.9890000+08:00","So even if there's 'unified naming' applied in the databases, the recommendation is still to go with a broker to prevent bottlenecks? Which kind of applications are then being connected that this is becoming a problem?","",""
"817835202746253344","IIoT#4707","2022-12-18T03:45:14.8890000+08:00","GG @Dvy, you just advanced to level 2!","",""
"795178288330440704","youri.regnaud","2022-12-18T14:21:54.7030000+08:00","Messaging mapping is key in a Event Driven Architecture. In our target architecture we use Highbyte for OT messaging/protocol mapping and SAP Integration Suite for IT. Messaging Broker is Solace","","üëç (2)"
"795178288330440704","youri.regnaud","2022-12-18T14:25:33.4910000+08:00","I‚Äôm not a big fan of Gartner. Nether the less this picture shows well that you need for UNS architecture. Producer and Consumer nodes can have embedded capabilities required for Pub/Sub communication, but you need some extra software/solutions for all other nodes.","https://cdn.discordapp.com/attachments/815945777452941313/1053920941840793600/IMG_2289.png?ex=68df6c5d&is=68de1add&hm=7e069f57ca5797a093ececc50a2123b4937018f82e80837a3969bdfd8696bdcd&","üëç (1)"
"783917475128410112","geoffnunan","2022-12-18T19:24:07.3730000+08:00","MQTT does not have the option to ""Acknowledge after processing"", only to acknowledge on receipt of message, meaning that once your client has received the message, it's gone from the broker. If the client fails to process the message, the broker cannot re-send the message like in many message queue technologies.
For this reason, I do not recommend that MQTT is used for transactional messages, but only for telemetry which is a transmission of current state that can be re-published without negative impact.
I'm afraid that your MQTT based UNS architecture would fail miserably to cope with real-world failure scenarios","",""
"745796393855352953","thedavidschultz","2022-12-18T19:40:20.2250000+08:00","One way to deal with transactional data and brokers is to create another flow based on the receipt/processing of a message. For instance, an ERP could publish a new WO to an MES  and an MES could publish the latest WO in added. If these do not match there was an error. That said, the business logic could get unruly. And tracking down a problem equally challenging.","",""
"783917475128410112","geoffnunan","2022-12-19T07:16:59.6000000+08:00","Yes @DavidSchultz you have hit on the problem precisely. Beyond hobby-scale, the complexity of building all of that failure logic into all of your systems quickly becomes unruly. That's why message queues were developed that greatly simplify the challenge. MQTT brokers are NOT message queues, the name is misleading.","",""
"254777321788145664","terrancesmith","2022-12-19T07:59:36.4030000+08:00","@Dvy thanks for drawing up a detailed architecture to encourage less hand wavy communication about a UNS.  I feel like since I've started paying attention there are at least two types of UNS concepts that people seem to use interchangeably which has added to the confusion..

 The first is telemetry focused, the second is a more wholistic event driven architecture. The telemetry focus is about creating a single data model that makes the real-time state of a plant's assets more easily available (and usually storing that for analytics in a time series db on the side).  And the other is about creating a flat, event driven architecture in addition to a unified data model and managing all communication and shared state between enterprise systems and OT.  From what I've observed MQTT can be pretty great at the first and poor at the second.","","üëç (1)"
"627696721903878156","dvy___","2022-12-19T13:10:38.7810000+08:00","Thanks for the feedback until now @TerranceSmith , @GeoffNunan , @DavidSchultz , @Richard Shaw . Indeed the transactions were one of my biggest worries in the proposed architecture. Attached an update of the architecture with the transactions removed from the UNS and back to point-to-point how it normally happens in a classical architecture for batch-based production systems. The biggest question now (marked in orange on the drawing) is commands from the scada to the controllers. What are the opinions on this? Is anyone going over MQTT for these commands instead of direct OPC connections?","https://cdn.discordapp.com/attachments/815945777452941313/1054264477433995334/image.png?ex=68df5ace&is=68de094e&hm=469d70ee07a525368bcf914ab631e7d4a6a955770f71b6f77a0122d349d5f0ae&",""
"894527802316046366","nickn5549","2022-12-19T15:58:53.4680000+08:00","How do you do it in Libre?","","üëç (1)"
"898217314741280828","hobbes1069","2022-12-19T21:47:51.0600000+08:00","On the shop floor (local network traffic) there's nothing wrong with OPC UA. It's once the data needs to leave the shop floor (especially the cloud) that MQTT is a better choice. I like using the LEAN analogue of ""1 piece flow"". It may not be possible or practical for many reasons to actually achieve 1 piece flow, but it's an IDEAL. I view point to point connections the same. You'll never completely get rid of them, but a MQTT based UNS can remove the need for many of them.","",""
"867075936054149191","rickbullotta","2022-12-19T22:52:53.6680000+08:00","And when you say MQTT, I assume you mean ""plain"" MQTT, since Sparkplug has no place beyond the shop floor.","",""
"1036772716604301364","dsi_101","2022-12-19T23:23:39.5920000+08:00","Sparkplug does have a place beyond the ""shop floor"".  Not everything in automation is manufacturing making widgets. We have implemented Sparkplug to cloud and is serving our purpose quite well.","",""
"867075936054149191","rickbullotta","2022-12-19T23:29:01.2280000+08:00","Then you're probably ""doing it wrong"".","",""
"1036772716604301364","dsi_101","2022-12-19T23:58:54.7070000+08:00","If you have 100 analog points from 3 remote sites that are on a cellular modem. This small company wants to see that data in one place on their phone without having to VPN into each site and consume more data - how is sparkplug not a good solution for that?  No need for UNS, ERP, MES tie ins - not a fortune 500 company - a small mom and pop shop that wants to save data so they don't have their employees having a open VPN connection consuming data all day. I don't think we did this project wrong.","",""
"867075936054149191","rickbullotta","2022-12-20T00:03:43.3070000+08:00","Ha. You don't need Sparkplug for that.  Or a broker.  But whatever.  If it works for you, it works for you.","",""
"958349073126129665","niravpatel16","2022-12-20T01:30:39.8550000+08:00","This is where the MQTT SpB Report By Exception comes in handy. You can have both publisher and subscriber QoS set to 1. So you are guaranteed data.","",""
"867075936054149191","rickbullotta","2022-12-20T03:58:02.6230000+08:00","...except you aren't guaranteed to get just the data you want.  You need to deserialize and parse a whole bunch of metrics to (maybe) find the one you want in the *DATA message.","",""
"783917475128410112","geoffnunan","2022-12-20T14:55:15.3420000+08:00","I spent a long time trying to make MQTT work for transactions, going down the path of ""Smart Client / Dumb Broker"" meaning that I tried building async responses for each transaction and building the logic into the client to handle failed transactions as per what @DavidSchultz mentioned earlier in the thread.
It worked OK at small scale, but quickly got unruly when the number of transactions, systems, services and clients grew to even moderate scale.
I then went down the path of ""Dumb Client/Smart Broker"" and switched to RabbitMQ for transactions which does some the reliability and scalability and general unrulyness problems, but introduced another component to the stack, and we had already added Kafka/RedPanda for streaming, so now we had MQTT, Kafka/RedPanda and RabbitMQ in order to be able to run reliably.
Unhappy with the number of tools in the stack, We are now moving back to NATS which as a single platform handles MQTT (although only 3.1.1), Reliable Messaging in the Dumb Client/Smart Broken model AND streaming, effectively replacing our MQTT broker cluster, RabbitMQ cluster and RedPanda cluster without loosing out on reliability or functionality.","","üëçüèª (1)"
"817835202746253344","IIoT#4707","2022-12-20T14:55:15.5980000+08:00","GG @GeoffNunan, you just advanced to level 8!","",""
"627696721903878156","dvy___","2022-12-20T16:11:25.8260000+08:00","So if commands to the controllers better stay over OPC as it's always done then the architecture looks like this.","https://cdn.discordapp.com/attachments/815945777452941313/1054672361137393674/image.png?ex=68df852d&is=68de33ad&hm=13612e10657cfe834bf6b6d207f550fd55ff727e3eb4fb19e6a1ec0a9aebb277&",""
"627696721903878156","dvy___","2022-12-20T16:14:16.5990000+08:00","Only putting the commands to the controllers on OPC while the actual values have to pass over MQTT (which would still need a middleware for most controllers) is a weird architecture, so let's also put this back on OPC, and move the publishing to MQTT to the point when we log the data into the historian.","https://cdn.discordapp.com/attachments/815945777452941313/1054673077398667305/image.png?ex=68df85d8&is=68de3458&hm=fcfc446d2de08fb52f89e93d4fb5a7a93f332551b56e54d14e838cbfab87b45f&",""
"627696721903878156","dvy___","2022-12-20T16:17:05.7790000+08:00","Re-arrange the position of the UNS in the chart:","https://cdn.discordapp.com/attachments/815945777452941313/1054673786978435157/image.png?ex=68deddc1&is=68dd8c41&hm=434777a3c89b635457571f05be0fe9314113f58aba920c4aaf5a325a2060b9db&",""
"627696721903878156","dvy___","2022-12-20T16:39:58.1670000+08:00","Basically that's a typical architecture of a batch process plant today. Many food, feed, pharma, fine/specialty chemicals, lubricants, cement plants all run on this kind of architecture, with some minor variations. It's not a small part of manufacturing, it's covering some of the key segments. The biggest issue in these plants is always to come to a proper architecture and software model to enable flexible execution of the recipes, in an environment where new products are only being developed faster and faster. S88 is really key here. So am I missing something about the UNS, or is UNS mainly critical for other types of industries?","",""
"894527802316046366","nickn5549","2022-12-20T17:49:55.9500000+08:00","NATS sounds good....I was just playing with EMQX bridged to Kafka combo but I wasn't sure if is the best I can get (with minimum/less effort...üòÅ )","",""
"783917475128410112","geoffnunan","2022-12-20T18:57:01.1440000+08:00","I don't actually think there is any problem with using MQTT at the PLC/SCADA layer.
The issue is when you have distributed, cloud-native applications and micro-service architectures.
I would leave the UNS in place at the control level. I would replace the have the UNS feed a data hub which everything else connects to.","",""
"627696721903878156","dvy___","2022-12-20T19:05:33.0810000+08:00","What do you mean by your last sentence? Guess you edited something?","",""
"627696721903878156","dvy___","2022-12-20T19:08:05.2480000+08:00","So in my v2 MQTT was between PLC/SCADA. Is his done for commands from SCADA to PLC? Does anyone have this running in production?","",""
"794020366536146977","mparris","2022-12-20T22:38:34.9490000+08:00","I'm working through the first parts of the NATS Core documentation, but not seeing any major differences from MQTT.

Will the differentiation come when Jetstream is included in a deployment?","",""
"783917475128410112","geoffnunan","2022-12-20T22:44:35.7900000+08:00","Yes @MParris JetStream enables all the good stuff","",""
"794020366536146977","mparris","2022-12-20T22:47:15.8780000+08:00","Any idea why they didn't use MQTT as the core, to enable all the existing MQTT clients out there?

Or does NATS have some fundamental difference that couldn't be achieved by extending MQTT?","",""
"801561312861618236","jon.forbord","2022-12-21T01:52:38.3110000+08:00","Definitely stay away from using RabbitMQ as your MQTT broker...","",""
"867075936054149191","rickbullotta","2022-12-21T04:06:40.3030000+08:00","FYI I've asked the NATS community (on their general Slack channel) if NATS could support publishing multiple subjects (a.k.a. topics in MQTT lingo) in a single message.  That's a big flaw with MQTT today IMO, and NATS could greatly increase its applicability in IoT use cases if they could address this.","",""
"783917475128410112","geoffnunan","2022-12-21T08:10:41.9140000+08:00","Started a thread.","",""
"795178288330440704","youri.regnaud","2022-12-22T02:22:21.9520000+08:00","What does the community think of Sparkplug 3.0?","","üòÇ (1)"
"867075936054149191","rickbullotta","2022-12-22T02:29:19.9670000+08:00","I don't think I need to comment any further.","",""
"795178288330440704","youri.regnaud","2022-12-22T02:32:22.1460000+08:00","Sparkplug Aware MQTT Server seems to me a better design for BIIRTH? No?","",""
"867075936054149191","rickbullotta","2022-12-22T05:39:22.8980000+08:00","Birth, metadata in general, fanout of topics/metrics, support for command responses, more data types, a JSON encoding option, etc...","",""
"794020366536146977","mparris","2022-12-22T07:42:25.0010000+08:00","Sparkplug 4.0 for Industry 4.0    FTW","","‚ù§Ô∏è (2)"
"743810005714600017","dep05d","2022-12-22T09:55:11.1630000+08:00","What are the issues using RabbitMQ with the MQTT plugin?  I see it only supports 3.1.1 and some workaround for sparkplug is needed; any other big gaps in functionality?","",""
"1049212363909378060","sachin_k22","2022-12-22T18:42:08.6030000+08:00","do chek out webalo. Its a platform that aggregates the workflow information from a number of processes and workflows - safety, quality, maintenance, warehouse, production etc and uses its intelligence centre as the single source of truth for making smarter decisions. Came across this very recently, so not sure of its efficacy.","",""
"794542235676180500","akoscs","2022-12-22T21:21:12.4200000+08:00","Webalo looks great! I like the BPMM based worklow definitions!","",""
"766684226455207996","bright_hummingbird_31342","2022-12-23T02:11:40.4100000+08:00","Rather than trying to enhance MQTT, could some sort of ‚Äúindustrial‚Äù implementation of AMQP work? 

Could, let‚Äôs call it, AMQP Spark Ignited Direct Injection satisfy most use cases? It does pub/sub and request/respond.","","üëç (1)"
"795178288330440704","youri.regnaud","2022-12-23T03:10:04.1780000+08:00","With Solace we use AMQP + MQTT + REST and everything work well!","",""
"801561312861618236","jon.forbord","2022-12-23T05:27:58.4920000+08:00","No QoS2 is the most obvious one, but there are other more subtle things, and if you‚Äôre using spark plug B, cirrus link recommends using other brokers, as several users have reported problems using rabbitMQ.","",""
"627696721903878156","dvy___","2022-12-23T10:20:51.8640000+08:00","I would like to see some more discussion around this. MQTT only solves use-cases that can work with pub-sub. It has no solution for transactions, and no clear answer how to combine with access to historical values.","",""
"801561312861618236","jon.forbord","2022-12-23T17:44:25.2210000+08:00","Why did it become unruly? I mean, if it can be handled by a ""smart broker"", doesn't it mean the logic is consistent and standardized, and can be handled consistently across smart clients as well?","",""
"801561312861618236","jon.forbord","2022-12-23T21:56:45.5730000+08:00","There's been some discussions around this already. I believe there is beauty in the simplicity of pub/sub, and I don't really care if we do transactions less efficiently than ideal. Compared to what most companies do now, which is mostly P2P, the occasional P2P between business applications to perform transactions, is probably better than what you do now, which is P2P for all data exchange. The main benefit of a UNS implemented with MQTT as a I see it, is the contextualization, normalization and democratization of the data, and the fact that MQTT makes it not too complex and scalable. Not transactional integrations. That doesn't mean the UNS can't contain transactional data, it can contain the current state of inventory for all I care, current BOM for production run X, etc.. but I'd rather do transactions from a system to another via some other means. For the time being this is how I think, until there comes something as simple as MQTT but with more advanced capability, which I think will never happen, as there's a always a tradeoff between simplicity and the space of capabilities. Most of the time, you'll find that a UNS implemented with MQTT solves one of the major issues for innovation and solving problems on the plant floor, which is data from your business systems or other plant floor systems, and mostly this is some form of context. Not transactions. This is at least how I see it now.","","üëç (2)"
"867075936054149191","rickbullotta","2022-12-23T22:58:49.2150000+08:00","...which is also why Sparkplug is horrible for a UNS.","",""
"627696721903878156","dvy___","2022-12-24T06:36:48.0970000+08:00","I'm actually questioning whether even MQTT is the right approach for many industries and applications. For example I'm highly doubtful it is for batch-based process industries as explained in my architecture posts above. And if it isn't then whenever someone asks for advice about an architecture in that kind of industry the first answer should not be MQTT.","",""
"867075936054149191","rickbullotta","2022-12-24T06:40:15.8940000+08:00","I‚Äôm a strong believer in event driven applications, and MQTT can provide that foundational capability for industrial data.  But it is only part of a comprehensive IIoT architecture.","","üëç (1)"
"1044299684803530832","willemrs","2022-12-25T01:39:01.9880000+08:00","To check my understanding.  The data issue is that sparkplug only allows a certain level of hierarchy in its topic namespace forcing subscribers to pull all data from a device_id forcing it to be pulled together?    Are there good examples of it being used within a larger MQTT based UNS?","",""
"817835202746253344","IIoT#4707","2022-12-25T01:39:02.3270000+08:00","GG @Will S, you just advanced to level 1!","",""
"801561312861618236","jon.forbord","2022-12-25T18:06:31.7220000+08:00","There are plenty examples of spark plug B in use for UNS. You have to remember that most UNS implementations are brownfield. Do you have an ERP that supports MQTT in house? Or even a WMS that does it or any other business applications that support MQTT? So the problems with Sparkplug B are mostly about how it should be improved for use in architectures where all the applications will have native support for IIoT or MQTT. Right now there would anyway be a gateway between spark plug B / MQTT for these business level applications. So how much of a problem these problems are is a matter of perspective and focus.","","üëç (1)"
"830193224504705035","marc.jaeckle","2022-12-28T20:51:32.7320000+08:00","The feature that RabbitMQ calls transactions is actually nothing else than what you can achieve using manual acknowledgments in MQTT. They just gave it a fancier name. If you wan to ensure that data has been properly processed and avoid message loss (which you are probably trying to achieve) then manual acknowledgments are the way to go with MQTT. If you need some form is reprocessing capabilities / want to use the broker for stream processing (e.g. using Flink) you should use Kafka. Usually we combine a MQTT broker with Kafka for the data analytics / stream processing part. If you want to avoid paying for a MQTT-to-Kafka bridge extension in commercial brokers, you could use our OpenSource MQTT-Kafka-Forwarding service which also happens to use manual acknowledgments to guarantee that messages are stored in Kafka without the risk of loosing messages. https://github.com/MaibornWolff/mqtt-kafka-forwarding-service","",""
"830193224504705035","marc.jaeckle","2022-12-28T21:04:18.5870000+08:00","MQTT actually offers the same functionality that RabbitMQ calls ‚Äûtransactions‚Äú. It‚Äôs called manual acknowledgments. From a marketing perspective it would have been better if they called it ‚Äûtransactions‚Äú üôÇ Also I don‚Äôt think MQTT should provide any functionality around historic data.  For that you should add a timeseries database to your architecture and build services that provide a REST API to access the data. I‚Äôm writing services because you might want to not only provide a single generic service to access the data.","",""
"830193224504705035","marc.jaeckle","2022-12-28T21:22:20.0250000+08:00","We used it in one of our projects in the automotive industry and it worked ok. I‚Äôm specifically using the term ok and not good because there are so many annoying things  and limitations in Sparkplug that people have written about here multiple times already. We used the ISA 95 equipment model levels in the group id which kind of worked but wasn‚Äôt great because the MQTT subscription wildcards are not flexible enough. For subscribing to subsets of data of a machine you also currently have to use workarounds like virtual devices under the edge node in the topic structure. We were aware of the limitations of Sparkplug up front and only used it because designing something similar by ourselves would have taken too much time. We didn‚Äôt need Sparkplug for compatibility with certain off the shelf tools which might be a reason to use it. If I think about it, the only thing I really like about Sparkplug are it‚Äôs birth and death messages. I think the only reason we are even talking about Sparkplug is that the alternatives like OPC UA C/S are even worse.","",""
"867075936054149191","rickbullotta","2022-12-28T22:17:25.1890000+08:00","None of those apps know how to subscribe to, interpret, or deserialize SpB payloads.","",""
"1044299684803530832","willemrs","2022-12-29T20:24:58.6160000+08:00","Its looking like SpB could be beneficial on the PLC sensor side of things feeding into an Ignition esque type platform.  Still not within the base UNS architecture though as it would have to have some middle ware to make it accessible for all.","","üíØ (1)"
"744671252605829181","jeff.rankinen","2023-01-03T09:12:30.6890000+08:00","Have you looked into Tesla Warp ERP @Dvy ? Tesla was building the Roadster and the stock value was $2.26 in 2012 when Elon ditched SAP to build their own ERP. Looking into some articles, it seems like a UNS approach was used. But no indication of the communications protocol. The WARP ERP architecture seems like it is based on your first diagram. https://fabric.inc/blog/tesla-strategy/","https://cdn.discordapp.com/attachments/815945777452941313/1059640367277932574/image.png?ex=68df22fe&is=68ddd17e&hm=472ed6f30d30465e39bb7b19873d4b43c781b14078361563d9ed168905fda637&","üí° (1)"
"627696721903878156","dvy___","2023-01-03T12:11:37.2620000+08:00","Thanks for the link, but from that article it looks Warp is a (much more flexible) alternative to SAP, specifically made to handle their different business model. I see some references to their possible OT systems like TMOS (Manufacturing Operating System), Tesla Executive Factory Dashboard and Tesla 3DX.  I see no indication that a UNS-like system is at the core of their OT, but maybe someone else has more insights.","",""
"817835202746253344","IIoT#4707","2023-01-03T12:11:37.6020000+08:00","GG @Dvy, you just advanced to level 3!","",""
"627696721903878156","dvy___","2023-01-03T12:19:39.9070000+08:00","Keep in mind that my architecture drawings are specifically for batch-based process industries.  Until now nobody has confirmed that putting a UNS central in this kind of plant is a valid and proven approach. Happy to find some actual examples if anyone has.","","üëç (1)"
"830193224504705035","marc.jaeckle","2023-01-03T21:16:11.0800000+08:00","First of all, working for a custom software development company, it's always nice to see how custom software development can give you a better, more fitting solution than using off-the-shelf products. 

Secondly I had to smile at this list:
- TMOS (Manufacturing Operating System): tracks where a Model 3 is in the process of manufacturing, repairs, and testing
- MES (Manufacturing Execution System): supports production of Model S and X vehicles
It sounds like they actually built two separate MES systems and didn't manage to replace the older one for Model S and X. 

About the article itself: Looking at how elaborate Tesla's software solutions are, nothing too special can be found in the article. The German premium car manufacturers have built a lot more elaborate/complex systems because almost each car they build is different from all the other cars due to the many configuration options you have. So for example they need a just-in-sequence logistics solution that makes sure that the right part is at the right time at the production line for a specific order. Or the onboard software has to work with all these different configurations. Or for example their POS systems have to work with many different national subsidiaries and markets. So the challenges they solved are much bigger.

Actually, I think the success of Tesla isn't related to them building fancy internal software. On the contrary, it‚Äôs because they built a more simple solution. The beauty in the Tesla solution is that they reduced the complexity by mostly building identical premium cars and selling them in the same way in all countries. This reduces the complexity massively and does give them a competitive advantage.","","ishocked (1)"
"744671252605829181","jeff.rankinen","2023-01-03T22:16:34.7060000+08:00","Intellic Integration, @Walker Reynolds, have built at least one ERP but I don't remember him going into the details. It will be great to get 4.0 Solutions take on using UNS for ERP for all types of manufacturing. In the MES Bootcamp class recently completed, we constructed a modular system that can be extended by adding functions.  I reviewed Odoo ERP and the available modules. I can understand how Tesla could build an ERP system in 4 months with 25 engineers by using a UNS architecture.  Better than spending $100 million on SAP that creates data silos and is not agile.","",""
"627696721903878156","dvy___","2023-01-03T22:18:23.5130000+08:00","@youri.regnaud but they didn't use UNS architecture?","",""
"744671252605829181","jeff.rankinen","2023-01-03T22:24:12.0790000+08:00","The information I read describes the Warp ERP system based on a common data ecosystem. I haven't found any direct information about a UNS being used, but it is implied.  I'll keep looking for more details.","",""
"814239321274974228","pmaestrelli","2023-01-10T00:01:26.1120000+08:00","Hey all. I am looking for examples of reference architectures for UNS on the F&B (food and beverage segment) some googling around led me to some examples but any suggestions where to look for more?","",""
"627696721903878156","dvy___","2023-01-10T05:26:40.8440000+08:00","This one. It shows for example where the batch/recipe manager belongs. A  practical solution could be to combine the MQTT broker/historian, for example with ignition. Aspentech's inmation might also be an option. It depends a bit from what kind of food. (Milk is very different than meat for example) Also is it only for the end-of-line, or including the production/processing part?","https://cdn.discordapp.com/attachments/815945777452941313/1062120249723453490/image-1.png?ex=68deee10&is=68dd9c90&hm=71099bba0733b555796fc7553ec27c4398ebf2a5eae7b09cbc4387abe0933c39&","üëç (2)"
"814239321274974228","pmaestrelli","2023-01-12T15:51:36.8590000+08:00","Thanks Dvy. It‚Äôs actually for the entire factory and they have multiple factories so there needs to be a data sharing layer here which I imagine by your architecture would be done on the cloud or directly through the UNS correct? (E.g HighByte)","",""
"627696721903878156","dvy___","2023-01-12T17:40:49.0140000+08:00","MES and everything under it is normally by factory. On my architecture the UNS can be on the cloud. Highbye can help putting all the data in the correct namespace. And I believe they are also adding  broker functionality in the latest version. The question for most food manufacturers will be where to get the historical data because most of the analytics/dashboards they want to run will need to look back in time to the last days/months/production orders/... . So either add a historical database in the cloud that will allow you to run these queries agains, or run the queries to the site historians. If you need historical data it should be part of the UNS, so storing the historical data should be in the same namespace.","",""
"627696721903878156","dvy___","2023-01-12T17:42:26.7350000+08:00","It's always a good exercise to discuss some sample queries/dashboards that people want to have. That will quickly show if the architecture is able to handle it.","",""
"777582396237283338","richard44160","2023-01-13T22:55:15.2620000+08:00","What i have understood from the community is that the UNS could still help a lot regarding historical data. For instance : 
  - store in topics standard queries and all informations regarding historical data connection so each subscriber could get the correct connection string from the UNS
  - store in datasets result of all standard queries needed for dashboards so each dashboard doesn't need to perform the query by itself but just show the up-to-date information from the dataset : dataset containing last hour production information, dataset containing last day production KPIs, ...
Is that make sense ?
Same for batch data :
- actual recipe in use on a particular unit including live batch information
- actual state of production (phases, recipes, procedures)","",""
"627696721903878156","dvy___","2023-01-13T23:58:12.9390000+08:00","Yes that makes sense. Some applications have enough with the latest values which can be covered by MQTT, but a lot of applications indeed need the historical data. The historian needs to be part of the UNS if you need access to historical data. Your idea of storing the queries in the topics is interesting. I would recommend an architecture where if you know the namespace of the data you want to retrieve that you then also know the query because your historian uses the same namespace.
Your 2nd proposal of storing the historical data in the datasets: do you mean the data in MQTT? That will quickly run against limitations if you want to run queries against different time periods (day, week, month, year, ...). The solution is still to send the query to the historian. For dashboards that need to show both the historical and real-time data they probably would need to first query the historian, and then use the MQTT data so they don't need to keep querying.
Actual recipes and production states: that's fairly straight-forward: just publish them to the MQTT broker as they get updated. But many queries will still require the historical data (like batches run in the past 24h). And most likely that will be a query against the MES/Batching system ...","",""
"817835202746253344","IIoT#4707","2023-01-13T23:58:13.3250000+08:00","GG @Dvy, you just advanced to level 4!","",""
"777582396237283338","richard44160","2023-01-14T00:01:49.1780000+08:00","For the 2nd proposal, the idea is to have a dataset that is updated every hour/day/month (from the historian / Flow / Highbyte?) containing the values.  Dashboards just needs to subscribe to it to get updated with data without the need to query anything.","",""
"627696721903878156","dvy___","2023-01-14T00:06:08.7040000+08:00","Ok let 's say by month. Even if you have only one data point by hour that 's 730 measurements per month. Every hour you get a full update of the data. If you want by minute that's 43800 points updated every minute. Let's say 1000 measurements then you get 43M updated measurements per minute. Probably just for one plant. That won't scale.","",""
"777582396237283338","richard44160","2023-01-14T00:11:14.9540000+08:00","OK. i'm not thinking about log of data here but more a kind of KPI approach that the dataset is not an extract of the historian database but a calculated representation of the month for that Unit or Product or Customer. So not raw data but already analytics results on the historian data. On top of that, you could have the 10 most impacting events or other 10 best runs or ...","",""
"777582396237283338","richard44160","2023-01-14T00:12:23.5570000+08:00","The idea that there no additional analytics to be performed at the dashboard. Just visualization.","",""
"627696721903878156","dvy___","2023-01-14T00:13:41.5020000+08:00","yes then it could work","",""
"898217314741280828","hobbes1069","2023-01-14T03:08:05.4070000+08:00","Depends on your architecture. On the broker side even mosquitto can handle millions of messages per hour, but I doubt you would need the values per second over a whole month. If I'm looking at a month (or last 30 days) time horizon I probably want the results per day. A historian (like Canary) or database could calculate the dataset and the publish a message with all the data as an array.","",""
"801561312861618236","jon.forbord","2023-01-14T07:09:29.6040000+08:00","It may seem counterintuitive, but you don‚Äôt need historical data inside a UNS, and you would still be able to do a lot of what you‚Äôd want to do. You plug in applications which handle persistence and from the real time events you can query inside that application, and publish the results to the UNS. Example, I want to know how much energy was consumed by site/area/line. I aggregate this data in a historian, and use the historian to calculate the aggregated energy and publish the energy consumption to the respective place in the namespace. Or you stream the UNS to a data lake and do the same analytics there. You don‚Äôt really need a queryable interface within UNS, as long as there is persistence in the clients that are connected to it, and you always make sure to publish back the results of whatever you use the history to do. This is also why most UNS architectures use some data ops platform to bring everything together. So if someone wants to do some query, you rather do it in the data ops platform and publish the result to the UNS for all consumers. Another option is even to send the where clauses of a query through the UNS, and have response topics.. there‚Äôs just so many ways to achieve this that I don‚Äôt really see this as a tremendous weakness. The two things missing from an MQTT based UNS as far as I see, is ad hoc historical queries and air tight transactional integrity without custom stuff.","",""
"627696721903878156","dvy___","2023-01-14T11:45:47.9140000+08:00","That's good if that specific implementation works for you, but in many other enterprises people do need the historical data. Both at site and enterprise level.  We can't predict the queries that will be run now and in the future.  Difficult to prepare aggregations for all of that.
Persistence at the clients also doesn't work in many cases. The goal of the unified namespace is to make data available to no matter what kind of application will need it. If we expect the applications the handle their own persistence it really limits the options. Additionally what if we add another application at a certain moment in time? Do we wait a couple of months until it logged enough data to work with?
Streaming the UNS to a 'data lake'? But if the data lake become the source of the data for the applications then it just becomes part of the UNS. Because it would be stored in the same namespace right?

There are different implementations of a UNS. One type of implementation is where an MQTT based UNS is sufficient because there's not much need for historical data except maybe some basic aggregations. The other type of UNS does need the historical data, and there the historian(s) should be part of the UNS since they need to store the data inside the same namespace.","",""
"894527802316046366","nickn5549","2023-01-14T19:34:20.7440000+08:00","some agregations are very predictible and can be calculated (in historian or micro-services) and published  back in UNS for other nodes to use. Agregations like: last hour, this shift, last shift...","","üëç (1)"
"801561312861618236","jon.forbord","2023-01-14T19:35:15.5780000+08:00","Aha! I think I understand now. We are saying the same thing, but mean something slightly different when we say UNS. My perspective is the UNS as strictly the broker, but I think you‚Äôre thinking more of the broker and everything that plugs into it as the UNS?","",""
"627696721903878156","dvy___","2023-01-14T22:11:38.9010000+08:00","Yes some are predictable. And otheres aren't.","",""
"867075936054149191","rickbullotta","2023-01-14T22:32:45.8970000+08:00","You ""don't need"" transportation, coffee, running water, or electricity either.  But those things such as the ability to use the same topic namespace to access history, the ability to query the namespace and its data, and the ability to invoke commands within the UNS model are *extremely* convenient and valuable.   Managing parallel access to historical data effectively doubles your security administration effort.  One underappreciated role of a properly architected UNS is that it can also provide a single point of access control.","",""
"627696721903878156","dvy___","2023-01-14T22:34:12.5130000+08:00","UNS: Unified Namespace. It literally means implementing the same naming conventions. In our case S95 and for some industries extended to S88. People have been advocating for this since many years. The original approaches have always been focused around the historians since that was the only place to find the data. Using an MQTT broker inside this consolidated namespace approach is a fairly new idea, at least for the industries I'm familiar with. I agree it's an approach with a lot of potential, but it won't work in many cases without the historical data. An ideal solution will have both the pub/sub and historian access.","",""
"627696721903878156","dvy___","2023-01-14T22:34:56.8650000+08:00","With 'our case' I mean Industry in general","",""
"627696721903878156","dvy___","2023-01-14T22:36:05.8790000+08:00","indeed","",""
"801561312861618236","jon.forbord","2023-01-14T22:47:39.9920000+08:00","OPC UA already has real-time and historical, so knock yourself out.","",""
"801561312861618236","jon.forbord","2023-01-14T22:49:49.1760000+08:00","I‚Äôm sorry, outside of OPC UA, or heck throw that one in there too, how would I go about implementing this UNS with history, query capability etc through one interface, TODAY?","",""
"867075936054149191","rickbullotta","2023-01-14T22:56:59.1990000+08:00","ThingWorx could do it, but they removed the pub/sub capabilities which greatly limits its fit as a UNS.  You can still build even-driven apps, but you have to do all the subscriptions inside of ThingWorx, which is silly.  It used to have full pub/sub.  My uber-broker also allows exactly this, plus namespace queries, plus a REST API for read/write.","",""
"867075936054149191","rickbullotta","2023-01-14T22:57:27.8510000+08:00","OPC UA - ewwwwww!","",""
"867075936054149191","rickbullotta","2023-01-14T22:57:53.4520000+08:00","I should do a demo of the uber broker someday.","",""
"801561312861618236","jon.forbord","2023-01-14T22:59:07.1620000+08:00","For the record, you can use Ignition or Highbyte today as this Uber broker, or UNS platform and that‚Äôs how you solve these limitations today with Mqtt.","",""
"627696721903878156","dvy___","2023-01-14T22:59:20.5520000+08:00","Well many have been trying through Osisoft PI, now owned by Aveva. It's lacking in many ways, and the pricing strategy makes it unusable for many cases. A relatively newer approach is Inmation.  I haven't used them personally but I know multiple multinationals are implementing it as their core data platform. I'm thinking we probably need to look towards a combination of an MQTT broker and open historians like Timescaledb or Influxdb with some additional tooling to tie it all together.","",""
"867075936054149191","rickbullotta","2023-01-14T23:03:00.6800000+08:00","Sort of. Kind of.  If you blur your eyes and look at it sideways. üòâ","","üëç (1)"
"801561312861618236","jon.forbord","2023-01-14T23:03:15.7660000+08:00","Read my posts again, I think you‚Äôll find we‚Äôre saying the same thing, but with different understanding. In the UNS there‚Äôs not strictly history, it can be the current state of some history, but it‚Äôs not the history. In the architecture that uses a UNS, there is definitely history, and likely at least one consumer that can bridge the gaps in capability with MQTT towards the needs you describe.","",""
"627696721903878156","dvy___","2023-01-14T23:03:57.5680000+08:00","Oh I want to know more about the thinking behind that üôÇ","",""
"627696721903878156","dvy___","2023-01-14T23:07:11.1200000+08:00","Can you give an example of a consumer that can bridge those gaps?","",""
"801561312861618236","jon.forbord","2023-01-14T23:08:22.8070000+08:00","Ignition/highbyte/tatsoft. Basically anything that can talk to anything and do stuff with the data to transform it into something useful.","","üíØ (1)"
"627696721903878156","dvy___","2023-01-14T23:16:35.7420000+08:00","Highbyte is basically just data transformation?  No historical capabilities as far as I'm aware. Also their pricing don't make it very scalable anymore. Ignition could go a bit further since they have the historian option, especially if you're already using them for their scada capabilities. It is actually one of the options we are considering or future architectures. But on the other hand if they're not used as a scada then why not just use kepware + MQTT broker + timescaledb/influxdb + a logger/query service that ties everything together?","",""
"801561312861618236","jon.forbord","2023-01-14T23:45:32.4500000+08:00","You kind of could, or at least it‚Äôs nearly there.. Highbyte can talk to whatever historian you‚Äôre using, and your data lake, or influx or whatever‚Ä¶ so you use highbyte to ‚Äútie everything together‚Äù so to say.","",""
"801561312861618236","jon.forbord","2023-01-14T23:49:56.0380000+08:00","I‚Äôll post a reference architecture here later..","",""
"801561312861618236","jon.forbord","2023-01-15T05:24:24.3970000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1063931617141325894/Reference_Architecture.png?ex=68deed88&is=68dd9c08&hm=37963bef7f2ef524420245f726ab72316ebe6dcf8d7229b32d36528b052387f9&","üëç (1)"
"801561312861618236","jon.forbord","2023-01-15T05:40:29.2510000+08:00","Some theoretical, some real, some future plans, some purely to illustrate.","",""
"627696721903878156","dvy___","2023-01-15T06:34:44.3040000+08:00","Thanks for sharing.  Do you need to write to the PLC's?","",""
"801561312861618236","jon.forbord","2023-01-15T06:35:39.0230000+08:00","Yes, but only SCADA is allowed access to DCMD topics.","",""
"627696721903878156","dvy___","2023-01-15T06:36:46.7990000+08:00","So the MES for example doesn't need to write to the PLC layer, right?","",""
"627696721903878156","dvy___","2023-01-15T06:38:10.7170000+08:00","And is your data in the on premise brokers already in the correct namespace? Because Highbyte is quite to the right?","",""
"801561312861618236","jon.forbord","2023-01-15T06:47:06.7220000+08:00","I didn‚Äôt say that. I said only SCADA  (Ignition) is allowed direct writes. Ignition btw does some of the MES/MOM layer responsibilities.","",""
"627696721903878156","dvy___","2023-01-15T06:51:24.3530000+08:00","Yes my question was rather if data/commands should go from the MES to the PLC's, either directly or indirectly.
But if you're using ignition edge for the writes, then the writes don't pass over the MQTT broker right? Ignition just directly takes care of it.","",""
"801561312861618236","jon.forbord","2023-01-15T06:56:18.9680000+08:00","The broker(s) contains both modeled/structured/correct namespaces and raw namespaces, modeling is done at multiple layers, edge/SCADA/highbyte. So both yes and no, I guess üòÖ the raw namespaces are kept in ISA-95 structure but kept separate from the rest. From the enterprise applications, a raw topic can be transactional records as tables (datasets or json), for a given period, last day/month etc. A raw topic from the edge is raw plc tags.","",""
"801561312861618236","jon.forbord","2023-01-15T07:02:54.7180000+08:00","Commands can go through the brokers. But they don‚Äôt have to.. you could use Ignition edge with tag sync instead.","",""
"627696721903878156","dvy___","2023-01-15T07:09:06.2320000+08:00","So what is really the central system in your architecture? The broker or Highbyte?","",""
"801561312861618236","jon.forbord","2023-01-15T07:13:11.1250000+08:00","Nothing is the central system. It‚Äôs all just nodes in an ecosystem.","",""
"801561312861618236","jon.forbord","2023-01-15T07:13:52.4110000+08:00","üé§","",""
"801561312861618236","jon.forbord","2023-01-15T07:22:47.4020000+08:00","Slight joke aside, the broker is the infrastructure for sharing events and current states while Ignition and highbyte plays a key role. The architecture would not work without the IIoT platform, or Ignition in this case. Highbyte is used mostly as middleware towards the enterprise systems, but has capability to extend into more.","",""
"627696721903878156","dvy___","2023-01-15T07:24:54.5770000+08:00","How many sites will this finally be rolled out to?","",""
"801561312861618236","jon.forbord","2023-01-15T07:39:20.0420000+08:00","Finally isn‚Äôt the right word here. This is some real, some theoretical, some future plans and some to illustrate. Why do you ask btw?","",""
"627696721903878156","dvy___","2023-01-15T07:44:17.5120000+08:00","Asking to get an idea of how scalable it should be.","",""
"817835202746253344","IIoT#4707","2023-01-15T07:44:17.8470000+08:00","GG @Dvy, you just advanced to level 5!","",""
"894527802316046366","nickn5549","2023-01-15T08:03:02.7250000+08:00","I've linked my UNS to neo4j to get the data saved in the same tree structure, be able to store historical data where needed and make my UNS queryable...","","üî• (1)"
"801561312861618236","jon.forbord","2023-01-15T08:06:28.2690000+08:00","This!","",""
"1044299684803530832","willemrs","2023-01-15T10:27:56.2480000+08:00","Thanks for sharing this, you reference a datalake in your architecture.  I've also heard Walker talk about this eventually replacing our historians as we view them today but i haven't actually been able to find any concrete examples of what this looks like.  What is the datalake in your example?  I'm working through this right now inside Ignition.  We push data to the historian but it lacks contextualization.","",""
"795178288330440704","youri.regnaud","2023-01-15T15:26:44.8420000+08:00","Agree","",""
"801561312861618236","jon.forbord","2023-01-15T17:16:04.6040000+08:00","The datalake is the place all data goes, so we can analyse all data. How come you lack contextualization when you do this through Ignition? And what kind of context are you missing?","",""
"801561312861618236","jon.forbord","2023-01-15T17:17:01.8490000+08:00","The historian contains a subset of all data, as it's timeseries data only.","",""
"801561312861618236","jon.forbord","2023-01-15T17:21:14.8800000+08:00","The public cloud timeseiers offerings are for the time being not able to replace a historian and the needs on the plant floor for the time being, in my humble view.","",""
"801561312861618236","jon.forbord","2023-01-15T17:34:16.1530000+08:00","better?","",""
"801561312861618236","jon.forbord","2023-01-15T17:38:14.4750000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1064116292329689199/Reference_Architecture_-_view_2.png?ex=68def0c6&is=68dd9f46&hm=a4bf4f7d31214d6ea1e4841d060ec603b38c5cfc981f8a76f9b4aea34310f85b&","üëç (1)"
"627696721903878156","dvy___","2023-01-15T18:49:53.8090000+08:00","That's just a re-arranged layout? I was more thinking about devices -> edge connection -> transform (Highbyte in your case) -> UNS <-> applications. Maybe someone with actual Highbyte experience can chime in here?","",""
"801561312861618236","jon.forbord","2023-01-15T18:53:04.3380000+08:00","It is just rearranged indeed. Ignition Edge does that. See Edge example, in the first drawing. You dont need highbyte to do a UNS, in many cases Ignition can serve the same function as highbyte, in fact Prior to Highbyte existing this was the case.","",""
"801561312861618236","jon.forbord","2023-01-15T18:53:36.6810000+08:00","üëÜ","",""
"801561312861618236","jon.forbord","2023-01-15T18:55:55.0310000+08:00","Thats one of the changes I might make if it was for a huge enterprise. Use one modeling platform instead of two.","",""
"627696721903878156","dvy___","2023-01-15T18:57:12.1820000+08:00","Ok I thought you used Highbyte for putting the device data into the UNS. No then your first layout was better.","",""
"801561312861618236","jon.forbord","2023-01-15T18:59:56.4710000+08:00","No, sorry that wasn‚Äôt clear. There‚Äôs two data ops platforms. Ignition at the Edge/SCADA layer, and Highbyte at the enterprise level, for business data and to bridge IT and OT systems.","",""
"801561312861618236","jon.forbord","2023-01-15T19:09:16.1330000+08:00","üëÜ but it kind of illustrates my point on some of the objections to Kudzai‚Äôs blog post on the UNS. When communicating to a broad audience, you have to simplify and omit details, that are important to some people. And if you add details still, it will cause confusion and blurr the message you want to communicate.","",""
"817835202746253344","IIoT#4707","2023-01-15T19:09:16.5500000+08:00","GG @Jon Forbord, you just advanced to level 19!","",""
"801561312861618236","jon.forbord","2023-01-15T19:12:38.5130000+08:00","@Kudzai Manditereza 

https://discord.com/channels/738470295056416930/815945777452941313/1063931617044865076","",""
"627696721903878156","dvy___","2023-01-15T19:13:41.0840000+08:00","I'm thinking if you could start from something like this representation to display your architecture","https://cdn.discordapp.com/attachments/815945777452941313/1064140311531634828/image.png?ex=68df0725&is=68ddb5a5&hm=5b236c4597dc166677f9fae090948d849bf4ac13561b2f946a1612ad7fb05492&",""
"627696721903878156","dvy___","2023-01-15T19:23:07.6030000+08:00","Those posts are way too simplified and that architecture is missing a lot of things to make it work. What broad audience is being targeted? Those are very technical topics. At least have the details explained somewhere else then.","",""
"801561312861618236","jon.forbord","2023-01-15T19:55:42.8970000+08:00","What would you add? The next posts have more details. But its still pretty high level. I‚Äôm guessing the audience is people uninitiated to the concept both technical and non-technical. I thought he nailed it for that audience. Did it teach me anything new about the concept, no, but then again I‚Äôm not uninitiated.. you‚Äôre beyond the stage of uninitiated, so it didn‚Äôt hit the nail for you, which is understandable. Take it for what it is, an introduction to a new concept. This HAS to simplify or it WILL confuse. Which my diagram (which actually has been simplified) of an architecture illustrates.","",""
"801561312861618236","jon.forbord","2023-01-15T19:57:29.6950000+08:00","Nice, a data ops view of it! I like the idea of representing the same architecture in different views! Another could be flow of information! I like it!","",""
"627696721903878156","dvy___","2023-01-15T20:09:09.6490000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1064154272419287070/architecture.pptx?ex=68df1425&is=68ddc2a5&hm=c2607446002a9e8b4b89bf3f89f97d56050980687fc178e22dbd555128e58d67&",""
"627696721903878156","dvy___","2023-01-15T20:09:33.8150000+08:00","Here's the ppt so you can see how those circles are aligned","","ü§òüèª (1)"
"627696721903878156","dvy___","2023-01-15T20:11:39.0080000+08:00","Right I've also been thinking that as p2p connections are removed that a data-architecture becomes more important, because it is not longer clear what the original source of the data is for the different applications.","",""
"627696721903878156","dvy___","2023-01-15T20:13:23.2990000+08:00","1. Historical data: post a view on it so people can decide if it makes sense for them.
2. Practical implementations for each system on those charts. Refer to documents and examples for how to implement them.","","üëè (1)"
"627696721903878156","dvy___","2023-01-15T20:14:40.8240000+08:00","3. Actual implementations. Users that want to talk about how they approached and implemented it.","",""
"801561312861618236","jon.forbord","2023-01-15T20:19:11.5890000+08:00","Actual implementations are tricky, as there‚Äôs a ton of IP in these, so most companies will not share this.","",""
"627696721903878156","dvy___","2023-01-15T20:23:55.8260000+08:00","Actually a lot of companies do share what they are doing. For example just looking at some Siemens stories:
https://www.siemens.com/global/en/company/stories/industry/2021/pharma-covid-19-biontech.html","",""
"801561312861618236","jon.forbord","2023-01-15T20:24:45.1110000+08:00","Historical data needs are not very diverse through different companies, they all need historical data. This is not where I‚Äôd put the demarcation between where a UNS makes sense or not. It is a VERY common question though, and it usually takes actual experience implementing it to really understand this as well, trust me I‚Äôve tried explaining this sooooo many times, and I am for sure not able to communicate this effectively. I‚Äôd put more of a demarcation on how much OT a business consists of. I‚Äôm not sure UNS would make sense in a pure e-commerce business, or an insurance company or a bank.","",""
"627696721903878156","dvy___","2023-01-15T20:26:53.1410000+08:00","UNS makes sense. The question if just an MQTT broker by itself makes sense as UNS. From my experience the answer is no: the historical data should often also be part of the UNS.","",""
"801561312861618236","jon.forbord","2023-01-15T20:28:04.2640000+08:00","A broker by itself makes zero sense. I would never architect this. You HAVE to plug in persistence!","","üíØ (1)"
"1044299684803530832","willemrs","2023-01-15T20:57:55.6380000+08:00","I am still lacking the ability to conceptualize what the datalake looks like though.  What software does it run on?  NoSQL?   The historian is great for simple timeseries, we also post events, but if our eventual plan is to move outside of Ignition and continue to analyze our historical data, we lose the metadata associated with those tags.  It sounds like the datalake would also retain this metadata as well as provide a location for the timeseries stuff.","",""
"627696721903878156","dvy___","2023-01-15T21:22:36.8990000+08:00","That's why the new timeseries databases are becoming very interesting. Like timescaledb is still a relational database at the core (postgres). And additionally postgres is currently also very capable in storing nosql data.","",""
"1044299684803530832","willemrs","2023-01-15T21:39:27.3490000+08:00","Thanks, yeah Il check them out.","",""
"801561312861618236","jon.forbord","2023-01-16T02:21:01.0500000+08:00","Besides this being a solution oriented approach, there is 0 architecture diagrams and really nothing of substance besides the software components they‚Äôre using.","",""
"867075936054149191","rickbullotta","2023-01-16T02:58:12.7130000+08:00","You do not want to lose the metadata (or context) for that data. Your data ops pipeline should ensure you don‚Äôt lose it.","",""
"1044299684803530832","willemrs","2023-01-16T04:18:52.4770000+08:00","Absolutely. I really like the idea of persistent metadata with the history.  Sounded like a datalake was what we were missing.  Started to look into timescaledBb too.  Looks like a solid platform, just haven't messed with postgres myself yet.","","üëçüèº (1)"
"627696721903878156","dvy___","2023-01-16T09:47:15.3800000+08:00","Right there's almost no information that could be of any IP concern. Yet it shows a leading company from a specific industry (life sciences in this case) adopting specific components as core of their architecture. Other vendors do the same. Actually HiveMQ also publishes their customer stories: https://www.hivemq.com/customers/ .  I don't see any of these stories featuring an example where indeed the broker has been used to tie all these systems from those blog posts together.","",""
"627696721903878156","dvy___","2023-01-16T09:52:10.4840000+08:00","Interstingly HiveMQ has specific pages for specific industrials.
Industries with user stories: Connected Cars, Transportation
Industries without user stories: Automotive Manufacturing, Energy, Pharma, Chemical, F&B","",""
"741170732742213734","kudzaimanditereza","2023-01-16T18:53:28.4930000+08:00","This is an interesting architectural layout, Jon. Thanks for sharing. I noticed that you have bridged on-prem brokers to the enterprise broker, and also have Ignition connect to the on-prem brokers and to the enterprise broker. Doesn't that introduce some sort of redundancy due to replication?","",""
"801561312861618236","jon.forbord","2023-01-16T19:30:35.8960000+08:00","Only if you republish the edge tags from Ignition as well. The Ignition to enterprise-connection is to publish the SCADA-layer tags to the enterprise broker. It's really not necessary, as you could publish everything from Ignition as well, including the edge-tags. So the broker bridging is really optional in this case.","",""
"801561312861618236","jon.forbord","2023-01-16T19:38:09.5060000+08:00","ok. And this goes back to your question whether there are actual implementations of an MQTT-based UNS anywhere? Clearly there is, although I suspect it's not that prevalent or common yet. Solution oriented approaches like the use-case above is far more prevalent, as well as digital twin use-cases.","",""
"741170732742213734","kudzaimanditereza","2023-01-16T19:40:54.6840000+08:00","A highly detailed solution architecture could literally be a company's only competitive advantage as Integration, software components and coding have been commoditized to a huge extent. Case in point, the Siemens link you shared doesn't show any detailed architecture. It's also important to bear in mind that IIoT solution architecture is hardly a one-size-fits-all, hence from an education standpoint through blog posts it's best the keep things as high a level as possible and let companies hire the best architects to flesh it out. All we do is throw light on the concept, and in most cases, it turns out to have a whole different meaning based on realities on the ground. Luckily, platforms like this discord server with many brilliant minds allow for in-depth discussions in ways that it is not possible through a blog post.","",""
"627696721903878156","dvy___","2023-01-16T19:46:18.9940000+08:00","No my questions are mainly about process industries","",""
"627696721903878156","dvy___","2023-01-16T19:48:49.0670000+08:00","I know that it's being used in some other Industries. I don't question that.","",""
"801561312861618236","jon.forbord","2023-01-16T19:50:33.8850000+08:00","I'm not quite ""in"" on what process industry entails, but I know it's used in Pharma, Agriculture, Food and Beverage, Packaging, Aerospace to mention a few.","",""
"627696721903878156","dvy___","2023-01-16T19:51:49.9980000+08:00","Pharma, Feed, food &bev and chemicals","",""
"627696721903878156","dvy___","2023-01-16T19:53:04.8190000+08:00","In chemicals you still have the distinction between continuous and batch-based. Continuous does love their PI systems though","",""
"627696721903878156","dvy___","2023-01-16T19:55:15.3190000+08:00","Some typical things for these industries are S88 being needed to bring the needed flexibility to the production. And it needs to be implemented in different systems to make it work","",""
"627696721903878156","dvy___","2023-01-16T19:56:02.1810000+08:00","Another property is that the automation in the main process is often a separate package, not coming with a machine, so the user has a lot of control of it","",""
"627696721903878156","dvy___","2023-01-16T19:57:10.4840000+08:00","It's also very easy to make the wrong design decisions and then to get stuck. And no UNS will save you then ...","",""
"627696721903878156","dvy___","2023-01-16T20:00:51.3300000+08:00","It's also quite difficult to scale over d multiple plants and countries because of this complexity, and I do see a role for UNS in that, but based on a combined broker/historian architecture","",""
"627696721903878156","dvy___","2023-01-16T20:06:07.4520000+08:00","That's mixing two of my arguments. 1.  Yes it's ok to have a high level overview, certainly if it's user stories that show where the value is for them. 2. We do need detailed info of how to tie the systems together if it's being presented as a recommended approach","",""
"801561312861618236","jon.forbord","2023-01-16T20:07:33.9770000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1064516258919362600/image.png?ex=68df13c5&is=68ddc245&hm=e181d8d0557c5085b6512bfef9f0b01b9142f372d0e8b441e899b45cfb0a307c&,https://cdn.discordapp.com/attachments/815945777452941313/1064516259133263892/image.png?ex=68df13c5&is=68ddc245&hm=5b15b6be6967b61227fa0d73b220415e03073d3ae1c4c0e9df5ee7822310b97d&",""
"801561312861618236","jon.forbord","2023-01-16T20:12:07.9930000+08:00","@jmckeon, @KevinJones Care to chime in on this discussion?","",""
"627696721903878156","dvy___","2023-01-16T20:17:34.9200000+08:00","Which one do you prefer?","",""
"801561312861618236","jon.forbord","2023-01-16T20:18:31.1260000+08:00","https://discord.com/channels/738470295056416930/815945777452941313/1063783353351950397","",""
"627696721903878156","dvy___","2023-01-16T20:19:39.4160000+08:00","So the 2nd one? Just the broker?","",""
"817835202746253344","IIoT#4707","2023-01-16T20:19:39.7090000+08:00","GG @Dvy, you just advanced to level 6!","",""
"801561312861618236","jon.forbord","2023-01-16T20:31:38.5740000+08:00","Prefer or prefer. I think this is a question of how we define the concept. I suspect your interpretation is closest to the second, and mine is closer to the first.","",""
"627696721903878156","dvy___","2023-01-16T20:38:06.7650000+08:00","Both approaches should be valid as a unified namespace. Indeed the kind of architectures we work with are better served with the historian(s) being in the namespace. Yours probably has enough with the MQTT broker.","",""
"627696721903878156","dvy___","2023-01-16T20:38:57.4380000+08:00","I feel we're getting somewhere üôÇ","",""
"740531920907010118","jmckeon","2023-01-16T20:43:50.9460000+08:00","Jon, there is a lot going on here in this discussion. The diagram above with 2 options have issue in my opinion with both of them....so what is the problem statement if people are looking for a one for all then it's not going to happen....we use what we have with the principle of the UNS ....(this can grow all sorts of arms and legs)..however sticking to the core of using the UNS (which can be considered as the mqtt broker in is lowest form) it is the single source of truth for stateful data (but ye all know that)...give me a bit more to work with here","",""
"801561312861618236","jon.forbord","2023-01-16T20:45:35.1510000+08:00","Haha, I know. I was more on the topic of relevance for process industry, or even use-cases from within the process industry.","",""
"740531920907010118","jmckeon","2023-01-16T20:47:57.5200000+08:00","I would not ingest the legacy historian through ignition...I would connect it to the broker and have another type of historian consume its content so it is based on time stamp","",""
"740531920907010118","jmckeon","2023-01-16T20:48:09.4400000+08:00","That's just one...but there are others","",""
"801561312861618236","jon.forbord","2023-01-16T20:48:51.9680000+08:00","The legacy historian ingest is not depicted in the diagram, it's outgoing to Ignition only.","",""
"740531920907010118","jmckeon","2023-01-16T20:49:12.9890000+08:00","Yes, it is going into ignition only ..I would not do it that way","",""
"801561312861618236","jon.forbord","2023-01-16T20:58:01.2510000+08:00","Ok, I'm always open to suggestions, but it isn't only going into Ignition  üôÇ This diagram is mostly to illustrate how detailed architecture diagrams can be REALLY confusing, and just cause debate over confusing details in a introductory blog post ala Kudzai's post. It's also a diagram to show at least a fairly realistic view of an example UNS architecture. I should make a few ""views"" of this diagram, so I don't get a thousand more questions about it. Some of it's real, some of it's future plans, some of it's imaginary and some of it's purely to illustrate something. The diagram isn't where I need help. It's the general question of whether UNS is applicable to process industry. @Dvy can chime in on his position himself, instead of me paraphrazing his position. @jmckeon","",""
"627696721903878156","dvy___","2023-01-16T21:14:49.5560000+08:00","To be clear I'm not targeting @Kudzai Manditereza , and I appreciate he's getting involved in the conversation. I agree that a unified namespace is good practice. I do think that having only a broker at the core will not really simplify the architecture for many industries. On the other hand a good concept with a combined broker/historian in the same namespace can be very powerful. In process industries you'll just get the question 'where is my historian?' or 'how do I access my historian'. And hopefully better at the start of the project before you implement everything, because people might just sign off on an architecture where they don't realise it would be a step back from what they currently have.","",""
"801561312861618236","jon.forbord","2023-01-16T21:35:02.6520000+08:00","That's actually a good point. To communicate this concept to the less initiated, you need to gloss over details and forget about pedantics, and focus on speaking their language.","",""
"867075936054149191","rickbullotta","2023-01-16T21:50:25.4030000+08:00","While lots of people want to diss DTDL 2.0 (and soon 3.0), from a definition perspective it fits our collective UNS needs better than Sparkplug. It also has declarative mechanisms for indicating which data/metrics/values should be historized by IIoT brokers/platforms that are capable of it.  Also supports a much richer class/type system.  It doesn't prescribe a wire protocol, but blended with MQTT it could be super interesting.  To echo Jon's statements, YOU CANNOT IMPLEMENT A PROPER UNS WITH JUST MQTT AND SPARKPLUG.  Just as you cannot implement a proper IoT platform with just MQTT.","",""
"756565963520081950","andersgustav","2023-01-16T23:14:52.1620000+08:00","But in contrast to those who just sit and rave about everything that doesn't work, there are some of us with knowledge about this who solve these shortcomings with MQTT and SpB with the tools that are available today, such as Ignition, FrameworX and HighByte.

Guess what we think is most worthwhile, getting the job done - or whining about something not being good enough.

ffs, b:
If someone wants to be a driving force for innovation, do so by demonstrating something of value instead of whining almost exclusively about what is already working for others.","","üòÇ (1),üî• (2)"
"867075936054149191","rickbullotta","2023-01-17T00:07:50.9870000+08:00","Or propose solutions.  Unfortunately, as @Walker Reynolds has repeatedly pointed out, the Sparkplug folks and MQTT folks don't seem to care.  So I've chosen to work with the innovators like HighByte, HiveMQ and others to make it happen.  If you accept the status quo as ""good enough"", you're part of the problem.","","üíØ (2)"
"756565963520081950","andersgustav","2023-01-17T00:12:13.7090000+08:00","Well, there you are wrong. It is possible to have two thoughts in the head at the same time. I work with what I've got. And will happily help all efforts to improve what must be improved. But the thing is that when you pollute a platform meant to help others to where I am with whining about it not working, you pretty much shoot the initiative.","","üòÇ (1)"
"756565963520081950","andersgustav","2023-01-17T00:13:07.0680000+08:00","Get a channel for innovation, where you promote improvements, and leave the rest as intended.","",""
"867075936054149191","rickbullotta","2023-01-17T00:13:43.0150000+08:00","OK boss.  I seem to be one of the few proposing solutions.  And if you aren't asking for better, you most definitely are part of the problem.  We'll leave it that we very much disagree.  And behind the scenes, there are a bunch of us working to fix it.","",""
"867075936054149191","rickbullotta","2023-01-17T00:14:32.7130000+08:00","You literally CANNOT do a proper UNS with just an MQTT broker and Sparkplug.  If you can't agree with that statement, then I just don't know what to say.","",""
"867075936054149191","rickbullotta","2023-01-17T00:16:05.9490000+08:00","Now I know why it's called ""Discord""","",""
"867075936054149191","rickbullotta","2023-01-17T00:16:48.4110000+08:00","dis¬∑cord
/ÀàdiÀåsk√¥rd/
noun
1.
disagreement between people.
""a prosperous family who showed no signs of discord""
Similar:
strife
conflict
friction
hostility
disagreement
lack of agreement
dissension
dispute
difference of opinion
discordance
disunity
division
incompatibility
variance
antagonism
antipathy
enmity
opposition
bad feeling
ill feeling
bad blood
argument
quarreling
squabbling
bickering
wrangling
feuding
contention
clashing
falling-out
war
vendetta
jar
disaccord
Opposite:
agreement
accord
harmony
2.
MUSIC
lack of harmony between notes sounding together.
""the music faded in discord""
Similar:
dissonance
discordance
lack of harmony
disharmony
cacophony
jarring
jangling
Opposite:
harmony
verbARCHAIC
/ÀådiÀàsk√¥rd/
(of people) disagree.
""we discorded commonly on two points""","",""
"756565963520081950","andersgustav","2023-01-17T00:17:48.6700000+08:00","If I say I can, will you please stfu then ? üòÜ","","üòÇ (2),ü•∞ (1)"
"756565963520081950","andersgustav","2023-01-17T00:37:51.3920000+08:00","I know there are a bunch of you working to fix it, which I for the record am very grateful for.

But I think you deserve to have your own channel so that it is possible to keep the messages tidy. üòâ","",""
"867075936054149191","rickbullotta","2023-01-17T00:39:08.7740000+08:00","Fear not, I'm going off the grid again for a few weeks.  Things should quiet down soon!","","üññ (1)"
"224307162254540801","a13d","2023-01-17T01:01:38.6750000+08:00","Rick leaves over an MQTT and/or OPC discussion take.. 2? ..3? What number are we on now","","ü§£ (1)"
"224307162254540801","a13d","2023-01-17T01:11:29.3820000+08:00","https://discord.com/channels/738470295056416930/740356499338952744/740647222391078997","",""
"801561312861618236","jon.forbord","2023-01-17T02:11:44.4310000+08:00","https://discord.com/channels/738470295056416930/815945777452941313/1064516259317809152

Having taken part in more than a few discourses in this discord, I‚Äôve observed what I mentally divide into two interpretations of what is meant by UNS. The strict interpretation is that it‚Äôs the namespace inside one or more pub/sub brokers (usually mqtt, but doesn‚Äôt have to be), the more loose definition is the UNS as the total package of the combined functionality of  one or more of data ops/record of history/broker/IIoT platform/historian. Anders is in the purist/strict camp and in this view you definitely CAN do a UNS with just the broker, but in the other camp you definitely can not. It‚Äôs just different interpretations of  the same freakin‚Äô concept. You (in the wider sense, not just you) may or may not notice but those two drawings are identical.","","üëèüèº (2)"
"801561312861618236","jon.forbord","2023-01-17T02:15:58.2450000+08:00","For persistent metadata you don‚Äôt need a datalake. Metadata as in engineering units, high/low documentation and the likes? This is one of the things I really like when you use Sparkplug B with OTS software, the metadata is propagated to all compliant consumers.","",""
"948835595734614018","ufog","2023-01-17T02:39:00.8040000+08:00","Where can this be credited/referenced? Working on a project for work:))","",""
"794542235676180500","akoscs","2023-01-17T02:44:32.5030000+08:00","This starts to get as unclear as what industry 4.0 is :))","","üòÖ (1),üòÇ (1)"
"801561312861618236","jon.forbord","2023-01-17T02:48:38.2370000+08:00","It‚Äôs mine. Use at your own risk, it‚Äôs partly made to illustrate how detailed diagrams are just freakin confusing üòÖ If you want to use it I‚Äôd appreciate some details, you‚Äôre welcome to PM me.","","ü§ü (1),ü§£ (1)"
"801561312861618236","jon.forbord","2023-01-17T04:40:49.8670000+08:00","I‚Äôm talking about interpretations, but this a kind of abstract concept and people will understand aspects of it at different levels. There actually is a definition, and in the strictest sense as the UNS taught in mentorship and mastermind, the strict interpretation is more correct, but it is also not the full picture.","",""
"794542235676180500","akoscs","2023-01-17T04:48:26.1560000+08:00","I guess this is what happens when you let your concept fly out of the nest and do its own thing :). There are many examples of someone defining/inventing something, documenting it well and then in the wild that thing transforms. My favourite example is the REST API. The guy write his dissertation on the topic, it is freely available, but what we now use as RESTful interface is not quite what was defined back then... this happens sometimes. Also in case of Restful interfaces there are purists who say the only true RESTful interface is the HATEOAS (Hypermedia as the Engine of Application State) type","","üíØ (1)"
"801561312861618236","jon.forbord","2023-01-17T04:56:44.6840000+08:00","Oh! I didn‚Äôt know that background on RESTful, but it‚Äôs the same story on the Agile manifesto. This will be true with the UNS as well. At least if all you know about the concept comes from this discord.","",""
"794542235676180500","akoscs","2023-01-17T04:58:44.7630000+08:00","There is a difference, usually you do not shoot yourself in the foot if you go against the RESTful definition, you very easily shoot yourself in the foot if you go against the Manifesto. Guess we will wait and see about UNS. My money is on shooting yourself in the foot with only a simple MQTT Broker for large applications. I always try to advocate for orchestration instead of choreography but I am not winning many arguments on this :)))","",""
"686318224320626734",".stibbits","2023-01-17T05:03:41.0290000+08:00","Something about walking a mile, or 1.61 km, in someone else's shoes feels fitting here...","",""
"801561312861618236","jon.forbord","2023-01-17T06:05:44.1850000+08:00","Ok, I give up! I‚Äôve tried drawing pictures, using words and using metaphors. I‚Äôm not saying you should only use an MQTT broker, but I‚Äôm out of ideas on how to get this nuance across at the moment.","","üëç (1)"
"794542235676180500","akoscs","2023-01-17T06:12:50.6400000+08:00",":))) I feel the same about orchestration. Did the diagrams, implemented the demo. Worked great, tons of advantages, nobody cares :)))  I do not have a name for it, maybe Unified Process Space just to induce more confusion.

as for MQTT, you can spin up a broker and get busy very fast. Nobody knows what to spin up if you want complete UNS, but the broker is the closest simple thing you can start with. You can get pretty far with it for simple usecases, but you hit walls pretty fast as soon as you get out of a demo environment. I think it is great that it is that easy to start a major part of a UNS, but it is also the curse of it, as you hit its limits quite far the line.  Same as with agile, you get pretty far with quasiagile","",""
"627696721903878156","dvy___","2023-01-17T06:47:03.8520000+08:00","Can you share those diagrams?","",""
"794542235676180500","akoscs","2023-01-17T06:48:47.0590000+08:00","Not in their current form, no. If I find some time I really want to make a publishable version.","",""
"627696721903878156","dvy___","2023-01-17T06:52:37.8430000+08:00","About spinning up things fast: an evolution that has been happening in the software world is that complex things can be spinned up very fast and easily, often with just one or a couple command lines. Or by firing up a docker container. That's in part possible because many modern applications can be fully configured by command line. A lot of our applications are still very closed.","",""
"627696721903878156","dvy___","2023-01-17T06:53:27.8950000+08:00","Although it's probably possible to do that for a combination of an mqtt broker and for example Timescaledb.","",""
"1044299684803530832","willemrs","2023-01-17T07:34:26.4770000+08:00","Ah yes that is true, I am still back and forth on the benefits of utilizing SpB.  This would be one big plus.","",""
"817835202746253344","IIoT#4707","2023-01-17T07:34:26.8990000+08:00","GG @Will S, you just advanced to level 2!","",""
"1044299684803530832","willemrs","2023-01-17T07:43:43.2860000+08:00","Then the next step, what is the best way to store that metadata, if either from Spb or another source.    I would think on change for any of the metadata in a separate ""sensor"" table?  Along these lines, what is  the best way to retain the UNS hierarchy within that data storage.   I have been looking at building out our UNS using basic SQL modified preorder tree traversal, anyone have experience with this?","",""
"867075936054149191","rickbullotta","2023-01-17T08:51:50.7990000+08:00","I'm in the same camp as @NickN, that a graph database fits that use case very well.  It can model many types of relationships that the namespace and the associated metadata provide.  It can be done with almost any database with enough effort, but a graph database feels very natural for this use case.","","üíØ (2)"
"1044299684803530832","willemrs","2023-01-17T09:02:43.3080000+08:00","Awesome, once again no experience with those but I will check it out. Thanks","",""
"867075936054149191","rickbullotta","2023-01-17T09:11:02.2640000+08:00","@NickN has done some writeups on his architecture somewhere around this server.  It‚Äôs really cool stuff.","","üëç (2)"
"894527802316046366","nickn5549","2023-01-17T12:18:21.9650000+08:00","Yeap, neo4j is working fine https://discord.com/channels/738470295056416930/740336189449699408/996206353414635680 and getting real time-ish SPC https://discord.com/channels/738470295056416930/740564843710382080/1008243477051625474","","ü§òüèº (1),üëç (1)"
"794542235676180500","akoscs","2023-01-17T20:18:58.8510000+08:00","While I see many reasons to argue for a graph database, I also see reasons to argue against a graph database to model these relationships. Do not get me wrong I love graphs, I use CosmosDBs Graph API just fro the fun of it in some applications where relational db would do just fine. One question I would like to ask. Are you using any graph traversal specific commands in your queries to the db? For me graphdbs start to be necesary (and not just fun) when you need to work with the ""routes"" or paths that connects the data, not just the nodes. Do you use graph traversal features often in your application?","",""
"1044299684803530832","willemrs","2023-01-17T20:32:49.3720000+08:00","Can you give some details as to why you wouldn't use a graph database?  And how you might model these relationships in a relational db?","",""
"794542235676180500","akoscs","2023-01-17T20:45:21.6040000+08:00","You can think of a graph database as a database very suitable for modelling n:n relationships as opposed to a relational db where you have to fight the normalization battle. Here is an example form stack overflow for N:N relationships: https://stackoverflow.com/questions/45407311/how-to-join-through-an-nn-relationship-table-in-sql If you need the path between two nodes in sql it is much much harder to work with the paths then in a graphdb. I cannot think of an example, but getting a shortest path between two nodes in a graph db is relatively simple, and complicated in sql. If you do not need any paths between nodes, my **assumption** is that you can get away with both relational and graph databases. If you can use both, it comes down to performance, price and other preferences etc. Nothing wrong with using a graphdb if you prefer one, I also did it just based on preference, nothing else. I asked the question to get insights to the problem that are not obvious to me.","",""
"894527802316046366","nickn5549","2023-01-17T21:08:45.8020000+08:00","Simple stuff that otherwise is not possible....example from UNS create A list of IP addresses for all the gateways and their type, model, OS....or more complicated ones that traverse the graph, parse big       JSON payloads and retrieve certain test measurements for SPC engine....The number of queries is growing by the day.","",""
"867075936054149191","rickbullotta","2023-01-17T21:45:05.2100000+08:00","Everything you can do with a graph database, you can do with almost any data store.  However, when there's any sort of ""n-level"" stuff or recursive structures, it becomes increasingly awkward to deal with them in traditional DB's.  As a related comment, most (virtually all) industrial facilities are NOT hierarchical, despite with the S95 folks want to tell you.  The interconnections/relationships between equipment are ""graphy"" (think pipes, conveyors, etc).","",""
"867075936054149191","rickbullotta","2023-01-17T21:45:35.7910000+08:00","Graphs are better for n-depth as well.","",""
"890244048739270656","brianpribe","2023-01-17T23:56:42.5740000+08:00","What I find pretty interesting are the workflow connection/node entities in part 4 of the standard (graphy). I do want to hear your opinion on what a graph structure for equipment would be like.","",""
"867075936054149191","rickbullotta","2023-01-18T00:09:17.0800000+08:00","Amazing that they didn‚Äôt address equipment structure.","",""
"890244048739270656","brianpribe","2023-01-18T00:11:58.7220000+08:00","In reference to the equipment with other equipment? Or internal structure of the equipment?","",""
"867075936054149191","rickbullotta","2023-01-18T00:14:56.3380000+08:00","Relationships between equipment (which is often equipment itself).","",""
"867075936054149191","rickbullotta","2023-01-18T00:20:23.9310000+08:00","Think of a manifold that connects a series of tanks to a series of mixers.  Not hierarchical.  Imagine that each of those pipe segments can also have data and state (clean/dirty status, capacity, material, last material through it, etc).  You can quickly see how this can inform smart manufacturing.  Same situation exists with conveyors and shared equipment (e.g. reconfigurable packaging lines).  Again, amazing that it was overlooked given that the committee was mostly made up of members from the S88 batch committee.   But the bottom line is that S95 does a poor job of representing real world equipment models.","",""
"219966967480582144","richardphi1618","2023-01-18T00:33:11.6520000+08:00","anyone in this channel look at using? https://cube.dev/","",""
"890244048739270656","brianpribe","2023-01-18T00:43:11.0480000+08:00","AGVs came to mind. Most can travel across different lines, areas, and even sites","","üíØ (1)"
"867075936054149191","rickbullotta","2023-01-18T00:46:50.7540000+08:00","An increasing number of F&B and CPG companies are also using reconfigurable filling and packaging lines with portable/shareable equipment.","",""
"890244048739270656","brianpribe","2023-01-18T00:48:10.8600000+08:00","I believe they're calling it vertical manufacturing","",""
"795178288330440704","youri.regnaud","2023-01-18T04:35:18.3670000+08:00","Nice slides üôÇ","https://cdn.discordapp.com/attachments/815945777452941313/1065006422640824360/IMG_0023.png?ex=68dee206&is=68dd9086&hm=9dc026a703f91cd0163b1db9d6f9943574f9c8fe76f2bd4821c323334800e9bd&,https://cdn.discordapp.com/attachments/815945777452941313/1065006422955405363/IMG_0024.png?ex=68dee206&is=68dd9086&hm=4dd940922b9988a4ab8361869a09a2527dcf9518d13300563e0f1197667e1212&,https://cdn.discordapp.com/attachments/815945777452941313/1065006423307718766/IMG_0025.png?ex=68dee206&is=68dd9086&hm=5e8327abb4266aaea72f31c9310f5946865fddd9b32f025ad02d58020cd3f4a1&,https://cdn.discordapp.com/attachments/815945777452941313/1065006423714574356/IMG_0026.png?ex=68dee206&is=68dd9086&hm=625adccef590a2e0fb3cd0f5e9144136aaa164381003a6f60f30f0fcd4d30454&","üëç (1),ü§£ (1)"
"794542235676180500","akoscs","2023-01-18T04:43:02.1470000+08:00","Everything you can do in any system you can do in the programming language brainf*ck, anything that us Turing complete can do anything. That being said, Neo4j can do an shortest path search with 1 simple query. I would like to see you do that in SQL in a simple way. Sure it is Turing complete, so you can do anything, but it is not about the technical possibility but the practicability.","","üíØ (1)"
"794542235676180500","akoscs","2023-01-18T04:55:14.8930000+08:00","It certainly is a graph, but we have been mapping graphs to matrices, tables and relational dbs since graphs exist. I am however trying to think of alternatives (both to graph and to database).","",""
"867075936054149191","rickbullotta","2023-01-18T05:56:14.4730000+08:00","Wow - that was from my joint presentation with Emil Eifrem from Neo4J a looooong time ago!","",""
"867075936054149191","rickbullotta","2023-01-18T05:57:06.3400000+08:00","Interestingly, in ThingWorx we did the inverse as well - mapping graphs to tables and nested tables so that they were easier to consume and visualize.","",""
"867075936054149191","rickbullotta","2023-01-18T05:58:02.3890000+08:00","Unfortunately, like a lot of the good stuff in ThingWorx, PTC took that capability out a couple years after they acquired it.  They also removed pub/sub, which is insane.","",""
"568913935147728896","zeratall","2023-01-18T06:24:56.4280000+08:00","Why?","",""
"867075936054149191","rickbullotta","2023-01-18T06:41:57.1570000+08:00","It‚Äôs a mystery","",""
"627696721903878156","dvy___","2023-01-18T07:19:32.8800000+08:00","Like you say it's covered in S88. The first reflex of people dealing with a system that has piping should be to look into that standard. Interestingly though I find it is also the graph-like structure in S88 that is holding it back from scaling. Because once your data doesn't easily fit in a collection of tables anymore then it become more difficult for other systems to be able to handle them. For example many F&B/fine chemical manufacturers like or aspire to have their recipe data at the ERP level, a.o. because it's also where the BOM is. Not a big issue if the recipe can be represented by a table. But if the recipe is implemented according the full S88 specification there's almost no practical way to still get it into ERP. Then because of that the decision is often made to keep the BOM at the ERP level, and the recipe at MES and/or Batch level. Which leads to having to sync up the production orders with the correct recipe. Not a big deal if they produce just a couple of products on which there's not much evolution. But the market has evolved to expect much more product variations, and at a faster pace. So that syncing will quickly become quite complex as two systems need to be updated. Add to that that the same products need to be produced in multiple plants and countries, and each plant having different levels of Batch/MES implementations ... . So what we today end up recommending is to take a good look if the full complexity of S88 is really needed, or if a production process can be implemented with just the parts that can be described in table-format. (still S88, just simplified with some clever tricks) If it's the latter we know we'll be able to scale easily. If it's the former then it will take much more effort, and budget.
This the key architecture choice to make in this kind of plants.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-01-18T07:49:57.3490000+08:00","Actually, some ERP systems can created recipes of that granularity (SAP), but very few people do it, because they don‚Äôt need that granularity of reporting. So they create a recipe called ‚Äúmake stuff‚Äù. üòâ","",""
"894527802316046366","nickn5549","2023-01-18T07:55:14.2460000+08:00","especially neo4j APOC functions proved to be very powerful - you can do stuff that SQL will tell you to f**k off straight away:                                                                           /DEFECTS PARETO
match (n) where n.name=~'.*-DEFECTS.*' with apoc.convert.fromJsonList(n.value) as j unwind j as d return d.DefectName,count(d.DefectName) order by count(d.DefectName) desc","",""
"794542235676180500","akoscs","2023-01-18T07:57:16.4000000+08:00","Is this graph related or just some neat functions of neo4j?","",""
"867075936054149191","rickbullotta","2023-01-18T07:57:48.2130000+08:00","https://erproof.com/pp/sap-pp-training/sap-master-recipe/amp/","",""
"890244048739270656","brianpribe","2023-01-18T07:59:11.7800000+08:00","ER(ror)Proof. Clever","",""
"867075936054149191","rickbullotta","2023-01-18T08:01:27.9140000+08:00","It‚Äôs basically Neo4J‚Äôs way to add functionality to Cypher.  Some others have adapted to different graph databases.  The source is on GitHub.","",""
"627696721903878156","dvy___","2023-01-18T08:02:19.4150000+08:00","Right but that structure doesn't line up with S88. Like what's the deal with SAP-phases? That definition should be at process instruction level according S88.","",""
"627696721903878156","dvy___","2023-01-18T08:03:02.1810000+08:00","People do use that, but mostly in a linear way.","",""
"627696721903878156","dvy___","2023-01-18T08:03:25.5870000+08:00","If you know anyone who has gone beyond then I'm interested to learn more though.","",""
"867075936054149191","rickbullotta","2023-01-18T08:09:38.9650000+08:00","Not sure what you mean. It supports recipe/operation/phase.","",""
"867075936054149191","rickbullotta","2023-01-18T08:12:34.2510000+08:00","Also, S88 was designed to be ‚Äúcollapsible‚Äù and the layers of a recipe can be optional (unit procedure, quite commonly, is not implemented).","",""
"627696721903878156","dvy___","2023-01-18T08:24:27.3010000+08:00","Indeed one of the steps to simplify is to collapse. Only keep the unit procedure or operation. For us it's mostly the Unit Procedure that stays since it refers to the 'Unit', which is the equipment it runs on, but I guess that's just a difference in naming.","","üëçüèº (1)"
"627696721903878156","dvy___","2023-01-18T08:25:50.3740000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065064439822422016/image.png?ex=68df180e&is=68ddc68e&hm=d53659efda9ca4e3cf7fb2fd241903a8c5bf85eb67e0f3c0fa5e64cece2ec523&",""
"867075936054149191","rickbullotta","2023-01-18T08:25:53.0130000+08:00","We debated this a lot when we were writing/evolving the spec, but since there were already a number of running implementations out in the wild we decided it made sense to be flexible.","",""
"627696721903878156","dvy___","2023-01-18T08:26:57.1370000+08:00","See how the phases are under the operation, and then there's an extra level 'process instruction'? But in S88 phase is the lowest level. What's behind that?","",""
"627696721903878156","dvy___","2023-01-18T08:28:40.0690000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065065151314788353/image.png?ex=68df18b8&is=68ddc738&hm=17d1a8e916df2494d2fd2dce62d6efcfafff42643c5aa8d9b661c521ea8f8aa2&",""
"627696721903878156","dvy___","2023-01-18T08:29:06.6820000+08:00","It's like people tried to use the same terms, but then misunderstood?","",""
"867075936054149191","rickbullotta","2023-01-18T08:30:34.0200000+08:00","Many implementations ‚Äúblack box‚Äù the phase implementation at the control level and simply pass params in.  But somewhere along the way something actually has to sequence the individual control tasks (PLC, DCS, or human).  PI‚Äôs can be things like setpoints to a controller or instructions/prompts to a person.  S88 does not dictate how fine grained a phase needs to be.","",""
"867075936054149191","rickbullotta","2023-01-18T08:35:28.0280000+08:00","Another example : let‚Äôs imagine that one of the phases is to pump in X gallons of Y via an inline preheater set to temperature Z.  Something needs to carry out a detailed set of steps to make that phase happen. Usually a PLC or DCS using whatever logic representation makes sense. So think of those steps in a sequencer as process instructions. ‚ÄúClose inlet valve. Set preheater to 90C.  Wait until temperature reached.  Open manifold valve for Glycol and the inlet valve and turn on pump. Wait until aggregated flow is 455 liters. Stop pump. Close valve. Turn off preheater‚Äù.   Plus error handling of course.","",""
"627696721903878156","dvy___","2023-01-18T08:53:43.7100000+08:00","Yes I'm very familiar with the approach. So what typically happens is that at SAP this is defined as 'DOSE_Y', and the quantity X and inline preheater temperature Z. refers to the BOM. At SAP this is probably a process instruction, SAP doesn't go more in detail. It would also not make sense to go more in detail because that instruction needs to be able to run on different plants. Then irregardless of how the MES/Batching layer is executed (even if it's paper) the PLC will need to execute this dosing. At the PLC this becomes a phase 'DOSE_Y' which takes in X and Z as a parameter. Then this dosing phase will control the necessary valves, pumps, PID controllers, .... . 
So at SAP it's just one instruction: DOSE_Y with X and Y. But they don't necessarily define it as a phase, at that level it's just a process instruction for many people.","","üëçüèº (1)"
"627696721903878156","dvy___","2023-01-18T08:55:55.6210000+08:00","So anyway you see it can quickly start to become complex, with people becoming lost in translation. Back to my point: much easier to handle if the recipes can be described in list/table format. Then it's rather easy to fix it with a mapping.","","üíØ (1)"
"867075936054149191","rickbullotta","2023-01-18T08:56:34.1780000+08:00","Unfortunately (and very confusing) is that it lets you do it multiple ways and provides little guidance as to what is the best practice.  Agreed that it‚Äôs not ideal!","",""
"867075936054149191","rickbullotta","2023-01-18T08:58:21.9770000+08:00","With big companies like SAP with thousands of customers, odds are that some customer insisted on one approach or the other and the net result by accommodating all of them was confusion!","",""
"867075936054149191","rickbullotta","2023-01-18T08:59:15.5090000+08:00","It can also be a side effect of legacy and avoiding breaking changes to existing stuff, even if it deviates from the newer best practices.","",""
"867075936054149191","rickbullotta","2023-01-18T09:00:35.5890000+08:00","Heck, I saw this within our work on S88 (I was at Wonderware at the time and was our rep on the committee) - each vendor did it slightly differently and wanted to make sure the spec didn‚Äôt break the way they did it.","",""
"627696721903878156","dvy___","2023-01-18T09:03:45.5580000+08:00","Oh interersting, you were involved in the S88 spec? But that's a very long time ago...","",""
"890244048739270656","brianpribe","2023-01-18T09:15:53.5840000+08:00","He was also involved in the beginning of S95","",""
"627696721903878156","dvy___","2023-01-18T09:32:22.4750000+08:00","Now to tie this conversation back to the UNS concept: a namespace in manufacturing is recommended to follow S95. So in process industries this gets extended with S88. Now in process industries there's a high chance the architecture already follows at least S88 partly. Likely the controllers will already have a high degree of structure (IO -> control modules -> equipment modules -> units) Similar for the batching/MES and historian. If we look at the scada and historians even if the tags are 'flat' people generally have a good idea where they are in the namespace. The better approach is of course to have the data in all those systems formally defined in the right namespace. (Which is indeed where things are evolving to).  And that's why even if for some industries/solutions UNS can be limited to a broker, for others it will apply to more systems.","",""
"890244048739270656","brianpribe","2023-01-18T09:40:49.6330000+08:00","S95 part 2. Which only pertains to levels 0-2 (sensors, equipment, and control system)","",""
"890244048739270656","brianpribe","2023-01-18T09:42:05.6770000+08:00","^gotta fact check myself tho, but definitely only part 2","",""
"627696721903878156","dvy___","2023-01-18T10:16:04.0430000+08:00","Why is Inmation not discussed more by the way? I only found three messages by @Fola , @g338n and @jstade .","",""
"627696721903878156","dvy___","2023-01-18T10:19:03.7820000+08:00","I was just reviewing a presentation they gave me in 2015 when they were just a startup. They really focused on 'Namespace Consolidation' and global rollouts. In the meantime taken over by Aspentech. I don't have experience with them but I see them being selected more and more by the big multinationals.","",""
"627696721903878156","dvy___","2023-01-18T10:19:18.5730000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065092995067674664/local-core-architecture.png?ex=68df32a6&is=68dde126&hm=da3c7e26a53d6c69e1188c5bc9883621bb5eb0d083d41bfcf91f6e27f4c0290b&",""
"627696721903878156","dvy___","2023-01-18T10:22:28.9620000+08:00","From what I understand their architecture allows for both subscription and querying historical data.","",""
"627696721903878156","dvy___","2023-01-18T10:23:18.7980000+08:00","Big chemical and pharma companies selecting them.","",""
"627696721903878156","dvy___","2023-01-18T10:23:32.2090000+08:00","Any insights @RickBullotta ?","",""
"795178288330440704","youri.regnaud","2023-01-18T10:36:43.9140000+08:00","Yes, it is! It‚Äôs a great presentation. I love the first slide ¬´¬†standard disclaimer¬†¬ª","https://cdn.discordapp.com/attachments/815945777452941313/1065097379361067069/IMG_0030.png?ex=68df36bb&is=68dde53b&hm=196e3986011bdeb49e18a70a375b3a69bc7ae7951fe51e2d3123624ca927903e&,https://cdn.discordapp.com/attachments/815945777452941313/1065097379625312266/IMG_0031.png?ex=68df36bb&is=68dde53b&hm=0a6493457381ddbb306d2a0a3f1d50941a925cfeb0ecdd492d133fdff5f59228&","ü§£ (1)"
"833941249362493450","sammysevens777","2023-01-18T13:22:34.5100000+08:00","Wow....this is like the biggest brained concept ive ever read about in an ERP. Such a great term - but little dated (Master Recipe üòÜ) - reads like it sounds good in German. 

This is my newest space (ERPs) coming from a heavy OT background. So a master recipe is basically the sum of all routes - all process constraints (at least for discrete).....i genuinely wonder how something like this is deployed....it must be bottom up (meaning you define all work center/processes, then at some point converge on a finished good? This is some brainy stuff i tell ya!!","",""
"627696721903878156","dvy___","2023-01-18T13:44:53.3060000+08:00","'Master' like in 'Master Data'. As far as I know it's a term mainly used in process industries. It's more like a template that should be equipment independent, defining how the product should be produced. Basically like the recipe in the cookbook on your shelf. From that the Control Recipes are created to be executed with the process order on specific equipment.","","üëçüèº (2)"
"627696721903878156","dvy___","2023-01-18T13:45:52.9080000+08:00","Process manufacturing plants are basically scaled up kitchens and labs üôÇ","","üòÜ (1)"
"867075936054149191","rickbullotta","2023-01-18T20:12:27.5770000+08:00","Actually never heard of them!  I was pretty much all consumed with post acquisition ThingWorx stuff around then.","",""
"867075936054149191","rickbullotta","2023-01-18T20:13:00.2120000+08:00","Transparency!","",""
"833941249362493450","sammysevens777","2023-01-18T20:28:33.1360000+08:00","Oh im aware of the use of the word recipes, but a master recipe for an entire process was something i hadnt heard before....but i come from the discrete mfg. world and frankly i was surprised when the term recipe was used for robotic automation programs....but now i know where it comes from! üòÜ","",""
"817835202746253344","IIoT#4707","2023-01-18T20:28:35.2990000+08:00","GG @SamSon, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2023-01-18T20:43:06.9210000+08:00","I think @Dvy described it well : equipment independent recipes that can be resolved when transformed into a control recipe.  When combined with equipment models and orders, they can be used to optimize scheduling based on equipment capability and status (and material availability and status)","",""
"833941249362493450","sammysevens777","2023-01-18T23:15:48.9240000+08:00","Now were getting into MRP and MPS correct? Matrix calculations based on item and planning setups? That is different than master recipe correct?","",""
"867075936054149191","rickbullotta","2023-01-18T23:23:42.6300000+08:00","It's more than that.  Imagine being able to incorporate real-time data about equipment cleanliness, maintenance status, capacity, and so on in the planning and scheduling process.  Cool stuff happens when you can intersect the two.","",""
"833941249362493450","sammysevens777","2023-01-18T23:26:12.0220000+08:00","Where would that happen, or what is that called? Sounds like OEE, Yield and maybe some maintenance models baked in? Is that all part of a master recipe?","",""
"867075936054149191","rickbullotta","2023-01-18T23:27:17.6380000+08:00","Most definitely NOT OEE...LOL.  OEE does virtually nothing good or useful.  Instead, it's part of the scheduling and dispatching process - and not a lot of scheduling systems can handle it.","",""
"867075936054149191","rickbullotta","2023-01-18T23:27:27.5170000+08:00","Now you're just trolling me.  Ha ha","",""
"890244048739270656","brianpribe","2023-01-18T23:31:33.3810000+08:00","I laughed so hard that you had the audacity to call it OEE to Rick ü§£","","üòà (1)"
"833941249362493450","sammysevens777","2023-01-18T23:32:55.5960000+08:00","OEE does nothing useful....now thats a hot take! Well you mentioned capacity, and OEE tends to capture a machines overall performance...so an aggregate of that? If its not maintained well, and faltering, OEE should capture that.","",""
"890244048739270656","brianpribe","2023-01-18T23:33:32.8340000+08:00","Now you poked the bear","",""
"833941249362493450","sammysevens777","2023-01-18T23:34:25.9160000+08:00","Haha....im Canadian, we can be pretty grizzly ourselvesüòÜ","","üêª (1),ü§òüèº (1)"
"867075936054149191","rickbullotta","2023-01-18T23:37:19.6090000+08:00","My contempt for OEE as a horrible way to drive operational performance is well documented around these parts. üòà","",""
"867075936054149191","rickbullotta","2023-01-18T23:38:47.4190000+08:00","OEE can't tell you if the mixer is dirty or clean, if it's likely to need service soon, or if you have crew or materials to run the job.","","üëç (1)"
"890244048739270656","brianpribe","2023-01-18T23:39:12.6600000+08:00","Rick can explain it better than I can, but the functionality of utilizing those real-time calculations to make changes to the production of a product is more contusive to a closed-loop PID system rather than just a KPI.","","üëç (1)"
"833941249362493450","sammysevens777","2023-01-18T23:39:13.9300000+08:00","Haha....well i'll have to do some digging....ill let you know i came from the contract manufacturing world and 20% OEE is not a bad thing....sellling point to customers who want to ramp quick.....but then theres a whole slew of consistency in how you measure etc....get that for sure","",""
"833941249362493450","sammysevens777","2023-01-18T23:40:15.7530000+08:00","But in an ideal world, if that sensor factored into the OEE calc....it would make more sense right? Rather than just generic ""downtime"".","",""
"890244048739270656","brianpribe","2023-01-18T23:41:51.5120000+08:00","It would effect the availability factor. So yes your OEE score would be effected.","","üëç (1)"
"867075936054149191","rickbullotta","2023-01-19T00:14:38.2680000+08:00","I think the key here is that the inverse is not true - ""OEE"" is typically not an ""input"" to anything, other than your bosses.","",""
"890244048739270656","brianpribe","2023-01-19T00:20:31.4640000+08:00","The inverse is true for AQP in each ones respect. OEE can tell you if you should buy more machines or not (in a broader sense), or if you need to work on either A, Q, or P.... Alright I'm off the OEE pony ride","",""
"890244048739270656","brianpribe","2023-01-19T00:21:14.4340000+08:00","Let's get back to better topics","",""
"890244048739270656","brianpribe","2023-01-19T00:28:27.4420000+08:00","I got a question: How graphy should we go? I'm starting to get on the graphy bandwagon, but to what extend? Do we really need to replace SQL DBs with Graph DBs? Do we extend this to the ERP level as well? @RickBullotta","",""
"867075936054149191","rickbullotta","2023-01-19T00:29:02.9120000+08:00","With the Postgres ecosystem, you can get graph, SQL, and timeseries all in one!","",""
"890244048739270656","brianpribe","2023-01-19T00:30:00.9800000+08:00","Oh I had no idea there was a graph in postgres!!","",""
"890244048739270656","brianpribe","2023-01-19T00:30:33.1050000+08:00","Does Crunchy Postgres have graph? I know it has Timescale added","",""
"867075936054149191","rickbullotta","2023-01-19T00:32:42.9620000+08:00","Apache AGE works w/Postgres.  You can also do recursive queries with plain old SQL, but that can get a bit weird compared to what you can do with native graph queries.  It's often more readable though.","",""
"830193224504705035","marc.jaeckle","2023-01-19T00:54:01.1650000+08:00","Which reminds me that @RickBullotta once called OEE a ""we were shitty yesterday KPI"" which describes it pretty well üòÑ","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-01-19T00:59:35.6670000+08:00","There are a very rare few who can do accurate real-time quality measurement...very few.","",""
"898217314741280828","hobbes1069","2023-01-19T02:26:53.2320000+08:00","That's our biggest challenge in discreet manufacturing. Most of the inspection is offline and happens later.","","üíØ (1)"
"908341993820811295","chris.demers","2023-01-19T02:27:19.5470000+08:00","In life sciences there is this clutch of technologies that we call ‚Äúprocess analytical technologies‚Äù - which are a lot of times optical sensors for inline measurements of critical quality attributes. In theory one would be able to (for example) place a Raman (laser, not noodle) probe into a bioreactor and get an instantaneous prediction on product quality. Provided you‚Äôve sufficiently trained a regression model. We were doing this at my previous company. Still wouldn‚Äôt make OEE any more valid as a number in my opinion as there would be a lot of other ‚Äúfudge factors‚Äù that would have to come into play.","","üëçüèº (1)"
"898217314741280828","hobbes1069","2023-01-19T02:29:59.1300000+08:00","Hm... In theory if you had enough data (i.e., what inputs into the process tend to result in certain outputs) could you ""predict"" what your quality would be using machine learning?","",""
"745796393855352953","thedavidschultz","2023-01-19T02:54:28.1470000+08:00","I remember the beginning of the PAT initiative. Actually used it as part of a business plan for a sensor company I worked for. There was slim to no chance that it would be successful due to threaded connections. But learned the value of a good Power Point presentation. And that adage that if you can't dazzle them with details baffle them with bullshit.","","üòÄ (1)"
"867075936054149191","rickbullotta","2023-01-19T03:20:49.6590000+08:00","And sometimes, the real quality issues pop up after it leaves the plant.  Those never get back-charged for OEE purposes.","",""
"867075936054149191","rickbullotta","2023-01-19T03:21:51.7500000+08:00","Absolutely, for some types of quality measures.  TwinThread is doing this for a couple of customers (and in some cases, making specific prescriptive recommendations to get quality back under control if it starts to drift).","",""
"908341993820811295","chris.demers","2023-01-19T03:53:46.1470000+08:00","Yup you can use it with soft sensors like the one Rick is talking about just above here with the TwinThread example  where you aren‚Äôt necessarily directly measuring a physical thing that could be tied to quality but you know so much about your process and it‚Äôs relationship with quality that you can predict it. Or you could further improve this prediction by actually measuring a physical parameter that is directly tied to product quality. In the example of Raman the laser is interacting with the molecule/drug/vaccine we are manufacturing and is directly correlated to product quality.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-01-19T05:08:04.4200000+08:00","I've seen vision systems also used to inline/near real time inspection in a number of use cases.  At some throughput rates it starts to be come challenging.","",""
"801561312861618236","jon.forbord","2023-01-19T05:16:59.0780000+08:00","This looks like your standard solution-oriented approach, not building an ecosystem of tools on common technology based on open technology and architecture. Unless the namespace in this / these core's is made available for all other consumers using an IIoT protocol, that's a different story.","",""
"1044299684803530832","willemrs","2023-01-19T05:18:50.6510000+08:00","Thanks @NickN for sharing this. Did you use node red to push the MQTT data to neo4j?  And did you end up using flat MQTT? or did you try and incorporate any SpB?","",""
"801561312861618236","jon.forbord","2023-01-19T05:26:18.6350000+08:00","ISA 95 part 2, and primarily the hierarchy- Enterprise/site/area/line/cell. This is the only ""standard"" that is recommended, it doesn't necessarily follow from this that S88 is to be followed for process industry. Unified namespace does not mean that you have to adhere to the entire ISA 95 part 2, and it also doesn't mean the consolidation of a bunch of namespaces, and the standardization of these. I've tried explaining in so many ways the nuances, but I will now just tell you that you have not completely understood this yet.","",""
"894527802316046366","nickn5549","2023-01-19T06:12:38.2940000+08:00","Yes, the sync between MQTT and neo4j is done using Node-Red, my own functions because existing nodes/modules were pretty buggy. In terms of MQTT, I stay away from any SpB and payloads are just flat. Many of the topics that i use are big JSONS instead of just a value. Example, the whole BOM or all defects recorded for a certain MO. Neo4j is quick in traversing all these and get the right answer for you. Otherwise is 1000% harder to get same answers from a non queryable tree  structure.","",""
"627696721903878156","dvy___","2023-01-19T06:25:32.0080000+08:00","We've been doing something similar with a golden batch application to monitor if the current batch follows closely enough to what someone defined as the 'golden' batch. I guess your solution was the same?","",""
"627696721903878156","dvy___","2023-01-19T06:29:41.6630000+08:00","We're  Timescaledb by the way for storing the data, pre-calculating some statistical properties like the deviation of the last X batches of the specific product at each timestamp","",""
"627696721903878156","dvy___","2023-01-19T08:04:55.7910000+08:00","Well we need solutions, not problems üôÇ
Common technology based on open technology: ‚úÖ (MongoDB for persistence, subcribe & publish to Kafka, subscribe & publish to MQTT, ...)
Common Namespace: ‚úÖ (They call it Namespace Consolidation, the term 'UNS' didn't exist when they started)

By the way they also have open documentation, not locked away behind some portal requiring login: https://docs.inmation.com/
(Let's see how long it stays like this now that they're part of Aspentech)

For sure they'll have parts that are not fully open. But neither are solutions like Highbyte.
Overall it looks like they have a pretty solid architecture that does have a solution for the historical data.
And they are being adopted by some big pharma and chemical manufacturers so they must be doing some things right.","",""
"627696721903878156","dvy___","2023-01-19T08:05:18.4030000+08:00","Where are the docs for HighByte by the way? Are they open?","",""
"917925131261718558","jpmoniz","2023-01-19T08:11:19.7270000+08:00","Arguing apples and oranges","",""
"627696721903878156","dvy___","2023-01-19T08:17:30.4170000+08:00","Well I'm here to learn.
Again:
- I understand that inside one company/enterprise the aim should be to have one namespace over all manufacturing sites. (Unified or Consolidated, doesn't matter, it's just a choice of words)
- I understand that it is recommended to follow parts of S95 to build the namespace. Like you say: Enterprise/site/area/line/cell

Now in process industries it is not Enterprise/site/area/line/cell. It is Enterprise/site/area/process cell. S88 further extends this with /unit/equipment module/control module. So the total namespace for process industry could look like: Enterprise/site/area/process cell/unit/equipment module/control module.

Did I understand this part correctly?","",""
"627696721903878156","dvy___","2023-01-19T08:18:51.9660000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065425072417947740/ISA-S95-and-ISA-S88-Physical-Hierarchy-Models-1.png?ex=68df166b&is=68ddc4eb&hm=0d0fcf168a504b536344ac81f633db229c775d301a894eaa0201fda54478cb68&",""
"817835202746253344","IIoT#4707","2023-01-19T08:18:52.4800000+08:00","GG @Dvy, you just advanced to level 7!","",""
"627696721903878156","dvy___","2023-01-19T08:19:54.4940000+08:00","Please explain","",""
"917925131261718558","jpmoniz","2023-01-19T08:23:27.9670000+08:00","Just on the HB open aspect. Use of and  exposure of open tech around the software is the point whether the software itself is open is somewhat trivial","",""
"917925131261718558","jpmoniz","2023-01-19T08:37:24.0980000+08:00","I was wondering when someone would point that out. I‚Äôm more a discreet guy so don‚Äôt pay attention to 88 much. It‚Äôs funny in a way because where 95 stops at equipment. The reality is there are still a series of nested data that may be from anywhere within the ecosystem. Simply meaning topics just get more complex. It really becomes build what you need the way you need it following a set of guiding principles.","",""
"627696721903878156","dvy___","2023-01-19T08:50:03.8110000+08:00","I was just asking about the docs. Anyway by your definition Inmation's solution is open?","",""
"917925131261718558","jpmoniz","2023-01-19T08:58:44.3080000+08:00","Maybe, never used it. Never had a need to.  I would consider it open if the underlying data models it uses/generates are fully accessible using open technologies. Along with open api‚Äôs. If so then I don‚Äôt see the big deal.","",""
"627696721903878156","dvy___","2023-01-19T09:02:58.9890000+08:00","Could it be that most people here have a discrete background?","",""
"917925131261718558","jpmoniz","2023-01-19T09:03:22.6280000+08:00","Highly doubtful","",""
"627696721903878156","dvy___","2023-01-19T09:04:40.4010000+08:00","Then which background(s) do most have?","",""
"917925131261718558","jpmoniz","2023-01-19T09:05:17.9050000+08:00","I would think it‚Äôs a healthy mix of both. Especially for the SI‚Äôs that are on here.","",""
"627696721903878156","dvy___","2023-01-19T09:12:39.7760000+08:00","I don't think I have seen any architectures for process. Maybe some older conversations? The Inmation architecture is interesting because it fits well for process industry. Architectures that are even more open will probably end up with something similar.","",""
"917925131261718558","jpmoniz","2023-01-19T09:17:07.6610000+08:00","Now your loosing me. The architectures are the same in either case maybe subtle differences. I think your confusing data and architecture.","",""
"917925131261718558","jpmoniz","2023-01-19T09:18:48.5350000+08:00","A PLC in discreet is still a PLC in process. Sure you have DCS in the mix but still all the same just a data producer.","",""
"627696721903878156","dvy___","2023-01-19T09:19:23.5120000+08:00","Look this is a P&ID I randomly plucked from the internet. I marked the control modules in red. Like FT-101 is a flow transmitter. So we're already very deep in the namespace. And one control module can even have multiple tags, like the ZLO-102 and ZLC-102 on that valve on the right.","https://cdn.discordapp.com/attachments/815945777452941313/1065440304251019354/image.png?ex=68df249b&is=68ddd31b&hm=a13acc9cdd79fe9cd31b842a2ad2902af0d89015d259a27c921a34c3fda8f3c9&",""
"627696721903878156","dvy___","2023-01-19T09:20:26.0350000+08:00","Totally agree with that. Look at Open Process Automation for example","",""
"917925131261718558","jpmoniz","2023-01-19T09:20:39.1670000+08:00","To me those are just functions of a process circuit. That are part of a process line.","",""
"917925131261718558","jpmoniz","2023-01-19T09:22:55.6420000+08:00","My discreet resistance welder that is a function of a cell within a line is no different from a caustic PID in a batch tank part of a treatment line/circuit.","",""
"627696721903878156","dvy___","2023-01-19T09:23:22.2040000+08:00","Those green lines in the Inmation architecure allow queries to the local data stores for example.","",""
"917925131261718558","jpmoniz","2023-01-19T09:25:42.1980000+08:00","Green lines? Don‚Äôt see them","",""
"627696721903878156","dvy___","2023-01-19T09:27:27.0900000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065442332494794853/local-core-architecture.png?ex=68df267f&is=68ddd4ff&hm=d4d6b5e8cf2dfadc78ae4a407110be5488c58e8a75e954a236711fdb4e6b379d&",""
"627696721903878156","dvy___","2023-01-19T09:28:41.6970000+08:00","Really? Are you saying with my background in process I could make architectures for a discrete line just by experience?","",""
"917925131261718558","jpmoniz","2023-01-19T09:29:54.5660000+08:00","Just trying to show the parallels.","",""
"917925131261718558","jpmoniz","2023-01-19T09:38:11.7400000+08:00","Ok yeah we can build the same architecture with ignition.  I think what you are missing is by moving to an edge driven architecture and using the UNS concepts. A lot of that architecture become obsolete.","",""
"627696721903878156","dvy___","2023-01-19T09:41:25.2120000+08:00","Agree you could build that with Ignition.
But which part of that architecture becomes obsolete?","",""
"917925131261718558","jpmoniz","2023-01-19T09:47:29.2690000+08:00","Depends on what the local cores are doing and what‚Äôs in the local data stores and what functionality is expected where. But the fact remains that we are moving towards a time and place where connectivity and latency are no longer significant roadblocks in industry. So heavy hub and spoke architectures will slim down eventually. Architecting around a UNS. Allows you to migrate and burn off that dead wood as you mature.","",""
"627696721903878156","dvy___","2023-01-19T09:50:14.7120000+08:00","So we're saying the same? üôÇ","",""
"627696721903878156","dvy___","2023-01-19T09:51:12.0330000+08:00","Is the architecture above considered to conform to the UNS concepts?","",""
"917925131261718558","jpmoniz","2023-01-19T10:04:07.4810000+08:00","Hard to tell as the diagram is very basic. Doesn‚Äôt show functionality as nodes and their connections or dependencies so to say. It very well could but would need more info.  Is it driven by the edge?  Can you plug in a new line and leverage self awareness?  Is communication lightweight? Is it report by exception. Judging by the connectors at the site level looks not to be the case but again diagram is too high level.","",""
"894527802316046366","nickn5549","2023-01-19T10:08:35.2630000+08:00","Yeah, i opted for a 7 layers topic structure too... simplifies the maming conventions","",""
"917925131261718558","jpmoniz","2023-01-19T10:10:34.7830000+08:00","What did you use","",""
"627696721903878156","dvy___","2023-01-19T10:11:00.7660000+08:00","Ah yes I also don't like it when the diagrams are too basic üôÇ","",""
"627696721903878156","dvy___","2023-01-19T10:11:40.4200000+08:00","The docs are open. We can check all those questions.","",""
"917925131261718558","jpmoniz","2023-01-19T10:13:03.4120000+08:00","Yes you can.","",""
"627696721903878156","dvy___","2023-01-19T10:14:51.8850000+08:00","I could put some effort in it. Do you have a list of the UNS concepts and the thinking behind it?","",""
"917925131261718558","jpmoniz","2023-01-19T10:18:25.2910000+08:00","Not really interested in doing your homework for you. Suggest you check out the YouTube videos walker has on the channel.","",""
"627696721903878156","dvy___","2023-01-19T11:10:22.2460000+08:00","Yes I said I would put some effort in it. That homework remark is not needed. The architecture focuses on Namespace Consolidation, so the namespace part should be covered. You say that it also depends whether it confirms to UNS concepts. There's a lot in the video's, and a lot of it are recommendations. (In general good recommendations I would say.). If there's other hard requirements before something can be called a UNS then we should have at least a list and thinking behind it.  In the last video it was mentioned that the 'UNS' concept is becoming a more common term in our business. So it will also become more common to review if architectures and solutions fit the concept and/or ecosystem. This is #reference-architectures , people are here to discuss those architectures. Since that particular architecture is becoming more common, especially at scale, it is worth to discuss it here.","","üëè (1)"
"917925131261718558","jpmoniz","2023-01-19T11:32:57.4740000+08:00","Sorry my mistake. My apologies Strongly encourage you to check out the videos. There is always mentorship and mastermind content as well.","",""
"627696721903878156","dvy___","2023-01-19T11:48:42.1470000+08:00","ü§ù","",""
"917925131261718558","jpmoniz","2023-01-19T11:48:49.7130000+08:00","Also check out kudzai‚Äôs posts via HiveMQ. He‚Äôs doing a series on UNS that would be beneficial to you.","",""
"627696721903878156","dvy___","2023-01-19T11:49:57.6630000+08:00","Yes we've also been discussing those here","",""
"894527802316046366","nickn5549","2023-01-19T15:28:31.5170000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1065533199758921818/image.png?ex=68df7b1f&is=68de299f&hm=f274b06803c4f8a0f3edc65a9145d53729fd5c00672b051121468a8fe457e59d&",""
"801561312861618236","jon.forbord","2023-01-19T16:29:33.9940000+08:00","Correct, Ent/site/area/line/cell is just an example of the hierarchies in S95. Adopt to your industry/standard (S88 too if applicable is probably a good idea).","","üëç (1)"
"917925131261718558","jpmoniz","2023-01-19T20:52:42.0140000+08:00","Yes similar to what we do but looking at other variations. Currently we would be. Enterprise/site/area/line/cell/station/device","",""
"568913935147728896","zeratall","2023-01-19T20:52:44.9500000+08:00","Do you have any recommended resources for learning neo? I haven't done much with graph dB, but love the idea of pairing a graph dB with a UNS.","",""
"817835202746253344","IIoT#4707","2023-01-19T20:52:45.6560000+08:00","GG @Zach E, you just advanced to level 9!","",""
"894527802316046366","nickn5549","2023-01-19T20:56:29.7940000+08:00","Have some, let me dig out","",""
"568913935147728896","zeratall","2023-01-19T21:01:39.2160000+08:00","Ty appreciate it!","",""
"867075936054149191","rickbullotta","2023-01-19T22:36:20.6160000+08:00","TwinThread has an app in pilot mode at a couple customers that not only tracks against the golden batch or perfect run but will recommend (or in some cases make) adjustments to setpoint to achieve the desired output.  It's super cool.  Driven by ML models.","",""
"867075936054149191","rickbullotta","2023-01-19T22:39:24.0890000+08:00","Here's an old presentation I did with the CEO of Neo4j a while ago.  @youri.regnaud reminded me of its existence.  It does give a good overview of Neo4J and some IoT applications of it.

https://www.infoq.com/presentations/Graph-Database-Power-Web-of-Things/","","üëç (3)"
"568913935147728896","zeratall","2023-01-20T00:35:51.0720000+08:00","Ty checking that out right now!","",""
"627696721903878156","dvy___","2023-01-20T05:16:59.0820000+08:00","Indeed that's also the next step for us: first recommendations to the operators, and finally fully close the loop.","",""
"894527802316046366","nickn5549","2023-01-20T07:16:56.5250000+08:00","here we go...","https://cdn.discordapp.com/attachments/815945777452941313/1065771876539965450/OREILLY-GRAPH_DATABASES.pdf?ex=68df07e8&is=68ddb668&hm=66247bfda4a8a16820c5e51da40527ca113be51243e9a8435216e5e1fd91d38c&","üëç (2),üíØ (2)"
"568913935147728896","zeratall","2023-01-20T07:21:15.8590000+08:00","You da man, ty!!","","üëçüèª (1)"
"833941249362493450","sammysevens777","2023-01-23T11:15:30.9690000+08:00","@RickBullotta This is seriously forward thinking for industry....I'm blown away that you guys are talking about this....first learned about Page Rank a couple years ago while doing my masters of Data Science....got the map/reduce and distributed computing joke from your talk with the CTO of Neo4j....and your point of how GraphDB easily allows us to see the relationships between data points is so on point....The concept of disassembling hierarchies is what I4.0 is all about - and you have really peaked my interest with the notion that graph DBs are a major enabler to this reconstruction of how data is exchanged. I'm in awe man....this is some serious brain candy!!! And squaring up data by recognizing the simplicity of table records....and transforming graph data to table data....this with the unified namespace is like the recipe for true I4.0 operability!","","üëçüèº (3)"
"817835202746253344","IIoT#4707","2023-01-23T11:15:31.3790000+08:00","GG @SamSon, you just advanced to level 3!","",""
"1020064546053959690","subash2680","2023-01-27T08:03:33.2390000+08:00","@Dvy","",""
"817835202746253344","IIoT#4707","2023-01-27T08:03:33.5640000+08:00","GG @Subash G, you just advanced to level 1!","",""
"808077381503680542","andymellor","2023-02-04T00:04:42.7560000+08:00","Sorry to bring up an old message, but just for the record. Tatsoft could handle data transformation, historical (records and replays natively to Canary, OSIsoft, TimescaleDB, Influx, or its native historian based on SQL) and the SCADA element of your future platform architecture.","","üëç (1)"
"627696721903878156","dvy___","2023-02-04T04:46:16.5030000+08:00","@Jon Forbord thanks, will take a look into them","",""
"867075936054149191","rickbullotta","2023-02-05T00:11:30.0130000+08:00","So much for OPC UA being ‚ÄúOpen‚Äù: https://www.linkedin.com/posts/erich-barnstedt-9a84685_what-a-pleasant-surprise-im-just-back-from-activity-7027168007894269953-m25P?utm_source=share&utm_medium=member_ios","","üò± (1),ü§£ (1)"
"627696721903878156","dvy___","2023-02-05T00:58:48.8030000+08:00","Looks they only refer to OPC UA as an example. I don't know much about patent law but I would guess they're actually doing the opposite: building a case for OPC UA having been an open standard for a long time, and that because of that similar protocols can't be patented. And that would also fit in the overall strategy for Microsoft since they benefit from open protocols.","https://cdn.discordapp.com/attachments/815945777452941313/1071474923450662944/image.png?ex=68df5808&is=68de0688&hm=274a13949699869790b4e54201dfbc2f30bd8c75834627a98b66cc9f6fee05d7&",""
"801561312861618236","jon.forbord","2023-02-05T01:03:18.8660000+08:00","The claims all reference OPC UA, and even if the language is lawyery, what is claimed seems to be the technology for a non OPC UA pub sub client/server to OPC UA pub sub, gateway. When you read patents, the ONLY thing that matters is the claims.","",""
"801561312861618236","jon.forbord","2023-02-05T01:03:51.0170000+08:00","What‚Äôs with the @ to me?","",""
"801561312861618236","jon.forbord","2023-02-05T01:11:10.8060000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1071478035456462848/image0.jpg?ex=68df5aee&is=68de096e&hm=22aa6ee4dc7079a0f16e66e8f87be706544e96dd1ccc03074d010ded36faf9e5&","üòÇ (1)"
"801561312861618236","jon.forbord","2023-02-05T01:11:32.4560000+08:00","What a fucking cop-out answer by Eric!!","",""
"382941357699760129","walker.reynolds","2023-02-05T03:29:40.2840000+08:00","Yes -- Erich is part of the problem -- always has been.  He knows full well that's exactly what it means.  Its a moot point, OPC-UA is useless in pub/sub and its difficult to make the case otherwise.  This move has no effect on the market and only confirms that which everyone already knows.  The OPC Foundation has never been about interoperability for Industry.","","üíØ (1)"
"627696721903878156","dvy___","2023-02-05T07:47:58.5560000+08:00","Sorry that was a reply to Andy, didn't mean to reference you.","","üòÖ (1)"
"627696721903878156","dvy___","2023-02-05T09:41:35.5500000+08:00","Focus on the message, not the messenger","",""
"833941249362493450","sammysevens777","2023-02-05T10:42:49.8660000+08:00","I wouldnt worry about it. I know Erich too...hes an excellent programmer and at companies like Microsoft filing patents are either required to remain relevant in your role (hes an industry guy at a tech company, so he has to position his ""influence""), and he likely got a shweet bonus. 

These types of patents arent enforceable, more as a footnote in microsofts shareholder meetings (x # of new patents).....i seen this at other F500s too. 

@Walker Reynolds why do you say OPC-UA is not about interoperability? Im intrigued","",""
"382941357699760129","walker.reynolds","2023-02-06T00:42:32.5920000+08:00","It‚Äôs about interoperability for OPC members ‚Äî those with the most influence steer the standard toward their solution.","","üëç (2)"
"833941249362493450","sammysevens777","2023-02-06T00:47:17.9390000+08:00","Thought that's what you may have been alluding to, and do agree...big industry tends to sit on ""open"" platforms boards","","üíØ (2)"
"794542235676180500","akoscs","2023-02-06T03:30:52.1100000+08:00","Isn‚Äòt this true for any other community? Even this one‚Ä¶those with the most influence convince others. How you gain that influence and if you use it in a positive way is a different question, but influence just means you have an effect on the outcome, right?

Regarding interoperability, are you referring to the comp specs or something else?","",""
"382941357699760129","walker.reynolds","2023-02-06T04:02:21.4490000+08:00","Companion specs are one issue, as are problems with part 14 (especially now that OPC Foundation paved a path in 2018 for Microsoft to patent one of the implementations)... but the big issue is OPC's stated mission is Open for Industry -- but what they mean is Open for Interoperability among select members and only in the event 'optional' specs are implemented.  Matt did a great job in his paper outlining the technical issues -- what most people don't understand is the 'why'.  Those who have sat on the working groups can tell you exactly what the problem is.  The major players at OPC do not care about Open or Interoperable -- at all.","","üéØ (1),üëç (2),üíØ (2)"
"766684226455207996","bright_hummingbird_31342","2023-02-06T09:19:05.2900000+08:00","One could also argue that those with the most influence steer the standard toward no solution.  In many cases, they don't even bother adopting it themselves.","","üíØ (3)"
"833941249362493450","sammysevens777","2023-02-06T10:21:45.2090000+08:00","Yes @Walker Reynolds is spot on here. Having been at a F500 that wanted to drive standardization through open platforms, our incentive was to get the platform to use our conventions so that it could ultimately benefit our operations worldwide.  In fact, that is one of the reasons why this consortiums invited me in....they wanted to attract big corporations to sign off that they would use the platform as well.....it gets incestuous after a while....especially when the vendors dont adopt! üòÜ","","üíØ (1)"
"833941249362493450","sammysevens777","2023-02-06T10:22:57.1190000+08:00","A bit of 4D chess right there","",""
"794020366536146977","mparris","2023-02-08T19:29:13.6830000+08:00","@Walker Reynolds I named the article ""HOW data access protocols fail"" purposely leaving the WHY up to one's imagination üòâ","","ismile (1),üëç (2)"
"794020366536146977","mparris","2023-02-08T19:30:54.3840000+08:00","It's harder to argue against the ""HOW"", so stayed I in that lane for the most impact","","üíØ (3),üëç (2)"
"833941249362493450","sammysevens777","2023-02-15T02:38:00.4530000+08:00","You know - I used to really admire these Cloud Architectures,  - Until I realized....they rarely show any value. They are just ""Smart"" block diagrams with a lot of complexity. Here's Googles - and I know Litmus really well...they are an excellent solution and probably the only value add of this whole diagram (true OT connector, built by amazing group of guys). Everything else is just an ask of ""If you give me all your data, I will improve your business"".....really?","",""
"833941249362493450","sammysevens777","2023-02-15T02:38:04.0030000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1075123779845505104/image.png?ex=68df6f4b&is=68de1dcb&hm=e1ceaf0db70fa92bf6621137c12fcafa64b2fad4975871a7c6666c6f5b07275a&",""
"833941249362493450","sammysevens777","2023-02-15T02:38:22.7520000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1075123858790690916/image.png?ex=68df6f5e&is=68de1dde&hm=95a1a85a5f144d5a34e8a0f35745f539d5d71bb93f08896839b48095e7d4f338&",""
"833941249362493450","sammysevens777","2023-02-15T02:39:39.3380000+08:00","I'm starting to think this is the downfall of microservice architecture diagrams. So many pieces when you know that you want the whole pie. Took me a long time to understand all these products (more or less, still learning), and wtf they were trying to do.....again, genuine example of smart people who want you to know they are smarter than you, and know your business better than you do (sarcasm).","",""
"833941249362493450","sammysevens777","2023-02-15T02:39:58.8210000+08:00","They do pay great though.....one of these daysüòÜ","",""
"891563487241842699","jbonhage155","2023-02-15T02:41:21.2750000+08:00","https://www.youtube.com/watch?v=y8OnoxKotPQ","","üòÜ (4),üëç (1)"
"1073312001788477471","sparkylarks","2023-02-15T02:50:52.2950000+08:00","So can I solve my problems creating architecture drawings, by not trying to make them say anything of value and make them pretty with lots of logo instead. 

That may make life easier for me.","","üôÉ (1)"
"833941249362493450","sammysevens777","2023-02-15T02:51:20.5820000+08:00","@Joe Bonhage this is absolutely brilliant.....thank you, thank you, thank you (Galactus!üòÑ)","","ü§£ (1)"
"833941249362493450","sammysevens777","2023-02-15T04:32:49.5920000+08:00","Riddle me this (PTC - Kepware). What are we really losing from eliminating OPC UA/DA on connectivity layer, and connect databases directly to Corporate HQ / Higher Level MES&ERP / Dashboards & Analytics (shards and duplications to manage load). Isn't the simplified diagram basically saying the same?","",""
"833941249362493450","sammysevens777","2023-02-15T04:32:53.0580000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1075152674753884250/image.png?ex=68dee175&is=68dd8ff5&hm=2bce80e1eca9872e450f29fcc7cd29c537112710f0ac035f047c309ad187256c&",""
"833941249362493450","sammysevens777","2023-02-15T04:33:02.7260000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1075152715207942315/image.png?ex=68dee17e&is=68dd8ffe&hm=f480a2338b3e641e78afcc2fc030b4dba0a28c56c90a138b0e59b592bde79caa&",""
"867075936054149191","rickbullotta","2023-02-15T07:34:12.0110000+08:00","You‚Äôre losing connectivity to HMI and SCADA - Kepware is used extensively there.  And Kepware uses quite a few more protocols than OPC UA, both in and out.","",""
"833941249362493450","sammysevens777","2023-02-15T07:49:41.4830000+08:00","could HMI/SCADA be a ""recipient"" in the simplified diagram?","",""
"867075936054149191","rickbullotta","2023-02-15T07:54:26.0960000+08:00","I wouldn‚Äôt. Too much latency and another point of failure in a critical data path.  Some process plants use the historian in that way, but usually still have a more direct link.   If you‚Äôre only visualizing data though, sure you can do it.  Just with some latency.  And you wouldn‚Äôt be able to ‚Äúclose the loop‚Äù.  But I would never use a database as the bridge to an HMI.","",""
"817835202746253344","IIoT#4707","2023-02-15T07:54:26.5780000+08:00","GG @RickBullotta, you just advanced to level 27!","",""
"833941249362493450","sammysevens777","2023-02-15T07:55:54.7500000+08:00","yeah HMI for sure - SCADA prob no issue, but that is an interesting point....HMI could be an input device as well, on the bottom I guess...","",""
"833941249362493450","sammysevens777","2023-02-15T07:56:39.7880000+08:00","My main gripe is with these bloated diagrams....kepware is solid - i 100% recognize the value","",""
"833941249362493450","sammysevens777","2023-02-15T11:33:23.7770000+08:00","one last one for today - ISA95 (couple of ones floating around).","https://cdn.discordapp.com/attachments/815945777452941313/1075258499744944138/image.png?ex=68df4403&is=68ddf283&hm=1cdb452a5b533ed1f3a5fc41a59188d4c5079675635f3415d6a8973c90487cd0&",""
"833941249362493450","sammysevens777","2023-02-15T11:33:59.9830000+08:00","This seems over-engineered, an mqtt message with a JSON payload is the way to go today correct?","",""
"794542235676180500","akoscs","2023-02-15T17:11:13.7950000+08:00","This seems to be a schema, which defines how a property should be defined. JSON is in most cases schemaless, MQTT nothing to do with this, infact if you would use sparkplug B instead of JSON you would need a similar schema. Back to JSON, it is in most cases schemaless, which is popular, but does come with disadvantages, i.e. you spend less time on data modelling and you probably spend more time on debugging/making sure everything is compatible. You can introduce schema to JSON, either by using an API definition like OpenAPI for HTTP Rest or Async API which includs MQTT (this is not striclty a schema for JSON but at least a way to assure compatibility) or you can look at json-schema.org (I never used it).","",""
"794542235676180500","akoscs","2023-02-15T17:17:39.0830000+08:00","Scada is supervisory control AND data aquisition. The Supervisory Control part is the problem. Data visualiation is Grafana + maybe a synoptic representation (aquisition and storage is a DB plus something that pulls/pushes the data to the DB). I have sooo many casas when I would have just do ne that but here were aleays 3-4 ‚Äûbuttons‚Äú i.e. commands. That is the ‚Äûcontrols‚Äú part. It is not feasible to route that through a database.","","üëç (1)"
"833941249362493450","sammysevens777","2023-02-16T00:33:07.0120000+08:00","Understood on schema - but the way its presented in the ISA-95 doc is that each data point is a separate node. That is not necessary if we leverage UNS with MQTT the message body (JSON - which may need a schema, not sure why you suggest JSON is schema-less) contains all of the pertinent info for sensor/machine topic. So one request, and then you extract the relevant data points of interest....","",""
"794542235676180500","akoscs","2023-02-16T00:39:24.3960000+08:00","I suggest that JSON is schema-less because JSON is schema-less, unless you are using JSON Schema (https://json-schema.org/) which is the additional think to JSON (not included in JSON) which makes it schema-full (if that word exists).","",""
"794542235676180500","akoscs","2023-02-16T00:50:24.2960000+08:00","Yes, there is schema, which says, that a Person property must adhere to the structure described in the rectangle, then you get 4 examples, describing an actual person propery. You cannot implement the schema in JSON, that is why it is schema-less, but you can implement the rectangle in XSD (XML Schema Definition). The ellipses can be implemented in JSON and XML both. How do you send the message, e.g. over MQTT or REST API is not really relevant here. You can publish 4 different messages to one topic in MQTT or make a REST call to an endpoint times, or you can use 4 different topics and publish 1 message to each or you can call 4 Rest endpoints 1 time. It is up to you to decide, however, if the 4 messages adhere to the same structure the entity receiving the messages will be able to parse and use the data from all 4 messages.","",""
"833941249362493450","sammysevens777","2023-02-16T00:53:16.3220000+08:00","My point is, why 4 topics? What is the purpose of that? If there is something specific it helps me to understand, otherwise a single topic payload (body) can include all relevant info, then up to subscriber to take what's needed.

Unless its a bandwidth / cpu issue, i think the ISA-95 view of temp data/location data/etc with each data point depicted separately is area for improvement (unless im viewing it incorrectly)","",""
"794542235676180500","akoscs","2023-02-16T01:07:15.6670000+08:00","It is eighter 4 topics, 4 messages or 1 message with a list of 4 objects (or combination). This is a design choice based on what makes sense for your application.","",""
"867075936054149191","rickbullotta","2023-02-16T01:13:42.7020000+08:00","Take a look at how DTDL is implemented using JSON-LD.  I like what they‚Äôve done.","",""
"794542235676180500","akoscs","2023-02-16T01:39:47.7090000+08:00","I really need to make time to take Azure Digital Twin for a spin!","",""
"867075936054149191","rickbullotta","2023-02-16T01:50:45.6660000+08:00","Even without ADT, DTDL is pretty useful.","",""
"898217314741280828","hobbes1069","2023-02-16T01:50:57.2220000+08:00","What is AWS's equivalent?","",""
"794542235676180500","akoscs","2023-02-16T01:52:36.5110000+08:00","maybe TwinMaker","",""
"867075936054149191","rickbullotta","2023-02-16T01:53:28.1390000+08:00","TwinMaker sort of, but no parallel that I know of for a definition language. DTDL has been open sourced FYI and the digital twin consortium is doing stuff with it.","","üëç (1)"
"794542235676180500","akoscs","2023-02-16T03:03:11.6260000+08:00","Since we are once again at the topic of queriable graph descriptions: what about datalog? https://blogit.michelin.io/an-introduction-to-datalog/","",""
"867075936054149191","rickbullotta","2023-02-16T06:18:19.2060000+08:00","‚ÄúDerived from Prolog‚Äù?  Seems that GraphQL would be a better and more modern option.","",""
"917925131261718558","jpmoniz","2023-02-16T07:19:36.2140000+08:00","Have you seen the BAMM model from ‚Äúopen manufacturing platform‚Äù? Looks like DTDL","",""
"833941249362493450","sammysevens777","2023-02-16T17:44:15.2380000+08:00","Thank you, great content. The proposed model is interesting:

Property, Relationship, Telemetry, Component

If relationship is many to many, then messages could be used to group all sensors together (one relationship )and as part of F1-B1-L1-M1 etc (another relationship).....very neat","",""
"867075936054149191","rickbullotta","2023-02-16T22:31:02.1260000+08:00","The relationship stuff is super powerful, since relationships can have types and properties also.","","üíØ (2)"
"894527802316046366","nickn5549","2023-02-18T13:28:47.7710000+08:00","that's what I like at my MQTT-neo4j combo","","üëçüèº (1),üíØ (1)"
"898217314741280828","hobbes1069","2023-02-20T23:31:04.5080000+08:00","So when are you teaching a Masterclass on it? üôÇ","","üíØ (6)"
"829502128191045652","joshuastover","2023-02-21T00:32:17.0540000+08:00","That'd be a great class.","",""
"894527802316046366","nickn5549","2023-02-21T05:30:57.4260000+08:00","Down Under class...ü¶ò","","üòÜ (2)"
"898217314741280828","hobbes1069","2023-02-21T05:31:20.8140000+08:00","Time to update my passport üôÇ","","üï∫ (1)"
"412993180368371712","ianskerrett","2023-02-23T21:56:36.4050000+08:00","I recently came across the term MING Stack, meaning Mosquitto/MQTT, InfluxDB, Node-RED and Grafana, as being the technology stack for IoT.  I see this stack of technology used in a lot of companies. Do others see this?  https://flowforge.com/blog/2023/02/ming-blog/","","üíØ (1)"
"867075936054149191","rickbullotta","2023-02-23T22:14:47.0760000+08:00","From LinkedIn: ‚ÄúMy main problem with this stack is mostly Grafana. It‚Äôs generally ‚Äúvisualization only‚Äù and not great for data input and interaction.  Also, I‚Äôve generally found that iiot/IoT applications need more than just time series data storage.  It‚Äôs a good start, but incomplete.

It‚Äôs an excellent ‚Äúhobbyist‚Äù or ‚Äúlearning‚Äù stack also.‚Äù","","üëç (2)"
"412993180368371712","ianskerrett","2023-02-23T22:33:12.0510000+08:00","I agree other technology is typically required but this is the minimum stack.","",""
"867075936054149191","rickbullotta","2023-02-23T22:38:32.4830000+08:00","The other problem with the acronym is that three of the letters are specific products but one is a ‚Äútechnology‚Äù.  Should be ‚ÄúHING‚Äù","",""
"412993180368371712","ianskerrett","2023-02-23T22:46:41.8280000+08:00","In fairness to the original author, the M was for Mosquitto. Given my heritage I generalized to MQTT. üôÇ  MING also sounds better than HING.","","üòÇ (1)"
"890244048739270656","brianpribe","2023-02-24T03:02:22.3540000+08:00","Only @Joshua Stover would understand","",""
"890244048739270656","brianpribe","2023-02-24T03:03:02.9650000+08:00","https://tenor.com/view/viking-spongebob-squarepants-durgen-fall-down-hard-gif-7302846","","ü§£ (1)"
"829502128191045652","joshuastover","2023-02-24T03:15:02.4550000+08:00","Yes I absolutely understand... Happy early Leaf-Erikson Day","","üî• (1),üßΩ (1)"
"224307162254540801","a13d","2023-02-24T17:25:21.9880000+08:00","Leif* :dab:","","üíØ (1),ü§£ (1)"
"224307162254540801","a13d","2023-02-24T17:25:34.0570000+08:00","Also you'd have to equip every HING node with Bluetooth Mesh pub/sub, gotta keep those Norsk viking vibes going if you catch my drift","","üî• (1)"
"812295088348200960","patanj2","2023-02-26T04:14:06.7210000+08:00","Has anyone ever benchmarked the chariot MQTT server?  I am running into performance issues way sooner than I think I should ‚Äî 100 connections on a single instance and 1 msg/s publish rate","",""
"867075936054149191","rickbullotta","2023-02-26T07:42:47.2480000+08:00","I‚Äôd end my test right there!","",""
"867075936054149191","rickbullotta","2023-02-26T07:44:06.4850000+08:00","Take a look at memory usage/allocation.  Often each connection requires a substantial buffer.","",""
"812295088348200960","patanj2","2023-02-26T10:41:57.0070000+08:00","Thanks for the tip. Chariot was recommended to me by an integrator and at the time I didn‚Äôt know better.  The other issue I have with Chariot is that observability is poor.  I was having issues with some client applications for months and it was not obvious that the source issue was with the broker.  There is no insight into message latency,  dropped messages,  growing buffers, etc.  I am now in the the process of migrating to HiveMQ.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-02-26T11:23:33.5440000+08:00","Usually when I encounter performance issues with software I start with resource configuration settings - there‚Äôs so much variability in use cases that it‚Äôs hard for vendors to provide an optimal setup out of the box.","","üëç (1)"
"745796393855352953","thedavidschultz","2023-02-28T00:43:08.2990000+08:00","I reached out to Wes at Cirrus Link regarding your issue. They have many more clients connected to the broker. Are there other details you are able to share about your application?","",""
"812295088348200960","patanj2","2023-02-28T03:31:14.5650000+08:00","Thank you @DavidSchultz .  That is completely above and beyond. I will post more details tonight.  I have tried some configuration parameters as @RickBullotta suggested.  One I have not tried yet is the Linux open files limit setting.  Other brokers have this setting in their recommended optimizations.  On thing to mention is the behavior I see is slowing response from the broker,  even while overall CPU usage and memory usage remain quite low.  More details to come.","","üëç (1)"
"745796393855352953","thedavidschultz","2023-02-28T03:33:25.0610000+08:00","You can reach out to Wes directly, too. He is quite responsive. I like the Chariot broker as it is geared toward OT applications. But if there are edge cases where it has issues, it would be good to know what they are.","",""
"867075936054149191","rickbullotta","2023-03-01T01:26:00.1910000+08:00","Maybe DTDL should replace Sparkplug. https://techcommunity.microsoft.com/t5/internet-of-things-blog/digital-twins-definition-language-dtdl-updates/ba-p/3751705","",""
"890244048739270656","brianpribe","2023-03-01T01:52:23.2470000+08:00","@MParris thoughts?","",""
"917925131261718558","jpmoniz","2023-03-01T02:11:23.6120000+08:00","This is the type of thoughts I get hung up on.","",""
"917925131261718558","jpmoniz","2023-03-01T02:28:34.6250000+08:00","https://github.com/digitaltwinconsortium/ManufacturingOntologies","",""
"898217314741280828","hobbes1069","2023-03-01T03:07:59.4940000+08:00","MQTT 5 + DTDL 3 + zstd compression?","","üëçüèº (1)"
"657361690379288596","du5tins","2023-03-01T05:04:27.0640000+08:00","Working on some internal training stuffs and reference drawings for some mqtt sp-b infrastructure we are putting in. Thoughts?","https://cdn.discordapp.com/attachments/815945777452941313/1080234048816943184/high_level.png?ex=68dee8db&is=68dd975b&hm=a8dd5f0511d18831a705fced31f29349fae93134b5159694d2c4b9ef9d427dff&",""
"657361690379288596","du5tins","2023-03-01T05:04:51.0300000+08:00","The blue squares are running Ignition Gateway.","",""
"833941249362493450","sammysevens777","2023-03-01T05:10:53.9950000+08:00","Honest question - from reading through sparkplug - the main addition to their protocol is acknowledgment / management of devices when they go offline / dead....that is a part of the protocol and definitely a value add....but beyond that, why all the hype?","","üíØ (2)"
"657361690379288596","du5tins","2023-03-01T05:41:45.9860000+08:00","Sp-B has a few things going: the online/offline status of the primary SCADA host, compression by representing data is binary (not text), plus publishing of edge node and device tags (and tag data types and tag metadata!) in the birth certificate for the edge node and the device.","",""
"833941249362493450","sammysevens777","2023-03-01T05:42:59.5030000+08:00","Great insight, thank you Dustin....especially the last point, very useful!","",""
"657361690379288596","du5tins","2023-03-01T05:44:53.1870000+08:00","Its definitely one of those ""it can't be this simple"" sort of things. And when you see Sp-B working properly its like ""oh, this is what they meant"". At least it was for me.","","üëç (1)"
"890244048739270656","brianpribe","2023-03-01T06:30:02.6700000+08:00","Fairly generic. For training, it looks good to me. What else do you want to communicate?","",""
"867075936054149191","rickbullotta","2023-03-01T07:14:06.0630000+08:00","And that part is very flawed.","",""
"867075936054149191","rickbullotta","2023-03-01T07:17:07.1370000+08:00","Many other protocols do the same things, but don‚Äôt conflate multiple values/data points in a single topic, don‚Äôt have weak request/response metadata and command execution techniques, and don‚Äôt require every client to re-request metadata each time they connect.  Sparkplug is OK, but far from ideal or complete. And it‚Äôs far worse (unusable actually) if you try to apply it beyond its simple original SCADA  purpose.","","üíØ (1)"
"756247672637358181","sherylmccrary","2023-03-01T07:20:58.8650000+08:00","Makes sense to me. Looks like one of those O&G scenarios you were telling me about.","",""
"657361690379288596","du5tins","2023-03-01T07:21:23.3290000+08:00","Yeah... Its 98% of my work so... haha! Please forgive me. üòÑ","",""
"756247672637358181","sherylmccrary","2023-03-01T07:24:20.7330000+08:00","You mentioned ""weird edge cases"" and a convoluted, enterprise  mess. But you've managed to make it look straightforward in this diagram. üòÄ","",""
"657361690379288596","du5tins","2023-03-01T07:31:09.1690000+08:00","Yes! Amazing what a little organization can do to a seemingly complicated thing.","","üëç (1),üëè (2)"
"833941249362493450","sammysevens777","2023-03-01T07:44:07.3830000+08:00","Having never used it - what's the issue here? And to your point of re-requesting metadata - what protocol has a DB (or something similar?) that persists the metadata after a connection is broken. That sounds like 2 different technologies to me (some kind of broker + a DB for logging etc.) - but maybe I'm misunderstanding?","",""
"867075936054149191","rickbullotta","2023-03-01T07:53:41.5450000+08:00","Related to another issue, the conflation of metadata and data in birth messages.","",""
"794020366536146977","mparris","2023-03-03T08:33:54.4390000+08:00","https://iebmedia.com/technology/iiot/how-all-protocols-fail-at-data-access-interoperability/

Reference the ""Challenges of Data Access Protocols""  section","",""
"833941249362493450","sammysevens777","2023-03-03T08:42:33.0390000+08:00","This Matthew guy writes some great content....üòÜ , i'll read and report back","","üíØ (1)"
"829502128191045652","joshuastover","2023-03-03T22:42:28.6420000+08:00","This'll be a good read","",""
"867075936054149191","rickbullotta","2023-03-03T23:54:45.9840000+08:00","https://www.linkedin.com/feed/update/urn:li:ugcPost:7037449452239929344/","",""
"833941249362493450","sammysevens777","2023-03-04T03:39:27.0720000+08:00","Great piece....appreciate the depth of content. I'll be honest, it read as a piece on thought leadership, and posing questions....and overlooks (IMO) the tremendous evolution of plant floor connectivity we've seen in the past decade...yes computers have standards, but computers ""need"" to operate on these standards to do things. One of the challenges I4.0 poses today....is what is a machine? What does it need to do? Factories were operating (with challenges) without MQTT, OPC etc....computers/ the internet simply does not work without everyone adopting standards. So as the definition of machines evolve....so does the need for the very important things mentioned in your article. I was a part of IPC-CFX, a standards group for SMT that rallied F500, Small mid manufacturers, integrators and vendors to develop common data standards across all SMT vendors so that they could pub/sub, swap in/out, etc.

What i learned was that the main holdup (again IMO) is not tech, its business. Why offer things for free, and develop open standards , when historically these vendors have made $$$ selling their own solutions (with healthy margins). The tide is turning here 100% - across almost every industry....

A couple followups:

- you're at GE, big, influential, how is GE driving change here?

- is the synopsis that the protocols allow connectivity, but without standardizing on data definitions they don't adequately enable I4.0 transformation? 

Assuming there was a standard, would a UNS be necessary anymore?","",""
"867075936054149191","rickbullotta","2023-03-04T05:42:27.6680000+08:00","‚ÄúAssuming there was a standard‚Äù is roughly equivalent to ‚Äúassuming there were unicorns who poop rainbow ice cream‚Äù.  ü¶Ñ","","üòÜ (1)"
"801561312861618236","jon.forbord","2023-03-04T06:41:18.6260000+08:00","Perhaps a naive proposition, but how about truly open standards made by end-users instead..","",""
"867075936054149191","rickbullotta","2023-03-04T06:48:11.0820000+08:00","Having been directly involved in a number of standards committees in our domain (ISA 88 and ISA 95, notably, plus some OMG and OAG stuff) the reality is that vendors drive these things.  I don't see that changing anytime soon.  Plus we have regional/national issues and differences, sub-industry differences, and on and on.  There will not be a widely adopted industrial UNS/data/protocol standard within the next 10 years - of that I'm fairly certain.","","üíØ (2)"
"801561312861618236","jon.forbord","2023-03-04T06:53:34.5140000+08:00","The skeptic half of my brain is in complete agreement, and I‚Äôd even say 10 years is a bit optimistic‚Ä¶","","üò¢ (1)"
"867075936054149191","rickbullotta","2023-03-04T06:57:08.8540000+08:00","Jon I really truly wish I was wrong.  And I‚Äôve tried to help and will continue to.  But the status quo has a lot of ‚Äúinertia‚Äù","",""
"917925131261718558","jpmoniz","2023-03-04T07:00:13.7320000+08:00","Can‚Äôt get agreement between controls engineers on best practices for machine code. Doubt there will ever be agreement on information exchange.","",""
"833941249362493450","sammysevens777","2023-03-04T07:00:48.0510000+08:00","It is totally the vendors....and in that regard, i feel its helpful to just accept this and make it work - considering the options we have available, the industry is in a much better place today than ever before, and i could be ignorant, but genuinely dont know any applications where connectivity was the bottleneck (not that it didn't exist - but that there was no way to extract data). 

E.g. ASM, major SMT vendor has their own data broker called OIB....and they kept pushing back, and back, and back their updates to conform to CFX....what a coincidence üòÜ","",""
"801561312861618236","jon.forbord","2023-03-04T07:01:26.7220000+08:00","What is the reasons/driving forces behind standards being driven by vendors?","",""
"833941249362493450","sammysevens777","2023-03-04T07:02:23.9860000+08:00","They make the hardware + software we all rely on to build stuff.....driven by their own stacks....until it makes commercial sense for them to move away from these developments....they won't integrate these functionalities to their products","",""
"801561312861618236","jon.forbord","2023-03-04T07:04:29.4170000+08:00","But the end users are buying the products. If a conglomerate of badass powerful buyers came to the vendors.. bladam implement this mathafaggas!!","","üòÇ (2)"
"867075936054149191","rickbullotta","2023-03-04T07:04:47.5020000+08:00","I always thought it was because they were willing and able to commit the resources usually, plus they had to live with the results first!  Chicken and egg problem.  And when most standards groups became pay to play it blocks out the true innovators at smaller companies.","",""
"867075936054149191","rickbullotta","2023-03-04T07:05:23.6220000+08:00","It has happened - but it‚Äôs rare.","",""
"801561312861618236","jon.forbord","2023-03-04T07:05:49.3410000+08:00","Phillips 66 comes to mind.. and Chevron..","",""
"833941249362493450","sammysevens777","2023-03-04T07:06:09.8060000+08:00","Thats what we did.....F500 was approached by industry and we drove the standard and lobbied the vendors....(we buy 1000s of this, heres what would help us, etc.)....but it directly competes with their own products in a lot of ways....","",""
"833941249362493450","sammysevens777","2023-03-04T07:06:46.5360000+08:00","BUT! What you said is the way, and hence the tide turning...","",""
"801561312861618236","jon.forbord","2023-03-04T07:07:57.6340000+08:00","This alone is the a good reason to shun away from the big vendors and go with the disrupters!","",""
"917925131261718558","jpmoniz","2023-03-04T07:09:13.6080000+08:00","Hopefully the disrupters can remain that way as well.","",""
"833941249362493450","sammysevens777","2023-03-04T07:09:57.8340000+08:00","I get you....but....is it? I mean these big vendors are who they are for a reason....great products, reliable, maintenance/support, community, tools, etc....jumping ship due to unified data standards is a tough sell to asset management üòÜ","","ü´£ (1)"
"801561312861618236","jon.forbord","2023-03-04T07:12:41.9350000+08:00","Hehe.. yes, but no risk no reward, and sometimes all the big vendor has really got going is name recognition and the disrupters are truly a better product in most dimensions.","",""
"801561312861618236","jon.forbord","2023-03-04T07:14:21.2230000+08:00","Anyway, Viva la r√®volution!!","","üíØ (1)"
"833941249362493450","sammysevens777","2023-03-04T07:14:25.8860000+08:00","So true....things will get better over time thanks to these disruptors","",""
"894527802316046366","nickn5549","2023-03-04T07:33:25.8880000+08:00","For SMT machines is all a big mess, but CFX and Hermes are getting more traction recently and maybe....we'll prevail...","",""
"794020366536146977","mparris","2023-03-04T10:36:07.1430000+08:00","Regarding your comment on connectivity being a bottleneck:

Consider an analogy: Is  rs-232 a bottleneck to connecting devices to a PC? 

Ever with how simple RS-232 is and how functional it is, people thought there could be a better way to connect devices. What would it look like to automate the integration of devices when connecting to the PC:
Step 1: connect device
Step 2: use it

Enter USB devices.

That's the difference between I3.0 systems and I4.0 systems. It's not primarily enabling connectivity to more things... It's enabling connectivity to more things and at scale.","","üëç (1)"
"1073312001788477471","sparkylarks","2023-03-04T18:42:25.2810000+08:00","USB != productivity. How many hours, days , nay years have been lost to have to rotate the plug 180¬∞ three times.to make it fit üòâ","","üòÖ (1)"
"794020366536146977","mparris","2023-03-04T18:51:36.7930000+08:00","Well, now you're talking about advanced Industry 5.0-level improvements üòÇ","",""
"817835202746253344","IIoT#4707","2023-03-04T18:51:37.1030000+08:00","GG @MParris, you just advanced to level 24!","",""
"833941249362493450","sammysevens777","2023-03-05T01:25:10.1960000+08:00","I get the anecdote, but is that really where we're at today? just look at RJ45 and fieldbuses, same medium, but they either reconstruct the way packets are formed (ethercat), or build off of tcp (ethernet/ip). We can analyze machine logs, use scalable broker tech, bluetooth....even the big  tech companies all have thorough mfg stacks (not a fan of most, but worth stating).

Ethercat in particular offers discovery at the click of a button, and xml files contain the templates with IO mapping....we're a far cry away from RS-232....

But what are your thoughts on the questions i asked (bottom of post)?","",""
"794020366536146977","mparris","2023-03-05T01:35:13.4750000+08:00","If you try connecting a PLC to a barcode scanner over Ethernet, does it feel like integrating RS-232 or like USB plug and play?","",""
"833941249362493450","sammysevens777","2023-03-05T01:39:03.0060000+08:00","It has more to do with software than connectivity that makes it easy to use (libraries, vendor setup software etc.). It could be a myriad of protocols that doesn't tend to be the issue....

I get the feeling you want to prove a point, which you can, but i genuinely dont see it the same.","",""
"1073312001788477471","sparkylarks","2023-03-05T01:57:44.8800000+08:00","Are those the ones, I have to scan a series of barcodes to configure the IP Address and the scanning settings.  Definitely much easier with profibus and setting the device number on the DIP switches.","",""
"794020366536146977","mparris","2023-03-05T02:00:34.6180000+08:00","Regarding your thought on software being the bottleneck, I fully agree with you.

Another way to look at it is from the network engineer's perspective. All of this is happening above TCP (mostly), so from their perspective, the entire discussion on this Discord server had been about ""applications"", which could, as a whole, be interpreted as ""software""

We could spend time trying to define the layers above TCP, like I outlined in the article, or we could simply say that the end result of connecting one device to another through TCP for some ""true purpose"" is failing integrators and end users by requiring too much integration efforts.","",""
"744671252605829181","jeff.rankinen","2023-03-05T02:02:35.7440000+08:00","@hobbes1069#0017","",""
"833941249362493450","sammysevens777","2023-03-05T02:14:29.5910000+08:00","I totally get your point, it could be easier but companies compete on those layers so outside of connectivity and protocols, theres sweet cash to be made. I wish there were universal barcode software standards, but that would be a steep hill to climb.","",""
"794020366536146977","mparris","2023-03-05T02:16:27.9420000+08:00","Regarding influence, I appreciate you attributing a large amount of influence to my role, but in all honestly, it's the same challenge for any end user: develop a vision, begin make vs buy analysis, challenge OEMs at every chance, coordinate with OEMs and Integrators that support the vision, and communicate the challenge with the market at large. 

Regarding point two, I say ""yes""... The I4.0 KPI for me is time spent to integrate two things together.

The main idea of the UNS is two-fold: 1) standardization of the namespace and 2) scalable connectivity. I think both of these concepts will be leveraged in future solutions trying to reduce integration time","",""
"794020366536146977","mparris","2023-03-05T02:21:55.3960000+08:00","I can't argue with you on that point üòî

It's disheartening that even Remote IO, as simple as that is, hasn't been standardized...","",""
"833941249362493450","sammysevens777","2023-03-06T07:46:27.3010000+08:00","Yeah you're making a really profound point on remote IO, and noted on the KPI - spot on. what do you think of solutions that abstract vendor specific-programming into a unified dev. interface (e.g. https://youtu.be/AVGhqS8c9cs) ? Is this a good example of what's missing, or part of the problem that commercial companies need to address this data gap, vs. aligning on industry standards?","",""
"794542235676180500","akoscs","2023-03-07T00:20:06.1100000+08:00","So‚Ä¶in you opinion standardized data models is the key to i4.0? You made this analogy a couple of time already, and I always point out that USB has a well defined data model, rs232, not really. Yes USB has a higher speed, agreed, but the key difference is the standardised data model.","",""
"794020366536146977","mparris","2023-03-07T00:24:40.6440000+08:00","Yes, agreed. Common example: USB Mouse is a well defined model.

And with that model, software is built into the operating system to handle different variants of that model, but the number of variants seems manageable. 

 --- Number of buttons (maybe max 3?)
--- Wheel
--- X-Y movement

Any thing extra above that requires custom drivers from the OEM.","",""
"794542235676180500","akoscs","2023-03-07T00:25:58.0770000+08:00","So‚Ä¶what are the communication protocols aiming to have a standardized data model for different equipment types? üòâ","",""
"794542235676180500","akoscs","2023-03-07T00:26:33.9500000+08:00","You know, like sercos, CanOpen, profinet. Ethercat? Anything else come to mind? :)) üòâ","",""
"794020366536146977","mparris","2023-03-07T00:26:42.3760000+08:00","What's happening today, is a bunch of people developing models of paper without concrete line of sight of what ""Operating System"" for the masses where this driver is built in.

Haven't seen any productive process on this front over the past 7 years","",""
"794020366536146977","mparris","2023-03-07T00:28:08.8630000+08:00","The client (consumer) of the model MUST be identified that is popular in the market and can obviously demonstrate to the market the benefits of that standard. That company would build that part of the interface, then the market will force devices to comply with the standard","",""
"794020366536146977","mparris","2023-03-07T00:31:15.8820000+08:00","How long did it take to define a USB mouse standard? Then how long to hit the market?

How does that compare to the efforts in our market?  Why can we not have a single victory, just one, that brings the similar benefits as the USB Mouse?","",""
"794542235676180500","akoscs","2023-03-07T00:34:39.8700000+08:00","Was not the question I was asking, but you know I can ask questions about what is the typical product cycle of a mouse? What happens if a mouse is faulty? What happens id the mouse data model is faulty? How easy it is to replace a mouse? How critical is a mouse? Does your production stop if the mouse does not work (ok, maybe do not answer the last one :)) )

Why do you think USB data models are now a complete mess and a headache to develop agains?","",""
"794542235676180500","akoscs","2023-03-07T00:38:11.8260000+08:00","So, I assume you agree that there is only 1 initiative that is even remotely related to what you think the key to i4.0 is. Right? Or can you give a different example. Not talking about quality, strictly quantity.","",""
"794020366536146977","mparris","2023-03-07T01:02:22.6360000+08:00","Yes, I agree that the OPC Foundation is the only organization ""attempting"" to standardize the industry.

They are The Industrial Interoperability Standard‚Ñ¢ after all...

Also the reason I was ALL IN a few years ago as the way forward.

And now I continue to question if their efforts are even the right approach or will bear fruit.

I check in every once in a while and still find them standing in a hole with shovel in hand excited that they are going to China.

Still not clear on why the struggle to commercial deploy a single information modeling over the past 18 years.

Why one killer use case has not been identified, then identify a platform to embed the ""driver"" for this model, identify two OEMs with products that produce the model (hey... Interoperability is important üôÉ), then bring that awesomeness to the world","","üíØ (1),üëè (1)"
"833941249362493450","sammysevens777","2023-03-07T01:11:32.7380000+08:00","I understand the point you're making, it's valid and forward thinking....i dont know if we'll have a unified data model...the trend seems to be a standard communication medium that then exposes the vendor specific model.","",""
"801561312861618236","jon.forbord","2023-03-07T01:56:39.5840000+08:00","The rate of adoption isnt a complete complete mystery. Take a quick glance at the released companion specs, aside from a few handful, they are generally useless. Weihenstephaner companion spec?!!! Now what the hell am I going to do with that?! I cant use a single one. I want simple Lego blocks models I can build a Millenium Falcon from, i dont want the Lego dreamhouse complete model, nor the Ninjago dojo.","",""
"833941249362493450","sammysevens777","2023-03-07T01:58:17.6030000+08:00","Well funny example because all products you listed originate from the same company....and that is precisely the issue in industry","",""
"812295088348200960","patanj2","2023-03-09T04:29:08.7380000+08:00","My setup is about 200 PLC publishing 1x/s,  two Ignition Gateways,  HighByte,  2 Siemens industrial edge devices,  canary collector, and a handful of internal apps.  Downstream of PLCs most things are subscribers.   I did find a scenario where chariot was leaving orphaned file descriptors when connections are being made with invalid credentials.  They have a fix coming within a month.  For me this situation happened when upgrading broker version before restoring the old configuration.  Clients were connecting with mqtt credentials that were not yet defined in the broker.  Broker quickly ran out of memory.  IMO,  quite an oddball situation.","",""
"745796393855352953","thedavidschultz","2023-03-09T06:51:09.8310000+08:00","Thank you for the message. Below is response I received from Wes.

I am aware of this bug and know it is fixed in our nightly builds. We should have a new release out within the next week or two with the fix included as well.","",""
"343452320216121345","hanno23","2023-03-10T19:20:30.7900000+08:00","Hi all, I am busy building a basic UNS for a client. I am at a stage where I need to start implementing the historian integration (Canary) and I have doubts and just want to hear what are your opinions/suggestions/tips/watch out for's.

**__Quick summary__**
-Tech: Ignition, Canary, EMQX
-Client has 3 sites, site 1's Ignition is being used as the dataops platform as well.
1-2) Each site acquires OT data and then transmits it via MQTT SpB into broker ""Staging"" area.
2-3) Site 1 subscribes to ""Staging"" (MQTT Engine module)
3-4) I create ref UDT tags that contain additional tags, alarming and other custom properties.
4-5)I then publish the final structure back into the broker under ""Live"" for enterprise to consume.","https://cdn.discordapp.com/attachments/815945777452941313/1083710974663589929/image.png?ex=68df08be&is=68ddb73e&hm=9d71f89bc533fd6fd8344228ecf9c94a254aaf3e954136457dbf6767c2f4c33c&",""
"343452320216121345","hanno23","2023-03-10T19:20:43.2410000+08:00","**__Question__**
I am happy with the architecture but I keep on going back and forth on where I should connect Canary (Historian)
__A__
Connect Canary to the broker. It will subscribe to ""SpBv1.0/#"" which means ""Staging"" and ""Live"" topics are historized.
Pro: 
- I will easily be able to get store and forwarded (S&F) data (Staging) and data from Enterprise (Live)
Con: 
- Managing which tags need to be historized from the MQTT Collector on Canary Portal is a nightmare. 
- Yes, I can use regex but many of the UDTs have instances where we do not want to historize (to save tag license count).
_ Every time I make changes to the MQTT Collector's tag settings, I need to stop the collector, losing history.","",""
"343452320216121345","hanno23","2023-03-10T19:20:56.1900000+08:00","__B&C__
- B =  Tags under ""MQTT Engine/Edge Nodes""
- C = Reference tags to B with additional tags, to be published to ""Live""
Pro: 
- I have the Ignition history config environment to my disposal which will make managing which tags need to be historized  much easier and setup of additional historical conditions possible.
- Adding and removing historical tags does not interrupt the historian from historizing.
Con:
- Adding config to tags under ""MQTT Engine/Edge Nodes"" (B)  is risky and requires a lot of scripting.
- Historizing tags in C being referenced from B will not catch S&F data.

**__To summarize__**
Connecting Canary to the broker makes it difficult to manage which tags get historized if you have thousands of tags. It is also not possible to setup specific  historize conditions.
Connecting Canary to Ignition will force me script history settings in tag area A as reference tags in tag area B do not carry over S&F events.

I know I can use views in canary to create structured history from unstructured history. But my concern still lies with what is the better solution if you have a lot of tags and need to manage historical conditions on large scale.","",""
"801561312861618236","jon.forbord","2023-03-11T04:47:03.2080000+08:00","Basically had the excact same ¬´problem¬ª. In short went with doing direct from edge to broker to canary, and use the canary module with Ignition central, and manually or using scripts to config tags in Ignition to be historized on the ‚Äúenterprise‚Äù level.","",""
"801561312861618236","jon.forbord","2023-03-11T04:48:46.1740000+08:00","But, in this case the edge namespace is not ‚Äúraw‚Äù it is modeled at the edge. Then using the same structure in Ignition central, and use views in canary to create the completed model, if that makes sense..","",""
"1020064546053959690","subash2680","2023-03-11T07:23:39.2690000+08:00","I‚Äôm","",""
"726522953084174337","hertztro","2023-03-11T11:06:11.8760000+08:00","I just read @MParris's paper ""How all protocols fail at data access interoperability"".  It was a lot to take in!  Question for the group?  If you could build both the producer and consumer of a local TCP based M&C system with the hope of  integrating a few OTS devices, what would you use?   Low bandwidth, maybe some precision timing.  Is OPC-UA the best option now?","",""
"794020366536146977","mparris","2023-03-11T22:22:15.9110000+08:00","Thank you for reading the article.  I'll paste a couple quotes from the article as food for thought regarding your question:

""The first step in developing an architecture is to identify the primary consumer applications and define their requirements for information.""

""Specifying ‚ÄúOPC UA‚Äù is not enough if the goal is interoperability.""","",""
"343452320216121345","hanno23","2023-03-13T13:41:38.1020000+08:00","Thanks Jon, it makes perfect sense. So basically you used Ignition to handle the history. We differ in the sense that you are staying true to using only one namespace whereas I am using two. I just realized, given the SpB G/N/D uniqueness limitation, I will probably end up with two areas in the UNS (Staging/Live or aka Raw/Clean) anyway somewhere down the line. Leveraging views from canary solves that issue i.t.o history.","",""
"801561312861618236","jon.forbord","2023-03-13T21:26:08.2950000+08:00","Not quite, history is mostly direct from edge, but the part that Ignition creates, we use Ignition to handle the history. You can say we take the staging direct to Canary, and the ""Live"" consists of only the parts missing from Staging (only the new data). It is the parts missing from stage that is historized through Ignition. Then we make views of the aggregated namespace in Canary, which we CAN publish to the enterprise level, to make what equates to your ""Live"" namespace. I'm not sure how well this scales, but it works for our case for the time being.","","üëç (1)"
"1085244229548245124","martin1235961","2023-03-15T01:58:29.2890000+08:00","If the Industry 4.0 architecture is to centralized everything in a Broker using MQTT protocol, how should we implement a request from a user asking all the data of our yesterdays run of Line1 in Plant A ? Should we still keep point-to-point connection for specific request (API, REST, storeProc...) OR we should publish a kind of 'Request ""Topics"" ' and susbscribe to a 'Response ""Topics"" ' ?","",""
"898217314741280828","hobbes1069","2023-03-15T07:03:31.0410000+08:00","A UNS is not just a broker (although that's the largest single component) but databases as well. The question I would ask myself is, how likely is it that someone else will want the EXACT same information. If so, then it should probably go through the UNS, if not it could be a point-to-point connection but there's a hybrid option. Using a dataops platform like Highbyte to make the request on your behalf, at least then you have the option of doing something with the data other than returning it to the requestor.","",""
"898217314741280828","hobbes1069","2023-03-15T07:03:58.2800000+08:00","New idea I just had... Store the queries people make, knowing what your customers are looking for is valuable data.","",""
"833941249362493450","sammysevens777","2023-03-15T08:40:22.8400000+08:00","If the data needs to persist, it needs to be in a database (and buckets/other object models can apply here too). 

The broker is for non-deterministic data that needs to be exchanged...so a historian requirement (yesterdays historical run on line A) falls outside of that scope. 

A lot of block diagrams present architecture, but it's really flow....if your business has a need to historically review data.....you need more than a broker, and to Richard's point, UNS is more than MQTT....","",""
"571815818308878347","binyameen_980","2023-03-15T17:33:42.7070000+08:00","""but databases as well"" can you elaborate it a bit more?","",""
"801561312861618236","jon.forbord","2023-03-15T19:26:02.9930000+08:00","UNS is the central node in the architecture, and you need persistence as part of your overall architecture. Whether this/these database(s) or other forms of persistence is ""part"" of the UNS or not, is purely a matter of perspective. Some think it's part of it, some think of those as nodes plugging into the UNS.","",""
"1003994033468747787","andreasbackman","2023-03-15T20:57:03.7850000+08:00","I've been wondering about this a lot but haven't really found a good answer to it. When people say that persistence is part of UNS or a node hooking into it, what does it mean in practice?
What data store are we talking about and how is the data persisted there that's consumed read from the UNS  topics?","",""
"801561312861618236","jon.forbord","2023-03-15T22:10:13.2330000+08:00","Depends on the application. In practice this means that most architectures uses Ignition as the IIoT platform, and consists of a Historian and a SQL database for persistence (the SQL database is owned by the IIoT platform). The IIoT platform is what you use to bridge the ""gaps"" between persistence and current.","",""
"801561312861618236","jon.forbord","2023-03-15T22:12:41.8780000+08:00","So an event from the broker, can trigger an update in a sql table. Such as a downtime event from a machine going into the SQL database for MES. MES then takes a bunch of historical records (SQL entries) to calculate some current value of some KPIs. These KPIs are published back into the broker.","",""
"801561312861618236","jon.forbord","2023-03-15T22:16:32.3320000+08:00","Another example, is that when you have a current workorder running on a machine, you can pull from the historian the record of the last 10 similar workorders, and calculate metrics on those, so the operators can compare the current workorder performance or operator notes or whatever has been recorded about these workorders, as they are on the current workorder. This ""record of comparable workorders"" can be published as a ""current"" state of history sort of, to the MQTT broker, to get a picture of how well we perform compared to those previous workorders. Say line speed has historically been 90 PPM on the previous 10 workorders, and we currently run only on 65.","","üëç (1)"
"571815818308878347","binyameen_980","2023-03-16T00:29:14.6270000+08:00","""UNS is a snapshot of your business in real-time"". Should we say it is part of UNS? Doesn't other systems also have database(s)?","",""
"801561312861618236","jon.forbord","2023-03-16T01:23:21.3600000+08:00","What do you mean ‚Äúit‚Äù? It is a part of UNS? The database? No I would generally not say that, but some people do. I would at most say the MQTT broker and the IIoT platform is your UNS. The IIoT platform would have a database, but I would not say the database is part of the UNS, but in some cases in order to explain to someone I might say that to hopefully make it easier to understand.","","üíØ (2)"
"801561312861618236","jon.forbord","2023-03-16T01:23:57.6370000+08:00","Again, this is just perspectives and different ways of thinking around the same concept.","",""
"571815818308878347","binyameen_980","2023-03-16T01:26:01.6910000+08:00","Sorry. yes ""it"" means Database.","","üòÖ (1)"
"571815818308878347","binyameen_980","2023-03-16T01:27:28.4470000+08:00","Got it. I would also say DB is not part of UNS.","","üëç (1)"
"867035383509024778","mattmigchelbrink","2023-03-16T02:18:11.3110000+08:00","Often terms are interpreted very differently, which leads to lots of communication and design intent issues. I appreciate how you always engage the granular vocabulary discussions.","","üôèüèª (1)"
"833941249362493450","sammysevens777","2023-03-16T05:29:08.1980000+08:00","Yet another architecture.....like I've shared before, I used to fawn over these, especially when studying my Data Science degree, learning all the tools, their names etc. etc. Now I look at them and see them for what they are....thinly veiled sales pitches from SaaS providers to create data pipelines for a business model that they don't understand....the digital twin stuff is also super confusing and lacks direction. It looks more like Industrial Engineering applications, than a digital twin (and has no relation to the product, what it is doing, made up of, or means to pull any of that relevant data) This one comes from https://github.com/digitaltwinconsortium/ManufacturingOntologies","","ü§òüèª (1)"
"833941249362493450","sammysevens777","2023-03-16T05:29:26.3150000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1085676155249623080/architecture.png?ex=68deeeb6&is=68dd9d36&hm=b89b6ad0f911d8eeffd16eec83b257e39d7b019e020501755750edd9e1b39b6c&",""
"801561312861618236","jon.forbord","2023-03-16T05:42:34.3710000+08:00","If a user wants to do this, he‚Äôs probably better off going direct to historian to do this. You CAN implement a sort of request/response pattern through mqtt for this, but my opinion is that this is hiiiiighly ineffective for these types of ad-hoc/impromptu needs for data. If however you need to setup a more reccurring type of query, then you can either use the IIoT application to build this query through a direct connection to the historian, and publish the results into the UNS, or you can create this type of request/response topics. It‚Äôs all doable, but using the UNS as an API for ad hoc data queries is not what I‚Äôd recommend. The user will most of the time be better off using the actual tool that owns the history/database. @Richard Shaw hits it, you should ask yourself questions like this. Will this query be performed on a regular basis or based off some current value in the UNS (can it be automated), will this query generate new information or data that can be useful for other apps.. etc.","","üëè (1)"
"801561312861618236","jon.forbord","2023-03-16T06:01:29.8420000+08:00","Here‚Äôs an example: you‚Äôve determined that operators should know the line speed average and max from the last 10 equivalent work orders, and this needs to be displayed on the HMI panel with the list of work orders, whenever a work order is about to start on the line. If your UNS consists of Ignition as an IIoT platform and your legacy MES contains the work order history (start and end times), and you have a historian with the line speed history, and Ignition is direct connected with historian and MES. You can the do the following: Ignition would get the current work order on the line from the HMI through UNS, this event would trigger a query to MES that finds the 10 equivalent work orders, and subsequently query the historian for the line speed record, and then publish the calculated values of line speed max and average and the list of those 10 workorders back into the UNS so it can be displayed on the HMI. You could also setup ‚Äúquery‚Äù topics and response topics, but I mean.. it kind of depends, but in the above case, I think it‚Äôs better to ‚Äúhand off‚Äù the querying to the IIoT platform that has direct connections.","","üëç (2)"
"833941249362493450","sammysevens777","2023-03-16T07:55:20.3970000+08:00","Great post Jon....as I've started to better understand UNS myself, it's not about substituting everything for UNS, but enabling its use as part of a digital transformation.....tech stack wise, it's a broker with a unified set of definitions for assets etc...but beyond that, you still need all sorts of Database technology (from transactional, to analytical, time series potentially etc.).....for any historical needs, the data needs to persist!","","üíØ (1)"
"673623178471276553","piege.","2023-03-16T22:00:06.6310000+08:00","Sounds like a typical mental bias, ""When all you have is a hammer, everything looks like a nail"" https://en.wikipedia.org/wiki/Law_of_the_instrument","",""
"817835202746253344","IIoT#4707","2023-03-16T22:00:06.8910000+08:00","GG @piege, you just advanced to level 1!","",""
"212982116764483597","elorso.","2023-03-17T15:47:27.2440000+08:00","Hi, in a lot of the proposed architectures i almost never see the historian. Why is this the case? Is this cost driven? At my company the historians are the closest thing we have to a UNS and really at the core of all data driven decision making.","",""
"908341993820811295","chris.demers","2023-03-17T20:36:11.9170000+08:00","In my opinion the historian is a required core technology. Otherwise consumers have no access to historical data. The historian subscribes to the UNS","",""
"867075936054149191","rickbullotta","2023-03-17T20:40:03.5160000+08:00","Yes and no - in many IIoT use cases, it's actually ""historian(s)"", often brownfield historians.  They should be accessible from the same IIoT platform that provides the UNS, ideally through the same namespace/model.  But adding another historian to the stack when one or more already exist brings a host of other issues with it.","",""
"1031940518730543106","thunt.career","2023-03-17T21:12:32.4890000+08:00","Should your data lake/data warehouse/data mart/data dumpster be coupled to your historian or be its own subscriber to the UNS?","",""
"833941249362493450","sammysevens777","2023-03-17T23:10:43.7910000+08:00","I am thinking decoupled because a historian is either OLAP or even OLTP, and in both cases, if you need to capture every record an operation is generating, then a UNS broker may not be the right approach to use.

I liked your point of UNS giving current state view - like the UNS is the window into an operation, but historical data belongs elsewhere and is independent","",""
"817835202746253344","IIoT#4707","2023-03-17T23:10:44.0630000+08:00","GG @SamSon, you just advanced to level 10!","",""
"477398944234733568","alexanderbattisti","2023-03-18T00:00:30.3140000+08:00","Hi, maybe somebody here can help me. I want to setup an UNS for each of our midsized industrial power plants. And I am struggling a bit with how to backfill data in case of a network outage.

The setup is as follows. The heart of our power plants is a DCS (either a Siemens PCS7 or a Siemens T3000). There all PLCs (more or less) send their data and it is archived for 6-12 months.

In order to get the data from the DCS I am thinking about to use HighByte Intelligence HUB's OPC UA client to subscribe to all tags/signals via the vendor provided OPC UA servers for their DCSs. Build up the UNS with HighByte and then archive everything in e.g. a local PostgreSQL DB and push the ""high value stuff"" to our cloud services. 

Given past experiences though the connection to these OPC UA servers is not exactly rock solid. So when the connection between HB and our OPC UA server is down we will now have a gap in our archive (i.e. the PostgreSQL DB archiving the UNS data), because HB does not seem to support the historical access part of the OPC UA spec - and AFAIK (at least) our OPC UA servers do not seem to support a store and forward functionality.

So now I am thinking about pushing a ""connection to OPC UA server down"" signal when the OPC UA connection is offline, and one ""connection to OPC UA server up"" signal, have then a little service watch the UNS for those signals that will then directly read/copy the missing (now) historical data from the SQL database storing the tags in the DCS to our PostgreSQL archive. 

But this ""feels"" like a pretty clunky Rube Goldberg machine ""solution"" to me. So my question is really necessary to cobble something like that together for myself, or is there a more straightforward way, or did I already run down a completely wrong rabbit hole and was completely missing the point of an UNS?","",""
"830193224504705035","marc.jaeckle","2023-03-18T01:45:58.4830000+08:00","I agree that the Historians should be accessible through the same IIoT platform that provides the UNS but I'm not sure if I understand your point with the same namespace (the model part is clear). Can you elaborate a bit how that might look like assuming you would want to access historic data through a REST API and not through messaging which would not be a good fit for historic data?","",""
"867075936054149191","rickbullotta","2023-03-18T02:17:39.4420000+08:00","The tag name/topic name/stream name for a real time update or for accessing historical data should be the same.","","üíØ (4)"
"833941249362493450","sammysevens777","2023-03-18T02:19:00.8010000+08:00","Hi Alexander - here are my thoughts:
- A functional architecture should try to do things in the ""best"" place, this means that determining what is ""high value"" data, is probably something that should be done closest to the data point. So you may want to evaluate edge / process monitoring as close to the data points to determine what should be published vs. tossed 

- For your requirements, your database should not follow your broker, you should probably record your data into a database, AND publish it to highbyte etc. for subscribers, why take the risk of missing data incase something is down, when the DB and connections will be far more reliable and ACID compliant

- I want to say you may be missing the point of UNS (As I did initially),  backfilling data = referencing historical records which != UNS/MQTT.....rely on your database to capture historical records, timestamps etc., and let the UNS/MQTT broker be a means to provide subscribers to data a flexible means of accessing current state across your organization","",""
"833941249362493450","sammysevens777","2023-03-18T02:19:22.2220000+08:00","I don't know if that answers your question, but with your DCS, that data should go straight into a DB IMO","",""
"833941249362493450","sammysevens777","2023-03-18T02:26:31.7670000+08:00","I may be misinterpreting, but I was reviewing the OPC UA webpage, and came across this diagram - and at the lower level of this architecture, you can see two paths for data: client/server (Database), and Pub/Sub (UNS/MQTT)","https://cdn.discordapp.com/attachments/815945777452941313/1086354900239253604/image.png?ex=68df6c97&is=68de1b17&hm=49e8185bce89c52e3b9f48864c4ec4799094814872bc9456af335b3152639832&",""
"991852688574779392","hutcheb","2023-03-18T02:39:44.0330000+08:00","That‚Äôs correct, the standard defines OPCUA over pub sub protocols, mostly MQTT but I think it leaves it open to be sent over other protocols as well.

In practise, while I think there has been some implementations, these are going to be few and far between.","","üëç (1)"
"830193224504705035","marc.jaeckle","2023-03-18T02:49:24.5550000+08:00","So let‚Äôs say if I need the data for a tag for the last two years because I want to display some chart then you would publish all that data over the message broker?","",""
"867075936054149191","rickbullotta","2023-03-18T02:50:18.6130000+08:00","Of course not.","","üëçüèª (1)"
"477398944234733568","alexanderbattisti","2023-03-18T03:14:57.7620000+08:00","Hi SamSon, thanks a lot for you answer! Yes it answers my question... assuming I understood you correctly (i.e.  mirror the tag DB of the DCS as an 'easily consumable' archive, and operate the UNS/Broker in parallel/independently... or if at all the broker should follow the archive and not vice versa) you fixed a conceptual thinking error of mine","",""
"817835202746253344","IIoT#4707","2023-03-18T03:14:58.0990000+08:00","GG @Alexander Battisti, you just advanced to level 1!","",""
"833941249362493450","sammysevens777","2023-03-18T03:25:23.8070000+08:00","I can't say for certain, there are always opinions to these types of things, but sounds pretty good to me!!","",""
"801561312861618236","jon.forbord","2023-03-18T03:27:40.9440000+08:00","The first thing most orgs do is set up ETL from the Historian to a data lake or warehouse. Once your UNS is in place and the historian subscribes to the namespace (events) you can transition to streaming into the datalake/warehouse instead, ie the warehouse / datalake is a subscriber/node to the UNS.","",""
"801561312861618236","jon.forbord","2023-03-18T03:47:17.4610000+08:00","This is the part of the UNS most people struggle with (me too, initially). It didn‚Äôt really click for me before I realized a few things: the broker AND the IIoT platform is absolutely required. The IIoT platform is what you use whenever you need data from non-mqtt sources, and you ‚Äúuse‚Äù the IIoT platform with a direct connection to fetch/put this data on behalf of other nodes that does not have the connection. 2. When a user needs data from a system, he can get it from the system, no need to go through the UNS for ad hoc stuff. 3. Some discrete connections are good, Connecting the historian to the SCADA system is probably a good idea. 4. Current state can also be a snippet of a historical/transactional record that is relevant to the current state of something. It really depends on what problem you‚Äôre trying to solve, but the UNS can contain topics massive tables with thousands of rows, IF the problem you‚Äôre trying to solve requires it.","","üôè (1)"
"801561312861618236","jon.forbord","2023-03-18T03:51:28.0670000+08:00","In the perfect scenario those OPC UA servers would support store and forward..","",""
"277515221885779970","jermuk","2023-03-18T04:04:03.6820000+08:00","Tip: you can also take a look at our blueprint for IT/OT - the United Manufacturing Hub: https://umh.docs.umh.app/docs/architecture/

This type of architecture works for a lot of use-cases and you can see how UNS fits together with what is here called IoT Platform, but what we call Historian and Analytics (database + analytics API + grafana). There you will also find example applications of a cache like redis, stream processing, etc and where to store what data in which data model","",""
"277515221885779970","jermuk","2023-03-18T04:11:56.6020000+08:00","We are currently adjusting our blueprint to have it exactly like that. Same data model for UNS than for database and analytics API.

If you have the same semantics, it will significantly increase user understanding","","üëçüèº (1),üíØ (1)"
"277515221885779970","jermuk","2023-03-18T04:15:07.1010000+08:00","I am personally not a fan of relying so much on OPC-UA. We prefer to move it out of it as quickly as possible. 

Buffering we do in our blueprint with Kafka, so that you never have data gaps, even if connections break down for days. Using a database to buffer things is also not really the best way to proceed.","",""
"1037102427985416202","loris6780","2023-03-18T06:05:48.7440000+08:00","Did you think about your alarms & events ? I would suggest to take a look at  crosser : https://crosser.io if you need a lightweight software that can talk S7 or opcua and bring your alarms, events or batch data from your dcs systems including store & forward. This piece of software can also directly push your high valuable data into your cloud systems from the edge.","","üëçüèº (2)"
"817835202746253344","IIoT#4707","2023-03-18T06:05:49.0720000+08:00","GG @Loris, you just advanced to level 3!","",""
"277515221885779970","jermuk","2023-03-18T23:44:59.7520000+08:00","We also tested it and it was quite good and reliable. In our tests where we compared it with Node-RED, HighByte, etc it was in the top field. @Marc J√§ckle maybe also interesting for you to take a look at if you are searching for tools like that?

Unfortunately unusable for us because it either just had a Kafka producer or consumer (not both of them which is weird).

The IT security department at one of our customers also had some problems with it as apparently some data was send unencrypted to their servers? But please note that did not yet verify this and the test by them was 1-2 years ago.","",""
"833941249362493450","sammysevens777","2023-03-19T01:36:44.8350000+08:00","What about Mendix? Low code app from siemens, gives a lot of extensibility and perfect for notifications, alerts, data distribution? Have you used it before?","","üí∞ (3)"
"830193224504705035","marc.jaeckle","2023-03-19T18:19:18.2270000+08:00","I'm already aware of Crosser but from what I know so far about it, it's more of a complete solution mostly focussed on getting telemetry data into the cloud and doing data analytics there. At least I'm not aware that the device connectivity for the shopfloor is available as a standalone solution.","",""
"830193224504705035","marc.jaeckle","2023-03-19T18:22:41.5970000+08:00","As Mendix wasn't originally developed by Siemens, this raises the probability that it might be a decent piece of software üôÇ","","üòÇ (5)"
"277515221885779970","jermuk","2023-03-19T18:56:38.0990000+08:00","It is more than the OPC-UA to MQTT docker container we talked about, but it is also different from a typical IIoT platfor. 

you could deploy a crosser container on edge devices, and then you could configure them in the cloud, to extract data locally via OPC-UA and push them somewhere else on the edge device (without the cloud). The cloud is just for management, not as the data plane.","","üëç (1)"
"1037102427985416202","loris6780","2023-03-20T02:56:51.0720000+08:00","https://www.crosser.io/connectors/crosser-connect-tools/","","üëç (1)"
"1037102427985416202","loris6780","2023-03-20T02:57:42.6630000+08:00","Here the crosser point of view https://www.crosser.io/blog/how-crosser-extends-siemens-mindsphere-low-code-strategy-to-the-edge/","",""
"830193224504705035","marc.jaeckle","2023-03-20T16:56:22.8020000+08:00","If I click on ""Trial"" it does not seem like the Connectors are a separate product. You get just the options ""Crosser Platform for IIoT "" and ""Crosser Platform for Intelligent Process Automation"" which are the two regular Crosser editions with the complete feature stack.","",""
"477398944234733568","alexanderbattisti","2023-03-20T18:43:37.1330000+08:00","Given my limited knowledge about the OT world, it (at least) looks like that it is very difficult to get data for ad hoc inquiries from our DCSs (it is possible though that we have been misinformed about that by our suppliers and vendors) - at least if you're not ""on premise"". 

The problem I need to solve (now) is to provide a reliable, low maintenance (bidirectional), and cheap to configure connection between our power plants DCS with our home grown, cloud based automated energy trading (has no problems with data gaps),  predictive maintenance (performs worse with data gaps), and customer billing systems (becomes useless with data gaps). 

The problem I have to solve in the near future is, that we will have many more systems (other DCSs, stand alone PLCs and even SCADA systems from different vendors) in our future powerplants where point to point integration for non-safety critical communication would be too expensive. 

Given what I learned now is that the UNS (build up e.g. using HighByte) would be suitable solution for my future problem, but I should look for something else (i.e. an IIot Platform like Ignition/Factory Studio, or an archive/buffer getting the data directly out of the DB backing the archive of our DCSs to ""store and forward"" data in case of a network outage)?","",""
"477398944234733568","alexanderbattisti","2023-03-20T19:00:14.2970000+08:00","Our current system looks similar to the architecture you're describing for your UMH (https://umh.docs.umh.app/docs/architecture/) - the only difference being that I can see is that we don't use Node-RED to connect to our DCSs (we have a home grown solution that can backfill gaps automatically if they're not larger than a couple of hours) and it looks like that the UMH is supposed to run on premise/the edge (vs. our solution that runs on AWS)? (AFAIK Node-REDs OPC UA client does not support historical access?) ... or did I misread your description? oh and we don't use Helm and don't have a MQTT broker","",""
"477398944234733568","alexanderbattisti","2023-03-20T19:02:08.7140000+08:00","Getting access to alarms and events is very important for our engineers! I heard of crosser, but haven't tested it (yet) - thanks for the suggestion I will check it out","",""
"277515221885779970","jermuk","2023-03-20T19:57:07.2210000+08:00","the UMH can run anywhere, you could also create an AWS EKS cluster and deploy the Helm Chart there. this is the big advantage when not using software tools with vendor lock-in: you can use them whereever you wan","",""
"477398944234733568","alexanderbattisti","2023-03-20T20:06:47.6350000+08:00","is it necessary to run the UMH on premise in order to guarantee that there won't be data gaps (under the assumption e.g. that you won't have a network outage in the local on premise network) or can you also guarantee that when the UMH runs in the cloud (e.g. because Node-RED will backfill gaps using OPC UA historical access when connected to an OPC UA server that does support that)? Or am I missunderstanding something?","",""
"277515221885779970","jermuk","2023-03-20T20:09:37.9230000+08:00","good point! we typically split it up and let companies have something on-premise (for data buffering only) and then have the main part (database, etc.) in the cloud","","üí° (1)"
"277515221885779970","jermuk","2023-03-20T20:09:57.9300000+08:00","just so that the production can continue to operate if the network connection fails","",""
"277515221885779970","jermuk","2023-03-20T20:10:23.2680000+08:00","also for latency reasons (you do not want to send time-critical information via the cloud)","",""
"477398944234733568","alexanderbattisti","2023-03-20T20:23:55.4320000+08:00","Ah ok thanks for the answer! I assume there is also some preprocessing on-premise using Node-RED (e.g. to map signal IDs to Kafka topics, and to determine what stays on-premise and what to send to the cloud)? 

Can I also ask you about you experience with managing/operating Kafka on-premise, and if you tried some other databases with Grafana (e.g. InfluxDB, Clickhouse, Cassandra etc)? I thought about mirroring our infrastructure on premise, but was afraid that babysitting a local Kafka installation for each of our powerplants would be beyond our capacity. And with regards to Grafana/TimescaleDB, we found the performance really poor for our use case (simple trend visualization) as compared to a more traditional historian","",""
"277515221885779970","jermuk","2023-03-20T20:29:34.1530000+08:00","yeah, we have then Node-RED (by default), benthos or any customer specific microservice on premise / on the edge that process the data and maybe already start to downsample some data streeams","",""
"277515221885779970","jermuk","2023-03-20T20:31:36.0690000+08:00","To be honest: I've heard now very often that Kafka is apparently hard to manage on premise, but we never had any problems with it. maybe it is hard to manage not because of the tool, but because you can add a lot of enterprise features on top of it and maybe also because of the problems of handling large amounts of data. Furthermore, we will switch from Apache Kafka to Redpanda (kafka compatible), as this is then a alightweight simple docker container","",""
"277515221885779970","jermuk","2023-03-20T20:32:19.8400000+08:00","we used previously InfluxDB, but decided to switch to TimecaleDB: https://learn.umh.app/blog/why-we-chose-timescaledb-over-influxdb/","",""
"277515221885779970","jermuk","2023-03-20T20:33:34.2260000+08:00","I am genuinely interested in why the performance was worse than with a traditional historian as it is quite performant (comparable to influxdb, etc.). how did you use it and what did you tried to query?","",""
"277515221885779970","jermuk","2023-03-20T20:34:14.8250000+08:00","because one disadvantage of TimescaleDB compared to a Historian is, that you need to handle some performance optimizations yourself (need to created indices, etc.). see also our article https://learn.umh.app/blog/historians-vs-open-source-databases-which-is-better/","",""
"477398944234733568","alexanderbattisti","2023-03-20T20:41:59.6680000+08:00","ah ok cool - I would have asked about Redpanda next üòÑ ... I see that you're based in Germany, too.  Would it make sense that I contact you directly (would you be open to some kind of short term consulting contract)? The big pain point for Kafka was the initial setup (maybe it got better since they switched away from Zookeeper?)  - and a vague fear, given the problems we already have with our on-premise IT, that anything more than two or three docker containers, that can be quickly restarted in case of failures would be beyond our capabilities to handle","",""
"277515221885779970","jermuk","2023-03-20T20:44:45.4560000+08:00","yeah, let's switch to PM. then I'll share my email","","üëç (1)"
"477398944234733568","alexanderbattisti","2023-03-20T20:46:38.4580000+08:00","visualizing the trends of maybe five variables over a period of 30-60 days was (according to our engineers, I have never seen it personally) more or less instantaneous with PI and with Acron it is ""pretty zippy"" ... with our setup the db server get crushed (it might be that we store the data in much higher resolution than what the PI system did - I don't know the specifics there, as it was before my time and the supplier who was responsible for that is not very forthcoming with regards to such infromation)","",""
"830193224504705035","marc.jaeckle","2023-03-20T21:02:54.6250000+08:00","I'd say the effort for managing Kafka depends quite a bit on the scenario. If you need to manage the company wide, central Kafka installation that runs on let's say OpenShift without a Kubernetes Operator, you are going to have a lot of ""fun"". Or using it for things that Kafka hasn't been built for, like a product IoT project with multiple hundred thousand devices and millions of topics, is probably also not the best idea. If you just run it in a smaller context using the Strimzi Operator and only services from within the same Kubernetes cluster need to access it, the effort is low. I'd say all in all it's a bit of an urban legend these days (unless you do stupid things).","","‚ù§Ô∏è (1),üôè (1)"
"1044299684803530832","willemrs","2023-03-20T22:00:41.3880000+08:00","What's the best place to get started with Kafka?","",""
"1044299684803530832","willemrs","2023-03-20T22:08:23.1050000+08:00","This is one of the things I've been wrestling with.  The historian and UNS are definitely separate entities however I see a huge benefit of ensuring the architecture carries over from the UNS to the historian in a semi seamless way.  That way the UNS is the current snapshot but if you know the UNS framework you can also get history if needed.  Still not sure the best way to do this though....","",""
"830193224504705035","marc.jaeckle","2023-03-20T22:24:18.6020000+08:00","For running on Kubernetes: https://strimzi.io/ If you just want to learn about Kafka, probably Youtube üôÇ","",""
"830193224504705035","marc.jaeckle","2023-03-20T22:30:23.5770000+08:00","Maybe it's important to add that running Kafka without Kubernetes on prem is also not a good idea and does cause a lot of effort.","",""
"277515221885779970","jermuk","2023-03-21T00:00:00.6410000+08:00","or just use the United Manufacturing Hub üòâ a couple of clicks and you have UNS based on HiveMQ and Historian based on TimescaleDB running. entirely open-source üôÇ","","üëç (1)"
"277515221885779970","jermuk","2023-03-21T00:00:28.5760000+08:00","you only need to pay if you want enterprise support üôÇ","","üëç (1)"
"833941249362493450","sammysevens777","2023-03-21T00:36:22.4600000+08:00","That's interesting, I think you need to map the broker topic definition, to a query? You would need to subscribe to a topic that is passing along historical data for a record - which on the backend would have to query a relational DB to get the relevant data, and then pass it back to the subscribers? Or even more clever....could a namespace query a database, and provide a user back a table view of the relevant records they are looking for? (maybe a link to a table / csv format?).","",""
"1044299684803530832","willemrs","2023-03-21T01:34:42.2340000+08:00","I definitely like the idea in some form or another of publishing short historical records of data back to the UNS.  I have been thinking of passing along MetaData for tags that i want added to the historical records at least to start with inside Ignition.  But the Ignition historian has its own problems...  I will also take a closer look at the United Manufacturing Hub.","",""
"801561312861618236","jon.forbord","2023-03-21T01:36:18.3180000+08:00","If I understand your original question correctly your main problem is that the OPC UA server of the DCS is unreliable, which any OPC client gateway to MQTT will not resolve whether you use UMH or Ignition or a purple Kafkapanda.. so you can either setup a batch job from the DB into some enterprise level storage, setup something that fetches the data at the source and bypass the DCS altogether (don‚Äôt even know if this is possible with DCS), or somehow fix the OPC UA server.. or.. a mix of the above. Accept some data loss on the UNS and use OPC UA to mqtt gateway for real time visibility, and batch jobs for the historical data.","",""
"603301251177775104","asthomas","2023-03-21T03:03:49.2350000+08:00","Have you looked at Cogent DataHub?  Full disclosure - I'm a developer there.  It will capture a stream from an OPC UA server into a local InfluxDB instance, and then forward from that InfluxDB instance to some client interfaces, including MQTT, Sparkplug (in beta), PI, AVEVA Historian/Insight, Influx Cloud. This has two effects - you can view your recent data on the edge with Grafana, and you won't miss any data if the connection between the edge and the cloud goes down.  It won't help, obviously, if the DCS's UA server becomes unavailable.","","üëç (1)"
"477398944234733568","alexanderbattisti","2023-03-21T03:16:09.0330000+08:00","yes you're right ... or to be more precise it *looks* from my perspective that the OPC UA servers that are part of the PCS7 and T3000 DCS(s) are unreliable, surprisingly slow and expensive... that said, some of the problems that we experienced might have been due to our unreliable internet connectivity, problems with our self written OPC UA client, inexperience on the side of the suppliers who are responsible for the configuration of our DCS, or a combination of all of these things (I know for a fact that we have problems in all of these areas)  - the big problem is that currently the only way for me to test new approaches is using a live power plant because realistic test environments for these DCS are in a price range far above what I can approve... and well I am not messing around with the control system of a 100 MW power plant unless I am sure  I know what I am doing üò¨","",""
"477398944234733568","alexanderbattisti","2023-03-21T03:17:26.5260000+08:00","No I haven't heard of it, but I will check it out this week!","",""
"817835202746253344","IIoT#4707","2023-03-21T03:17:27.2200000+08:00","GG @Alexander Battisti, you just advanced to level 2!","",""
"477398944234733568","alexanderbattisti","2023-03-21T03:25:02.3710000+08:00","technically it is possible to grab the data directly from the PLCs (the PCSS7 and T3000 use Siemens S-400 PLCs) ... the suppliers/system integrators who are responsible for setting up these systems are telling us though that doing so would void any warranties for the system (that said given some other information they recently provided us that is within my area of expertise, I don't see them as a credible source anymore)","",""
"1037102427985416202","loris6780","2023-03-21T04:34:45.6140000+08:00","Everything is stored in influxdb? Is there any backup mechanisms or store and forward capability if you want this influx to be remote ? What about the stored data, does it goes to the db itself ? If yes should you plan to purge and archive it ?","",""
"745796393855352953","thedavidschultz","2023-03-21T04:41:18.5430000+08:00","Currently using DH on a project. Great product.","",""
"833941249362493450","sammysevens777","2023-03-21T04:43:27.6050000+08:00","I haven't used this specific Siemens product - but the point that collecting data will void your warranty sounds dubious....I have to imagine one of the following scenarios is feasible (from the PLC itself)
- read in records and write to a local DB (which can then be pushed to an external database)
- pass data in near real time over an ethernet socket and transmit data via a variety of methods (CSV, JSON, etc...)
- Use a fieldbus 
- write to an external DB directly (if feasible)

something is not right about this integrator.... :S","",""
"794542235676180500","akoscs","2023-03-21T04:52:33.4800000+08:00","As soon as you touch the inside of the control cabinet, your warranty is void (in the EU). And I very much agree with this and strongly support this. If it breaks in the warranty period I need to fix it for free. I sure as hell do not want you to modify PLC logic and add janky PCBs to the machine I need to service for free. Can you ask me to retrofit stuff? Sure! Can you retrofit stuff? sure, but then I will not service it for free. Machine stopeed, you are yelling, I come to fix it, I try to connect to the PLC and I cannot as the software does not match. You have your downtime, I am on site, the guy who added the custom code is nowhere to be found. Who is at fault here?","","üëç (2)"
"833941249362493450","sammysevens777","2023-03-21T05:41:17.4770000+08:00","Perhaps I misunderstood Alex's point....when he wrote pulling data would void warranty I assumed that was a general statement, not specifically directed towards the end user coming from the machine builder/integrator.","",""
"801561312861618236","jon.forbord","2023-03-21T05:47:05.8090000+08:00","No, you‚Äôre right, unless they‚Äôve set the PLCs up with limits on the number of connections, pulling data from the PLCs is not the same as the scenario he describes. I agree that voiding the warranty for the reason they pulled some data from the PLC sounds like somewhat motivated reasoning, and I would press them for some better reasoning.","","üëç (1)"
"801561312861618236","jon.forbord","2023-03-21T05:57:18.5580000+08:00","You could set up a test with a gateway on prem and try to observe the stability of those OPC servers..","",""
"801561312861618236","jon.forbord","2023-03-21T06:00:19.9530000+08:00","Meaning an off the shelf gateway.. I would use Ignition edge to test this. 800 bucks..","","üëç (1)"
"477398944234733568","alexanderbattisti","2023-03-21T17:02:59.4740000+08:00","Yes, sorry - I was not clear about that. We were of course NOT planning to mess around in someone else's work and expecting them to fix our mess in case we screw up. The discussion was along the line- Q: ""Dear system integrator is it possible to get the data directly from the PLC instead of going through the DCS?"" A: ""No it would void the warranty, because we can't guarantee if the additional load on the PLC could degrade the performance of time sensitive programs on it"" ... a couple of weeks later after we were talking to an engineer from Siemens Q: ""Hey would it be possible to mirror the PLC with a <sorry I am blanking about the name of the connector ... UNP?UPNP? something like that>  and grab the data from the mirror?"" A: ""Yes this would work."" Q: ""Why didn't you tell us about that option when we asked about grabbing data from the PLC?"" A: ""Well you didn't ask about mirroring it""","","ü§£ (1),ü§¶ (1)"
"277515221885779970","jermuk","2023-03-21T19:09:39.4060000+08:00","the field of tapping into existing data in always a grey area. we've seen all types of approaches in various industries. some do not care at all (they just change stuff in the machine rack while the production is running, lol), and some do not want to touch it at all.

The only way to counter this if you do proper risk management. You need one person, who says that he will take the fall/ the risk if anything goes wrong and then often (but not always) machine vendors, etc. are also fine with it. if you then have a warranty problem, you can just disconnect the device and show that it is not the devices fault. for some machine vendors this is also a business model to charge significant amount of money for just tapping into the data and the only resolution is to swtich the vendor when procuring the next machine","",""
"1085244229548245124","martin1235961","2023-03-22T03:20:21.1550000+08:00","Thanks.","",""
"603301251177775104","asthomas","2023-03-22T03:31:12.0440000+08:00","DataHub is primarily an in-memory UNS that performs many-to-many protocol translation on the way through.  InfluxDB is optional, both as a historian and as a storage cache for store-and-forward.  You can use it to aggregate data from many edge systems into a central InfluxDB, where every edge can optionally also run a small store-and-forward InfluxDB.  In effect it will aggregate data from multiple edge systems to a central system with store-and-forward, so you don't lose data through a network outage.  Purging data is part of the configuration.  InfluxDB will purge data after a certain period of time, so you would typically set the retention policy on the edge to be relatively short.  There is also a mechanism to push or pull historical data depending on your network security requirements, and a way to bounce the real-time and historical data through a DMZ so you can have external access to plant data while maintaining plant network isolation.  And, if necessary, there is a mode where it will traverse a data diode, so long as the data diode supports TCP (many do).","",""
"1037102427985416202","loris6780","2023-03-22T06:19:15.6680000+08:00","Clear answer thank you ! Is a connection to PI and aveva historian directly possible without the influx db in between ? Like having OI server connected to cogent or a pi adapter ?","",""
"603301251177775104","asthomas","2023-03-24T01:39:16.7340000+08:00","Yes, a direct connection to PI and AVEVA Historian are both possible.  The connection to PI is via the web API, so loss of connectivity = loss of data for the period if you don't use InfluxDB as a local buffer.  Connection to AVEVA Historian/Insight goes through the AVEVA store-and-forward service already, so InfluxDB would be redundant.","",""
"1037102427985416202","loris6780","2023-03-24T21:14:09.2560000+08:00","Ok clear, I need use cases where I can understand the added value of the product but already thank you for your explanation","",""
"833941249362493450","sammysevens777","2023-03-27T13:25:35.3460000+08:00","Is there such a thing as a ""Master Factory Architecture""? I imagine it could be massive for some companies, but would be nice to see an architecture follow a sales order  converted to a finished good. Like a swim lane diagram with functions on y axis?","",""
"756247672637358181","sherylmccrary","2023-04-03T07:16:43.0660000+08:00","Pinned a message.","",""
"474394678750609408","douga.7429","2023-04-04T21:08:36.4410000+08:00","Would this be like  ERP and MPR modeling? Or, are you looking for a modern 4.0 take with a reference architecture that has this combined with UNS?","",""
"1031940518730543106","thunt.career","2023-04-04T23:26:08.7490000+08:00","Not sure if this is exactly what you are looking for but makes for a nice read https://factoryplus.app.amrc.co.uk/core-framework/","",""
"277515221885779970","jermuk","2023-04-05T03:40:20.5240000+08:00","post it again in a couple of days, those guys are currently updating it üôÇ","","üëÄ (2)"
"833941249362493450","sammysevens777","2023-04-05T03:40:53.3690000+08:00","Yes similar to ERP process modelling, but includes OT layers, and UNS. I am tempted to put something together myself and just share it here....","",""
"833941249362493450","sammysevens777","2023-04-05T04:05:48.0640000+08:00","This is phenomenal, great read. granular with clear examples. Thank you","",""
"817835202746253344","IIoT#4707","2023-04-05T04:05:48.2460000+08:00","GG @SamSon, you just advanced to level 11!","",""
"568913935147728896","zeratall","2023-04-05T04:41:13.4620000+08:00","Idk if there‚Äôs one in the public domain but as an architect that type of model is what I‚Äôm developing for my enterprise using Sysml and cameo","","üëç (2)"
"833941249362493450","sammysevens777","2023-04-05T07:24:18.0870000+08:00","Appreciate that, always good to learn a new tool.

That's cool....did you come from an IT or OT background, and how broad is your scope?","",""
"795178288330440704","youri.regnaud","2023-04-05T12:25:54.9480000+08:00","We have organized 2 days of workshops in Sheffield with the Factory+ teams, next week, to exchange on Factory+ around the topics of infrastructure, protocols, equipment management, ... Factory+ has done a great job and we really think that these 2 days will be beneficial for our IIoT teams. let‚Äôs see next week","","üëç (3)"
"743810005714600017","dep05d","2023-04-06T04:50:06.9420000+08:00","Eager to hear any feedback from your trip.  I hadn't read their content lately but we have started working on building our own services very similar to their consumption framework, so now we are taking pause to see if we should pivot to follow or adapt some of their methods.","",""
"833941249362493450","sammysevens777","2023-04-06T06:55:00.0910000+08:00","Sorry i missed responding to your longer comment yest, it was very insightful....maybe too much info to share? üòÜ","",""
"568913935147728896","zeratall","2023-04-06T07:58:38.5820000+08:00","Hahaha no worries and nah it was generic enough and it was a methodology/approach I developed myself, just thought the post was a little on the long side so I felt bad lol.","",""
"568913935147728896","zeratall","2023-04-06T07:59:11.8760000+08:00","At the end of the day it just goes back to good Systems Engineering","","üíØ (1)"
"753688565807841492","ravil1","2023-04-12T10:33:19.2250000+08:00","I saw some discussions about historians vs open-source databases and collectings data from OPC UA Servers and storing/forwarding to those databases. 
Maybe you could look at our product ogamma Visual Logger for OPC. You can connect directly to PLCs if they support OPC UA, or use Modbus OPC UA Server to connect to older devices over Modbus. 
Then your data can be forwarded to all popular time-series databases as well as MQTT.  
For details please refer product web page: https://onewayautomation.com/visual-logger","",""
"477398944234733568","alexanderbattisti","2023-04-12T17:25:54.1390000+08:00","This looks interesting for my use case. Is there an example how bulk configuration from CSV files would look (I couldn't find it in the documentation)? ... ah damn no Alarms & Events support yet (and it looks like it does not backfill data via OPC UA historical access in case it's connection to the OPC UA server went offline?)","",""
"1027653517386727548","jorgenk1000","2023-04-13T02:44:48.4270000+08:00","Not sure whether to put this here or in the UNS channel but I guess it is kind of architecture related. How do you solve multi-site and even multi-site across different countries with regards to enterprise wide UNS? Do you chose a cloud based broker like HiveMQ cloud? What are the pitfalls to look out for when rolling out this sort of architecture? I guess it would make sense to have a UNS at each site and one central UNS at the enterprise main site or would you distribute to even a country based UNS? Appreciate any inputs to this topic","",""
"603301251177775104","asthomas","2023-04-13T03:52:18.7420000+08:00","We generally recommend having a UNS at each site, and then forwarding (some portion of) that data to the central location.  If your wide area network goes down you still have local operations until the network is back, and then the central location catches up afterward.  In some cases you might want to have a UNS at each process area, aggregating that centrally within the plant, then up to the central location.  That lets your system degrade gracefully when a network link fails.  Check out Cogent DataHub's tunnelling feature for how that's done in practice.","",""
"1027653517386727548","jorgenk1000","2023-04-13T03:59:47.0360000+08:00","Thanks for your reply. So you use Cogent for communication between the sites?","",""
"833941249362493450","sammysevens777","2023-04-13T07:04:07.0910000+08:00","Since this is a safe space üòÜ  what's the difference between a historian and an ""open-source database"". Maybe it's worth sanity checking myself....a historian is industry speak for database more or less right (or closer to a log?)....is it that historians are usually tied to a product that has other capabilities (And so it acts as a database for a specific product?), while open-source means you can use with whatever/however you want?","",""
"254777321788145664","terrancesmith","2023-04-13T07:32:08.7160000+08:00","Check this article out. It does a great job comparing the two.  They are very similar, but the differences are important. https://learn.umh.app/blog/historians-vs-open-source-databases-which-is-better/","",""
"833941249362493450","sammysevens777","2023-04-13T07:45:29.6490000+08:00","Fantastic article, thank you for sharing....from what I read the main distinction comes down to this: *(A historian) stores data and allows the OT engineer to query the data using their language and the models they know (without needing to worry about ""crashing"" / overloading the database) using drag-and-drop UIs. *. So it's the GUI on top of the database to help OT folks interface with a database?","","üíØ (2),üëç (1)"
"603301251177775104","asthomas","2023-04-13T18:46:06.9960000+08:00","That's right.  If you want to keep the sites isolated from one another you can run Cogent DataHub on Azure, for example, as a point of contact for data that's being shared among plants.  In effect it lets each plant import data into its UNS from a shared subset of the UNS from another plant.","",""
"1027653517386727548","jorgenk1000","2023-04-13T22:45:49.2920000+08:00","Gotcha, thanks for the explanation, sounds like a great way to solve it üëå","",""
"801561312861618236","jon.forbord","2023-04-14T00:58:27.9770000+08:00","Historians can also generally speak natively to OT assets. They also have generally better compression and are designed to be used to monitor processes in real time (as they happen).","","üëç (1)"
"833941249362493450","sammysevens777","2023-04-14T03:02:48.7780000+08:00","Thank you....real happy I asked and got this clarified!","",""
"801561312861618236","jon.forbord","2023-04-14T03:06:12.5110000+08:00","It‚Äôs important to understand a ‚Äúhistorian‚Äù is more than a database, it‚Äôs more of a solution with tools to collect, store, analyze and visualize time series data from operational assets, while open source DBs are mostly just the DB.","",""
"833941249362493450","sammysevens777","2023-04-14T03:14:09.6180000+08:00","I genuinely did not know that, and that is a helpful distinction. would you consider a product like SSMS to be a historian?","",""
"801561312861618236","jon.forbord","2023-04-14T03:15:37.2760000+08:00","SQL server management studio?","",""
"833941249362493450","sammysevens777","2023-04-14T03:17:14.4970000+08:00","yes, or maybe better comparison is SSRS? I ask because when I visited many of our EMS factories around Asia, I didn't see historians, but i saw a lot of SSRS for OT reporting, so I wonder if use cases could be interchangeable?","",""
"801561312861618236","jon.forbord","2023-04-14T03:18:48.6560000+08:00","Not anyone I know would consider those historians.. Canary, OSI PI..","",""
"833941249362493450","sammysevens777","2023-04-14T03:20:49.3180000+08:00","so more like ETL + BI tools = historian? Is there any equivalent IT tool stack, or are historians really unique OT tools (in the way that a PLC is somewhat unique). Cause if people are comparing historians to open source databases....based on what you're saying, there is a deep lack of understanding of what historians are","",""
"568913935147728896","zeratall","2023-04-14T03:21:11.0300000+08:00","To @Jon Forbord point a historian is a solution designed specifically for time series data, and in addition to the db optimizations (query performance, compression, Auto Tag recognition, etc) it supports various capabilities that are specific to time series data. That being said can you log time series data to a RDBMS‚Ä¶..absolutely can, is it the best solution for time series data, absolutely not. Especially when you start to talk about scale.","","üíØ (1)"
"568913935147728896","zeratall","2023-04-14T03:22:46.5160000+08:00","A TSDB is a type of NoSql db, it has nothing to do with open sourceness","","üíØ (1)"
"568913935147728896","zeratall","2023-04-14T03:22:58.8880000+08:00","That being said a lot of NoSql db are open source (which is where part of the confusion is prob coming from)","",""
"801561312861618236","jon.forbord","2023-04-14T03:23:54.3300000+08:00","More like influx DB + grafana + telegraf.. but this still isn‚Äôt quite there yet, but closer.","","üëç (1)"
"801561312861618236","jon.forbord","2023-04-14T03:25:09.5110000+08:00","It‚Äôs not ‚Äúunique‚Äù in any sense, but it is uniquely designed for OT problems..","","üíØ (1)"
"833941249362493450","sammysevens777","2023-04-14T03:28:08.7390000+08:00","Very insightful....and from a use case perspective, is the historian concept intended to empower OT teams to interface with their data, vs. being reliant on IT? These are still ""IT"" solutions, but manageable by OT teams? Is that the point (because influx + grafana + telegraf is out of scope for most OT teams)?","",""
"568913935147728896","zeratall","2023-04-14T03:30:20.0540000+08:00","I think governance is another aspect that is left to the architect. Aka it‚Äôs not specific to the technology. At its core TSDB allow you to log tags at scale that would be resource intense in an RDBMS. That being said for governance you could have a historian at the site level that is managed and controlled by the OT personnel, and also have a historian at the factory/enterprise level that is managed by an IT group","","üíØ (1)"
"801561312861618236","jon.forbord","2023-04-14T03:31:06.8700000+08:00","Yes ish. You‚Äôre on to it. Influx + grafana + .. is used by some OT teams, either because they have more time than money or because they will sell what they develop as a product to others.","","üëç (1)"
"801561312861618236","jon.forbord","2023-04-14T03:33:12.3230000+08:00","So where I‚Äôve seen the most adoption of this combo is with OEMs, integrators making some form of IoT product to sell to customers..","","üî• (1)"
"833941249362493450","sammysevens777","2023-04-14T03:34:44.8520000+08:00","Great feedback, thank you guys!","",""
"568913935147728896","zeratall","2023-04-14T03:40:55.1610000+08:00","Absolutely @SamSon , one thing I want to point out also is we often talk only about historians or TSDB because most individuals are interested  in machine data. But in iiot architecture your going to have a lot more then just time series data. For example you might have relational/transactional data, you might have objects or files. Proper iiot architecture deploy multiple data storage strategies and solutions based on what types of data they are dealing with.","",""
"568913935147728896","zeratall","2023-04-14T03:42:46.7180000+08:00","For example I might have some thermal chambers they are logging machine data and dumping that into a historian like canary. But I might also have calibration data aka when a machine was last calibrated how long that calibration is good for etc in a SQL db. The architecture needs to be able to work with both data stores and contextualize that data for use by other consumers","",""
"833941249362493450","sammysevens777","2023-04-14T03:52:29.0360000+08:00","This is a really great point.....and definitely need multiple methods to store / manage data.....is that a pretty good justification for platforms like ignition, in that you get the inherent scalability that irrespective the data source... You hav a platform that can handle and scale as needed (requiring dev. work of course).

Otherwise you may be managing point solutions....i ask because this is exactly what im in front of. We have 5 data collection projects across our facility, all with their own monitoring/control requirements. I have started developing web apps using flask.....but, maybe i should develop in ignition (their historian, connectors, interfaces, etc )instead (its on me to do data collection e2e - small team). So instead of developing and maintaining a local SQL DB (few transactions a second) and tables, just use ignition....im genuinely not sure whats the best architectural approach here....i also thought of hosting  a mosquitto mqtt broker..","",""
"568913935147728896","zeratall","2023-04-14T04:04:45.7450000+08:00","Will respond in a few at the gym lol","","üòÜ (1)"
"568913935147728896","zeratall","2023-04-14T05:09:10.4240000+08:00","Yeah that is exactly right, if you think of a I3.0 Architecture, what would happen is if we had 2 applications that we wanted to pull data from into a single new application, we would have to create an interface for the two other applications into our new application (aka a bunch of point to point integrations). That's all fine and dandy until were talking about large scale applications where the management of interfaces becomes very unmanageable (MSA has the same issues btw). That's where something like Ignition, or really any type of application that does data modeling/data contextualization really plays a key role. 

We can create a model of our data around how we believe it should be structured, and then map the various data sources to the properties of that model definition. So for example I could have a single data model for ""Thermal Chambers"" On that model definition I could have a property ""Calibration Date"" that pulls from my SQL database,  and then I could have other properties like ""Status"", ""Job Number"" etc that are pulling data from the machine itself. The result is a single data structure (Could be a UNS, or some other structure you define) that is modeled how you believe the data should be represented and easiest for other consumers to consume, that data can then be fed to other data consumers. 

There are several tools that handle Data Modeling/Data contextualization, Ignition, Thingworx, Intelligence Hub. I personally prefer Intelligence Hub, because I like to apply SRP to architecture, aka data contextualization IMHO should be its own separate layer of the architecture, not embedded into another application that does other functions like it would be in ignition or thingworx. It's my personal belief that applying SRP when possible helps with scalability tremendously (although its more expensive).

The beauty of what Walker teaches is applying data contextualization in a distributed fashion, meaning Factory 1, Factory 2, Factory N has their own data model that they control, that can then feed into an enterprise data structure (UNS). This is an awesome design pattern, because it allows the OT layer to control how they model and handle data at their own level, and then they could push their data model to the enterprise level, at the enterprise level your UNS would subscribe to all the UNS defined at the factory level. This creates a really nice flexible design pattern, where OT can use the data how they want, and then that data can be pushed to the IT level where IT governs/manages it.","","üî• (1)"
"867075936054149191","rickbullotta","2023-04-14T05:11:41.5370000+08:00","You can implement a historian/time series database in ANY DATA STORAGE YOU WANT.  Some are more efficient than others.  Some are cheaper than others.  Some are more performant for ingest.  Some are more performant for query.  Some allow you to update data and deal with random timestamp arrival.  Some don't.  Some make it easy to purge and archive.  Some don't.  Some are simple, single sensor streams.  Some can support complex data with tagging and context.  Some require virtually no administration after installation.  Some require constant care and feeding.","",""
"867075936054149191","rickbullotta","2023-04-14T05:13:12.1800000+08:00","Going one step further, modern thinking on time series data leans towards multi-modal storage for hot, warm and cold data.  Typically in-memory (checkpointed to storage) for hot, some type of NoSQL or proprietary format for warm storage, and blob storage (often Parquet format) for cold storage.","","üëçüèª (3)"
"568913935147728896","zeratall","2023-04-14T05:18:13.8500000+08:00","That‚Äôs interesting ty for the info, I would love to see how the mechanics work under the hood, I wasn‚Äôt tracking they were  multi-model but it makes sense","",""
"867075936054149191","rickbullotta","2023-04-14T05:19:45.4100000+08:00","Interestingly, even if you used something like SQL Server or PostgreSQL ""raw"" for your time storage, you'd indirectly get the benefit of some ""hot storage"" due to caching.","","üëçüèª (1)"
"568913935147728896","zeratall","2023-04-14T05:20:15.4660000+08:00","Yeah I was reading a timescaleDB article and they were talking about that since it‚Äôs relational under the hood and not NoSql","",""
"867075936054149191","rickbullotta","2023-04-14T05:20:53.9190000+08:00","The other thing to consider is that the cost of each of those types of storage is increasingly less expensive as you go from memory to blob storage.  It's helpful to be able to ""tune the dials"" for retention in each of those buckets based on need/cost.","",""
"568913935147728896","zeratall","2023-04-14T05:21:36.9190000+08:00","Yeah totally","",""
"568913935147728896","zeratall","2023-04-14T05:22:49.9960000+08:00","My side hustle (application to analyze race car performance) does that, for hot data it‚Äôs all in memory and cold data gets stored in a blob since blob is so cheap. You‚Äôd be surprised how much memory you start utilizing when your talking about high sample rates and a lot of different signals. Same reason I have an appreciation for real time graphing lol","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-04-14T05:25:39.2020000+08:00","For sure.  While it's not race car suspension level, I've done some high speed DAQ in the past.  Requires a different way of thinking!  And the funny thing is that many data storage options can't handle data > 1KHz due to the way they store timestamps (SQL Server can't even handle 1KHz!)","",""
"568913935147728896","zeratall","2023-04-14T05:27:07.9230000+08:00","Hahaha yep exactly, that‚Äôs why I love little side projects you always end up learning so much","",""
"833941249362493450","sammysevens777","2023-04-14T06:07:43.4540000+08:00","Bam! Got it, and on point Rick, thank you both....I need to sit on this for a bit and map out something that is going to ultimately make my life easier....and I'm glad before I got into the custom python apps....spoke to you guys about architecture, very helpful!","",""
"568913935147728896","zeratall","2023-04-14T06:18:36.4560000+08:00","Of course man always here if you have questions there are tons of really knowledgeable people on this discord, but I love talking architecture, that‚Äôs my day job Hahahah, love discussing different design patterns","","ü§òüèº (2)"
"794542235676180500","akoscs","2023-04-14T17:45:50.7150000+08:00","Kind of ,yes, but taking Influx as an example, it does have telegraf (almost integrated) it does have a dashboard...","",""
"477398944234733568","alexanderbattisti","2023-04-14T19:31:07.8630000+08:00","The storage engine of the process historian that is part of the Siemens PCS 7 DCS is just a normal MS SQL Server. For the Siemens T3000 DCS it is just a MySQL DB. So I doubt that there is anything ""special"" about process historians apart from some having storage engines that are more efficient when storing timeseries data or logging events and bundling a set of (important) tools that are familiar to the operations people.","",""
"603301251177775104","asthomas","2023-04-14T22:10:06.3210000+08:00","FWIW, we use InfluxDB because it requires almost no knowledge or setup.  We put a couple of buttons on our interface to launch InfluxDB, Grafana and Chronograf, and that's all the knowledge the OT team needs - up to a point.  Things get more complicated when you want high availability and sharding, but as a basic local TSDB, we have found it the simplest by far.  It's even simple enough that we can use it as an edge cache for store-and-forward.","","üëç (2)"
"1031940518730543106","thunt.career","2023-04-14T22:34:53.2310000+08:00","Still waiting on the 2023 update... any news?","",""
"1031940518730543106","thunt.career","2023-04-14T22:35:27.4270000+08:00","Started a thread.","",""
"277515221885779970","jermuk","2023-04-14T22:41:37.5830000+08:00","me too, to be honest. let me ask them üòÑ maybe they were busy because @youri.regnaud was visiting them üòÑ","","ü§£ (1)"
"277515221885779970","jermuk","2023-04-15T02:41:45.1500000+08:00","ok, the release is now still a couple of weeks in the future","","üëç (1)"
"753688565807841492","ravil1","2023-04-18T12:52:11.1870000+08:00","Hi Alexander,
Sorry for the delay, I did not get a notification from Discord.
Import from CSV file is described in the How To section of the User Manual: https://onewayautomation.com/visual-logger-docs/html/howto.html#import-variables-from-csv-file
But soon you might manage without importing or manual selection of nodes altogether. A new feature is coming: you can set some Python script, which will be called during the process of server address space discovery, and there you can mark what nodes to log, with what options (sampling rate etc.), and how to map to target time-series database.
Yes, Alarms & Events are not supported yet.
And no reading history from the OPC UA server, only subscriptions plus optional periodical polling. If there are more requests from the community to add this feature, can be done. In short, if the OPC UA server supports history, then we could first read history from some starting time point up to now and then continue getting real-time data over data access. And for disconnected periods to fill data gaps by history read calls.","","üëç (1)"
"753688565807841492","ravil1","2023-04-18T13:12:13.6270000+08:00","In my understanding, your definition of the historian is correct in this context. And yes, they are tied to or part of a specific product. So I think they might have the functionality to store data, as well as to read data back. 
Speaking of reading history back, usually, they support a whole bunch of ways of processing data: like minimum for some time window, maximum, average, etc. In OPC UA they are called aggregate functions.
Among open-source databases, some are more generic: like PostgreSQL, and some are closer to historians, like InfluxDB - it is designed to store time-series data from scratch.  For PostgreSQL, there is the extension TimescaleDB - which makes it closer to historians, because it adds extra features to support storing time-series data. And they also support different ways of reading data back - and in some use cases, it is possible that they have all the processing features you need from historians. In such use cases perhaps an open-source database like InfluxDB can satisfy all your requirements. And also it might be easier to integrate them with OT side applications - because they are already used in OT, for example, SQL servers are kind of standard in OT.","","üíØ (1)"
"898217314741280828","hobbes1069","2023-04-18T22:04:53.3070000+08:00","I haven't put TimescaleDB in production yet, but I am running a PoC and so far it has performed very well.","",""
"474394678750609408","douga.7429","2023-04-18T23:18:42.4150000+08:00","I want to point out that his distributed data contextualization approach, where each factory has its own data model feeding into a higher-level enterprise data structure (UNS), is an excellent example of applying Conway's Law.

Conway's Law states that organizations will design systems that mirror their own communication structure. In Zach's approach, the design of the system reflects both the decentralized nature of factory-level operations and the centralized nature of enterprise-level data management. This alignment leads to improved efficiency, scalability, adaptability, and better collaboration and information sharing throughout the organization.

By allowing each factory to have its own data model and control over how they handle its data, the system design acknowledges the specialized knowledge and understanding of their respective factories. This mirrors the decentralized communication and decision-making structure within the company. At the same time, the higher-level enterprise data structure (UNS) consolidates the data from all factories, reflecting the organization's need for centralized information sharing and management.

In conclusion, Zach's approach demonstrates a practical application of Conway's Law by designing a system that aligns with the organization's communication and decision-making structure, resulting in a more effective and collaborative system overall.","","üî• (2)"
"919232821476851783","petrusaraujo","2023-04-20T12:02:18.5170000+08:00","I may already know the answer, but how could I learn more about the data contextualization and model being owned by every plant and how to explain to business the importance of having it close to the datasource as possible to not overload IT with curation activities?

Here, the main solution has been Azure. ERP, MES Camstar/Rockwell, LIMS, PLM are all sending tables to Azure Databricks environment. There‚Äôs a missing part related to the data from machines, where we have legacy and new ones. They propose azure iot hub as solution. I don‚Äôt know if this is the right approach. 

One site is proposing using siemens iot 2050 to connect machines, use node-red and send the data to solutions like Highbyte and the data could arrive in azure to correlate with other info. At the same time, other sites are still improving MES, connecting them to machines to improve electronic batch records. At the end, we have big ships (functional areas) that have separate objectives and are hard to move‚Ä¶","","üëç (1)"
"817835202746253344","IIoT#4707","2023-04-20T12:02:18.8490000+08:00","GG @Petrus, you just advanced to level 1!","",""
"1087323187454410762","benjaminsynsor","2023-04-20T15:34:49.9160000+08:00","Hey everyone, question that somewhat relates to what @Petrus has asked:
What do you think of the approach some German automotive companies are taking with Cathena-X (to also solve data contextualization issues i assume)? 
https://www.linkedin.com/posts/joergwicik_video-message-by-robert-habeck-catena-x-activity-7054502709017595904-dX5G?utm_source=share&utm_medium=member_desktop

The way I currently see it, superficially it's about accepting commonly agreed standards for data but so much of it seems wrong for me:
- How do you keep your companies unique processes alive in a ""least common denominator"" approach
- Who is allowed to even make changes to the standard? It takes away all flexibility
- It's the opposite of agile
- Incentives of participants can't always be aligned, but there is no way to resolve it if you are bound to a common system (see Germans abusing Euro currency zone - I say that as a German)

Etc.
@Marc J√§ckle you mentioned a lot is being invested here, any opinion?","",""
"477398944234733568","alexanderbattisti","2023-04-20T21:01:43.6100000+08:00","To me (a German who previously worked for a small supplier of BMW, VW, and Daimler) this looks like a corporate welfare program for members of the Catena-X Automotive Network e.V. (e.g. Accenture, Deloitte, IBM ,T-Systems and SAP... and Palantir?!?!) and maybe the biggest automotive suppliers.

I can't see BMW, VW, Merceds, and Siemens voluntarily agreeing on anything that would require non-trivial changes **from them** in how they deal with their suppliers. So I assume the ""standard"" will be a  complicated, contradicting mess of requirements that is a super set of all their current requirements. Very hard, if not impossible for small to medium sized suppliers to fulfill/get certified without the ""help"" of above mentioned members of the Catena-X Network. 

Suppliers that are not able to afford this will either go bust because they won't be able to sell to their biggest clients anymore or be bought for cheap by Bosch, Continental or ZF (who are all members of Catena-X e.V. ) .

Best case is probably that this initiative will be quietly shutdown after a couple of years but this would require some other German digitalization success story.","","üëç (2)"
"474394678750609408","douga.7429","2023-04-20T23:11:08.0750000+08:00","Interestingly, you used the terms ships. I came to find that there were what I called Data Pirates in IT.  And their booty was information they could gain from their misadventures in dealings with data transport.  When considering the UNS architecture, I see it as a way to get IT out of that pirate role. 

I think the key is to make an architecture that makes the data seas safe from IT data pirates.  Having built a production operations data warehouse that established KPIs like OEE, I often used this data pirate metaphor.  The drama and political fallout became too much, and I jumped ship. 

Now that I am out on the market, I see this dynamic everywhere.  Many are on their second or third Digital Transformation, and IT is full of Data Pirates.  I think more than a DTMA is needed for organizations rebooting like this.  So, I have been thinking a lot about what an ideal Ind. 4.0 edge-driven MES looks like.  There should be a way to have a ""self-aware"" analysis layer like what Walker has been doing for SCADA.  My Power BI frontends were of a similar ""self-aware"" design.  

The Data Pirate Captains of the MES ships were not playing nice too. So I have also been thinking a lot about what an edge IoT MES device or template should encompass.  This would allow for a way to put IT back in a service role and focus on running data transport vs. highjacking information. I think the Edge Object definition should carry up not only to the SCADA layer but also the analytical layer.  These MES IoT devices should also endeavor to embrace the IoT ideals that create industry 4.0 expectations and allow for additional units to be added seamlessly to an MES infrastructure and have visibility, control, and analysis with minimal configuration.","","ü¶æ (1)"
"794542235676180500","akoscs","2023-04-21T01:27:47.5680000+08:00","There are at least 5-10 very similar programs with somewhat similar goals in Germany. These eventually may lead to some cool stuff, but not directly, in most cases in a very indirect matter (like people working on the project gain knowledge/network/experience and start their own company, independently of the program)","","ü§ì (1),üíØ (1)"
"833941249362493450","sammysevens777","2023-04-21T12:36:46.6750000+08:00","Walker said this very well - fight the results war - demonstrate why your approach is better. IT is a really odd department....some guys are legit IT guys, most are glorified program managers...","",""
"893960745467912254","jwolk","2023-05-01T09:31:12.5600000+08:00","I don't know how quick you need to integrate machine data, but I would like to suggest IIH (Industrial Information Hub) solution, from Siemens. It's an out of the box solution for data contextualization, in a distributed and Edge Driven way. Here is a link to know more about that https://customerinfo-siemens.highspot.com/viewer/6436462d6739fbb94ba0c3a9","","ü¶æ (1)"
"893960745467912254","jwolk","2023-05-01T09:41:06.7650000+08:00","This approach it's similar of how BIM (Building Information Modeling) initiatives groups has been discusting for O&G (Oil and Gas) and AEC (Architecture, Engineering and Construction). It's about how to exchange engineering information considering geometric and non geometric data, using a Neutral format to promote interoperability between engineering systems. In the BIM context, BuildingSmart (https://www.buildingsmart.org/) has describing IFC format.","",""
"277515221885779970","jermuk","2023-05-17T22:47:32.1510000+08:00","Hi, are there any experts from pharmaceutical, energy or process industry here using Historians? I am currently writing an article about Compression and Retention in Historians vs Open-Source Databases, and could use some expert input. Feel free to write me a PM if you are interested in giving feedback.","","üëç (1)"
"898217314741280828","hobbes1069","2023-05-17T23:27:59.3220000+08:00","Definitely interested in the results!","",""
"908341993820811295","chris.demers","2023-05-18T18:58:00.6500000+08:00","@MikeBartlett worked at OSIsoft specifically in the Life Sciences vertical for many years.  I also work in life sciences and can probably find answers to questions through contacts if you have them unless in the off chance I can answer directly üòÄ","",""
"908341993820811295","chris.demers","2023-05-18T19:00:21.2000000+08:00","I heard stories from one of our sites about ‚Äúcompression related deviations‚Äù due to the fact that PI interpolates data","",""
"914993398526656542","mikebartlett_nh","2023-05-18T20:13:11.3950000+08:00","Thanks @chris.demers.  @Jermuk happy to help!","",""
"891563487241842699","jbonhage155","2023-05-18T22:16:33.1340000+08:00","Here's a link to PI (Aveva) on some of the parameters used by the PI data archive:
https://docs.aveva.com/bundle/pi-server-da-admin/page/1022865.html

Specifiically the CompDev and ExcDev functionality is pretty good and I'm curious how other historians stack up.
Also PI support different scan classes.","",""
"277515221885779970","jermuk","2023-05-18T22:17:58.3130000+08:00","there is also a very good video of them explaining it! https://www.youtube.com/watch?v=89hg2mme7S0","","üëç (2)"
"277515221885779970","jermuk","2023-05-18T22:18:18.6430000+08:00","let me work in the first feedbacks that I got and get back to you @MikeBartlett @chris.demers  @Joe Bonhage","",""
"891563487241842699","jbonhage155","2023-05-18T22:19:30.8080000+08:00","Ah yes, great video! I remember how easy it was to get support / learn about PI. Oh please Aveva don't screw it up, LOL.","","üòÄ (1)"
"277515221885779970","jermuk","2023-05-18T22:22:49.0120000+08:00","dont want to be a downer, but on hannover messe we did not meet a single guy who could properly explain the PI system and the slides they showed us were from 2021 üòÑ on the schneider electric stand.","","üò¢ (1)"
"914993398526656542","mikebartlett_nh","2023-05-18T22:32:29.3150000+08:00","I'm sure those were mostly legacy AVEVA people, unfortunately.","",""
"914993398526656542","mikebartlett_nh","2023-05-18T22:34:09.0770000+08:00","I was thinking of this video from training after I read your message.  Those slides could be around 25 years old, but still valid.","","üëç (1)"
"914993398526656542","mikebartlett_nh","2023-05-18T22:36:04.7210000+08:00","And on a tag by tag basis you could turn the exception and compression features off and store everything.","",""
"891563487241842699","jbonhage155","2023-05-18T22:39:27.9590000+08:00","@Jermuk can you buy PI from Schneider and integrate into UMH?","",""
"891563487241842699","jbonhage155","2023-05-18T22:39:46.3990000+08:00","#savePI-today","",""
"914993398526656542","mikebartlett_nh","2023-05-18T22:43:53.1930000+08:00","This is probably administrative error in the tag configuration, or user error in the way they asked for the data.","",""
"891563487241842699","jbonhage155","2023-05-18T22:47:51.7260000+08:00","True, and interpolation can be disabled?","",""
"914993398526656542","mikebartlett_nh","2023-05-18T22:59:47.6250000+08:00","Interpolation is dependent on what query you use to fetch the data.  If you do an archive or compressed data call  (either via PI DataLink or the API/SDK), and you set the arguments right, the function will return all events in the time span, no interpolation.  If you do a call for evenly spaced data (like hourly over the day), more than likely the value at the top of the hour is a time-based interpolation between the closest two archive values before and after the top of the hour, unless the data source puts out a value at 00:00:00 every hour.","",""
"867075936054149191","rickbullotta","2023-05-18T23:11:51.1250000+08:00","One could argue that with SSD costs per GB at practically nothing, storage compression doesn‚Äôt add much value anymore.","","ü§î (1),üíØ (2)"
"277515221885779970","jermuk","2023-05-18T23:17:59.9590000+08:00","thank you for writing that earlier to me, I think it gave the article an entire different direction.

@RickBullotta @MikeBartlett @chris.demers I send you all a preliminary version of the article (again). It would be really good to get your thoughts on that.","",""
"914993398526656542","mikebartlett_nh","2023-05-19T00:10:05.2120000+08:00","My advice was always to set the compression to try and match the turndown/accuracy of the instrument.  Reducing noise and only recording the ""good"" data definitely increases query performance.","",""
"898217314741280828","hobbes1069","2023-05-19T02:55:18.3560000+08:00","It wouldn't surprise me if the could providers are not already compressing the data but still charging you for the full amount unless you pay top $ for high performance SSD.","",""
"1089192477837230181","philfreeman","2023-05-24T05:46:03.3110000+08:00","In case you missed it, the AMRC has recently released a much more comprehensive specification and reference implementation of Factory+. https://factoryplus.app.amrc.co.uk/. This covers not just the protocol layer, but requirements and conforming opensource implementations of services that provide a (nearly?) full solution stack for a universal namespace on MQTT/Sparkplug.

From the ""What's New""
""In 2023, we have not only revamped Factory+ to outline a comprehensive list of components that we deem essential for a state-of-the-art IIoT architecture, but we have also created a complete, MIT-licensed open-source rendition of the framework, dubbed the AMRC Connectivity Stack. This stack is provided as a Helm chart for Kubernetes and can be deployed by anyone on any Kubernetes cluster using just a few simple commands.""","","üî• (2)"
"568913935147728896","zeratall","2023-05-27T00:41:19.6200000+08:00","Just finished this book and wanted to share, really good book and especially relevant to what walker preaches and I4.0 in the EDA section.","https://cdn.discordapp.com/attachments/815945777452941313/1111695575683960892/IMG_7243.png?ex=68df53ef&is=68de026f&hm=3635a06b6237ae03702a264009298baa6d5b8a5fb66699f5fb1da426290dd7b8&","üíØ (1),üëç (2)"
"568913935147728896","zeratall","2023-05-27T00:42:06.3880000+08:00","Also appreciate the author taking a domain modeling approach when explaining the different data needs and considerations for different domains.","",""
"277515221885779970","jermuk","2023-05-31T00:46:10.5960000+08:00","nice! this looks like this is my new book that I'll be reading","",""
"608421038283423810","danmac.","2023-06-26T09:58:51.7940000+08:00","hi","",""
"277515221885779970","jermuk","2023-06-26T18:51:39.2240000+08:00","hi?","","üòÇ (2)"
"323209031076413443","uddersnz","2023-06-29T05:48:59.3140000+08:00","hi!

but also...
Hey folks,

Looking for some feedback around a sensible system architecture for the company I work for.
We are a small machine-building company with around 100 machines across 20 client sites.

We are publishing machine state, faults, and MES data to a site MQTT broker.
What we are looking for is centralised dashboards and reporting at our head office.

Was thinking along the line of bridging site brokers back to a head office broker.
We'd like to do this as cheaply as possible (obviously!) but more importantly not to spend money where it won't help.

We're considering Ignition, but I've heard the historian is average (although the price is good) and the reports and charting don't look great.
As such, I'd probably be looking at using Python to implement excel charts for our reports.

Would I be better off focusing on a dedicated historian like Canary, and using its visualization tool for dashboards?

Any feedback welcomed, where is the best place to focus funds to get things moving?

Ta for any advice!","",""
"323209031076413443","uddersnz","2023-06-29T05:50:05.6710000+08:00","Sample of shift report chart, that I figure will need to stay in Excel:","https://cdn.discordapp.com/attachments/815945777452941313/1123732079151165520/image.png?ex=68def38d&is=68dda20d&hm=e5a1c064646e7c95c7f8fa90dec1aff2bf113c0fe0290da832a19f212b4769af&",""
"475955754788978688","jdingus","2023-06-29T18:00:26.6490000+08:00","I have Cogent DH on my list to review.  Can you speak to the pros and cons?","",""
"348877771705155584",".2rd","2023-06-29T18:06:08.6470000+08:00","windows only. propriatary tunneling SW (vendor lock)
Buts seems really efficient to use","",""
"475955754788978688","jdingus","2023-06-29T18:10:02.5130000+08:00","Curious to the cost?  How does it position up against highbyte seems to be some overlap there.","",""
"348877771705155584",".2rd","2023-06-29T18:32:05.7970000+08:00","Unsure, we decided not to go for that solution. No prices on the webpage!","",""
"745796393855352953","thedavidschultz","2023-06-29T19:18:33.9140000+08:00","I used Cogent DH mainly to connect to OPC DA to expose the data as an OPC UA endpoint. It also supports MQTT/SpB and has smart broker than puts messages in order. Lots of other endpoints, but the flatform only translates data. It does not model the data like HighByte. It only runs on Windows. Pricing is available at Software Toolbox. OPC product is $1500.","","üëç (1)"
"801561312861618236","jon.forbord","2023-06-30T01:33:29.3100000+08:00","If I were in your shoes, I‚Äôd consider looking at timescaleDB/influx + grafana/powerBI if what you mostly want is dashboards and reporting. Canary can make some decent dashboards, but their reports are essentially screenshots of dashboards at a given time. Never tried Ignitions reporting, but I have the same impression as you. Making dashboards in Canary is very efficient, but less flexible than Ignition. As you‚Äôre already on mqtt, trialing Canary can also be a good first step. They gave me a 6 month trial with 40k tags. We use both Canary and Ignition, and use Canary for more ‚Äúsimple‚Äù dashboards and Ignition when we want to do things that require more flexibility than Canary.","",""
"323209031076413443","uddersnz","2023-06-30T13:29:05.3610000+08:00","Thanks for the insights @Jon Forbord. Will have a bit more of a dig around those options.","",""
"277515221885779970","jermuk","2023-06-30T14:46:20.1920000+08:00","If you want to go for TimescaleDB and Grafana, you could also look a the open source United Manufacturing Hub. It bundles them together with HiveMQ, Node-RED, etc into an easy to use package","","üëç (1)"
"348877771705155584",".2rd","2023-06-30T14:55:35.4910000+08:00","Unless they have experience with Grafana and timescaleDB/influx, coupled with high general SQL knowledge. Then i would go for a ""managed/licensed"" solution such as Canary or Ignition. Building your thing from scratch using open-source takes time, and has certain risks assosiated.

Although the performance of the Ignition historian is not great, I think it is fine for most cases. You can always move your data later if you are not happy.","",""
"808077381503680542","andymellor","2023-07-05T01:49:26.4990000+08:00","Duncan, you sound like you might be UK/Ireland based. I represent Tatsoft and Canary and can probably help you out if you need anything. Just DM me if I can help.  If cost is important to you, you might want to look at Tatsoft with the embedded Canary historian.","",""
"794542235676180500","akoscs","2023-07-05T04:15:26.9740000+08:00",":)) because ""Will have a bit more of a dig"" ?","","üòÜ (2)"
"323209031076413443","uddersnz","2023-07-05T04:33:55.2880000+08:00","Haha! Nah I'm from New Zealand, so geographically distant, but dialectically adjacent! Also, Mum was born in England. 

Thanks for the heads-up, forgot that Tatsoft had some embedded Canary. Ignition is gaining traction over here in NZ, Tatsoft not so much. I only got into Ignition training through the mentorship, and the level 2 Tatsoft stuff hasn't really happened yet. Tatsoft need to push harder for that! I think it would benefit them greatly!

I'll look into the pricing and cost benefits of Tatsoft. Thanks for the pointer, that's super helpful!","",""
"323209031076413443","uddersnz","2023-07-05T04:35:46.5000000+08:00","Ah, good to know. I stumbled across some UMH docs, but hadn't heard of it before, I'll take a closer look.","",""
"323209031076413443","uddersnz","2023-07-05T04:42:02.6610000+08:00","My boss has  some grafana experience, and I've done enough sequel to not be scared of it, but just a few too many learning curves to know how to fit it all together into a good solution. So, yes was looking for a slightly more curated approach, to speed the development process.
Just talking to a guy at one of our sites, and he's used Ignition with their sql module to do custom sql logging as controlling the table structure worked better for his needs. But I feel like this would miss a bunch of the functionality of a true historian.","","üëç (1)"
"323209031076413443","uddersnz","2023-07-05T08:51:50.9630000+08:00","Ah, Tatsoft also has native Beckhoff (TwinCAT) drivers.
We are using Beckhoff PLCs, so def going to have to look into this further.","",""
"808077381503680542","andymellor","2023-07-05T13:36:14.2910000+08:00","A friend of mine moved out to NZ a few years ago. The time zone shift is a killer. If you do go down the Timescale route, there's also a connector for that in Tatsoft. Maybe you can spearhead the Tatsoft take over of New Zealand üòâ","",""
"323209031076413443","uddersnz","2023-07-05T14:30:59.8470000+08:00","I feel like the opportunities are probably here. Looks fully featured, and price is hard to beat. I'll def be investigating.","",""
"323209031076413443","uddersnz","2023-07-05T14:37:38.6180000+08:00","I keep seeing factory automation projects being underdone due to financial or time constraints, when a good solution architecture doesn't necessarily cost more or take longer to realise ROI.
Frustrating. 
I couldn't even get Ignition over the line at the last, slightly larger company I worked at previously. They may have got there eventually, but automation dept was languishing there, so I moved on.

Think I'm going to have to head to some of our government sponsored industry 4 factory tours to see if it's being done better other places. I kinda hope so.","",""
"603301251177775104","asthomas","2023-07-11T19:20:24.9170000+08:00","Aren't all industrial tunneling solutions proprietary?  That's the point, to change the network behaviour of a standard protocol to fit a target network architecture or security posture.  The entire command set of the Cogent DataHub network protocol is published in the online documentation, and a portion of it is implemented in a source-code API as a free download.  The protocol is proprietary, but not secret and not IP protected.  You also have the option of using any of a number of standard protocols supported in Cogent DataHub if you want to avoid tunneling.","","üëç (1)"
"867075936054149191","rickbullotta","2023-07-11T20:09:17.0340000+08:00","Is a SOCKS based tunnel really proprietary?","",""
"603301251177775104","asthomas","2023-07-13T22:13:27.1190000+08:00","The transport layer isn't proprietary.  Anybody doing tunneling is doing it over TCP, which is not proprietary.  The TCP payloads need to encapsulate the data being transmitted somehow, and that encapsulation is going to be proprietary.  There is no spec that says, ""these are the bytes you must send when encapsulating OPC DA async advise packets within a TCP packet"".  Nor is there a spec that says, ""here is how you reconstitute that encapsulated packet back into a DCOM message"".  Different tunnellers can take very different approaches to preservation of protocol semantics as well.  One popular tunneller takes what I consider a worst-of-all-worlds approach by encapsulating the messages but preserving the synchronous semantics, with all the network failure modes that come with that.  Cogent DataHub insulates the client and server from one another by making the tunnel asynchronous and mirroring the data between the two systems.  Innovative solutions to difficult problems will be unique by definition.  Some people call that proprietary, even if the interface is publicly documented.","",""
"867075936054149191","rickbullotta","2023-07-13T22:17:58.2350000+08:00","Yup.  We did something similar with ThingWorx tunneling. We actually were able to tunnel virtually any protocol over - believe it or not - websockets. The nice part is that from a firewall POV it only required the usual ports open.  Once a websocket is initiated it‚Äôs basically just a TCP socket anyway. VNC, SSH, FTP, SCP, all kinds of use cases. We also implemented secure bidirectional file transfers over that channel.  Fun stuff!","",""
"867075936054149191","rickbullotta","2023-07-21T02:15:43.8640000+08:00","How many of you are running dedicated hardware vs virtualization vs containers at the edge?","",""
"1073312001788477471","sparkylarks","2023-07-21T02:34:57.5590000+08:00","Started moving to virtualiSed machines in 2014 and by 2020 would only use dedicated hardware for very rare cases.  Started working with containeriSed solution 2021, in my last role by march this year we were at a point where we were strongly pushing for containeriSed solutions, and I would say by the end of the year they will have containeriSed as the default and only virtual machines by exception.  Of couse that was a shipping and logitics company so talking containers was just confusing as they embraced containers( Ro-Ro) in the 70's 

And my current project is getting a dedicated SCADA PC  up and running again. But that is in a remote location and a system that was installed in 2012. That company in todays spec is using virtualiSation machines and I would say they will start looking at containeriSation in the next year or so.","","üëçüèº (1)"
"894527802316046366","nickn5549","2023-07-21T12:10:55.2680000+08:00","I'm on virtual servers","","üëçüèº (1)"
"908341993820811295","chris.demers","2023-07-22T00:20:39.8240000+08:00","I‚Äôm on hardware (Opto22 groov EPIC) really for the sole reason that it takes us 3 days to get one and install it versus 3 months to have a VM delivered.","","üëçüèº (3)"
"837389803376214046","susannewhite","2023-07-22T06:41:23.8050000+08:00","I love the emphasis on the S üòÜ","","üíØ (1)"
"867075936054149191","rickbullotta","2023-07-22T20:03:59.9660000+08:00","I‚Äôm going to use the elevator to help load the cases of cookies and sausages into the truck. What color sneakers should I wear?","","üëü (2)"
"812295088348200960","patanj2","2023-07-22T22:31:55.9650000+08:00","Mostly running on virtualized hardware‚Ä¶have a few specialized edge machines where I need a GPU.  IT has actually told us we are not allowed to use Docker as they don‚Äôt have a strategy for governance.","","üëçüèº (1),ishocked (1)"
"812295088348200960","patanj2","2023-07-22T23:03:01.6300000+08:00","How long long did it take for your IT to approve allowing you to put a Groov Epic on your network?","",""
"908341993820811295","chris.demers","2023-07-23T00:09:38.4220000+08:00","I didn‚Äôt ask permission üòÇ","","ü§òüèº (6),üî• (2)"
"1073312001788477471","sparkylarks","2023-07-24T16:05:50.4520000+08:00","I couldn't care less. Many words in American English make a lot more sense. And as I speak Hiberno English rather than the King's English I can't really complain. But do not I couldn't care less, not I could care less because If I could care less that would mean that I care at least a little bit.","","üòÇ (2)"
"890244048739270656","brianpribe","2023-07-25T11:45:53.2500000+08:00","Hardware for machine control. Might have a future SCADA job coming down the pipeline, so we‚Äôll see. Specs gotta be written up first tho.","","üëçüèº (1)"
"891563487241842699","jbonhage155","2023-07-26T01:41:43.3280000+08:00","virtualization. Tried containization via Podman but there wasn't enough backing internally to move it forward.","","üëçüèº (1)"
"891563487241842699","jbonhage155","2023-07-26T01:43:03.8860000+08:00","what is interesting is our 'edge' virtual servers are actually running in the 'fog' (local data center). We are using L2NAT switches and sending plant floor data (Ethernet/IP 44818 traffic) over the WAN to the data center to do the edge compute.","",""
"891563487241842699","jbonhage155","2023-07-26T01:43:10.0560000+08:00","not sure how I feel about that.","",""
"568913935147728896","zeratall","2023-07-26T04:43:09.9290000+08:00","@Joe Bonhage I think that's pretty common with enterprise architecture, imho I argue nearly every day with my colleagues that when people talk about edge compute/storage its not actually edge. I know my company we don't really have any true edge data centers at the site. it's all distributed compute/storage. I've been calling out for future performance reqs we 100% need to start building infrastructure and getting on the edge.","","üëç (1)"
"891563487241842699","jbonhage155","2023-07-26T05:21:06.1330000+08:00","Nice at least you have distributed compute/storage.. do you mean small PCs / embedded devices? What I don't like about having the edge processing in the fog is we lose the ability for buffering / store & forward for any network outage. But maybe I'm over-valuing that functionality.","",""
"568913935147728896","zeratall","2023-07-26T05:31:51.1940000+08:00","Thats exactly why I want to move things closer to the edge as far as connectivity is concerned which is a need TODAY, but also in the future for more performant data processing requirements we might see in the future as AI/ML comes closer to the edge.","",""
"568913935147728896","zeratall","2023-07-26T05:32:57.2740000+08:00","As far as what I mean by distributed compute/storage, our company uses large EDCs (2-3 spread throughout the country) running large hw resources, where VMs can be provisioned. These VMs can be used for hosting things like Thingworx, Canary etc. and each site/factory does not have their own small data center thats on prem that they can connect edge networks too. aka our company is distributed for compute/store resources.","",""
"794020366536146977","mparris","2023-07-30T13:08:30.1620000+08:00","Curious what you mean by edge?

For the quality systems, our rule is to continue running production even when the connection to the Enterprise network is down.

So, in the plant, we have bare metal running windows for desktop apps. Also have bare metal to run Linux for docker. Use docker swarm for better availability on those systems.","","üëçüèº (1)"
"890244048739270656","brianpribe","2023-07-31T01:19:07.5170000+08:00","Why only for quality systems? Assuming the plant‚Äôs network is intact.","",""
"794020366536146977","mparris","2023-07-31T01:22:39.7670000+08:00","Because that's what I own and control üòú","",""
"890244048739270656","brianpribe","2023-07-31T01:24:00.3200000+08:00","Ahhhhh üòÇüòÇ","",""
"867075936054149191","rickbullotta","2023-08-10T01:35:08.2690000+08:00","https://www.influxdata.com/blog/influxdb-3-0-is-2.5x-45x-faster-compared-to-influxdb-open-source/","",""
"794542235676180500","akoscs","2023-08-10T02:50:32.0450000+08:00","whoop whoop, oh wait, so the free verison i much slower? or will there be an OSS influx 3.0?","",""
"867075936054149191","rickbullotta","2023-08-10T03:20:42.8360000+08:00","Towards the end of the year I'm told.  And IoX source is already available.  Entire engine has been rewritten in Rust with a totally new architecture.

https://github.com/influxdata/influxdb_iox","",""
"794542235676180500","akoscs","2023-08-10T03:22:09.0820000+08:00","wow, influx did RIIR, at some point I will definelty start wrinting code in rust...","",""
"867075936054149191","rickbullotta","2023-08-10T03:26:14.7540000+08:00","The Apache Arrow aspect is quite interesting also.","",""
"794542235676180500","akoscs","2023-08-10T03:31:00.8290000+08:00","It is! thanks for the highlight! I would have missed that!","",""
"867075936054149191","rickbullotta","2023-08-10T03:35:33.1740000+08:00","Also from what I've been told, iox has a ""hot cache"" for recent data which will make ""most recent value"" queries lightning fast.","",""
"794542235676180500","akoscs","2023-08-10T03:39:15.8670000+08:00","so .... you have timeseries db, with SQL queries (I have not looked into what that actually means for influx I used theri other languages) and last value ""retention"". Sounds like the persitance solution for your uber broker","","ü§£ (1)"
"812295088348200960","patanj2","2023-08-10T10:36:35.6200000+08:00","Possibly a different mechanism but this has been employed in historian products for years.,  with recent queries being priorities.   Any info on API compatibility version 3 to V2?  V1 to v2 was a pretty big change.","",""
"867075936054149191","rickbullotta","2023-08-10T10:42:21.3050000+08:00","Seems to still support Flux and SQL","",""
"619945686456336414","tamersalem","2023-08-24T00:32:55.0090000+08:00","Version3.0 only for Cloud version . Means for opensource version only v2.0","",""
"1127965241729351780","aleem2446","2023-08-24T20:48:45.6980000+08:00","If you are given a option to build a new factory from scratch what will be your dream OT/ IT stack  complying to Industry 4.0 architecture standards?","",""
"783765494275506256","autopsias","2023-08-24T21:08:10.2250000+08:00","I actually have the same question as I‚Äôm facing a similar challenge","","üëç (1),‚ûï (1)"
"568913935147728896","zeratall","2023-08-24T21:46:46.0180000+08:00","I hate to be ‚Äúthat guy‚Äù but it really does depend. The needs of the architecture are what dictate the specific implementation of the architecture. Understanding the use cases, your requirements, the actors of the architecture, etc are all inputs to a huge multi variable analysis called Systems Engineering that spits out your tech stack. With a green site that function becomes a little easier because you don‚Äôt have as many constraints as you do with a brown site  as well as politics (people invested in the current stack)","","üëç (1)"
"1127965241729351780","aleem2446","2023-08-24T22:21:26.7750000+08:00","Great Inputs
Thanks Zach,
However what am I looking for is say for discrete/ continuous manufacturing especially with UNS architecture

A stack that can't go wrong irrespective of requirements or use cases of course end state will have variation 

May be to make things easier let me put a stack and people can point out this looks good bad or ugly üòâ

OT
____
1 . Dataops Layer : Highbyte or HiveMQ
2. SCADA : Ignition ( containerised)
3. MES : Sepasoft
( Containerised)
4.  Historian : OSI PI / Edge + Cloud
( Do I need one can I not do this with a datalake ? )
5. Cloud LIMS

IT
______
ERP : SAP ( can't change existing)
PLM : Team centre ( existing)
Datalake: GCP (existing)","",""
"876559193417597000","og_grendyl","2023-08-24T23:48:15.6660000+08:00","Setting asside the fact that we're talking about a software stack rather than a technology stack ( @Walker Reynolds forgive us )...
3. MES: Sepasoft - I've been told the Sepasoft MES is restrictive and hard to build on.  When combined with the fact that everyone eventually needs to customize their MES solution it may not be the best tool for this layer.  We used Sepasoft Web Services in Ignition and actually found the included Ignition WebDev module easier to work with.  Sepasoftw was also perpetually behind in certifying it's product for new Ignition releases.  We will be moving the web services we have in Sepasoft out of it.
4. There are multiple references in various @4.0 Solutions videos to OSI PI having limitations (I think mostly in it's interoperability).  I have no personal experience here, but make sure you are aware of those potential problems before you implement.","","üëç (1)"
"844671073827291156","yasirtuncer","2023-08-25T01:34:24.4230000+08:00","I couldn't quite get the discrete/continuous manufacturing. Is it continuous, discrete or hybrid? What industry are we talking about? For example, if we are talking continuous like chemical manufacturing then you actually do not have any choice on SCADA because the facility will come with one whoever you choose, Honeywell, Yokogawa etc. 

Since you mentioned Teamcenter I believe it is probably discrete.","","üëç (1)"
"1127965241729351780","aleem2446","2023-08-25T06:30:07.5050000+08:00","Well is battery manufacturing hence has some chemical processing as well but is still a solid state battery","",""
"844671073827291156","yasirtuncer","2023-08-25T14:36:44.8910000+08:00","Like @Grendyl mentioned you should build your stack based on technology, not solutions. 
I would suggest you create minimum technical requirements first and determine the functionalities you need from each of the components
After that point, you can choose your partners that will deliver based on requirements","","üëç (1),üëè (1)"
"867075936054149191","rickbullotta","2023-08-25T19:50:05.2740000+08:00","Not sure I 100% agree here.  Solutions that are open and extensible and that embed a solid technology stack would be my choice over a complete DIY approach.","","üíØ (2)"
"844671073827291156","yasirtuncer","2023-08-25T20:01:59.8260000+08:00","When I mean partners it is not just integrators üòä but also solution providers. They are all part of your partners in this journey. 
I agree it should not be 100% DIY moreover, I would argue it should have more common blocks rather than customization because technical debt will cost more in the long term","","üíØ (1)"
"867075936054149191","rickbullotta","2023-08-25T20:06:44.5430000+08:00","True - the ""interest rate"" on technical debt can be very high!","","üî• (2)"
"1139269147126153216","suran23.","2023-08-26T15:56:02.1490000+08:00","Device connectivity + Data collection + normalization + contextualizing it + edge analytics + storage for time series data + flows and analytics + Data modeling and Digital Twins + message broker and client + integrations to Cloud and popular enterprise databases n tools + Run containerized apps + ML at the edge = Litmus Edge . So if u r setting up multiple plants and want to do more with the data, Litmus Edge can be your trusted partner.","",""
"844671073827291156","yasirtuncer","2023-08-29T06:22:41.9150000+08:00","Here is how I designed a greenfield factory 
3 major process 
1. Product Lifecyle Management (I believe you will cover everything with Siemens Teamcenter here) Your BOM/BOP will be defined here and transferred to ERP as well as MES 
2. Horizontal Integration (Integration of value chain from the customer to supplier. I believe SAP will cover these)
3. Operations (You need to cover 5 functions planning, quality, maintenance, MES, material movements could be WMS)
How to connect all of these UNS 
How to store historical data - Historian should be natively integrated with UNS 
How to analyze those - AI/ML platform 
If you miss visualization in any of those then a visualization software I would have gone with Grafana

But @Zach E touched on some critical points, you need buy-in from other stakeholders on how they would like to conduct their process and make decisions in real-time

For example is SCADA definitely required? Will there be operators which will need assistance for SOPs? Will MES cover any compliance features?

So the list goes on and on","",""
"1127965241729351780","aleem2446","2023-08-29T07:13:32.0800000+08:00","Great Insights thanks Much @yasirtuncer 

Can elaborate a little more on historian natively integrated with UNS?
Thanks","",""
"756247672637358181","sherylmccrary","2023-08-29T08:08:27.1990000+08:00","A good vid  on that : https://www.youtube.com/watch?v=AjIgJ6sSrnU","","üëç (4)"
"568913935147728896","zeratall","2023-09-03T22:26:52.5870000+08:00","Has anyone here developed iiot architecture using volatility based decomposition? I think VBD works well for DT, curious if anyone else has had similar experiences.","",""
"740383178279354388","mriiot","2023-09-06T20:32:32.0470000+08:00","Example?","",""
"568913935147728896","zeratall","2023-09-06T21:40:00.0480000+08:00","On what volatility based decomposition is? Or how I use it for iiot architecture?","",""
"740383178279354388","mriiot","2023-09-06T22:00:37.9570000+08:00","Both.  Teach us.","",""
"568913935147728896","zeratall","2023-09-06T22:54:26.0640000+08:00","Sounds good let me draft up a proper post when I get to my pc, a bit long to be on my phone lol","","üëç (2)"
"568913935147728896","zeratall","2023-09-07T22:52:26.3770000+08:00","So I crafted up a response but it ended up being super long so I‚Äôm actually gonna make a blog post, so it can be a little easier to read. I‚Äôll post the link in the next day or two!","","üëç (6)"
"686612416196640790","dezemand","2023-09-11T21:36:30.4700000+08:00","Hey all,
I'm doing a project with a large manufacturer. I would like to find a solution that can visualise the IT components that we are currently operating in. Does anyone know a visualisation tool that can we use? 

I'm thinking it will be important to visualise:
- The components (devices, sensors, servers, services, cloud applications, etc.)
- The area it lives in (production network, edge, on-premise server, cloud, etc.)
- The integrations (with protocols)
- The firewalls between different areas
- Other metadata

(I think this relates to ref archs but let me know if I should ask somewhere else)","",""
"844671073827291156","yasirtuncer","2023-09-11T21:51:55.0690000+08:00","Where does this data live? What we usually see is the company does not have a central repository for all of the items you listed.

For example network team has the list of components but do not have the list of all integrations with protocols. Moreover, they could have the firewalls' details but not the details the source lives in

ManageEngine might be a good alternative if they are using with OpManager tool","",""
"817835202746253344","IIoT#4707","2023-09-11T21:51:55.4590000+08:00","GG @yasirtuncer, you just advanced to level 5!","",""
"686612416196640790","dezemand","2023-09-11T21:52:42.2340000+08:00","We'll be creating a centralized data source, but I'm more looking into the actual visualisation aspects of this","",""
"844671073827291156","yasirtuncer","2023-09-11T21:58:31.0620000+08:00","Will you be creating this in a GraphDB?","",""
"686612416196640790","dezemand","2023-09-11T22:02:15.7750000+08:00","I think that's the best way, yes","",""
"1139269147126153216","suran23.","2023-09-12T00:20:27.4170000+08:00","@Maarten All the data pieces you mentioned are available on customizable dashboards on Litmus Edge. Are you looking to do this for a single site or multiple sites at an enterprise level?","",""
"686612416196640790","dezemand","2023-09-12T00:58:57.5550000+08:00","Multiple sites, enterprise level","",""
"686612416196640790","dezemand","2023-09-12T00:59:23.2570000+08:00","Maybe even going beyond, as we're part of a group","",""
"686612416196640790","dezemand","2023-09-12T01:19:14.6910000+08:00","I looked into that, we're currently not using any of these products so using that would be a bit overkill","",""
"686612416196640790","dezemand","2023-09-12T01:19:55.0920000+08:00","I'm thinking of writing a little vis tool myself, D3 looks pretty interesting to do it","",""
"753688565807841492","ravil1","2023-09-12T02:26:44.3100000+08:00","Have you looked at Grafana? It is often used to monitor IT infrastructure.","",""
"686612416196640790","dezemand","2023-09-12T02:42:48.9070000+08:00","Interesting, I think Grafana's graph view is the closest thing to what I need for now","","üëç (1)"
"817835202746253344","IIoT#4707","2023-09-12T02:42:49.2120000+08:00","GG @Maarten, you just advanced to level 2!","","üëç (1)"
"756247672637358181","sherylmccrary","2023-09-12T02:43:44.1540000+08:00","This is essentially one of the problems a UNS data architecture is designed to solve, and the visualizations can be done pulling from the hierarchical, contextualized data.","","üíØ (1)"
"686612416196640790","dezemand","2023-09-12T02:45:46.8780000+08:00","Yep yep, but we're not able to change to a UNS architecture over night üôÇ","",""
"686612416196640790","dezemand","2023-09-12T02:46:38.4370000+08:00","We're currently facing that the company has grown out so much that a lot of parts have split off and did their own thing, which was fine for I3.0, but a problem for I4.0","",""
"686612416196640790","dezemand","2023-09-12T02:47:22.0140000+08:00","And now no one really knows what everyone is doing, or has done","",""
"1139269147126153216","suran23.","2023-09-12T06:27:57.4310000+08:00","100% agree on@SherylM 's point and exactly why UNS should be top of mind. Went through countless similar stories and visualization can only be as good as the data itself. At multisite, enterprise level if agility and autonomy of plants are important while not sacrificing on corporate initiatives like digital transformation, fixing the data problem is core. Grafana can be a greta visualization tool but there's likely pre-work on the data, underlying infra and architecture themselves.","",""
"568913935147728896","zeratall","2023-09-12T13:14:51.6210000+08:00","Took a little bit longer then I wanted to but finally got to writing up my thoughts: https://www.linkedin.com/pulse/using-volatility-based-decomposition-vbd-tool-iiot-zach-etier let me know what you guys think!","",""
"686612416196640790","dezemand","2023-09-12T15:34:24.4020000+08:00","Interesting, maybe I have jumped to conclusions too quick then? Personally I have trouble seeing how we can implement UNS without having a good overview of the rather (too) complex architecture we have now. But I'm young and dumb so I'm happy to learn üôÇ","",""
"794542235676180500","akoscs","2023-09-12T15:51:42.1940000+08:00","This is interesting. Is it really an alternative to functional decomp or is it just an addon, adding ""volatility as a functinal feature"" i.e. adding a functionality that handles abstractions in case elements need to be switched out? I would be inclined to say the latter","",""
"741170732742213734","kudzaimanditereza","2023-09-12T16:59:59.9970000+08:00","Great article @Zach E , thanks for sharing. I agree with @akos , it seems like the Volatility approach is being used to enhance Functional decomposition rather than serving as it's replacement.","","üôè (1),üëç (1)"
"568913935147728896","zeratall","2023-09-12T21:18:21.3810000+08:00","Absolutely, you guys are spot on. In traditional software architecture it can be a complete replacement, but because a lot of our architecture is COTS and not built it can be hard to completely contain all areas of volatility, so I adapt it as an add-on when thinking of IIoT Architecture. I tried to capture that with this part of the article, but  looking back I probably should have made more of a point that it‚Äôs complementary","",""
"568913935147728896","zeratall","2023-09-12T21:20:27.0010000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1151145300728238090/IMG_7674.png?ex=68df24da&is=68ddd35a&hm=df0b376a4746c04d052cbed52a35678a3963585c1744ff9b127bad87b0bcabd8&",""
"568913935147728896","zeratall","2023-09-12T21:31:38.6480000+08:00","If you guys are interested in the more traditional sense of VBD and less of my adaption of it for IIoT then Id recommend this article as well, https://www.hakantuncer.com/2015/06/28/zen-of-architecture/amp/","","üíØ (1),üëç (1)"
"1139269147126153216","suran23.","2023-09-12T22:34:23.4370000+08:00","What does your current architecture look like?","",""
"686612416196640790","dezemand","2023-09-13T18:01:22.3340000+08:00","Like a big I3.0 architecture. Lot's of point-to-point integrations, lot's of protocols, lot's of services. Also big vendor systems, Dassault's Apriso is used for MES (not implemented everywhere yet), SAP is being implemented, but there are a lot of legacy applications active as well (pre-90s even)","",""
"1139269147126153216","suran23.","2023-09-14T01:26:03.9230000+08:00","@Maarten Nothing unusual and as I had suspected. You have got the factory floor, the production systems on top and now the next 2 things to complete: ensure agility and autonomy for the plants but sufficient federated control to implement corporate initiatives across the sites. The next step here would be to use a data platform that decouples the risk of innovation and data-driven initiatives from the production systems. How you do that? Hook up all and any systems into this data platform to feed data into this layer. And I am talking any kind of PLC, CNC machine, SCADA, MES, Historian, PDF files, CSVs, anything else you have. Now if it's a smart platform, it will normalize the data for you, statistically correlate data from multiple systems, enrich the data...Now your focus would shift into what you can actually do with that data. Build flows, run analytics, visualize, create data models for specific use cases, and prep the data for larger Big Data analytics, or other northbound ingress layers. Now UNS is not a panacea for all woes, but it can be a great stepping stone into greater and bigger strategies. If you think you can save ""x dollars"" per site by adopting this strategy, in terms of reduced downtime, better inventory management, reducing scrap, implementing a trustable OEE, predictive maintenance, and name any use case, ideally the platform would pay for itself.","",""
"1139269147126153216","suran23.","2023-09-14T01:32:37.4520000+08:00","If you are interested, i posted a video on YT channel on how UNS is implemented in Litmus.","",""
"686612416196640790","dezemand","2023-09-14T14:34:26.7340000+08:00","Please do, I believe we are considering Litmus üòÑ","","üíØ (1)"
"833941249362493450","sammysevens777","2023-09-20T14:24:46.8510000+08:00","Guys im in a new role, test engineer for servers. Automated testing.

The current pipeline is all bash and management of raw csv /txt files. I think we need:

- bash to extract

- python transform / load / serve where needed

- mysql db with json object rows (we collect sensor data, and every server has a different convention for sensor names & count)

- Networked file storage

- VLAN for segmented network of servers in our labs for test

We dont use any products, i am exploring ELK, but wondering if anyone here in mfg. has worked on test engineering systems?","",""
"794542235676180500","akoscs","2023-09-26T22:54:29.8830000+08:00","If there is an existing ERP in place and 4 SCADAs are supervising majority of the plant, what is the best way to a UNS and dashboards? Add a data hub (e.g. Highbyte) to add axisting data to a broker and persist everything important for dashbards in a separate DB? Any other generic approaches?","",""
"753688565807841492","ravil1","2023-09-27T02:35:39.5530000+08:00","Hi @akos, you can consider our product https://onewayautomation.com/index.php/visual-logger
With it you can collect data from SCADA over OPC UA interface and publish to MQTT brokers, as well as store data in databases (SQL databases, InfluxDB, Kafka).
Affordable and quick to configure.","",""
"794542235676180500","akoscs","2023-09-27T02:37:32.9950000+08:00","Any hint on the Enterprise Edition pricing model (in provate if it is not a public info)","",""
"1139269147126153216","suran23.","2023-09-27T02:39:26.0890000+08:00","@akos A few qs: 1. SCADA and ERP systems are typically Data Consumers. They directly impact plant operations. Would you want to expose them for DataOps? 2. Are your SCADAs from the same vendor? Have you already normalized the data?","",""
"794542235676180500","akoscs","2023-09-27T02:41:33.5420000+08:00","Yes, I would want to expose them to data ops (is there any other way?), not the same verndor, no info about the vendor yet. It is assumed that the data is somewhat normalized for ERP and probably not for SCADA","",""
"1139269147126153216","suran23.","2023-09-27T02:44:15.0210000+08:00","That's right. So, you would want to expose them to DataOps not necessarily a data hub only which will only provide a data container. You would need to consider Data collection + normalization + contextualizing it for efficient pub/sub operations in the hub.","",""
"753688565807841492","ravil1","2023-09-27T03:11:31.6970000+08:00","Please send email to sales@onewayautomation.com to get a quote, with information on number of OPC UA Servers, total number of tags, expected data flow rate (number of values per second), targets to forward data to, do you need it software only or pre-installed in an IPC, Windows or Linux OS.","","üëçüèº (1)"
"1073312001788477471","sparkylarks","2023-09-27T07:15:34.0180000+08:00","Best way depend on your goal but if you want to use a need to provide Dashboards and Dataanalytics to kickstart the UNS architecture I would
Set the Minimum Technical Requirements, and select a technology that complies, lets say its MQTT
Define an outline of the Systemic hierarchy you want to use.
Use a gateway to add the Data to the UNS and model it to the Systemic Hierarchy.
The Gateway you use depends on your existing infrastructure and Budget  but I would look to go PLC->Gateway->MQTT Broker. 

I would be careful using the 4 SCADA as the Gateway, especially if it is 4 Standalone SCADA. There are two sources of technical debt that may cost you in the future.
- if you change your SCADA you lose your data in the Broker
 - It is difficult to Scale as the data in each SCADA is likely to be different, e.g. there is no guarantee they are using a common approach at all.
- you are limiting you Dashboards to data in the SCADA, anything in the PLC is not availible, and to make it available you need to connect to the PLC","",""
"794542235676180500","akoscs","2023-09-28T21:25:14.8630000+08:00","You probably cannot connect the PLCs to a gateway to feed the data to MQTT. I would like to avoid to reqire the SCADA and i doubt I can get two parallel connections to the PLCs. So the SCADA will be the source of information coming from the PLC.","",""
"794542235676180500","akoscs","2023-09-28T21:25:23.2900000+08:00","SCADAs are running well for years","",""
"1073312001788477471","sparkylarks","2023-09-28T21:32:36.8000000+08:00","What are the PLC's? Can you add an additional Network Card? 
Connecting to SCADA gets you going and certainly is a good start. but anytime I have taken that approach I end up wanting to connect to the PLC for more information withing 6 to 12 months.
If you had a single SCADA where you could pull all the information into 1 node it woudl be better. If you have two SCADA both reading the same value, which publishes to the UNS, It just makes it a bit more difficult to manager IMHO","",""
"323209031076413443","uddersnz","2023-10-04T07:56:32.2040000+08:00","Hey folks,
I have a question around multi-site UNS architecture.
Our site PLCs are publishing MQTT messages, data is displayed in a custom app.
Wanting to store historical data, so thinking to store to a local timeseries DB to allow plant logging even if internet or local network is down.
Would also like this data back to HQ for reporting. 

Option 1: bridge MQTT back to a broker at HQ which can then log messages to time series database
     - results in 2x data stores with potentially different data

Option 2: Database mirroring of local DBs back to HQ

Option 3: site custom app writes direct to cloud db 
     - potentially loses data if offline (but maybe kafka could store)
     - customer has no access to data if internet is down

Basically, at what level is it best to feed site data back to HQ?
MQTT? Database? Other?","",""
"867075936054149191","rickbullotta","2023-10-04T12:23:09.0690000+08:00","I prefer a local time series DB synced to a cloud instance. Real time decision support off the local instance and analytics off the cloud instance.","","üëç (1),ü§òüèª (1)"
"323209031076413443","uddersnz","2023-10-04T12:33:01.4720000+08:00","Thanks Rick. This separation of duties matches our use case pretty closely. 
This is early days for us, so likely to be a PoC that turns into year one production. Ran last season without it, so doesn't need to be flawless.
Ideally would like to run self hosted DB at head office for PoC.
Any ideas on best way to sync site db to a self-hosted head office db?
Or is a cloud service with edge-sync capability (I see Influx has this) a better choice?","",""
"745796393855352953","thedavidschultz","2023-10-04T18:54:39.8310000+08:00","Option 2. Modern time series databases/historians support replicas. This can be done asynchronous (lower overhead, but potential data loss) and synchronously. I prefer to use the right technology, which is the technology you can support.","","üíØ (1),üëçüèº (2),üëç (2)"
"867075936054149191","rickbullotta","2023-10-04T22:27:08.5650000+08:00","Depends also if you need to keep the high granularity data in the cloud or not.","","üëç (1)"
"844671073827291156","yasirtuncer","2023-10-04T23:53:55.5330000+08:00","I had an interesting meeting today with a bus manufacturer. They almost don't have any automation on the shop floor and their production volumes are really low.

The head of IT also responsible from digital transformation argued that they don't currently have any real-time data from OT side thus want to have an enterprise service bus and ETL tools to cover connectivity rather than UNS.

I tried to give several examples why they need UNS and discussed minimum technical requirements for scalabile infrastructure but started to question myself.

If they don't have any data from OT side, does an architecture like CDC from DBs, ETL to push data to ESB and ESB to share to data consumers what will be the downside?

Would love to get your opinions","",""
"794542235676180500","akoscs","2023-10-05T00:12:54.4190000+08:00","What are they using as ESB?","",""
"867075936054149191","rickbullotta","2023-10-05T00:17:43.3490000+08:00","Classic backward IT thinking.  No point in an ESB and ETL if you don't have any data!","","ü§£ (1),this (1)"
"794020366536146977","mparris","2023-10-05T08:44:08.6520000+08:00","@yasirtuncer does ""they don't have any real time data"" mean that IT doesn't have access to the real time OT data that exists in OT?

And that IT's proposal to get the data is through a ESB or ETL toolset?","",""
"844671073827291156","yasirtuncer","2023-10-05T12:03:26.4300000+08:00","They do not generate almost no OT data. For the whole plant they have 1 robot for sealing the window and place it.

There is no machinery at all everything is manual like welding, painting, assembly etc.

They do not track operations in real-time like any spatial analysis of operators, they get confirmations to ERP at the end of work centers. 

They have a SCADA for cataphoresis  but that's it nothing else has a controller in 55,000 square meters production area.","",""
"844671073827291156","yasirtuncer","2023-10-05T12:06:43.2770000+08:00","They currently don't","",""
"794542235676180500","akoscs","2023-10-05T12:33:35.6520000+08:00","So why do you want to introduce an ESB? I mean if they do not have shopfloor data, that does not mean that on the IT side they should not benefit from modern architectures, right?","",""
"844671073827291156","yasirtuncer","2023-10-05T12:35:45.8620000+08:00","I am not the one who proposed ESB. Almost everything is happening in IT side and they want to use ESB to publish data to consumers","",""
"873009180938743828","sim_sam3","2023-10-06T05:47:43.6540000+08:00","Walk crawl run. Get them bought into basic access to systems (maybe just opc servers) and then layer esb (or any of their other ideas) on top. Slow roll; win the access battle first and then fight for uns over esb or other tech","",""
"783917475128410112","geoffnunan","2023-10-06T15:55:16.3400000+08:00","I've seen many manufacturers like this that don't have real-time data or SCADA systems. It's fairly typical in Job-shop manufacturing and low-volume discrete.
You're right to question the architecture. UNS is a SCADA-CENTRIC concept. It really has very little applicability if you don't have SCADA.","",""
"795178288330440704","youri.regnaud","2023-10-06T21:59:33.6500000+08:00","I would be curious to know if anyone in this community has had a positive or negative experience with AWD Outpost.‚Äù","",""
"254777321788145664","terrancesmith","2023-10-06T22:07:46.1030000+08:00","Same. I have an solution architect suggesting we look into it for a current project rn...","",""
"867075936054149191","rickbullotta","2023-10-06T22:31:22.4840000+08:00","The big issue with Outpost (and it's corresponding Azure equivalent) is the limited number of services that are available at the edge.  If you're going this route to ensure availability and reduce latency, if you still have a dependency on a cloud-based service that isn't available on the edge, you're screwed.","",""
"568913935147728896","zeratall","2023-10-06T23:48:30.9010000+08:00","We looked into outpost at NG, and I came to a similar conclusion, but additionally cost, outpost is not cheap when compared to some other edge options.","",""
"867075936054149191","rickbullotta","2023-10-06T23:52:54.1480000+08:00","Did you consider TCO (cost of hardware, managing the devices, etc)?  Just curious.  That's usually the counterargument why these can make sense in some cases.","",""
"568913935147728896","zeratall","2023-10-06T23:56:21.6910000+08:00","Yeah and honestly the support is the major reason we end out out sourcing tbph. We ended up not going that route for Outpost for Manufacturing, but we are outsourcing more and more now a days.  I think a lot of the vendors are getting  pretty creative with how they package the TCO for the solution, offers like MTaaS from Dell/EY/PTC where your able to use Opex instead of Capex, really makes that attractive since a lot of our money gets tied up in color of money.","","üí∞ (1)"
"1129435706285101076","ted.garrison","2023-10-07T00:14:37.5980000+08:00","Yup.. I love everything being aaS since it's easy to spend against OpEx and not have to go thru the CapEx approval process.","",""
"867075936054149191","rickbullotta","2023-10-07T00:42:21.9400000+08:00","Except once capex is spent the products don‚Äôt disappear. When told to trim OpEx, it can be a pain in the aaS.","",""
"1129435706285101076","ted.garrison","2023-10-07T00:46:10.9780000+08:00","True.For me thankfully, all my OpEx aaS stuff is pennies in the larger scheme, so they won't start with my stuff generally.  Lots of other lower hanging fruit..","","üëçüèº (1)"
"568913935147728896","zeratall","2023-10-07T00:53:33.2200000+08:00","hahah you should see some of our Cisco Lease quotes that were evaluating to overhaul all of our manufacturing networks for the enterprise......talk about $$$$ lol, amazing capabilities with the technology though.","",""
"568913935147728896","zeratall","2023-10-07T00:54:26.9600000+08:00","As an architect, I love more flexbility and more options for help curiating the solution. The thing I hate is when sales comes in and ramps up our leadership without me, and it's totally the wrong tool for the job.","",""
"1129435706285101076","ted.garrison","2023-10-07T00:56:03.1010000+08:00","yeah.  sales shouldn't be allowed to talk to execs.","",""
"1129435706285101076","ted.garrison","2023-10-07T00:56:24.3840000+08:00","i keep saying, the best thing we could do is cut off the C-Suite's ability to use the internet.","","ü§£ (1)"
"568913935147728896","zeratall","2023-10-07T00:57:03.2930000+08:00","1000% lol, what normally ends up happening, I get invited 2-3 meetings in, I start asking the ""real"" questions to get what to the solution is, and then I have to spend 2-3 days making a slide deck to explain the pro's, con's, and if it's a fit for our current strategy.","",""
"568913935147728896","zeratall","2023-10-07T00:59:11.3950000+08:00","Honestly, I can't blame the vendors, they are just trying to get to the decision makers, but I wish our internal org would realize having leadership talk without technical representation isn't an efficient way of doing business.","",""
"1129435706285101076","ted.garrison","2023-10-07T01:00:36.3470000+08:00","agreed. it's how we train our sales people.. start as high up as you can get.  For exactly that reason.","",""
"1129435706285101076","ted.garrison","2023-10-07T01:00:56.5950000+08:00","but yeah, the execs should be smart enough to immeditely punt them back down to us grunts.","",""
"855607029518434314","hiptopjones","2023-10-07T01:04:41.9310000+08:00","Interesting comment that UNS is a scada-centric concept.  Our facility is not built on SCADA (at least not by name), and I see a ton of potential in the UNS pattern.  We don't have SCADA or PLCs (outside of some COTS equipment) but we have lots of other digital technology... homebrew platform like Tulip, functional testing hardware, etc. and I 100% plan to move all of it towards a UNS pattern.  Maybe picking on what you said / what I heard vs. what you meant, but I don't see it as a SCADA-centric at all.","",""
"453944368751968277","vastcnc","2023-10-07T05:28:04.8440000+08:00","Is there any architectures I should know about utilizing RabbitMQ? I‚Äôve been looking at MQTT broker/clients and haven‚Äôt found much info for rabbit in industrial contexts.","",""
"783917475128410112","geoffnunan","2023-10-07T05:45:24.0310000+08:00","There is a better way for your architecture.
A Manufacturing Data Hub architecture is a lot more suitable for non SCADA-centric applications.","",""
"855607029518434314","hiptopjones","2023-10-07T07:28:57.0650000+08:00","Thanks Geoff.  How do you define that?  Can you point to something that explains that technology / architecture?  Quick search reveals a lot of solutions that call themselves data hubs, but what's the concept?","",""
"783917475128410112","geoffnunan","2023-10-07T09:36:21.3380000+08:00","Great question.
A Data Hub Architecture is a real-time integration architecture that stores real-time event data in a standardised schema close to the source, and makes it easily accessible to other applications and algorithms. There are strong parallels with a UNS, but a Data Hub architecture takes the concept further to solve the limitations of a simple UNS.


We can think of the schema as a way of standardising the way data is modelled and represented across sites, machines or areas meaning that if you build a Tulip application on the data hub, you can deploy the application across sites easily.

A Manufacturing Data Hub is the standardised foundation that provides clean, contextualised data into your future AI and ML capabilities, solving the challenge of getting good data for data science.

A Manufacturing Data Hub has the following 6 characteristics:
1 - It is able to consume and produce real-time streams of events and orchestrate actions in response to those events, enabling a real-time event-driven architecture
2 - It collects data and events using open protocols and persists them and their derivatives in a low-latency, real-time data store.
3 - It enables standards-based modelling and configuration that enforces standardisation of data structure and ontology
4 - It allows the ens user to configure custom business logic to extend the standard model using low-code or no-code tools
5 - It provides a single subscribable API based on open standards allowing consumers of current state and historical data to easily access that data, and to call user-defined functions.
6 - Is is built on a horizontally scalable, natively highly available foundation capable of supporting zero-downtime configuration.","",""
"855607029518434314","hiptopjones","2023-10-07T11:24:13.1430000+08:00","Interesting, thanks!  Your words helped me find more words on the web.  It doesn't necessarily sound like an either-or thing.  I can see some parallels (as you said), but a data hub architecture sounds like more of an engineered solution for connectivity, where a UNS just puts it all out there in real time and lets you choose how to use, remix and organize it... for better or worse.  I would expect that in any organization that adopts a UNS there is a slow maturation from wild teenager to a more refined and defined hub (although some people never grow up!)  Basically, UNS lets you do whatever you want, but choice can be a curse, so a hub is a step somewhere along a natural path of evolution that encodes common patterns of access and tries to strike a better balance between freedom of expression and useful productivity.  Something like that?","","üî• (2),üëç (2)"
"817835202746253344","IIoT#4707","2023-10-07T11:24:13.3910000+08:00","GG @Indiecat, you just advanced to level 3!","",""
"783917475128410112","geoffnunan","2023-10-07T13:06:14.8700000+08:00","Thats incredibly well stated","",""
"795178288330440704","youri.regnaud","2023-10-07T20:29:40.3170000+08:00","In our organization, we‚Äôve adopted the terminology ‚ÄòEvent Hub‚Äô when referring to the ‚ÄòUNS‚Äô concept. As Geoff pointed out, we use ‚ÄòIndustrial Data Hub‚Äô to describe the storage of data that flows through the ‚ÄòEvent Hub‚Äô. This dual concept has been pivotal for us. I‚Äôve attached an image that illustrates this relationship","https://cdn.discordapp.com/attachments/815945777452941313/1160192218691289179/IMG_2892.png?ex=68df18f4&is=68ddc774&hm=330c4fd18b7e16688b092e20c71f61d548087f75953c3ad5689f53f2a9896841&","üíØ (1),üôå (1)"
"795178288330440704","youri.regnaud","2023-10-07T20:32:56.5090000+08:00","And here's another diagram showing how quickly you can iterate with a nocode platform like Tulip, thanks to a solid data foundation.","https://cdn.discordapp.com/attachments/815945777452941313/1160193041383043202/IMG_2893.png?ex=68df19b8&is=68ddc838&hm=af4f391b23bfdade5624c2ced71481d6d228bffb160aa69366371326e46e703d&",""
"795178288330440704","youri.regnaud","2023-10-07T20:33:37.8560000+08:00","I'd love to hear your feedback.","",""
"568913935147728896","zeratall","2023-10-07T23:41:46.6130000+08:00","One side note on design patterns aka UNS vs Geoff def of a Datahub, etc. it‚Äôs less about digital maturity (teenage vs more mature example you used) it‚Äôs more about the needs of the domain and what design pattern fits that need the best (digital maturity is one component of the domain, but there are many more). Standardization works really well for traditional IT systems where data is more structured/rigid but using a central/master data model for an entire enterprise aka many factories that may be different manufacturing types is not the best approach for the OT domain. The OT domain requires design patterns that are more flexible and implicit by nature. 

Master data models do work really well in L4+, but L0-L2, and somewhat L3 are tightly coupled to the manufacturing floor. My personal belief is that data structure needs to be more of a federated approach.","",""
"783917475128410112","geoffnunan","2023-10-08T05:18:05.4400000+08:00","I have not yet found a scenario in OT that is not able to be successfully modelled using the standardised schema.
I've been searching for examples for 25 years.","",""
"568913935147728896","zeratall","2023-10-08T05:27:27.7460000+08:00","Can you use a standardized schema for manufacturing sure, but to what end? It‚Äôs obviously much easier to create a standard model for a single factory,  or a small to med size homogenous enterprise, what about a standard model that needs to support 5, 10, 100 factories? What if those 100 factories are all their own independent orgs all making different products,  which manifests itself as different types of manufacturing and needs for data, what if across the enterprise you have similar but different devices all with their own specific properties with some commonality but also uniqueness that needs to be accounted for?","",""
"568913935147728896","zeratall","2023-10-08T05:33:35.2520000+08:00","@yasirtuncer had an excellent example of the same thing I‚Äôm mentioning https://discord.com/channels/738470295056416930/1156271613885558864/1156471383426076704 

Like I mentioned above, it depends on the problem space/domain,  a central data model can be an effective design pattern but in some cases it could be hard to scale/maintain.","",""
"783917475128410112","geoffnunan","2023-10-08T06:04:33.0690000+08:00","a standard model for 5, 10, 100 factories is even more relevant that a standard model for 1 factory.
Without a standard model, it's more difficult to 
- distribute best practices from one factory to another
- share learning across factories
- benchmark performance across factories
- distribute new applications and algorithms from one machine to another
- reuse interfaces to IT systems to enable OT applications
- enable a shared support / cost of ownership structure
- establish a centralised ""Operating Centre"" concept to leverage the critical subject matter expert skills across factories
- train new staff on how things work, and allow those staff to easily move between factories","",""
"568913935147728896","zeratall","2023-10-08T06:06:50.2070000+08:00","Totally agree, I‚Äôm not arguing the need for a data model I think we can all agree on the points above, I‚Äôm arguing the practicality of implementing such a data model, when the domain  is heterogenous it becomes to large to manage centrally.","",""
"783917475128410112","geoffnunan","2023-10-08T06:08:38.9290000+08:00","That's the reason we choose to stick with the ISA95 standard. I've never found a need to it to grow, even across heterogenous sites","",""
"568913935147728896","zeratall","2023-10-08T06:11:23.7680000+08:00","I think where it grows and become un manageable is really in the L0-L2. Those levels are incredibly specific to the manufacturing type. If your enterprise has a bunch of different manufacturing types all with different machines, you end up with a lot of different machine models, etc.","",""
"783917475128410112","geoffnunan","2023-10-08T06:15:17.0840000+08:00","Agree, but the ISA95 standard allows you to model that difference using a standardised schema. Different machines does not have to mean a different schema","",""
"568913935147728896","zeratall","2023-10-08T06:18:17.7830000+08:00","Totally agree, all models work on abstraction, so you can abstract where there is commonality, when we have taken a similar approach we have ended up with a lot of different children objects though because there‚Äôs always a property that is specific to a machine  that someone has a need for that isn‚Äôt common to other similar devices, so it becomes a ‚Äútype of device‚Äù with its extra few prosperities.","",""
"568913935147728896","zeratall","2023-10-08T06:19:36.2150000+08:00","Btw I point out these issues, not because I think I‚Äôm right, but because I want to lay out my line of thought so if there‚Äôs errors others can point them out. Only way to learn.","",""
"783917475128410112","geoffnunan","2023-10-08T06:21:42.1020000+08:00","It is indeed common to find many similar types of machine that are slightly different. That's where you need a data hub that support composition over inheritance","",""
"783917475128410112","geoffnunan","2023-10-08T06:22:46.0360000+08:00","The complexity still fits neatly within the ISA95 structure, the problem you have is more an application problem of how inheriteance and composition are suported","",""
"568913935147728896","zeratall","2023-10-08T06:29:02.3040000+08:00","That‚Äôs a fair point most of the tools/data models I‚Äôve seen are built around abstraction/inheritance. If there are other approaches then Id be willing to re-evaluate my stance.","",""
"783917475128410112","geoffnunan","2023-10-08T06:33:27.3820000+08:00","It's a major limitation with most of the modelling tools around.
When we built out data hub, we made sure we enabled multiple inheritance and composition, allowing you to model equipment classes as specifc behaviour, and then to compose a machine using a list of classes. That means that if you want to add a new behaviour to a specific machine, you can create a class for it, and then just add that class into the list for the machine you want to add it to.","",""
"855607029518434314","hiptopjones","2023-10-08T10:16:01.0170000+08:00","I like the concept and visualization, thanks!","",""
"855607029518434314","hiptopjones","2023-10-08T10:25:19.3670000+08:00","Yeah, makes a lot of sense that it is also tied to the needs of the organization.  My own path will likely be the maturity path, figuring things out as we go, hopefully accelerated by all of the excellent perspectives in this community. üôÇ","",""
"855607029518434314","hiptopjones","2023-10-08T10:30:34.6140000+08:00","Can you guys clarify what you're actually talking about, because the conversation is very abstract.  Sorry if I'm just slow.  Inheritance vs. composition suggests you're modeling actual object / data relationships in software, but I though you were talking about things at more of a block diagram level.  Inheritance vs. composition is an important consideration, but it's more of an implementation detail than a critical part of (high level) modeling, right?  Maybe I'm just not familiar with the concrete tools and methods you guys are talking about, hence why it felt abstract.  (I have more of a software background rather than manufacturing.)","",""
"783917475128410112","geoffnunan","2023-10-08T16:52:49.7820000+08:00","ISA95 has concepts for Classes and Instances of resources like equipment, materials and people.
So modelling the physical equipment and physical production process is a lot like modelling concepts in software engineering.
An example would be where a factory has several similar machines, you should create a class, or classes that contain the definition of the type of machine, and the create instances of the class for each machine","",""
"855607029518434314","hiptopjones","2023-10-09T00:12:35.0810000+08:00","Ah, right, got it.  My bad--do your research, Peter. üôÇ  https://reference.opcfoundation.org/ISA-95/v100/docs/4.2.4","",""
"568913935147728896","zeratall","2023-10-09T01:28:00.2840000+08:00","Yep, ISA 95 is just one attempt at modeling the manufacturing domain, and probably the most adopted/used, the idea of modeling the floor and thus the end result could look different though depending on who does the modeling. The idea of modeling and taking an OOD approach to manufacturing data is what we were explaining above.","",""
"867075936054149191","rickbullotta","2023-10-09T04:20:20.8490000+08:00","ISA95‚Äôs adoption in practice is greatly exaggerated.","","üßÄ (1)"
"1159798906570408017","bb04958","2023-10-09T04:40:49.9440000+08:00","Hello, new to this discord channel and discord in general so apologies if I would not comply to some rules.
We are a manufacturing company and have an IIOT Cloud platform (Cumulocity - whether that‚Äôs the right platform is a whole other discussion). As we had use cases where latency was of the essence, we deployed Cumulocity also in the edge. But I was wondering: given that you need to have an edge iot platform, does it make sense to still have a cloud iot platform? If I‚Äôm not mistaken, Ignition is also typically deployed in the edge? Note that we still do data offloading to a datalake for offline use cases (reporting and model trainig etc)","",""
"568913935147728896","zeratall","2023-10-09T06:46:10.9090000+08:00","Yeah that‚Äôs probably very true.","",""
"783917475128410112","geoffnunan","2023-10-09T07:19:12.6240000+08:00","Is there another standard that is more widely adopted?","",""
"867075936054149191","rickbullotta","2023-10-09T07:31:21.1670000+08:00","Yes. The null standard.","",""
"867075936054149191","rickbullotta","2023-10-09T07:35:20.2190000+08:00","I have no major issue with folks using some aspects of it - better than nothing unless you‚Äôre force fitting it or spending time and money trying to follow the ‚Äústandard‚Äùand converting  stuff to and from B2MML rather than spending those resources doing something of direct value to the business.  If more major app vendors supported it natively it might be a different story. But if the compliance and adoption burden shifts to the customer/integrator, it can quickly become a net negative.","","üíØ (2)"
"783917475128410112","geoffnunan","2023-10-09T10:36:04.9390000+08:00","I agree completely.
I just think that as engineers, we should start with what is already available, and adjust where required, rather than starting from a clean sheet of paper each time.
Personally, I don't see any value in B2MML. I think that the goal of ""plug-and-play"" is floored, but I see enormous value in a standard ontology that is battle tested across industries","","üíØ (1),üëçüèº (1)"
"568913935147728896","zeratall","2023-10-09T22:45:43.9940000+08:00","@RickBullotta @GeoffNunan so I‚Äôm going to ask a theoretical question and it‚Äôs really rooted with my concerns with ISA and a standard ontology/taxonomy and @RickBullotta hinted at it with his comments about ISA95 adoption in practice.

I think we can all agree that ISA95 is a generalized descriptive model (data, ontology, function model). I think it uses UML? I take the same approach for my domain models except I use SysML, While it does a  job at taking a structured approach for defining what is ‚Äúthe factory‚Äù, it‚Äôs still a generalized solution. My concern is when you look at the functions and interactions of a specific factory they can differ quite a bit from ISA95 definition‚Ä¶.to me that really gets the question is a standard ontology actually a possibility  or more of a pipe dream? I feel that for us to truly use a standard ontology based on ISA95 most factory‚Äôs would need to be designed from ISA95 and that‚Äôs not the case.","",""
"867075936054149191","rickbullotta","2023-10-09T22:47:19.4010000+08:00","To me it's just a best practice, not a compliance standard.  Fit the ""standards"" to your needs, not the other way around.","","üëç (2)"
"867075936054149191","rickbullotta","2023-10-09T22:48:25.3940000+08:00","And when I say ""best practice"" I really mean sharing knowledge - not ""best"" in the ""betterer"" sense.","",""
"568913935147728896","zeratall","2023-10-09T22:49:04.1700000+08:00","Yeah that makes sense and is aligned with more or less what I think of ISA95.","",""
"867075936054149191","rickbullotta","2023-10-09T22:51:10.7180000+08:00","As I mentioned and @GeoffNunan points out, ISA95 is a lot of stuff.  Fully drinking the koolaid and going down the B2MML rabbit hole is a whole 'nother world of pain.","",""
"568913935147728896","zeratall","2023-10-09T22:54:03.0300000+08:00","Yeah totally agree, while we have been talking about ISA95 I think the bigger question really is generically, can we even achieve a ‚Äústandard ontology‚Äù, my initial thought is no, based on the points I made above, but was curious what others thoughts were.","",""
"867075936054149191","rickbullotta","2023-10-09T22:57:33.9840000+08:00","I was involved heavily in ISA88 and for quite a while with ISA95.  The realization that we came to is that if we accomplished nothing else than a common set of terminology by which end users, integrators, and vendors could discuss requirements and implementations, we would have done a good thing.  That's ultimately where it delivered value IMO.","",""
"568913935147728896","zeratall","2023-10-09T23:00:25.5380000+08:00","Yeah see that makes a lot of sense, aka a common framework that we can all work with and use as a way to calibrate everyone on what we are talking about, but using it to drive standardization that‚Äôs where I get a little iffy, only because there are differences  between how factory‚Äôs actually operate vs what is defined in ISA95.","",""
"568913935147728896","zeratall","2023-10-09T23:02:27.3730000+08:00","I‚Äôll admit my viewpoint also might be a little bit just because I support aerospace and defense and our factories can be structured very differently.","",""
"890244048739270656","brianpribe","2023-10-10T00:46:13.5200000+08:00","@DavidSchultz can we get your input as well? Someone‚Äôs gotta go up against Rick ü§∫ü§∫","",""
"783917475128410112","geoffnunan","2023-10-10T02:29:45.3180000+08:00","I'd love to hear about some of those differences.
Starting to get the sense that you may not understand how the standard works.
ISA does not tell you how you factory should operate, it's a generic framework for modelling resources, recipes and recording actuals.","",""
"568913935147728896","zeratall","2023-10-10T02:31:51.7030000+08:00","It‚Äôs not a modeling resource it‚Äôs a functional hierarchy.  it even says so in the standard itself, aka it seeks to model the behaviors and interactions (aka logical view) of the factory. Everything else like the physical architecture which your mentioning as modeling resource is required to model the entire descriptive model. But the main purpose of ISA 95 is to model the interactions and functions aka the logical side of a factory.","",""
"568913935147728896","zeratall","2023-10-10T02:33:49.0660000+08:00","Those interactions are abstract and generalized and that‚Äôs where you can see differences between how a factory operates vs what is defined in the standard.","",""
"568913935147728896","zeratall","2023-10-10T02:34:23.5560000+08:00","If the logical behavior is fundamentally different that can also mean differences in physical or how the physical was modeled.","",""
"783917475128410112","geoffnunan","2023-10-10T02:38:28.5440000+08:00","Can you share an example of something that you think does not fit well in ISA95","",""
"568913935147728896","zeratall","2023-10-10T02:40:52.2360000+08:00","Absolutely, give me a few to pull up my copy of ISA95  and create a seq diagram","",""
"867075936054149191","rickbullotta","2023-10-10T03:54:09.5460000+08:00","Bzzzzzt.  Wrong answer.  Just part 1 would cost you $468 to get a copy of it (seriously - how f*cked up is that).","",""
"867075936054149191","rickbullotta","2023-10-10T03:55:52.8180000+08:00","The full collection would cost thousands of dollars.  So much for ""open standards"".  LOL","","üéØ (1)"
"568913935147728896","zeratall","2023-10-10T03:58:24.7470000+08:00","I have the full standard and have read it entirely lol","",""
"568913935147728896","zeratall","2023-10-10T03:59:41.9550000+08:00","I even have some it modeled  in  a cameo model","",""
"867075936054149191","rickbullotta","2023-10-10T04:01:07.1870000+08:00","You need a hobby.","","ü§£ (3)"
"745796393855352953","thedavidschultz","2023-10-10T04:05:41.0180000+08:00","I was at the ISA Automation & Leadership Conference last week. I had a lengthy conversation with Chris Monchinski who is the current chair of the S95 standard committee. Although over 200 people, 6 years and 1000s of hours were spent developing the first publication of the standard, it is not well understood by integrators or manufacturers. We both agreed that it has not been marketed or communicated well. As such, there will be much more focus on teaching the standard so that people understand what it is and how it can be used. To be sure it is more than Enterprise/Site/Area/Line/Cell.

As far as the cost of the standard, I have some upcoming meetings to discuss how the standard could be made available for free and sell training. There is currently training offered for $1800 that includes the first 6 parts of the standard. I am finding out when this curriculum was last updated. The conversation with Chris suggested it is outdated and needs to include more content for modern technology. Stay tuned for updates on this.","","üëèüèº (5),üï∫ (1)"
"568913935147728896","zeratall","2023-10-10T04:06:25.4430000+08:00","@RickBullotta  btw you‚Äôd appreciate my actual hobby (https://racingsimtools.com/download) software project I created a few years back now, have 5k active users lol.","","‚ù§Ô∏è (1)"
"783917475128410112","geoffnunan","2023-10-10T04:11:36.3020000+08:00","This is my simplified overview of ISA95 (with a couple of adjustments to make it suitable to use as a DataHub schema)","https://cdn.discordapp.com/attachments/815945777452941313/1161033243840221195/ISA95_Overview_diagram.pdf?ex=68df8538&is=68de33b8&hm=8008350c814a4de5867aac553aa37918c821952182c204cd07e260f5effa6568&",""
"756247672637358181","sherylmccrary","2023-10-10T04:13:52.4870000+08:00","Why am I afraid to open this diagram ^? LOL","",""
"867075936054149191","rickbullotta","2023-10-10T04:16:33.4230000+08:00","That's the ""simplified"" version? üòà","","üòÄ (1)"
"867075936054149191","rickbullotta","2023-10-10T04:19:35.2320000+08:00","I think Dennis Brandl was also doing some ISA95 training at some point.  Both Dennis and Chris are good people, and I have faith that they want to do what is best for the community.","",""
"568913935147728896","zeratall","2023-10-10T04:22:24.6230000+08:00","No, that's only a simplified version of part 2, and not the entire standard as a whole üòõ","",""
"568913935147728896","zeratall","2023-10-10T04:40:53.5700000+08:00","So if you look at ISA-95 as a whole standard and really think about what it's trying to do, it's really trying to create a descriptive model of the factory. The image they use in the standard (ISA95 Part 1) is below, as you can see each view depends on the view before these different views are contained within different parts of the ISA95 standard:","https://cdn.discordapp.com/attachments/815945777452941313/1161040614209617970/image.png?ex=68dee355&is=68dd91d5&hm=e2702231e7b53d793a4250cd34a62fbb21e20e30eae411264bc1d52ab967a282&",""
"783917475128410112","geoffnunan","2023-10-10T04:42:23.0510000+08:00","It's part 2 and part 4. 
For the purposes of UNS / Data Schema, this is what we work with most of the time","",""
"568913935147728896","zeratall","2023-10-10T04:42:59.1400000+08:00","To create a descriptive model you need a few different views (A Domain Model, a Logical Model, and a Physical Model). From the above picture you can see ISA-95 is covering all of those:
1) Domain Descriptions = Domain Model
2) Functions = Logical, Activities/Functions.
3) Information Flows = Interactions, aka flows between activites/functions. 
4) Categories = Physical and really the ontology that helps bridge the gap between physical and logical.","",""
"568913935147728896","zeratall","2023-10-10T04:49:35.6280000+08:00","My whole pick with ISA-95 and using its onotology to support factories that weren't built with ISA95 in mind. Is that the ontology depends on the decomposition of the logical architecture, if a factory doesn't operate as the functions/flows that are depicted in ISA-95 that ontology might not make sense for the factory. or look very different. That being said I really like the approach ISA95 took to model the factory, and I follow a very similar process (but in SysML) to model my factories. I really think all factories should create a descriptive model like ISA95 for themselves.","",""
"783917475128410112","geoffnunan","2023-10-10T06:58:16.4860000+08:00","As a schema for a Data Hub, I've not found a factory yet that does not fit.","",""
"794542235676180500","akoscs","2023-10-10T15:26:40.3490000+08:00","Turns out, you were right to hesitate opening it!","",""
"783917475128410112","geoffnunan","2023-10-10T15:32:29.0420000+08:00","Thats why we love working in Manufacturing.
It's complex enough to always be a challenge","","üòÄ (4)"
"867075936054149191","rickbullotta","2023-10-10T19:55:22.3470000+08:00","Truth!","",""
"740383178279354388","mriiot","2023-10-11T20:50:57.6720000+08:00","No need to hide your love of standards.","",""
"740383178279354388","mriiot","2023-10-11T20:52:31.7790000+08:00","I dont want to pay $500 for a PDF, where can I get a copy?","",""
"745796393855352953","thedavidschultz","2023-10-11T21:46:19.2620000+08:00","You can join ISA and view every standard for free. I am working on making them available for free in general. I will keep you posed.","","‚ù§Ô∏è (5),üëç (1)"
"568913935147728896","zeratall","2023-10-11T22:12:56.3540000+08:00","Hahaha, I definitely don‚Äôt love standards, I just make sure to read everything so I understand/know what I‚Äôm talking about.","",""
"867075936054149191","rickbullotta","2023-10-11T22:16:56.1310000+08:00","Documents must always pass the airplane test.  If I can't read/view them on an airplane, they're dead to me.","",""
"745796393855352953","thedavidschultz","2023-10-11T22:17:42.6450000+08:00","I can send you my printed copies üòÇ","",""
"867075936054149191","rickbullotta","2023-10-11T22:18:37.4190000+08:00","Will they fit in the overhead compartment?","",""
"766684226455207996","bright_hummingbird_31342","2023-10-12T09:08:53.7110000+08:00","I like your approach.  Has any factory been built with ISA95 in mind?","",""
"783917475128410112","geoffnunan","2023-10-12T10:44:14.1320000+08:00","That's like saying ""Has any factory been built with architecture in mind"" ISA95 is a framework that supports anything  factory. It is not opinionated about what the factory does or how it works","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2023-10-12T11:02:08.8900000+08:00","I like your approach as well. That‚Äôs actually a better question. Has any factory been built with architecture in mind? Further more, if it were, would the staff broadly know and think about it this way?","",""
"568913935147728896","zeratall","2023-10-12T11:54:46.5610000+08:00","You are correct, the data model that is defined in ISA95 is a framework, but it was derived from defining an abstract definition of how a ""factory operates"" aka defining the functions and interactions.  If you read the entire standard, modeling how the ""factory works"" as you said, is exactly one component of ISA95 (aka function and flow model which is highlighted below). ISA95 is literally telling you that's the case (see the screenshot below).","https://cdn.discordapp.com/attachments/815945777452941313/1161874580596596827/image.png?ex=68df4906&is=68ddf786&hm=ce6ed0c02b724bf5e39a70437d74464991f1c72b5f331e6873404d0dbea5fa87&",""
"568913935147728896","zeratall","2023-10-12T12:04:06.7350000+08:00","Yeah I love that question tbph, my take is probably not.","",""
"783917475128410112","geoffnunan","2023-10-12T13:11:12.7650000+08:00","Yes, but it's conceptual.
Almost all manufacturing factories will have these concepts in some form. The implementation may be different from the conceptual model.
It's just a checklist to help you think about all the possible functions that a manufacturing business may have.","",""
"867075936054149191","rickbullotta","2023-10-12T21:06:40.4770000+08:00","Here's an article from ISA, basically saying the the ISA95 hierarchial model doesn't work as well anymore, particularly in the context of Smart Manufacturing/I4.0 - but I also don't see any recommendation/solution for addressing it?

https://www.isa.org/intech-home/2021/october-2021/features/beyond-the-pyramid-using-isa95-for-industry-4-0-an","",""
"745796393855352953","thedavidschultz","2023-10-12T21:35:11.2650000+08:00","tldr;
ISA95 does not mandate PERA.","",""
"867075936054149191","rickbullotta","2023-10-12T21:49:17.0490000+08:00","Of course not. But in the context of a UNS aren‚Äôt most of the folks here using that approach?","",""
"745796393855352953","thedavidschultz","2023-10-12T22:28:52.5310000+08:00","Sort of. There are equipment models that mimic PERA. But the UNS structure will reflect how the plant is organized. For instance a manufacturer may have a legacy side of a plant that is Site/Area/Equipment with multiple pieces of equipment for the area. The new modular side that has single piece of equipment is Site/Train/Equipment. The functional and asset namespaces/models that exist within them will remain consistent to facilitate data exchange with other nodes. What Dennis is attempting to do is decouple S95 with PERA.","",""
"867075936054149191","rickbullotta","2023-10-12T22:53:35.3460000+08:00","Got it.  I do think there's still a fundamental disconnect trying to model the equipment that is shared across lines/trains or that is movable/portable.  Hard to represent in a hierarchy of course.  I know I'm a dreamer, but topic links (which are effectively relationships or edges in a graph) would be killer.  And throw in metadata on topics and topic links and we could do some really, really amazing things.

I think it's time to maybe consider what comes after MQTT.  It could work a lot like MQTT, but with its shortcomings addressed to enable more modern applications.","",""
"745796393855352953","thedavidschultz","2023-10-12T22:57:53.6080000+08:00","There are equipment models and there are asset models. One of the topics we learn in Mentorship is how to create dynamic equipment hierarchies that facilitate ""portable"" assets. While this works great in SCADA, not as easy to do in MES. Part of the challenge has been the traditional technology available. Knowledge graphs certainly help with this (and versioning).","",""
"783917475128410112","geoffnunan","2023-10-13T04:14:45.8250000+08:00","ISA95 has 2 ways to deal with this.
First, there is a separation between Role based Equipment and Physical Asset, allowing moveable/portable physical assets to be dynamically linked to the role its playing on a line.
Second, there is a Resource Network concept which allows any relationship to be modelled. This is usefull for modelling shared equipment, upstream/ downstream, or modelling all of the equipment that shares the same electrical distribution board. You can link literally any resource to any other resource in a graph with metadata.","","üëçüèº (3)"
"783917475128410112","geoffnunan","2023-10-13T04:19:04.1600000+08:00","What comes after MQTT is GraphQL.
MQTT is just for publishing telemetry data. It is a flawed architecture for a UNS for anything other than very simple use-cases","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-10-13T04:35:44.8180000+08:00","Except some of the major graphql implementations like Apollo don‚Äôt recommend using their built in pub/sub in production or at scale - and one of the things they recommend - wait for it - is backing it with an MQTT broker.","",""
"783917475128410112","geoffnunan","2023-10-13T04:48:33.6940000+08:00","I know you can separate the technology from the implementation though üôÇ","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-10-13T05:00:23.9190000+08:00","Have any of the GraphQL servers solved the challenge of heterogenous joins across large datasets from multiple systems yet?  Something ""Spark-like"" to divide and conquer?","",""
"783917475128410112","geoffnunan","2023-10-13T05:05:30.5300000+08:00","Apollo Router is as close as that gets in GraphQL.
https://www.apollographql.com/docs/router/","",""
"568913935147728896","zeratall","2023-10-13T05:16:36.1890000+08:00","Just curious what is wrong with that design pattern?","",""
"867075936054149191","rickbullotta","2023-10-13T06:26:17.0050000+08:00","No idea what the limitations are of their built-in pubsub.","",""
"568913935147728896","zeratall","2023-10-13T06:39:33.8890000+08:00","Yeah sorry I meant the comment about having to pair a broker with a graphDB, not the limitations of their built in capability, sorry.","",""
"867075936054149191","rickbullotta","2023-10-13T06:40:44.4090000+08:00","Above my pay grade. Maybe @GeoffNunan can chime in.","",""
"794542235676180500","akoscs","2023-10-13T13:55:46.4860000+08:00","""Apollo GraphOS is the platform for building, managing, and scaling a supergraph"" I am not gonna lie, they had me at supergraph!","",""
"740383178279354388","mriiot","2023-10-13T21:04:31.8560000+08:00","@Russ from the Internet how is this addressed in MTConnect","",""
"329780110704246790","rkwadd","2023-10-13T23:06:52.9940000+08:00","‚ÄúModel based standards development.‚Äù The constraints Rick is talking about with xml and hierarchical representations are exactly why MTConnect‚Äôs canonical data model is built with SysML instead of plain JSON schema or XML. There are whispers that B2MML, an xml implementation of ISA95, is also going to move that direction. OPC UA same thing. Microsoft has solved the same problem in Digital Twin Definition Language (DTDL) using JSON Linked Data (LD). SysML, UML, JSON LD, and RDF are all dedicated modeling languages.

So far there‚Äôs no language to model the acronym soup of what I just typed, so maybe we should spin up a new standards body.","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-10-13T23:16:19.0630000+08:00","‚ÄúThe great thing about standards is that there are so many to choose from‚Ä¶‚Äù","","ü§£ (4)"
"740383178279354388","mriiot","2023-10-13T23:35:38.7210000+08:00","What about the ‚Äúmovables‚Äù?","",""
"329780110704246790","rkwadd","2023-10-14T00:35:12.7110000+08:00","The entire point of these modeling languages is to express open ended relationships. A cart full of parts that has stopped at 12 machines has a lot of relationships all existing at once: part to cart, part to part, part to machine, cart to station, cart to operator, part to operator, part to batch, etc.  Some of these relationships are hierarchical; some are not. Some are permanent; some are transient.","",""
"329780110704246790","rkwadd","2023-10-14T00:37:29.7490000+08:00","To paraphrase Rick, reality is not hierarchical. So when your information model is strictly hierarchical there are going to be a lot of things that simply cannot be represented by a hierarchical model.","","this (1),üëç (1)"
"329780110704246790","rkwadd","2023-10-14T00:52:58.8370000+08:00","On the off chance that any regular, normal people are trying to follow along and thinking ‚Äúthis sounds pretty complicated, I really just need some XML,‚Äù you are not wrong. Having some system architect upstream getting deep into the weeds is still helpful because the simple hierarchies don‚Äôt disappear. They are just subsets or derivatives of the bigger more complex model. A simple XML schema that you build as a one off is not easy to retroactively relate to other hierarchies; a simple schema inherited from a wider framework or reference architecture has already had that relationship established upstream.","",""
"568913935147728896","zeratall","2023-10-14T01:01:01.9110000+08:00","@Russ from the Internet awesome to have another architect/modeler here in the discord! Wish I could show you the framework I‚Äôve created for modeling our factories at NGC in Cameo, curious are you doing anything similar for your projects?","",""
"329780110704246790","rkwadd","2023-10-14T02:02:45.5400000+08:00","Yep, machine tool and some process modeling. In cameo. That came as recommended from long discussions with Boeing. However I‚Äôm just the mouthpiece. You need @Will Sobel and @Shaurabh","","üëÑ (1)"
"568913935147728896","zeratall","2023-10-14T02:43:57.5220000+08:00","Aaaah very cool I am modeling quite a bit for IT/OT we have models for both domain and solution, which includes physical, operational, logical of our architectures, then I have a few other models for enterprise which includes RACI and then all internal processes like approvals etc .","",""
"898217314741280828","hobbes1069","2023-10-14T09:01:58.9130000+08:00","Dang I've missed a lot over the last few days here... Under the gun on a project at work. My drive-by summary of ISA95 and abstraction: Define a cell.","",""
"794542235676180500","akoscs","2023-10-16T20:29:25.2020000+08:00","I am about 80% done with a proof of concept implementation of a very data heavy application incl. machine learning (I cannot share it) where I really really really wanted to go full blown UNS to counter my OPC-UA fanboy tendencies. Everything that has logic is written from scratch, everything is a microservice implemented as a container (inputs coming from machines are currently all emulated). There is a mix of IT tech which is only state of the art. Anything that could be legacy is emulated with a microservice written from scratch especialy for that purpose, so there are absolutly no restrictions on what is used and no restrictions coming form any legacy system. So far so good, perfect grounds for doing a UNS with absolutly no restrictions. In practice the ""feature"" of the UNS to be a singe soruce of truth is with a generic MQTT Broker very cumbersome to implement. You either implement a request/reply mechanism over MQTT which, you can, but kind of defeats the purpose of MQTT, or you missuse MQTT as a database and add a bunch of static data, which will never change but you add them as a persistent message, pre-emptively, jus tbecause you need it down the line. So the UNS if implemented with a generic MQTT broker should be the single source of truth ONLY for dynamic data, otherwise you are runnnig a very inefficient infrastructure. Anybody care to chage my mind?","","üíØ (4)"
"817835202746253344","IIoT#4707","2023-10-16T20:29:25.7190000+08:00","GG @akos, you just advanced to level 18!","",""
"794542235676180500","akoscs","2023-10-16T20:34:25.2390000+08:00","The other limitation not necesarily directly UNS, but a limitation derived frm it being a single source of truth to which everything connects. If you have a microservice running needing input from more then 1 mqtt topic, and those topics are corelated in time, normally, you would cache everything to redis and let the microservice work on the cache and find the message tuples it needs on its own. Now with the UNS being the central hub everything connects to this is also not possible, so cahcing becomes a more local issue then something done more centrally. I also do not like this aspect.","","üíØ (1)"
"794542235676180500","akoscs","2023-10-16T20:36:24.8720000+08:00","My conlcusion is that the UNS is great, when applied with much more creative freedom then what short descriptions/youtube videos/minimum technical requirements and anything else similar would suggest.","",""
"867075936054149191","rickbullotta","2023-10-16T21:07:01.2680000+08:00","This.","",""
"867075936054149191","rickbullotta","2023-10-16T21:08:08.5860000+08:00","Caching can sorta be done with retained topics if the broker supports them.","",""
"794542235676180500","akoscs","2023-10-16T21:10:38.5220000+08:00","No, only if the message tuples you need form n different topics are guarnteed to be in the same publish rate on each topic. Otherwise on one topic you already have 5 messages but their ""pairs"" come later due to more heavy processing.  Eventually you need to balance this by replicas of the services ""doing more work"", but until you detect which services need to scale out and you actually scale out, you need the cache otherwise you loose mesge pairs without caching them. Fruthermore if the cache is more central you can derive scale-out logic from seing what is qeued up and what is missing.","",""
"867075936054149191","rickbullotta","2023-10-16T21:15:35.5860000+08:00","Yeah, I agree. My Uber broker also includes a time series DB and a query layer that doesn‚Äôt go through the broker.","",""
"867075936054149191","rickbullotta","2023-10-16T21:17:13.9370000+08:00","I do think you should plan for some of that normalization to occur at the query processing to deal with pre-existing time series stores.","",""
"794542235676180500","akoscs","2023-10-16T21:44:26.1210000+08:00","That as an implementation would mean storing somwherer (in readis) and having a service picking the tuples, when needed, right? I mean I could do it in a timeseries db, OK, but at the end I do not want to persist these values, just use them on the fly and persist the resutls.","",""
"867075936054149191","rickbullotta","2023-10-16T21:48:33.5080000+08:00","That's an option.  TwinThread does some of that (cache a certain amount of historical data in Redis).  Why won't you be persisting the data as well?  At a minimum persisting any composite/synthetic data, alerts, and events you generate for visualization and analysis purposes?","",""
"740383178279354388","mriiot","2023-10-16T21:50:59.0430000+08:00","Didn't even know this was a thing.  But I sure did party hard on Saturday. https://spectrum.ieee.org/world-standards-day-2023","","ü§£ (1)"
"794542235676180500","akoscs","2023-10-16T21:52:31.7150000+08:00","Intermediary steps in a large chain of computation for data preparation stage. I would store only the final features which will be input for the ML model, not the calculation chain's intermediary steps, the rest I just need cached to make sure all intermediary results are available where needed with their coutnerparts coming from a different chain.","",""
"867075936054149191","rickbullotta","2023-10-16T21:59:38.7110000+08:00","You may find that limiting in the long run as AutoML gets better and better - it's usually best to ""overdo it"" when first training models and I think you lose important context if you overnormalize data.","","üëç (1)"
"794542235676180500","akoscs","2023-10-16T22:03:37.0590000+08:00","I do pretty heavy feature engineering not (over) normalization, but I vent overboard with the micro part in microservices :))). I agree with the AutoML aspect though, but this is more or less en exercise and proof of concept...so this is why everything is a bit exagerated.","","ü§£ (1)"
"867075936054149191","rickbullotta","2023-10-16T22:09:11.3590000+08:00","That's actually a very useful process sometimes - test the extremes.","","üëçüèº (1)"
"756247672637358181","sherylmccrary","2023-10-25T03:33:20.7150000+08:00","Hi. I just watched your SmartIndustry.com webinar with John Harrington ""Where IT Meets OT...""  Really enjoyed it. Some of the best comments were yours at the end: need to map relationships between site models and Ent ontology; need for software defined networking, identity based security to enable data flows.","",""
"568913935147728896","zeratall","2023-10-25T04:21:09.4280000+08:00","Thank you, It was a lot of fun! Was excited to share some of thoughts and what we‚Äôre doing at NGC","","üòÄ (2)"
"666121790610735110",".dmays","2023-11-01T01:17:49.7440000+08:00","Where can we find the actual standard?","",""
"745796393855352953","thedavidschultz","2023-11-01T01:49:02.6150000+08:00","It is available for purchase at the ISA store (isa.org). I think parts of it are included in mentorship/mastermind as well.","",""
"867075936054149191","rickbullotta","2023-11-01T05:29:16.7380000+08:00","You'll need SVP level approval though - it's expensive.","","üò± (1)"
"745796393855352953","thedavidschultz","2023-11-01T05:31:23.1990000+08:00","Still working on it...","",""
"744671252605829181","jeff.rankinen","2023-11-06T09:18:58.5140000+08:00","Evidence that claude.ai has ingested much or all of the ISA-95 standards. Wondering if that information might help ISA make quick and wise decisions for a better business model. @DavidSchultz can you check it out?","",""
"744671252605829181","jeff.rankinen","2023-11-06T09:21:11.0650000+08:00","Claude.ai has about an 80 page, 100k token read ability.","",""
"745796393855352953","thedavidschultz","2023-11-06T09:28:09.4100000+08:00","I will look into it. Not sure what the last sentence means. Part 2 is over 360 pages by itself.","",""
"745796393855352953","thedavidschultz","2023-11-06T09:29:47.4040000+08:00","Your comment also makes me wonder how copyright protection will apply in LLMs. I seem to recall this becoming an issue.","",""
"744671252605829181","jeff.rankinen","2023-11-06T10:09:00.9560000+08:00","I used a prompt to generate an Arduino program to publish to a broker using the ISA part 2 hierarchy and it was able to produce it without question. I asked it a few more questions concerning the standard, and it said it could answer specific questions. I also wonder how these LLMs will deal with copyright.","","üëç (1)"
"745796393855352953","thedavidschultz","2023-11-06T23:24:32.6920000+08:00","The hierarchy you are referring to is the Part 2 equipment model, which is explicitly modeled in Part 1. This is directly from the Purdue Enterprise Reference Architecture or Purdue Reference Model as it is called in S95. It would be interesting to know what other information it could provide. The standard itself could not be used for training (copyright). But the concepts presented could be, provided they were from a different source. That said, the standard itself does not have the value. It is the application of the standard that does.","","üëç (1)"
"1129435706285101076","ted.garrison","2023-11-11T03:04:31.5620000+08:00","Copyright? who care's about copyright.. we're AI!...we'll just ingest EVERYTHING and to bad for copyright..  (/sarcasm)","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-11-14T05:57:36.1390000+08:00","Grafana is absolutely, positively the WEAK LINK in the MING stack.  Such a frustrating, obtuse, and limiting piece of software.  Great for monitoring IT infrastructure. Lousy for a more sophisticated IoT or IIoT user experience.  Gotta keep looking...","","üíØ (1)"
"568913935147728896","zeratall","2023-11-14T06:49:26.9680000+08:00","Build your own this is the library I use for all my graphic needs, the performance is insane: https://www.scichart.com/example/javascript-chart/load-500-series-x-500-points-performance-demo/?_gl=1*1tzj4av*_gcl_au*OTUzNTMxMTYyLjE2OTk5MTU2ODQ.#bs-cookie-bar","",""
"867075936054149191","rickbullotta","2023-11-14T07:20:01.0070000+08:00","Yeah, that‚Äôs what I‚Äôve been doing, but I want a no/low code solution also.","",""
"894527802316046366","nickn5549","2023-11-14T18:35:52.8640000+08:00","PHPRunner (low code) has AnyCharts incorporatred, which are not bad","","üëçüèº (1)"
"794542235676180500","akoscs","2023-11-15T05:32:56.4340000+08:00","Do you have a quick price info on the nonfree version?","",""
"794542235676180500","akoscs","2023-11-15T05:33:39.4730000+08:00","nevermind I foudn it on the site","",""
"568913935147728896","zeratall","2023-11-15T06:01:29.3500000+08:00","Not sure, I actually dont have the JS version, I paid 1k/dev for the C# version since my side husttle is all .NET","",""
"568913935147728896","zeratall","2023-11-15T06:01:58.7230000+08:00","That being said the performance has been incredible, been able to have real time graphs for race car analysis which is a pretty big challenge considering the number of data points being draw every 16ms","",""
"867075936054149191","rickbullotta","2023-11-16T08:50:38.1680000+08:00","Discuss: https://www.linkedin.com/posts/erich-barnstedt-9a84685_accelerating-industrial-transformation-with-activity-7130688417960488960-Hxyx?utm_source=share&utm_medium=member_ios","","üëÄ (1)"
"917925131261718558","jpmoniz","2023-11-16T08:56:08.8680000+08:00","Would like to see the all in $$$  based on msg/sec or something like that for the whole stack.","",""
"917925131261718558","jpmoniz","2023-11-16T08:57:39.4310000+08:00","Also would like to know how they handle the integration across subscription boundaries","",""
"917925131261718558","jpmoniz","2023-11-16T09:07:09.1480000+08:00","And Like all of the other edge brokers need the capability to curate the namespace at first glnce that seems to be missing.  I suspect they deem that a cloud function.","",""
"917925131261718558","jpmoniz","2023-11-16T09:12:49.6320000+08:00","Also odd that they are not showing MQ leave the cluster only OPC UA and Akri","",""
"456226577798135808","Deleted User","2023-11-16T09:13:32.5570000+08:00","Wow this is interesting. I like the direction they're headed. 
Would also really love to see better PLC health management similar to Cisco DNAC or maraki without having to manually expose tag data through PLC logic. Maybe this already exist and I'm not aware of it.","",""
"917925131261718558","jpmoniz","2023-11-16T09:15:52.7480000+08:00","What do you mean by health management?","",""
"456226577798135808","Deleted User","2023-11-16T09:32:31.7850000+08:00","I don't know what cluster diagram you are referring to.. but I think Azure IoT Data Processor is where a UNS can be built if wanted.","",""
"456226577798135808","Deleted User","2023-11-16T09:35:26.2560000+08:00","Like monitoring the CPU utilization, memory, Class 3 utilization, uptime, etc","",""
"917925131261718558","jpmoniz","2023-11-16T09:35:53.6630000+08:00","Was just the way they drew it.  Makes sense reading the Docs.","",""
"917925131261718558","jpmoniz","2023-11-16T09:36:24.0400000+08:00","what PLC's?","",""
"456226577798135808","Deleted User","2023-11-16T09:47:18.3770000+08:00","My experience was with Rockwell. But, this would be desired in any PLC. However, I'm sure this type of software would need to come from the PLC hardware manufacture itself. Unless one day all the PLC manufacturers decide to hold hands and work together to create a standardized exposed health monitoring interface. Which I'm sure would never happen lol","",""
"917925131261718558","jpmoniz","2023-11-16T09:48:08.8620000+08:00","Have you tried scraping the web page for it?","",""
"917925131261718558","jpmoniz","2023-11-16T09:49:01.0220000+08:00","We did that with Fanuc and thier robots.  Became pretty handy.  Scraped the information with node red i think and then published it to a broker","",""
"917925131261718558","jpmoniz","2023-11-16T09:49:37.9770000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1174526661941805056/image.png?ex=68df2bb1&is=68ddda31&hm=ac4a2c048fac4589dc0730814d40d38bfd2752b156f412944f30a76cd3ced3ca&",""
"917925131261718558","jpmoniz","2023-11-16T09:49:59.8200000+08:00","Just happen to have an example right here","",""
"456226577798135808","Deleted User","2023-11-16T09:52:26.3050000+08:00","Ugh that's so much work and time lol
Plus class 3 communication is not even exposed natively. You have to enable it in the PLC for the web page. 
I wish there better observability and monitoring tools available.","",""
"917925131261718558","jpmoniz","2023-11-16T09:54:57.1460000+08:00","I hear you its a pain.  We generally dont pay to much attention to PLC heath.  I view it as pretty fixed Same program running all the time comms load rarely changes.  I think we get something from claroty but not much from what I remember.","",""
"254777321788145664","terrancesmith","2023-11-16T20:26:43.9710000+08:00","Big stuff here. They can't be as agile or off the cuff as startups or SIs but they aren't sleeping on innovation either!","",""
"867075936054149191","rickbullotta","2023-11-16T21:09:47.4740000+08:00","It would be foolish to underestimate the impact on the market, customer perception, and so on.  Whether it gets real traction or not is another discussion, but it will absolutely shape the conversation moving forward.","",""
"867075936054149191","rickbullotta","2023-11-16T21:11:21.6770000+08:00","It also falls well short of what I envision as the ""uber broker"" or next gen UNS/IIoT platform.  It's lacking in key areas like a time series data store, edge visualization, and a twin model or asset model - but they have all of those components elsewhere in Azure, and since this is built on Azure Arc/Kubernetes, it's not a heavy lift for them to add stuff.","",""
"254777321788145664","terrancesmith","2023-11-16T21:12:18.9410000+08:00","Exactly. The original IoT Hub et all was so iot device focused that it wasn't very fit for purpose for IIoT. This is a big pivot to the stronger adoption coming from industry.","",""
"867075936054149191","rickbullotta","2023-11-16T21:13:47.4650000+08:00","And it's edge, not cloud!","",""
"1129435706285101076","ted.garrison","2023-11-17T01:43:40.3050000+08:00","""Fully featured MQTTv5 broker"" that's missing features like LWT and retain...","",""
"867075936054149191","rickbullotta","2023-11-17T01:49:29.6360000+08:00","Sort of. LWT is actually not all that useful for iiot use cases in my view. I prefer application level heartbeats that reflect the actual end devices, not the MQTT publisher. I would definitely like to see retain added, but if you look at the docs there‚Äôs a separate LKV (last known value) store included in the stack, so the functionality is there (and is accessible to apps that want it without having to spin up an MQTT connection and subscription, which is actually something I very much like). It should support standard retain though too, and it will at GA I‚Äôm told.","",""
"1129435706285101076","ted.garrison","2023-11-17T01:54:38.2230000+08:00","just a pet peeve of mine.  Like when Engineers love to declare a project ""complete""..  except there are 20 things on the to-do list, and it's not yet in production...","","üíØ (1)"
"867075936054149191","rickbullotta","2023-11-17T02:14:15.2630000+08:00","I agree with you completely.  Words matter.","",""
"240066112773947393","leeeelemon","2023-11-18T11:32:49.0830000+08:00","Interesting. This'd be why IoT Edge development has gone quiet. Looks like the mqtt broker doesn't support mutual tls or shared subscriptions either.","",""
"817835202746253344","IIoT#4707","2023-11-18T11:32:49.3630000+08:00","GG @leelemon, you just advanced to level 1!","",""
"830193224504705035","marc.jaeckle","2023-11-19T02:31:38.9950000+08:00","The good thing is that they will now also promote the UNS approach and MQTT. It‚Äôs a bit embarrassing that Erich Barnstedt now claims on LinkedIn they been doing this for years (they haven‚Äôt). Well maybe he still has some other idea of what a UNS is. I also find it interesting that he writes that it provides connectivity to EventHubs, EventGrid etc. What the engineering team actually built is an MQTT bridge and a Kafka bridge just like HiveMQ provides it for example. For me that is another big change that they fully adapt MQTT and Kafka instead of doing something proprietary.","",""
"830193224504705035","marc.jaeckle","2023-11-19T02:33:29.5510000+08:00","It‚Äôs a public preview (beta). There are other things as well that have not been completely finished yet.","",""
"830193224504705035","marc.jaeckle","2023-11-19T02:35:58.9630000+08:00","One more thing I love: Azure IoT MQ even provides Prometheus monitoring endpoints. I hope this will feature not be cancelled in a step to ‚Äûazure-ify‚Äú the product before GA.","","üôè (1)"
"830193224504705035","marc.jaeckle","2023-11-19T02:40:52.1810000+08:00","Same problem with AWS Greengrass. Both solutions were built with connected products in mind which is where the device-centricity comes from. It speaks for Microsoft that they were willing to listen to feedback.","","üíØ (1)"
"817835202746253344","IIoT#4707","2023-11-19T02:40:52.6250000+08:00","GG @Marc J√§ckle, you just advanced to level 11!","",""
"830193224504705035","marc.jaeckle","2023-11-19T02:43:47.7320000+08:00","Not yet. It‚Äôs still in beta.","",""
"830193224504705035","marc.jaeckle","2023-11-19T02:51:15.6390000+08:00","It actually lets you define assets, even via CRDs in YAML. You just don‚Äôt see that in the documentation. The problem is that you cannot define the assets independently enough of the specific machine as you currently can‚Äôt use any transformations when mapping data tags from the PLC into the data model. You can build your own hierarchy and use proper attribute names but you can‚Äôt do any unit type transformations for example. So you can‚Äôt create a standardized model for all your machines of the same type that come from different vendors for example.","","üëç (1)"
"795178288330440704","youri.regnaud","2023-11-19T14:25:59.0830000+08:00","This is a very important point you mention here. Where to define the model of a piece of equipment, these mapping rules with the real machine, how to make sure that the whole acquisition chain is aligned! For our part, we're trying to use the ""schema registry"" technique to centrally define all parameters from the PLC down to certain consumers. Today it's a JSON file in our DevOps pipeline that will, for example, update Kepware, Highbyte, our brokers, ... How do you see things from your side?","",""
"830193224504705035","marc.jaeckle","2023-11-19T16:10:29.5940000+08:00","So far I‚Äôm still hoping for the machine connectivity tools like Litmus Edge and Cybus Connectware to provide good solutions for this (as they all move towards becoming something that Cybus and Highbyte call Data Hub). Litmus Edge already lets you define and roll out models centrally with Litmus Edge Manager and I‚Äôm pretty sure this will integrate with their upcoming MQTT broker (which could for example check messages based on those schemas like HiveMQ Data Hub does). If you look closely at the latest YouTube videos from Cybus, you can see that they will provide something they call configuration templates for machines which seems to be going into a similar direction. I‚Äôm hoping that Microsoft will also improve the current implementation in Azure IoT Operations as well. Unluckily all of them still have some limitations that make managing models difficult. Litmus might have fixed one of them as they now seem to provide versioning for the models in Litmus Edge Manager (it was announced in the last days). Even though Cybus is still lacking support for managing models in the currently released version of Connectware, I think they have the better foundation with using yaml based configuration and git + providing a low code UI in the future. Litmus is essentially forced to re-implement things that the git + file based approach provides out of the box. The Cybus video can be found here: https://youtu.be/PD4juszxOrE?si=oDfYq68ljXMEt7Ci (without any sound, it feels kind of weird).","",""
"867075936054149191","rickbullotta","2023-11-19T20:26:55.1000000+08:00","To me it‚Äôs critical that we not think of these models as primarily PLC and device data though.  That would be a very limited solution and would take the ‚Äúuniversal‚Äù out of the UNS.","","üíØ (1)"
"830193224504705035","marc.jaeckle","2023-11-19T20:57:37.4280000+08:00","Good point. We‚Äòve been defining use case specific models, events etc. with those tools as well but they don‚Äôt always play a role in a communication for example if a service directly publishes something via MQTT. So in that case they won‚Äôt help. So far we haven‚Äôt tried to really centrally manage all the data models that are used to communicate via the UNS and I don‚Äôt think I want to do this. Instead we‚Äôve followed more the approach of making data source discoverable and document them in a data catalog. The problem with the data catalogs on the market is that they all assume they are being used for data analytics with mostly data at rest (and maybe Kafka) so they don‚Äôt fit well for documenting the data models of a UNS or of industrial machines. If someone knows a data catalog that lets you document data source like MQTT topics or industrial machines as well, please let me know.","",""
"867075936054149191","rickbullotta","2023-11-19T21:25:48.5530000+08:00","In keep with the theme, I also think that focusing just on ""data"" is a mistake also.  I passionately believe that the universal model must also include services/methods that these entities expose.  Whether to make insights actionable or to expose more sophisticated query capabilities, I consider this essential capability also.","","this (2)"
"794020366536146977","mparris","2023-11-20T09:47:40.6600000+08:00","@RickBullotta  Don't forget about upgrading metadata to the same service level of data: subscription, history, browsable, etc","",""
"794542235676180500","akoscs","2023-11-20T19:37:39.7660000+08:00","Throw in workflow orchestration to get out of an evend drven reactive hell (emphasis on reactive, not on event driven), where you have nabsolutly no idea about possible dataflows and I am on board.","","üëç (1)"
"867075936054149191","rickbullotta","2023-11-21T22:42:31.5420000+08:00","Not sure if I shared this yet, but for you graph and semantic modeling fans, here's a presentation I did (in 2011 - yikes) with the founder of Neo4J:

https://qconlondon.com/london-2011/qconlondon.com/dl/qcon-london-2011/slides/EmilEifrem_and_RickBullotta_UsingAGraphDatabaseToPowerTheWebOfThings.pdf

It's actually quite relevant still.","","üëç (4),üî• (2)"
"740365995419631736","omarazizahmed","2023-11-22T00:55:11.5700000+08:00","Slide 2...","",""
"740365995419631736","omarazizahmed","2023-11-22T00:58:12.2560000+08:00","Pretty cool @RickBullotta - when was that presentation?","",""
"867075936054149191","rickbullotta","2023-11-22T00:58:28.9170000+08:00","2011","",""
"740365995419631736","omarazizahmed","2023-11-22T00:58:41.9050000+08:00","cool","",""
"795178288330440704","youri.regnaud","2023-11-22T06:28:11.9820000+08:00","¬´¬†Mashup the world¬†¬ª üëè","","üíØ (1)"
"770068706247180309","tgchip_1235","2023-11-23T23:35:59.8570000+08:00","# v","",""
"528668306690015284","vatsalshah","2023-12-08T01:49:37.3030000+08:00","You are spot on, Marc - we introduced this ""secretly"" as a part of the Litmus MQTT Broker private beta launch about two months ago.
So if data hits our MQTT brokers in a non-standard way, we can convert them to standard schema or just manipulate topic instream.

We thought about it holistically from existing customer usecases where they have many not-configurable MQTT clients (PLCs, robots, and more) and still want to match it to UNS.","https://cdn.discordapp.com/attachments/815945777452941313/1182378395661766776/Schema_Registry.png?ex=68df63f1&is=68de1271&hm=685557dfb438afbe670715f63921bfcb450f232005c01ccf99354b3236bff7a2&,https://cdn.discordapp.com/attachments/815945777452941313/1182378396030881843/Map_Non_standard_data_to_Schema.png?ex=68df63f1&is=68de1271&hm=9154a4649510f6c329ecae3a29f577059b922f866e2f5fe02c698673fa832750&,https://cdn.discordapp.com/attachments/815945777452941313/1182378396479651850/MQTT_In_stream_manipulation.png?ex=68df63f1&is=68de1271&hm=5f26ec6de2cc8bfb40e04885e1d668917a97ff439a47aceedfbcf4ed2065cf22&","üëèüèº (4)"
"1129435706285101076","ted.garrison","2023-12-08T03:55:26.2570000+08:00","that looks AWESOME.","",""
"528668306690015284","vatsalshah","2023-12-08T05:48:39.2070000+08:00","Yepp - Let me know if you want to try it. Happy to get your feedback.","","üëç (1)"
"873009180938743828","sim_sam3","2023-12-08T06:58:17.9870000+08:00","Something something ThingModel something something","","üòÇ (1),üíØ (1)"
"867075936054149191","rickbullotta","2023-12-08T07:13:24.5770000+08:00","The W3C announced a new version of the web of things spec and it looks a lot like the thing model! DTDL also supports this.","",""
"568913935147728896","zeratall","2023-12-08T08:37:04.3840000+08:00","The thing model is great imho, but not going to lie, the name makes me want to punch something every time I have to explain what it is to non-tech","","üòÇ (3)"
"867075936054149191","rickbullotta","2023-12-08T08:37:38.7170000+08:00","Truth! We felt the same after a while.","","ü§£ (2)"
"873009180938743828","sim_sam3","2023-12-08T09:00:14.0740000+08:00","Oh wow! I only recently heard about WoT in combo with dreamy chatgpt ideas for asset ontology and tag mapping. I‚Äôve never seen it in the field. I should do more reading, seems neat.","",""
"873009180938743828","sim_sam3","2023-12-08T09:11:14.7610000+08:00","Looking at notes my intro to WoT was related to Azure DTs. Wonder how commercially widespread dtdl and wot are outside of azure?","",""
"898217314741280828","hobbes1069","2023-12-08T12:16:10.2960000+08:00","This would work for MTConnect as well. The bog standard cppagent supports MQTT and I've found it an easy way to get data into Kepserver, but I can only specify the root topic. Everything else is a JSONified version of the typical XML that would usually be published.","",""
"528668306690015284","vatsalshah","2023-12-08T13:59:29.3880000+08:00","Yepp it should work. I will ask team to validate in the lab. We saw bunch of those ""dumb""  (and insecure) MQTT clients that does some weird stuff in MQTT broker.
Hopefully Litmus MQTT broker with instream processing solves it for good.

Btw CNC -> MTConnect - > MQTT -> OPCUA is a long way home üòâ 
Try ""CNC -> Litmus -> Anything"" OR ""CNC -> MTConnect -> Litmus -> Anything"" sometimes","","üî• (1)"
"898217314741280828","hobbes1069","2023-12-08T23:51:38.9000000+08:00","Yup, we want to move towards pure MQTT machines but it's a long road with ~600 machines, of which are about 400 Fanuc based CNCs.","",""
"528668306690015284","vatsalshah","2023-12-09T00:48:17.1060000+08:00","Yehh Fanuc CNCs will take a while to get there for MQTT. MTlink might buy some time.
We did a similar project for one of the Precision Parts customer recently. About similar size as yours - ~300 plus a bunch of Heidenhain. TCO was much lower and they control all the data. Their Data Science teams helped them optimize changeovers and working on identifying parts breakage patterns.","",""
"817835202746253344","IIoT#4707","2023-12-09T00:48:17.3890000+08:00","GG @Vatsal Shah, you just advanced to level 4!","",""
"753688565807841492","ravil1","2023-12-09T00:57:21.8890000+08:00","@Vatsal Shah, if you need to get data from Fanuc CNC to MQTT, we might have solution for that. Please DM me.","",""
"528668306690015284","vatsalshah","2023-12-09T01:04:31.9380000+08:00","Thanks - Litmus Edge does that for a while now üôÇ","","üëç (1),ü§£ (1)"
"873009180938743828","sim_sam3","2023-12-09T02:22:10.7840000+08:00","Vatsal is CEO of Litmus üòâ","","üôè (1)"
"753688565807841492","ravil1","2023-12-09T02:30:17.0670000+08:00","Oh, cool! Nice to meet you, Vatsal, namasta!","",""
"528668306690015284","vatsalshah","2023-12-09T03:03:11.1100000+08:00","Great to meet you as well! Namaste üôè","",""
"1021407074988601419","pdmitriev","2023-12-09T04:40:58.2160000+08:00","I have 4 months to stand up UNS in our organization. I‚Äôm evaluating litmus as an edge solution. Will I be able to test this broker as a part of PoC as well or is it available for selected folks only?","","üëçüèæ (1)"
"528668306690015284","vatsalshah","2023-12-09T05:32:55.2390000+08:00","Yes we can. Can you please Dm me ?","",""
"1139269147126153216","suran23.","2023-12-09T06:25:56.9870000+08:00","@PeterDmi plz reach out via DM to me or Vatsal and we can loop you in to the private beta","",""
"568913935147728896","zeratall","2023-12-10T02:15:19.6690000+08:00","So working on a little bit of a side project atm, that I thought was cool, and wanted to share. I've been reading a lot about data mesh, decentralized data model, semantic modeling, etc. Been playing around with Neo4j, have a web app that essentially lets me define an enterprise ontology, and then map local/edge models back to the enterprise ontology via graph. The cool thing is you can then query the enterprise ontology to return the local representation. Almost like a ""virtual/logical UNS.","",""
"568913935147728896","zeratall","2023-12-10T02:16:29.8690000+08:00","In the web app, the yellow graph is a simply enterprise ontology in this over simplified example its just the traditional Purdue Pyramid (Ent, Site, Area, etc), the blue model is the raw data that is being collected at the site (in this case my garage lol).","https://cdn.discordapp.com/attachments/815945777452941313/1183109935811272730/image.png?ex=68df6a3d&is=68de18bd&hm=b709182d518c19e9cfe624ad19e9e7b8bb9d6d55a21f5df40a1e3d5850176a8d&",""
"568913935147728896","zeratall","2023-12-10T02:17:03.5210000+08:00","Ignore the fact that the blue model is already in the pyramid format, you can imagin it could be in any format.","",""
"568913935147728896","zeratall","2023-12-10T02:17:43.8960000+08:00","Then without knowledge of the local model, you could query the enterprise ontology aka return all work centers that trace back to the enterprise ontology definition of a work center.","",""
"568913935147728896","zeratall","2023-12-10T02:18:19.5050000+08:00","```MATCH (t:Topic)-[*]->(e:Enterprise_Ontology {name: ""Work Center""})
WITH DISTINCT t
MATCH path = (t)-[*]->(n)
RETURN t, n, path'```","",""
"568913935147728896","zeratall","2023-12-10T02:19:18.0440000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1183110641217716354/image.png?ex=68df6ae5&is=68de1965&hm=b0c662dc430980b9b06ac1a45f215e07d886cf4b12aec3a805141e42e20cba39&","üëçüèª (2),üíØ (1)"
"568913935147728896","zeratall","2023-12-10T02:20:56.2610000+08:00","Super simple example, so not really useful yet, but the idea is cool imho.","",""
"894527802316046366","nickn5549","2023-12-10T08:02:56.6690000+08:00","Cypher...here we come...","","ü§£ (2)"
"917925131261718558","jpmoniz","2023-12-10T09:55:42.1000000+08:00","Nice work.  Been doing to same. Things get really cool applying the different domains on top of that as well.","",""
"568913935147728896","zeratall","2023-12-10T09:57:08.0140000+08:00","Thanks, and absolutely!","",""
"894527802316046366","nickn5549","2023-12-10T10:21:50.7080000+08:00","get to the APOC functions and things get very, very interesting, very quickly...","",""
"867075936054149191","rickbullotta","2023-12-10T21:47:43.7690000+08:00","Well the ‚ÄúA‚Äù is for ‚ÄúAwesome‚Äù!!!!","","üòÇ (1)"
"894527802316046366","nickn5549","2023-12-11T04:23:31.1490000+08:00","It is","",""
"615958029027901440","bughunter1337","2023-12-11T18:43:25.2910000+08:00","Hey All,
I work at a company that builds machines, and we're currently focused on enhancing our data services. Our goal is to empower our customers with the flexibility to access and utilize machine data as they see fit. We plan to achieve this by offering an OPC Server interface and a standardized information model for our machines. Additionally, for interested customers, we aim to provide a user-friendly webbased dashboard showcasing our machine's performance.

With customer approval, we intend to analyze the data collected by our machines to enhance future machine iterations. However, I'm facing a challenge in finding the right architecture that caters to our specific needs. Many existing solutions seem geared towards end users rather than machine builders or original equipment manufacturers (OEMs), and their pricing models aren't very appealing for that reason.

I'm currently exploring options like AWS IoT Sitewise and Siemens Industrial Edge. I'm curious about your experiences in a similar situation and would appreciate any suggestions you might have.","",""
"1011806669874937956","vikanchira","2023-12-11T19:41:12.9610000+08:00","@Sam.E Why not use a sparkplugb device like Red Lion DA30/Flexedge or IPC+N3uron/Ignition Edge IIoT and publish all the data tags in ISA-95 like structures to AWS IoT Core? That way, any system can just connect to AWS IoT Core and get the machine's data.

If you want to have an IIoT platform in the cloud for the customers to view the dashboard. Use N3uron or Ignition deployed in AWS. Job done.

PS. We have built this for our OEM boiler customer for 2kUSD per site and 24kUSD for the platform","",""
"867075936054149191","rickbullotta","2023-12-11T21:11:38.9050000+08:00","The OP said that they want to make it easy to share data. That‚Äôs not Sparkplug. The way that multiple metrics/datapoints are conflated in Sparkplug messages plus the protobuf encoding is fine for dedicated scada or historian connections and awful for loosely coupled data sharing. AFAIK IoT Core won‚Äôt expand those messages.  The Cirrus Link SiteWise adapter can though.","","üíØ (1)"
"1011806669874937956","vikanchira","2023-12-11T21:19:04.1850000+08:00","Then use the standard MQTT with AWS IoT Core. Any IIoT platform can then subscribe to it. E.g. N3uron, Thingsboard, etc.","","üíØ (1),üëçüèº (1)"
"867075936054149191","rickbullotta","2023-12-11T21:22:57.2670000+08:00","That could work well!","",""
"867075936054149191","rickbullotta","2023-12-11T21:24:27.9030000+08:00","Have you experimented much with ThingsBoard? I‚Äôm curious what your thoughts are.","",""
"1011806669874937956","vikanchira","2023-12-11T21:31:03.4120000+08:00","- It's fine for simple projects like fleet management, or smart building but it is not good at modelling complex machine.
- It doesn't have semantic hierarchy apart from Asset and Device. 
- You can't really do SCADA style Process Flow Diagrams visual like that in Ignition. 
- Need to check the available widget. If it's fine for the customer then it's a good low cost choice.
- By low cost it would be the multi-tenant deployment in AWS or their cloud offering.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2023-12-11T21:34:23.8630000+08:00","Thanks for the feedback.","","üëç (1)"
"615958029027901440","bughunter1337","2023-12-11T21:44:56.8170000+08:00","Thanks guys!","","üëç (1)"
"794542235676180500","akoscs","2023-12-12T22:25:33.3870000+08:00","Blazor...nice!","",""
"1139269147126153216","suran23.","2023-12-13T03:25:09.4260000+08:00","@BugHunter A lot of it what you described is Limus Edge.","",""
"740383178279354388","mriiot","2023-12-14T20:55:21.6190000+08:00","Would this fit in somehow?  https://github.com/iofoundry/ontology/tree/202301","",""
"801561312861618236","jon.forbord","2023-12-16T19:38:07.4400000+08:00","If you‚Äôre using OTS solutions that support SpB out of the box it IS easy to share data. Doesn‚Äôt matter how conflated or protobuf-encoded it is. Many do though take inspiration from SpB to make their own mqtt payload specification when they are NOT using OTS solutions with SpB support. This is actually a more common approach than actually implementing SpB in their IIoT architecture. Probably partly because of the much discussed limits of SpB!","","üëçüèº (2),üëç (1)"
"740383178279354388","mriiot","2023-12-16T23:26:00.0210000+08:00","OTS or not, compliance to specification is interpreted across vendors and results vary.","",""
"568913935147728896","zeratall","2023-12-16T23:29:21.3230000+08:00","That‚Äôs a pretty cool find!","",""
"740383178279354388","mriiot","2023-12-16T23:31:34.0680000+08:00","I hope you can break it down for us. üòµ","",""
"801561312861618236","jon.forbord","2023-12-17T00:03:35.6320000+08:00","I haven‚Äôt seen this (yet) in the OTS we‚Äôre using, but have you? Which OTS solutions would that be?","",""
"867075936054149191","rickbullotta","2023-12-17T00:31:46.5590000+08:00","It's still hard to share it with IT/enterprise middleware without a lot of gyrations though.","",""
"801561312861618236","jon.forbord","2023-12-17T00:45:26.6200000+08:00","Gyrations? I‚Äôm not familiar with that expression, English being the second language for me. If one line of code to publish in regular mqtt on tag change in Ignition, or a handful of lines of Python to expose the tags using the web dev module as http request is what constitutes gyrations then ok üôÇ","","üëèüèº (1)"
"867075936054149191","rickbullotta","2023-12-17T00:46:05.1250000+08:00","One line is too many if none is possible. üòâ","","üòÖ (1),üòÅ (1)"
"801561312861618236","jon.forbord","2023-12-17T01:14:39.4280000+08:00","If one line of code is your definition of ‚Äúhard‚Äù, it must‚Äôve been a an insurmountable impossibility perpetual motion machine of a project to make Thingworx?!","","üòÇ (1)"
"867075936054149191","rickbullotta","2023-12-17T02:01:21.7130000+08:00","You musta been doing it wrong. Actually it‚Äôs a great example - over time more and more functions that required scripting became a checkbox or automatic. I‚Äôd like to see that with ignition, HighByte, etc","",""
"745796393855352953","thedavidschultz","2023-12-18T20:58:09.3910000+08:00","Doing some reading over the weekend. Ran across the following. Curious if anyone has seen this.","https://cdn.discordapp.com/attachments/815945777452941313/1186291312811577444/arch_dgm.gif?ex=68df1fa1&is=68ddce21&hm=ab75002d14031dca255339405e103c833b180680ef12ece5fe23ca1f832a7697&",""
"867075936054149191","rickbullotta","2023-12-18T21:17:44.6910000+08:00","It says ""MIS"" on it.  Was this hand drawn with colored pencils in the 1980s?","","ü§£ (1),üòÇ (1)"
"745796393855352953","thedavidschultz","2023-12-18T22:04:45.7940000+08:00","Lotus Freelance Graphics","","ü§£ (1)"
"193359832340889600","onlylyon","2023-12-29T22:52:55.6690000+08:00","I was real confused because on dark mode it‚Äôs like a partially complete image","","üíØ (1)"
"193359832340889600","onlylyon","2023-12-29T22:53:16.4700000+08:00","You can barely make out the text and on mobile when you click it it‚Äôs even worse","",""
"745796393855352953","thedavidschultz","2023-12-30T05:48:43.3720000+08:00","The image has a transparent background. You will need to place it on a white background to view.","",""
"745796393855352953","thedavidschultz","2023-12-30T05:50:32.7710000+08:00","The image is can be found at pera.net which is all about the Purdue Enterprise Reference Architecture.","",""
"783917475128410112","geoffnunan","2023-12-31T04:37:47.5580000+08:00","The Purdue architecture has certainly been challenged by newer technologies like data hubs, machine learning and the like.","",""
"898217314741280828","hobbes1069","2024-01-12T23:40:36.7510000+08:00","I think that would fall more under ISA 88, but that's fine, you can publish that data where in the hierarchy it exists, such as an open order topic.","",""
"890244048739270656","brianpribe","2024-01-13T00:27:48.2090000+08:00","Work orders (and I believe finished products) will be in ISA95 part 4. Instructions is more ISA88.","",""
"867075936054149191","rickbullotta","2024-01-13T01:18:00.8900000+08:00","Work instructions are covered as activities and tasks in Part 3","","üî• (1)"
"1096937278632374334","younitty","2024-01-13T10:49:08.6740000+08:00","ISA88, ISA95-4, ISA95-3.....Hummm !","",""
"783917475128410112","geoffnunan","2024-01-13T12:39:48.6270000+08:00","ISA95 is a comprehensive standards that comprises 9 parts and is over 700 pages of detailed information. It can be as hard as it sounds to consume it and understand the content.
Our team are working on a training course which we hope to release later in the year","","üî• (2)"
"795178288330440704","youri.regnaud","2024-01-13T14:30:45.2710000+08:00","A ChatGPT plugin tomorrow üôÇ?","","üíØ (1)"
"867075936054149191","rickbullotta","2024-01-13T20:55:03.7710000+08:00","Dennis Brandl also has a few classes on ISA 95 and does custom education as well. I would recommend engaging him in this.","","üíØ (1),üëÄ (1)"
"1173270244291264535","andreasvogler","2024-01-16T18:11:38.2120000+08:00","Like that idea. For the case you want to have the current state/data from the shopfloor be reflected in the graph, I have added a Neo4j logger in my open source project automation-gateway.com. So you could combine and connect your ontology to the nodes of factory data and query them together with cypher queries... https://www.linkedin.com/posts/andreas-vogler_mqtt-uns-graphdb-activity-7135353283639934976-U0MX?utm_source=share&utm_medium=member_desktop","","üëçüèª (3)"
"1154812895457185812","rutger_18900","2024-01-16T19:05:14.1410000+08:00","Are these classes by any chance available online, and if so can you point me in the right direction?
I read a couple of Dennis' books and would definitely be interested in his courses.

I found some related courses on the ISA website but don't see an instructor name specifically, although they do reference his books.
Interesting anyway, and includes the standard too. I might hold out until Black Friday or some other ISA deal üí∞ 
https://www.isa.org/training/training-courses-by-topic/standards-based-courses","",""
"867075936054149191","rickbullotta","2024-01-16T21:14:43.9880000+08:00","I'd suggest reaching out to him directly on LinkedIn.  He's a good person!","","üëç (1),üíØ (1)"
"305259056476454912","tom02686","2024-01-17T22:32:57.3260000+08:00","I used a Graph DB (Rhize) for material Geneaology. Looks slick, _once_ you've captured all the data...","https://cdn.discordapp.com/attachments/815945777452941313/1197186805884256336/Material_Geneaology.mp4?ex=68df35d9&is=68dde459&hm=a9ff72ef937161ea8741a59a12006290c402b1059230b7839786864600465002&","üî• (5),üëÄ (1),üëç (1)"
"795178288330440704","youri.regnaud","2024-01-18T03:26:04.7730000+08:00","Is there a widget for that in Grafana?","",""
"305259056476454912","tom02686","2024-01-18T03:52:45.5260000+08:00","Just the echarts plugin -> https://grafana.com/grafana/plugins/volkovlabs-echarts-panel/","","üëç (1)"
"867075936054149191","rickbullotta","2024-01-18T04:51:01.7200000+08:00","It's super easy to do with D3.js also (including two-directional genealogy visualization).","",""
"867075936054149191","rickbullotta","2024-01-18T04:52:10.2560000+08:00","You can make the node graph work for material genealogy","",""
"867075936054149191","rickbullotta","2024-01-18T04:52:22.9570000+08:00","https://grafana.com/docs/grafana/latest/panels-visualizations/visualizations/node-graph/","","üëç (3)"
"795178288330440704","youri.regnaud","2024-01-20T17:59:05.1080000+08:00","Hello everyone,
I‚Äôm curious about the future of solutions comprising a Unified Namespace (UNS) within Industry 4.0. We‚Äôre observing a notable trend where MQTT broker providers are expanding their base offerings to include DataOps functionalities, like what HiveMQ is doing. Similarly, solutions primarily focused on DataOps are incorporating MQTT broker capabilities, as seen with Highbyte. Even connectivity solutions like Cybus are gradually moving towards DataOps functionalities.

How do you foresee the evolution of these integrations and functionalities in the context of UNS? Are there any specific developments or trends that we should be particularly aware of?
Thank you for your insights!","",""
"867075936054149191","rickbullotta","2024-01-20T22:49:22.7460000+08:00","This is how I foresee it...","https://cdn.discordapp.com/attachments/815945777452941313/1198278103009611887/venn.png?ex=68df39b2&is=68dde832&hm=7d3d3e55351fa38a258068629e0153498193fa7a1104d56f05a0e7ba43e01eef&","üíØ (4)"
"795178288330440704","youri.regnaud","2024-01-20T23:00:32.9120000+08:00","What would you say are the points of attention for these solutions over the next 3-5 years? For example, in our case we're combining the 3 circles with 3/4 different vendors via a DevOps pipeline. For example, short enough commitment","",""
"740383178279354388","mriiot","2024-01-20T23:04:23.2870000+08:00","Nice logo","",""
"867075936054149191","rickbullotta","2024-01-20T23:09:02.8670000+08:00","I like to say that they overlap more in PowerPoint and with their marketing stuff than they do with product.  I'd like to see some mergers/consolidation in the space.  I'd also like to see companies become less focused on ""purity"" with standards and focused more on meeting customer needs and innovating beyond the spec.","","üíØ (5)"
"801561312861618236","jon.forbord","2024-01-21T03:13:55.0120000+08:00","I understand that the Highbyte broker is more of an Edge broker, so it doesnt really compete with HiveMQ. But it doesn‚Äôt make the solution landscape easier to navigate for sure.","","üíØ (1)"
"766684226455207996","bright_hummingbird_31342","2024-01-21T04:51:11.5560000+08:00","As usual, Rick is spot on.
¬†
The solution overlap is more on paper and in messaging than in reality.¬† I believe the root of this is caused by a few things.
¬†
Some investors really don‚Äôt understand the industrial market.¬† It‚Äôs not like other technology.¬† The buyers are wedged up against many heavy, slow-moving constraints.¬† Even with the best technology, it still takes sufficient digital maturity and organizational alignment to be successful.¬† Wins don‚Äôt happen overnight in this space.¬† If investors don‚Äôt understand this, they would better served investing in crypto or AI.
¬†
Solution providers took on way too much money in the low-interest-rate era.¬† They took on more money than what their market can naturally grow at.¬† Their customers can only shake up their org and adopt new tech so quickly.¬† As a result, we‚Äôre seeing a lot of solution providers pivoting to compensate for this.¬† There is less transparency about what solutions do and don‚Äôt do.¬† Messaging gets more competitive and capabilities are exaggerated. ¬†Also, it leads to weird, incomplete features that are built out as a ‚Äúquid pro quo‚Äù to close specific big deals rather than address market needs.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-21T04:51:13.0150000+08:00","Buyers are early in their digital transformation journey.¬† They‚Äôre creating large RFPs with preconceived notions of what they‚Äôll need without understanding the root of their problems and a vision for what competencies they want to develop as a digital company.¬† This approach can work for upgrading an established and well-defined function like PLC or SCADA for example, but it‚Äôs inadequate for something an org or its peers have never been done before.¬† Having some use cases in mind is a practical way to inform the viability of a solution.¬† It‚Äôs just impossible to create a general feature/cost matrix of functionality ‚Äì especially when said features did not exist on the market less than 12 months ago.¬† Otherwise, it‚Äôs like comparing a Tesla to a Model T to a space shuttle to an oil tanker to a drone to a skateboard to a fiber optic cable.¬† Can you imagine a Gartner Magic Quadrant comparing all of these things?¬† One must understand what a solution is, why it was built, and have some understanding of how it works before it can be compared.‚Ä®‚Ä®

Rather than listing and comparing features sourced from marketing materials, I would advise on refining a vision for digital transformation and develop a problem set to start with.¬† This allows one to evaluate and trial solutions in the context of their own organization and its needs.¬† This is the only way to cut through the noise, grasp the nuances, and discover the merits of new technology.","","üëè (4),üî• (5)"
"766684226455207996","bright_hummingbird_31342","2024-01-21T06:17:37.3290000+08:00","Great point.  I thought I'd build on this.

I don‚Äôt believe anyone would purchase a HighByte license just for an MQTT broker or as an alternative to HiveMQ.¬† It very clearly does not bill itself as an enterprise-class MQTT broker.¬† It‚Äôs almost a misnomer to call it a broker because it‚Äôs not really intended for traditional or standalone brokering.¬† It‚Äôs primarily used as an MQTT server interface for a DataOps platform.¬† It‚Äôs to locally land data that needs to be transformed and modeled before it can be brokered for other consumers.¬† There are a lot of edge devices (e.g., sensors, PLCs, gateways) on the market with so-called IoT connectivity that are not much more useful than a fieldbus.¬† In other words, sending a cryptic payload across the network over MQTT instead of Modbus does not really solve interoperability problems.¬† ‚Ä®‚Ä®

On the other hand, I don‚Äôt believe anyone would purchase HiveMQ for DataOps or as an alternative to HighByte.¬† The HiveMQ edge offering is to provide customers an option to plug in devices that don‚Äôt natively support MQTT.¬† Most would consider this as satisfying connectivity or gateway requirements.¬† HiveMQ also has some fantastic quality control features to ensure MQTT clients don‚Äôt ‚Äúpoison‚Äù other clients with faulty/corrupt publishes. ¬†These are features to aid in the adoption of MQTT and HiveMQ‚Äôs excellent brokering technology. ¬†Most would conclude it‚Äôs not a data engineering platform to systematic solve interoperability problems spanning MQTT and beyond.
¬†
It turns out that the market is actually using both HighByte and HiveMQ.¬† Some of the largest and most sophisticated UNS architectures stood up in the past year would have not been possible without the two solutions and their collaboration.","",""
"766684226455207996","bright_hummingbird_31342","2024-01-21T06:17:40.6860000+08:00","The same goes for Ignition.¬† Ignition is unrivaled in the SCADA space.¬† Its ability to rapidly build applications as well as use and visualize industrial data is incredible.¬† Many have found they need HiveMQ to accomplish what they want with MQTT and Ignition.¬† Many have found they can‚Äôt sustain Ignition across their enterprise and/or interoperate with applications, data stores, and cloud services without HighByte.","","üëç (1)"
"1073312001788477471","sparkylarks","2024-01-21T15:59:18.3650000+08:00","@js 
Really good points.  It think "" They‚Äôre creating large RFPs with preconceived notions of what they‚Äôll need without understanding the root of their problems and a vision for what competencies they want to develop as a digital company.  "" is a really powerful statement.  And I think that approach is one of the biggest causes for ¬£Digital Transformation Failure""

I work with clients who want a UNS and want to use Canary, HighByte,  Kafka , Snowflake, across 10 plants, and I am suggesting a Proof of Concept built on Node-Red and Mosquitto with maybe a DB and Graphana.

And it is a hard sell, Sometimes we end up with a Ignition based system for the pilot.  

I can understand the clients concerns, They are hearing
- If your not digitally transformed, your company is dead.
- UNS is magic, Everything plugs in and communicated over MQTT SpB.
- Modern Applications like Canary and highbyte, will automatically detect new equipment and grow up
- You need a solution that can Scale,

This is filtered through consultants or Advisors, or even IT leaders who have been It focused so are terrified of Technical Debt so they want products that can scale from the start.

I just finished a installation job with a client,
- 5 Machines, 
- Pulls Job data from ERP and books back actual Production numbers
- Give an measure of waste at each machine
- A Standard OEE solution, track  A,Q,P, Operator assigned reasons, Dashboard and reports deployed where it helps.

A nice solution, add value and we are in a good place to scale to other machines ,Other Plants. and to start to solve the next problem 

But talking to the company's Technical lead for Digitalisation and we both agreed, we learned so much  about how the machines are actually operated, we should have done a pilot of 1 line, Node-Red base, and we woudl after 6 weeks be in a much better place to move from POC (Proof of Concept) to POE( Proof of Execution)","",""
"1073312001788477471","sparkylarks","2024-01-21T16:24:13.8220000+08:00","@RickBullotta I might be strange but when I want to operate on some data, I look at a Data Ops solution. When I want to Broke some MQTT data, I look at an MQTT Broker. IF I want to store historical data I look at a historian.

When companies are successful, then look to expand, and for software that is often features. I read a great book a long time ago called "" Inside the Box"". Outside the box thinking was very ""hot"" and the book looked at companies that succeeded by not reinventing themselves.

Toyota was a great example. They made boring unexciting cars, that people could drive from a to b ,and they didn't bread down because they were really reliable. Every Sales rep in Ireland and the UK drive a Toyota Avensis.

I don't see anyone really deciding to use High Byte because they add data OPS. It might be handy to leverage if I already have it. Like I might leverage a Wonderware historian or an Existing SQL DB on a site if it is there. But that is really in a POC Stage. AS I build I'll get the right told for the job.

My big fear is that  as companies try to expand there services, they will try to provide a total solution to users, a few new products, mergers and acquisitions later and we get have deeper integrations between their own products, and over time that will be to a point where it difficult to integrate third party solutions, and we end up back with single supplier product stacks, between the PLC and the ERP.","","üëçüèº (3)"
"795178288330440704","youri.regnaud","2024-01-21T22:48:57.0180000+08:00","This is indeed one of my fears. How can we make the business and IT understand that several ""inside"" solutions are preferable to a single solution?","","üëçüèº (2)"
"867075936054149191","rickbullotta","2024-01-21T23:05:21.5020000+08:00","Well, there are cases where a unified solution is indeed the lowest TCO/highest value.  It's not always the case, but sometimes it is.  I would not rule out integrated solutions just ""because"".  It's kinda like demanding ""open source"".  You'll often be forced into suboptimal choices if you create filters like that.","",""
"801561312861618236","jon.forbord","2024-01-22T03:07:33.1730000+08:00","Unified or not, bad competition where big market leaders can buy any competition and control a market will always end up hurting the end-user/consumer in the end!","","üíØ (3)"
"1096937278632374334","younitty","2024-01-24T00:20:06.6640000+08:00","I think we could use a @Walker Reynolds video on i4.0/UNS and how this could be extended with a more i5.0 oriented layer using Ontology and AIP such as Palantir.","","üëç (2)"
"1063829764164563026","mariano.beracochea","2024-01-24T18:54:26.4690000+08:00","Dennis have books about architecture and ISA95? Im looking to learn about how to stablish an scalable architecture. Can you give me the Dennis full name to google him or give me his books name please","",""
"867075936054149191","rickbullotta","2024-01-24T19:01:22.4260000+08:00","Dennis Brandl : https://www.linkedin.com/in/dennis-brandl-871545/","",""
"721438232004263997","utf_lifeform","2024-01-24T21:57:13.4250000+08:00","Denis Brandl also co-authored *The Road to Integration* with Bianca Scholten. It definitely helped me get started with learning about what S95 looks like in practice.

https://www.amazon.com/-/es/Bianca-Scholten-ebook/dp/B0B7VKQF35/ref=tmm_kin_swatch_0?_encoding=UTF8&qid=1694802531&sr=8-2","","üëèüèº (1),üíØ (1)"
"766684226455207996","bright_hummingbird_31342","2024-01-25T02:24:17.6210000+08:00","Great idea.  My understanding of solutions like Palantir or Cognite is that the data must be first persisted to construct these ontologies.  These solutions don't ""virtualize"" data.  They store data and then model data for their own use to drive analysis, digital twins, etc.  So, in the context of a UNS, the whole thing would need to be historized in a data lake or into the platforms first.  They can't be the UNS or first-class consumer of it.","","üëç (3)"
"801561312861618236","jon.forbord","2024-01-25T06:37:15.5600000+08:00","Pretty much my conclusion as well. Generally not a ‚Äúnode in an ecosystem‚Äù mentality, more a ‚Äúbring the data to us‚Äù. They do have open APIs and some of the stuff they can do is pretty darn impressive..","","üëç (1)"
"1073632885153730621","vaughnturner","2024-01-26T00:45:35.3750000+08:00","I like this idea as well.","",""
"793044645546426390","belkerisai","2024-02-08T01:17:36.7890000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1204838388893491280/IMG_20240207_224636.jpg?ex=68df5c70&is=68de0af0&hm=5df27ace1cb0114adc7952b03c07d05ef07173520aedcc1a28660410049cb00b&","üëç (2)"
"1073312001788477471","sparkylarks","2024-02-08T04:34:43.2360000+08:00","Looks Good. 
But remember Node-Red can be more than a gateway,  it can be used for calculation and even functionality.

And your IoT device can Publish directly to the MQTT Broker","",""
"793044645546426390","belkerisai","2024-02-08T22:39:16.4040000+08:00","Yes, But I would like to filter & format the data before sending it to Broker at the Gateway. Hence the gateway","",""
"1061942681821003798","dylan_iiot","2024-02-09T19:15:53.8740000+08:00","Good day all from sunny South Africa. Could anyone point me to some great industry standard dashboard/hmi screen examples? especially for remote equipment monitoring solutions like, remote diesel generators, remote solar PV systems, remote pumps etc etc","",""
"794020366536146977","mparris","2024-02-14T00:07:00.6010000+08:00","From CESMII Virtual Smart Manufacturing Architecture & Technology Workshop
Feb 13, 2024","https://cdn.discordapp.com/attachments/815945777452941313/1206994948264824873/image.png?ex=68df4be4&is=68ddfa64&hm=d20f0ed3a2b2af965bd85f4fdbfce3a59e308423e0e885e5d5227a58ed80208b&",""
"794542235676180500","akoscs","2024-02-14T04:30:59.1200000+08:00","Please tell me there is actual usabel content behind this bullsh*t bingo slide","",""
"873009180938743828","sim_sam3","2024-02-14T07:57:36.3010000+08:00","It‚Äôs from LNS / a research firm so its goal is only conveying important ‚Äúfederated‚Äù concepts at a high level (for better or for worse)","",""
"1063829764164563026","mariano.beracochea","2024-02-15T00:14:54.0930000+08:00","Hello, im trying to define the architecture to build a UNS. I had the idea of using Ignition as my UNS because of its drivers and because i already have an 7.9 license, but heard Walker on a mentorship call saying Igntion have it scalability limit on 100K tags because of its internal architecture, that is java based and other option with other structure closer to the processor(not sure how it works) could handle more data.

The architecture im planning is

An MQTT broker: Which would be the difference of using EMQX that is purely a broker with using Frameworx or other IIOT platform with an MQTT broker (thought of ignition but dont want to hit critical mass)?

A Historian: that will take data from the MQTT, thought about canary because of its optimization(I would be saving ""large"" amount of that for a long time) and contextualice system that i heard from Walker, havent contacted them directly yet. Suggestions?

A visualization platform that could be vision on Ignition 7.9 because is the license we already have. It would be for bussiness inteligence

Edge service for the legacy systems that are not MQTT compatible, i have many on Modbus and Siemenes 300. Probably an OPC UA or maybe convert directly with node red that take the data and publishing it with MQTT node(there is a reliability fear with open source solutions).

Could want to read your suggestions of best practice and thinks to improve","",""
"1127965241729351780","aleem2446","2024-02-15T17:47:14.2420000+08:00","You may need Highbyte or Neuron
For Data integration/ pipelines and transformation
You can take a look","",""
"1063829764164563026","mariano.beracochea","2024-02-15T19:01:21.2350000+08:00","We had a demo of Highbyte and they said it didnt have communication drivers, you need to have to use another data gateway","",""
"1127965241729351780","aleem2446","2024-02-15T19:02:44.6990000+08:00","Ah ok it can't replace ignition however work on top of it and can help with  your IT/ OT integration","",""
"691634250713399297","ylmz8226","2024-02-16T01:28:08.2460000+08:00","I suggest you to use some kind of OPC Server under the HighByte like Kepserverex. So, it allows you to create a flow from level1 to higher levels.","",""
"753688565807841492","ravil1","2024-02-16T01:39:56.5640000+08:00","@Mariano B, please check out our offering: https://onewayautomation.com/forge
You will get funcitonlity somehat similar to HighByte+KepserverFX. The differentce is that you can get all set shipped to you installed in an industrial PC box. Then you can manage it remotely via secure web interface (OS and all applications).
You can also order components shown there separately depending on your requirements.","",""
"1081971075971289148","jose.granero","2024-02-16T03:21:49.4720000+08:00","@Mariano B , Take a look at https://n3uron.com/","",""
"1081971075971289148","jose.granero","2024-02-16T03:26:35.9640000+08:00","You can seamlessly integrate it with Ignition through OPC UA Server or Sparkplug (https://sparkplug.eclipse.org/compatibility/compatible-software/)","",""
"230441548653789184","r.pop","2024-02-16T06:59:56.0770000+08:00","Am I the only one that is noticing how much the Neuron website/module icons/colors look exactly like Ignition?","",""
"766684226455207996","bright_hummingbird_31342","2024-02-16T07:59:15.4270000+08:00","You're not the only one.  I initially wondered if it were some sort of white labeled version.","",""
"917925131261718558","jpmoniz","2024-02-16T08:33:14.4970000+08:00","It‚Äôs quite odd indeed.","",""
"894527802316046366","nickn5549","2024-02-16T11:35:01.5830000+08:00","lucky colour scheme...","",""
"1063829764164563026","mariano.beracochea","2024-02-22T20:27:30.4820000+08:00","Could Litmus edge be the complete UNS?","https://cdn.discordapp.com/attachments/815945777452941313/1210201199526281238/image.png?ex=68df1872&is=68ddc6f2&hm=f49ee86224a67511c1e01534ac478d04ec3ca248a8aef187f4fffda057d442bb&",""
"635165200357654551","talos5503","2024-02-23T21:12:35.7710000+08:00","Hey folks, does anyone have a reference architecture or a use case where UNS has been deployed for a smart building?","",""
"1011806669874937956","vikanchira","2024-02-24T16:55:31.9210000+08:00","The answer is as always... it depends.

It depends on your definition of a 'complete' UNS.","","üíØ (1)"
"830193224504705035","marc.jaeckle","2024-02-25T04:14:42.9840000+08:00","No. It only has an internal broker to be used by Litmus Edge itself. The whole thing is also not highly available/does not support clustering and cannot scale horizontally so even if the broker was meant for non-internal usage it wouldn‚Äôt be a great option for a UNS. Litmus Edge can work great for machine connectivity, data modeling and data transformation & normalization but you need a MQTT broker to which it publishes and which contains the UNS. In my experience the best commercial broker is HiveMQ which we have been using in many projects over the last years. From what I remember EMQX still has no great clustering, for example I think it does not replicate data messages in the cluster and it may drop/lose messages silently. Also I think it had difficulties with rolling upgrades under Kubernetes and the Kubernetes Operator was still under heavy development about 2-3 months ago. But it‚Äôs better to check things like that yourself. Litmus is currently also working on its own MQTT broker which they want to provide for free (at least according to the initial announcement). If you are an Azure customer, you could have a look at Azure IoT Operations which also comes with a MQTT broker but it‚Äôs still in public preview and only runs on Kubernetes (which is a great thing for our projects because it‚Äôs a Kubernetes-native product). Another option to consider might be Cybus Connectware which comes with machine connectivity and a MQTT broker.","","üëçüèª (2),üëç (1),üòµ (1)"
"830193224504705035","marc.jaeckle","2024-02-25T04:42:56.2570000+08:00","Btw has anyone tried RabbitMQ recently since they added MQTT 5 support? Well, they are not really MQTT 5 compatible but seem to implement a large portion of the standard. Unluckily they don‚Äôt seem to support shared subscriptions yet which makes the current implementation somewhat useless in many cases. Also retained message support still seems to be limited so far. https://rabbitmq-website.pages.dev/blog/2023/07/21/mqtt5","",""
"1073312001788477471","sparkylarks","2024-02-25T23:34:39.2540000+08:00","I think it can solve a lot of issues for a UNS initially, but as you grow it won't.","",""
"721948711126827009","jaylinyu","2024-02-26T19:31:04.9440000+08:00","no good clustering? lol do some research on erlang and BEAM
What you described could be solved by altering one line of configuration thing.","",""
"830193224504705035","marc.jaeckle","2024-02-26T19:36:48.8500000+08:00","Well, we lost messages in our tests and rolling upgrades did not work great yet. Obviously you can build clustered software using Erlang but that doesn‚Äôt necessarily mean it‚Äôs well implemented. Are you referring to the message replication with that ‚Äúone line of configuration‚Äù?","",""
"721948711126827009","jaylinyu","2024-02-26T19:50:30.1060000+08:00","Hi Marc, I don't meant to argue or be offensive. But just cannot help to clarifying some truths from technical perspective.  clustering is one of EMQX doing best with, Even the rabbitmq gives their credit https://youtu.be/k9DxUVOaz8g?si=3a1bd1jjuqJ5oc21","",""
"721948711126827009","jaylinyu","2024-02-26T19:53:50.8210000+08:00","I was referring to the msg lost case( it is because EMQX absorbs msg inflow with a very much higher rate from Pub client than sub client consuming it, and it cause a overflow in in-flight queue. You can extend the length of queue in configuration)","",""
"721948711126827009","jaylinyu","2024-02-26T19:56:08.4330000+08:00","About rolling update and grayscale upgrade, You can try with https://github.com/emqx/emqx-operator","",""
"830193224504705035","marc.jaeckle","2024-02-26T20:11:38.1160000+08:00","One limitation in regard to clustering that EQMX still seems to have according to its documentation is that it doesn't have a masterless architecture. Even in the current 5.x versions, you have the core nodes that correspond to the Mnesia nodes in 4.x and the replicant nodes that can't participate in write operations. Since the recommendation for the 4.x nodes was not to scale beyond 5 nodes, the assumptions suggests itself that this is also true for the 5.x core nodes. If optimizations were made there as well, it would be interesting to know to how many core nodes one can scale now.

As you might have read, we were using the EMQX Operator that didn't feel completely finished about 2-3 months ago but was under active development so this might have changed by now.","",""
"721948711126827009","jaylinyu","2024-02-26T20:13:00.1010000+08:00","4.x is a masterless clustering","",""
"721948711126827009","jaylinyu","2024-02-26T20:14:07.2730000+08:00","Oh ok I get your point. Mnesia is a pain in the ass for EMQX 4. But It still scales well to support 10million","",""
"830193224504705035","marc.jaeckle","2024-02-26T20:14:53.5940000+08:00","About the RabbitMQ clustering and using Erlang: RabbitMQ has been famous for significant message loss in case of a network partition for about 10 years (made known through the jepson.io test) . I think I read not too long ago that they think they fixed it now. Just because it's built on Erlang doesn't mean that everything works.","","üëç (1)"
"721948711126827009","jaylinyu","2024-02-26T20:21:58.4970000+08:00","The core-replica clustering architecture of EMQX v5 is the most scalable design for the MQTT Broker(at least from the performance perspective, no other can scale up to support 100million now, only EMQXv5 25 nodes used ) , for you have to replicate the topic trie among all nodes.  You'd better sync the topic trie among a few core nodes, and asyn to more replica nodes, just like the leader and follower nodes in raft protocol.","",""
"830193224504705035","marc.jaeckle","2024-02-26T20:31:55.4750000+08:00","HiveMQ has a benchmark out about achieving 200 million clients in case you meant clients with the 100 million. https://www.hivemq.com/resources/achieving-200-mil-concurrent-connections-with-hivemq/","",""
"721948711126827009","jaylinyu","2024-02-26T20:57:03.4370000+08:00","it is not on same cluster...","",""
"830193224504705035","marc.jaeckle","2024-02-26T20:58:40.6630000+08:00","Well, the blog post it says it is.","",""
"830193224504705035","marc.jaeckle","2024-02-28T16:46:18.6630000+08:00","I had a closer look at the EMQX documentation this morning and these are the points where it sounds like the clustering of EMQX is indeed limited. Please let me know if I misunderstood something there or if the documentation is wrong. I will have to split up the points in multiple Discord messages.

- So from your documentation and your blog post of achieving 100 million connections, I get this about Mnesia: ""The Mnesia cluster uses a full mesh topology: that is, each node establishes a connection to every other node in the cluster, and every transaction is replicated to all nodes in the cluster.‚Äú As the core nodes in EMQX 5 corresponds to the Mnesia nodes from EMQX 4, this would mean that every node contains the same data, meaning all of the data. As a result, you would have to scale those nodes vertically, the larger your cluster gets, as every node has to hold all of the data. If correct, I think this is an issue for scaling EMQX. If there is some form of data partitioning available I couldn‚Äôt find an info on it. Also I couldn‚Äôt find a place where I would be able to configure the amount of message replicas as it is state of the art in other clustered applications. Of course if every message is replicated to every other node, there is no point in configuring the amount of message replicas. You only seem to be able to configure the amount of core and replicant instances through the EMQX CRD. Maybe this is just a documentation issue or I just didn‚Äôt find it. If this is the case, please let me know.","",""
"830193224504705035","marc.jaeckle","2024-02-28T16:46:34.3930000+08:00","- Now lets have a look at the replicants. The documentation states: ""Replicants will replicate data from Core nodes, they have a complete local copy of data‚Äú. As every core nodes seems to contain all of the data from the cluster, this would in turn mean that also every replicant contains all the data. This again would require to scale the size of the replica nodes the larger your cluster gets. If correct, again I think this is an issue. 

- As replicants are only read replicas and do not take writes, if a client is connected to a read replica, this would mean that the replicant would need to forward any publish to a core node for writing adding to latency. This is also no ideal.

- ""We can think of this data replication model as a mix of masterless and master-slave replication.‚Äú That‚Äôs a fun one. As apparently you have explicit master nodes (core nodes) and read replicas (replicants) you obviously do not have a masterless architecture. It‚Äôs either masterless or not. You have masters and you have read replicas.

- Looking on the paragraph on hardware requirements in the blog post: ""Core nodes require a large amount of memory, and the CPU consumption is low when no connections are undertaken; the hardware configuration of Replicant nodes is consistent with v4.x, and its memory requirements can be estimated according to the connection and throughput configuration.‚Äú The way I understand this, it does confirm my deduction from further up.","",""
"830193224504705035","marc.jaeckle","2024-02-28T16:46:42.5490000+08:00","- Routing Table Replication or Message Replication? Based on the documentation, I find it difficult to tell, if you really replicate the messages or if you just replicate the routing table configuration. The docs talk a lot about replicating the routing information and doesn‚Äôt explicitely state if messages are also being replicated. The closest to explicitely stating is the description about how Mnesia works/is used which reads ""and every transaction is replicated to all nodes in the cluster."". This sounds like message data is being replicated. On the other hand, since every node seems to contain the identical data, I find it hard to imagine that you replicate all of the message data in a large cluster as well because each node would beed a crazy amount of memory for this. Could you give some insights if you also do replicate message data or is it just the routing information?","",""
"876880919988957205","ryankershaw","2024-03-01T05:38:58.5250000+08:00","Here's the updated one: https://blog.lnsresearch.com/the-ix-reference-architecture-evolves-for-the-journey-to-zero","",""
"876880919988957205","ryankershaw","2024-03-01T05:45:47.1720000+08:00","Can't disagree, what we release publicly tends to be pretty high level.  We go into a lot more detail, but keep that behind a paywall.  Yes, keeping things behind a paywall isn't great, but our analysts need to eat (until GenAI gets better, then all bets are off).  We just have to make sure that what we put out is worth paying for.","","üëç (3),üíØ (2)"
"766684226455207996","bright_hummingbird_31342","2024-03-06T05:16:37.5410000+08:00","Is anyone using MongoDB in their architecture?  What use cases is it supporting?","",""
"894527802316046366","nickn5549","2024-03-06T18:12:19.4470000+08:00","I use a NoSQL database for the Intranet Search Engine...I have Apache Solr (https://solr.apache.org/) indexing all the lost souls on the Intranet.  Other than that I stick to SQL and more recently Graph databases (neo4j).","",""
"812295088348200960","patanj2","2024-03-06T19:31:25.1730000+08:00","Not in my current role,  but in previous role my company had MongoDB as persistent store as part of a large IoT implementation (non-manufacturing)  for connected residential equipment. It supported backend of consumer onboarding via phone app as well as maintaining history of actions and operations.","",""
"740383178279354388","mriiot","2024-03-06T20:20:27.7300000+08:00","We considered it for storing device model information but have moved on to another approach","https://cdn.discordapp.com/attachments/815945777452941313/1214910462630567976/image0.jpg?ex=68df16ca&is=68ddc54a&hm=75824b38a67558dc94035d5ecdde3edb0349fe4f2d60cd02cdbcae8661be6521&","üëç (1)"
"801561312861618236","jon.forbord","2024-03-07T04:05:01.8630000+08:00","Considering it for a queryable event log of sorts. Regular sql seems too rigid for the use case we have in mind.","",""
"1212245669558100021","tyler092335","2024-03-10T11:02:16.7470000+08:00","I have a question on why I see people using kepware as a opc ua server to connect to things like PLC‚Äôs then they connect ignition to the kepware opc ua server. Why would you just not use ignitions built in opc drivers to connect to the PLC‚Äôs and legacy items?","",""
"766684226455207996","bright_hummingbird_31342","2024-03-10T12:13:41.6790000+08:00","1) Ignition didn't always have the same offering of drivers it has today and it previously may have been a separate module to license. Also, some users may have already been using Kepware before they adopted Ignition.  There also may be some enterprise agreement in place that makes it efficient to procure among other PTC solutions an org may use (e.g., Creo, Windchill, ThingWorx).

2) Some users may not want a monolithic architecture and elect to decouple device connectivity from their Ignition gateways. It can make upgrades easier. There may be other OPC UA clients in their architecture beyond Ignition.

3) Kepware has much broader driver support than Ignition.

5) Kepware's drivers have more features than Ignition's (e.g., S7 browse/import, S7 transport security, unsolicited / report-by-exception drivers).

6) Kepware has historically delivered new drivers and features to the market before others.

7) Kepware has historically sorted out support across the many device firmwares before others.

8) Kepware has a broader market beyond Ignition. It's being used with other SCADAs and other solutions.  More users, more systems, more use cases generally leads to more robust and capable solutions.

9) There are some indications that Kepware may be more performant as well as more efficient on the native communication load.","","üëç (2)"
"801561312861618236","jon.forbord","2024-03-10T17:39:26.3750000+08:00","10) Kepwares marketing has been so efficient that in the US, when I say OPC Server, I have to specify I do NOT mean kepware.. üòÖ","","üëç (1),üòÇ (1)"
"766684226455207996","bright_hummingbird_31342","2024-03-10T19:47:01.9250000+08:00","Gateways have been the only way to connect to devices.  Even some of the early Siemens stuff with embedded OPC UA was basically unusable.  On board OPC UA has not been a viable option until recently.  Even if it's an option on the control platform, it can be sometimes hard to get machine builders to deliver a machine with a firmware that supports it.

Looking back, it's odd how long this has took.  It took about 10-15 years to get mainstream adoption of the ""UA"" version of ""DA"".  During that time, the foundation was busy championing ground breaking initiatives like XML/SOAP or companion specs for some obscure asset that some tiny german machine builder may ship a handful of units of.

The confusions around servers vs gateways is probably also a Rockwell Automation factor.  There are a large amount of PLC programmers in the US that don't really have formal training backed with any theory.  They only know what they learned on the job.  They just know Allen Bradley.  They have used RSLinx to connect to PLCs their entire career.  They don't understand or know of any other way.  Kepware is like the third-party version of this and has been bundled into Rockwell Automation products.","",""
"1212245669558100021","tyler092335","2024-03-11T11:03:09.0540000+08:00","Thanks for the feedback guys üëç","",""
"1212245669558100021","tyler092335","2024-03-11T11:07:43.8130000+08:00","Would it make sense to have a ignition edge sever to connect Allen Bradley systems and then feed that up to a main ignition gateway for trending and reporting","",""
"1063829764164563026","mariano.beracochea","2024-03-11T19:04:16.4590000+08:00","I have being on the same question recently, i looked over kepware because it was more robust, but found that you have to buy the drivers independently, it is not a single rounded package, and only the siemens suite were aroung 2k. I think that it depends on the range of drivers you are needing, kepware will have more options, but if you need few and the ""mainstream"", i think that with ignition(maybe a couple of edge will still be cost effective) you are good to go","",""
"1111719898482212874","d_leblanc","2024-03-11T19:06:05.3030000+08:00","We purchase the manufacturing suite from kepware. contains all the drivers we use and a lot of drivers we dont use.","","üëç (1)"
"1111719898482212874","d_leblanc","2024-03-11T19:48:21.5450000+08:00","I also have a call this week with EMQ for pricing on NeuronEX as they don't have pricing on the website. They have a better driver selection the Ignition does.","",""
"1214242167640424619","zack.scriven","2024-03-11T20:13:37.7810000+08:00","In the past, ignition drivers were often problematic. Kepware offered greater control over utilizing the poll-response functionality, which was crucial, especially for wireless and remote sites. While the Ignition driver might have been suitable for plant floor networks with PLCs, it often failed to perform well over radio networks in my experience, which dates back a while.. before MQTT (Pub/Sub) came in and solved a lot of these network bandwith problems.","","üëç (1)"
"1129435706285101076","ted.garrison","2024-03-11T22:16:35.6820000+08:00","#2 on this list is a big one.  Not having to go validate all your device connections everytime you upgrade Ignition is huge.","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2024-03-11T22:29:47.8450000+08:00","As Daniel mentioned, what you might be looking for is the Manufacturing Suite.  Look at the component driver page to see all the drivers.  I recommend going through the user guide of the drivers you would use.  You walk away with an idea of how the protocol works, it's dependencies, what's possible, and what you might want to experiment with or optimize.

https://www.ptc.com/en/store/kepware/suites/manufacturing-suite","",""
"1073312001788477471","sparkylarks","2024-03-11T22:31:25.9380000+08:00","Do you have to validate when you upgrade Kepware? üòâ 
Seriously though, is the update frequency for Kepware noticeably less than Ignition?","",""
"1129435706285101076","ted.garrison","2024-03-11T22:32:44.4620000+08:00","I'm not sure if kepware produces updates more often or not, but our implementation of those update is significantly less.","","üëç (1)"
"1129435706285101076","ted.garrison","2024-03-11T22:33:42.8900000+08:00","one of the benefits to some degree of kepware - short of a major security patch - if the comms are working, the comms are working. So there's rarely a benefit to an upgrade.","",""
"1111719898482212874","d_leblanc","2024-03-11T22:37:34.0830000+08:00","upgrades generally have no issues (we do monthly server patching and update kepware whenever there is a new version). update frequency is maybe 2-3 times a year and may contain bug fixes to drivers or the occasional new driver. I backup the kepware project any time a make a change so if there is an issue, just load the backup and your good.","",""
"817835202746253344","IIoT#4707","2024-03-11T22:37:34.3250000+08:00","GG @Daniel LeBlanc, you just advanced to level 5!","",""
"1212245669558100021","tyler092335","2024-03-11T23:00:21.3800000+08:00","With kepware is it best to have a Chanel per plc? Or does it make more sense to have one Chanel with all the PLC‚Äôs under it?","",""
"817835202746253344","IIoT#4707","2024-03-11T23:00:21.6950000+08:00","GG @Tyler, you just advanced to level 1!","",""
"1063829764164563026","mariano.beracochea","2024-03-11T23:11:21.9240000+08:00","I saw a couple of year ago how the manual explain it, all the communications on one channel are executed at ones, if one of them fails all the channel's messages are discarted, so you would want to organice on some channels, but if you have too many channels you can have efficiency problems and delay on the messages.","",""
"898217314741280828","hobbes1069","2024-03-11T23:12:17.5890000+08:00","Technically I'm running it at home because I have Ubiquity Unifi Network Controller self hosted but for a more industrial setting, I believe Tulip uses it for the machine monitoring side of things.","",""
"1129435706285101076","ted.garrison","2024-03-11T23:17:10.5990000+08:00","separate everything out into their own channels.  As Mariano states, everything in a channel gets executed sequentailly. So if one PLC is down, the others in the channel will experience SIGNIFICANT delays.","",""
"1111719898482212874","d_leblanc","2024-03-11T23:18:23.2840000+08:00","I set up all our kepware servers with 1 device per channel which is how they reccomnd in the documentation.","",""
"1111719898482212874","d_leblanc","2024-03-11T23:21:22.2380000+08:00","When I run into a situation where I have multiple assets programmed within the same controller, I actually set up a channel/device for every asset. This is more of a convenience for me as everything is programmed from python and the channel name describes the line / asset","",""
"1073312001788477471","sparkylarks","2024-03-11T23:45:38.0860000+08:00","One asset  per channel is a good rule, assuming that you are happy to lose comms to all devices on an asset if comms to one is lost.
Basically if one device in a channel has no comms, you effectively lose all the data from that channel( Not technicaly but in effect it can become so slow it is useless)

Before Christmas I had a situation where 8 Modbus units were set up in a single channel in Kepware. Each one was an Bosch Indra Unit.
When a Machine was powered off, for Maintenance and at night, all the other data coming in started only coming in about once a minute.
and we were trying to count pulses about 90 a minute. 
When the comms fail, Kepware will retry the connection as per the settings before moving on to the next one.
and if you have a few devices timing out things can get very slow.","",""
"1129435706285101076","ted.garrison","2024-03-11T23:56:56.8430000+08:00","We've stuck with 1:1 device per channel.   Then when we have   more than 1 asset per device, we handle that over on the ignition side..","",""
"1129435706285101076","ted.garrison","2024-03-11T23:57:21.7120000+08:00","not sure if there's a great way to deal with it.. consistency is the key I think.","",""
"1129435706285101076","ted.garrison","2024-03-11T23:58:15.6140000+08:00","and our channel names don't give you any clue as to what asset it's looking at.  We started with that, but then once we had more than one asset on a device, it blew that out the water.","",""
"1129435706285101076","ted.garrison","2024-03-11T23:58:46.7500000+08:00","so now we have fruits, dog breeds, etc for our channel names (based on device type)","",""
"867075936054149191","rickbullotta","2024-03-11T23:59:43.5110000+08:00","i suspect that if you have multiple channels per PLC, the driver might not be able to effectively optimize block reads.  maybe @Sam.E  can clarify.","",""
"1111719898482212874","d_leblanc","2024-03-12T00:42:46.8420000+08:00","The last bullet point suggests that multiple channels for a device is not a bad thing provided the device supports multiple connections.. 
I have server servers with up to 17 channels on the same PLC (Siemens and AB) and have not seen an issues with this.","https://cdn.discordapp.com/attachments/815945777452941313/1216788422581293178/image.png?ex=68df5446&is=68de02c6&hm=7b443f293a5049a80f9eb18ca1f5dc6a3c3bd1077235e7c25973e582ddcadb25&",""
"873009180938743828","sim_sam3","2024-03-12T07:14:02.0060000+08:00","This is true but depends on the protocol. We‚Äôd take a very careful look at the addresses or symbols and the request types utilized. With Siemens Optimized Blocks and ControlLogix family it‚Äôs less an issue. For register protocols it may reduce efficiency to split unless you know how our drivers block and the blocking requirements of the protocol","","üëçüèº (2)"
"1111719898482212874","d_leblanc","2024-03-12T19:17:59.4910000+08:00","Agreed. 98%  of the time where we have multiple channels for 1 PLC is with Siemens or ControlLogix driver. The odd time I do this with Mitsubishi and in that case, I use UDP and different port for each channel/device. 

 Kepware has excellent documentation for every driver including driver specific performance optimization which is always worth reading","",""
"1212245669558100021","tyler092335","2024-03-12T23:12:00.4010000+08:00","Sorry for the delayed response haha thank you guys for the feedback and help!","",""
"1214242167640424619","zack.scriven","2024-03-13T03:43:17.8070000+08:00","depends entirely on your architecure. what we did in water distribution / scada systems was had one channel per radio access point. so it could do round robin polling.","",""
"1214242167640424619","zack.scriven","2024-03-13T03:44:25.6090000+08:00","on a lan network, such as a plant floor, one device per channel does allow for the optimal polling settings for each device.","",""
"898217314741280828","hobbes1069","2024-03-13T03:50:33.7560000+08:00","Before I knew better, I setup up to 12 Fanuc based CNC machines on one channel. Has worked fine but I don't do that anymore, then again I'm not pulling a ton of data compared to pulling 1000s of tags from a PLC.","",""
"1139269147126153216","suran23.","2024-03-13T05:03:14.3580000+08:00","When we talk about UNS, the first thing we say is UNS is NOT EQUAL to MQTT. Because a UNS needs to have Data Hierarchy, Data Standardization, and on top Data Governance - along with a central (MQTT) broker at its core. Now, if you have Litmus Edge on your shopfloor, it can easily be used as your local UNS. We did a full scale article on that and happy to answer any qs as well. https://litmus.io/blog/embracing-the-unified-namespace-architecture-with-litmus-edge/
Now assuming you have an environment that has additional non Litmus Edge connected devices, systems, whatsoever, and need a global UNS, that's where we brought Litmus UNS to life. We just did a webinar on that with a demo. Again, happy to deep dive and take qs. Let me know if you would like the recording. I can DM you.
But long story short, Litmus Edge is a great starting point, creating your local UNS - standardizing the data, building models and hierarchy, building rules that govern the data and what you do with it, and then send it to wherever you need to.

And this is a more accurate representation of Litmus Edge, Litmus UNS, and Litmus Edge Manager - put together that we call the Litmus Industrial DataOps Suite.","https://cdn.discordapp.com/attachments/815945777452941313/1217216357595086888/image.png?ex=68dee892&is=68dd9712&hm=c6ceef507f966a6c8af4784ac07e9d493b782edd7742be20014a9b006cf20f98&",""
"1214242167640424619","zack.scriven","2024-03-13T06:53:06.2580000+08:00","excellent post. Thank you for sharing. this will be usefull for some of the things we are working on. I'm trying to get up to speed on Litmus.","","üôèüèæ (1)"
"873009180938743828","sim_sam3","2024-03-13T08:58:45.7650000+08:00","Thank you for the compliment about documentation, it‚Äôs a team effort but I think our small tech writing group is something special","",""
"873009180938743828","sim_sam3","2024-03-13T09:08:36.5610000+08:00","100%. Radio access points, cell towers with limited bandwidth, Ethernet to serial converters, all good reasons for single channel/multiple devices. 

If you have to use multiple protocols (i.e. multiple channels) and serialize polling there‚Äôs a channel setting called Virtual Networking aka Communication Serialization. Have to be careful to manage TCP states tho since those will be managed independently by each channel. TCP state management / inactivity timeout if supported is usually exposed at device properties -> timing.","",""
"1214242167640424619","zack.scriven","2024-03-13T10:33:24.1220000+08:00","yes forgot about ethernet to serial converters! lol","",""
"795725198980677734","diederik9434","2024-03-15T21:43:47.4420000+08:00","Hi everyone, I'm looking for a historian fitting for my usecase.
I have a beginning OEM that wants to collect data from its machines worldwide.

Ideally it should be: cloudbased, easy to setup & maintain, able to connect to MQTT and/or OPCUA and cheap

We very price bound and not very IT minded. Ideally i would have a historian as a service somewhere in the cloud. I dont know many of these. (Factry.io & Canary?) These are pricy. 

Second best option i could think of is to reproduce their functionality kinda DIY.
using cloud grafana, cloud influx/timescaledb and nodered connection i was able to make something.

other option is to have a local NAS with some docker containers and visualize locally (and connect over VPN?)

Anyone has some experiences/recommendations? 

Thanks! Diederik","",""
"867075936054149191","rickbullotta","2024-03-19T22:03:13.6250000+08:00","How many of you have actually read the original Industry 4.0 paper? I suspect very, very few. Here's the English version so that you can better understand the original vision and scope:","https://cdn.discordapp.com/attachments/815945777452941313/1219647372309823518/industrie4-0-smart-manufacturing-for-the-future-en.pdf?ex=68df2ee1&is=68dddd61&hm=c4606c78e343130ec96864fef45dcc65dcab90888945ad6663361ac7a447154f&","parrotcat (1),üî• (1)"
"917925131261718558","jpmoniz","2024-03-19T23:50:42.1690000+08:00","To me it's always been simple.   Use the technology you have available to you to solve use cases.  As technology evolves Rinse and Repeat.  It doesn't have to be complicated.","","üëè (2)"
"743826569918939217","reliabilityrooster","2024-03-22T07:46:24.8220000+08:00","I was looking for this thing online. Glad I checked discord üòÇ","","üëçüèº (1)"
"817835202746253344","IIoT#4707","2024-03-22T07:46:25.2190000+08:00","GG @Redheadedstepchild, you just advanced to level 1!","",""
"795725198980677734","diederik9434","2024-03-22T17:49:39.1970000+08:00","Someone could provide me feedback on this idea? üôÇ","https://cdn.discordapp.com/attachments/815945777452941313/1220670722246971392/TLT_data_setup.png?ex=68def373&is=68dda1f3&hm=64784c6c85f4376a529bdb84c29a5c8d67b960d14350ed5eeb748cb00557a9a3&",""
"795725198980677734","diederik9434","2024-03-22T17:50:34.1370000+08:00","It's using @Jermuk 's United Manufacturing Hub","","‚ù§Ô∏è (3),üëè (1)"
"698244484302897323","lmtx","2024-03-25T17:33:56.4230000+08:00","IoT Solution Reliability Checklist: Ensuring High Availability and Seamless Connectivity! üì±üí°

‚úÖ Endpoint High Availability: Ensure that the IoT platform endpoint is highly available for uninterrupted connectivity with devices and external applications. Implement load balancing and multi-region deployment for maximum uptime.
‚úÖ Fallback Endpoint and Switching Logic: Prepare for unexpected disruptions by exposing a fallback endpoint and implementing switching logic in devices. Reduce outage risks during major breakdowns by seamlessly transitioning to the backup endpoint.
‚úÖ Quality of Service (QoS) Levels: Prioritize essential messages using appropriate QoS levels to guarantee reliable delivery. Avoid overflows caused by non-critical telemetry messages during communication outages.
‚úÖ Reliable Storage for Inbound Messages: Store inbound messages in reliable storage before processing to prevent data loss in case of backend application failure. Utilize message queues or databases for secure and durable storage.
‚úÖ Automatic Credentials Rotation: Implement automatic credentials rotation to bolster security and prevent unauthorized access to devices. Use a certificate authority or a key management service for secure credential management.

By following this checklist, you can significantly improve the reliability and resilience of your IoT solution.

What would you add to this list?","",""
"1214242167640424619","zack.scriven","2024-03-26T04:55:16.2060000+08:00","interesting. from a purlely design perspective a little hard to read. What are your thoughts on UMH?","",""
"795725198980677734","diederik9434","2024-03-26T19:00:01.4590000+08:00","I'm experimenting with it now.  Rolling it out as a PoV at an OEM now (that's what's the architecture is for). I currently like the open-source mindset, flexibility and community support. I did encounter multiple (minor, no showstopper) bugs already tho.","",""
"795725198980677734","diederik9434","2024-03-26T19:00:47.5490000+08:00","For in detail advices on UMH i can recommend to contact @Jermuk","","‚ù§Ô∏è (2)"
"931748475543097435","nkhalasi","2024-03-26T20:13:24.1950000+08:00","I have been reading the UMH documentation for the last 2 days and I am liking the solution thought process so far. Unfortunately I do not have enough understanding of the manufacturing domain and the various tools and frameworks available to setup a lab environment. I would be interested in learning further if there is a way to setup a lab environment without having a dependency on the actual shop floor environment and ability to pull data for various scenarios.","",""
"795725198980677734","diederik9434","2024-03-26T20:30:38.7470000+08:00","That's possible: i recommend this guide and using there internal OPC-UA simulation server to get started! üôÇ https://learn.umh.app/blog/installing-the-united-manufacturing-hub-on-ubuntu/?ref=united-manufacturing-hub-blog-posts-newsletter

Here you set it up on a ubuntu VM (cloud or local), all tools to get started are in there already","","üëç (2)"
"931748475543097435","nkhalasi","2024-03-26T23:53:01.4590000+08:00","Thank you so much. You ensured I am going to be busy this long weekend ü§£","",""
"795725198980677734","diederik9434","2024-03-27T00:02:45.1480000+08:00","I've been there last couple of weeks, I will be available if you have questions! üôÇ","",""
"277515221885779970","jermuk","2024-03-27T00:54:49.1900000+08:00","if you have any questions, feel free to write me or join our discord server üôÇ","",""
"703661072535781456","kinokaf","2024-03-27T16:16:34.9900000+08:00","Hey everyone! Seems like their is a surging interest in re-designing IT service catalogs, specially for ITSM providers with multiple companies or OEMs under their command (Shared Service Centres). Does anyone have any reference material or reading material on designing service catalogs as such? Ideally something beyond ITIL-4?","",""
"537493750621143041","hisma","2024-04-06T23:41:48.0900000+08:00","I would add deadband/filtering of noisy data to prevent filling your IoT database with spam.  IE a noisy transmitter that's not filtered or treated with a deadband can quickly fill your database with rubbish as well as create a lot of unnecessary traffic.","",""
"817835202746253344","IIoT#4707","2024-04-06T23:41:48.5270000+08:00","GG @Richard Meyer, you just advanced to level 3!","",""
"698244484302897323","lmtx","2024-04-07T03:39:34.3740000+08:00","That is a great point. The backend should be able to detect a malfunctioning device, report the issue to the support, and temporarily disconnect that device.","","üëç (1)"
"537493750621143041","hisma","2024-04-08T06:33:57.6150000+08:00","why are you using node-RED in this factory side of this setup?  Don't understand.  I would assume you'd be using an HMI/SCADA solution that supports OPC-UA natively (such as ignition).  Why not go directly from PLC to HMI using OPC-UA?  What value is node-RED providing?","",""
"537493750621143041","hisma","2024-04-08T06:45:33.4240000+08:00","or perhaps node-red is pushing MQTT data directly to your HiveMQ UNS?  Is that what's happening? Not clear from this architecture drawing.","",""
"795725198980677734","diederik9434","2024-04-08T14:48:45.7200000+08:00","In the machine itself you mean? üôÇ Fair question, that's some trickery we do to get around a lacking feature in the Siemens Open Controller. (OPC server of the PLC to Node-red on the PC side to other systems)","",""
"795725198980677734","diederik9434","2024-04-08T14:50:07.2560000+08:00","This happens as well. We push data around in the plant with OPC/S7 (to be used by the end costumer/interaction with other machines) and push data to the cloud via MQTT to HiveMQ (to be used by the OEM)","",""
"795725198980677734","diederik9434","2024-04-08T15:21:29.8290000+08:00","A siemens opencontroller consists of 2 parts; A PLC side and a PC part.
The way my OEM develops their machines is that the PLC part is exactly the same for each machine (each drive, robot, sensor,..). has the IP adress in the machines. This means if we connect these to the plant network we get IP conficts. The PC side of the opencontroller has unique IPs

So we bridge the PLC and PC part (using a virtual ethernet OPC UA connection) to get our machine data to the plant network.","","‚ù§Ô∏è (1),üëç (1)"
"795725198980677734","diederik9434","2024-04-08T15:22:47.7600000+08:00","That's the PLC OPC server to Node-red opc client.

That node-red communicates with other machines in the plant over S7 (for example: if OEM machine is running; turn on this belt/put this heater on)","",""
"795725198980677734","diederik9434","2024-04-08T15:23:28.3160000+08:00","node-red also sends data to a cloud based HiveMQ (because all our machines are worldwide)","",""
"795725198980677734","diederik9434","2024-04-08T15:25:27.2450000+08:00","then UMH (installed in the HQ of the OEM) node-red subscribes to the cloud based hiveMQ, pushes it internally and shows it in the UMH historian","",""
"795725198980677734","diederik9434","2024-04-08T17:28:54.3190000+08:00","@Richard Meyer","",""
"882106463013711903","barbaram2070","2024-04-08T20:24:21.0730000+08:00","@Diederik how does a Siemens open controller look like? Is it a device that combines both PLC and PC or these are separate devices physically connected?","",""
"537493750621143041","hisma","2024-04-08T20:24:25.7950000+08:00","That's quite interesting, never used siemens open controller and didn't under how it worked. Thanks for the explanation!","",""
"795725198980677734","diederik9434","2024-04-08T21:06:58.1770000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1226880972142678097/image.png?ex=68df21b2&is=68ddd032&hm=0596b48e67daf257c993bb9caffdbe6d73926a89c1fcdfcc940844788078e096&",""
"795725198980677734","diederik9434","2024-04-08T21:07:44.6230000+08:00","It's an PC and PLC running individually on a hypervisor on the same hardware
This means if you restartthe  PC, the PLC is not affected (and visa versa)","",""
"795725198980677734","diederik9434","2024-04-08T21:08:09.1450000+08:00","Broadly used in machinebuilding/OEM applications because of it's price, size and compute power","",""
"795725198980677734","diederik9434","2024-04-08T21:10:43.0830000+08:00","It's ET200SP buildformat (if you're familiar); that's the small PLC size :p (As big as a S7-1200 for reference); bit bigger then a LOGO, smaller then a S7-1500 (i only know Siemens products; other brands i can't compare easily)","",""
"795725198980677734","diederik9434","2024-04-08T21:11:52.3790000+08:00","Pricing is very nice due to reduced hardware (only one piece of hardware instead seperate PC and PLC); we also run a HMI virtually on it so that's also cost reduction (then this device is PC, PLC and HMI)","",""
"795725198980677734","diederik9434","2024-04-08T21:13:36.6250000+08:00","and compute power is also nice (required for advanced motion control in OEM applications (reverse kinematics,...)); it has compute power of a S7-1516 (which costs about 150% of this device (and here you get the PC and HMI as extra))","","üëç (2)"
"537493750621143041","hisma","2024-04-08T22:25:56.9570000+08:00","would love to play with one of these.  Curious as to the limitations.  Seeing as it costs less than an S7-1500 PLC yet comes equipped with a PC + PLC, I'm wondering what its intended use-cases are.  First thought that comes to mind is memory & compute limitations... since it's running in a hypervisor, memory & compute must be shared across the PC & PLC.  Does this mean it's targeting smaller bespoke projects, or could you deploy this for a large complex factory?  Also safety... due to price & it's hybrid-device architecture, I can't see the IPC/PLC having a TUV performance-level rating beyond something like A or B.","","üëÄ (1)"
"795725198980677734","diederik9434","2024-04-08T23:22:15.5240000+08:00","Intended usecases are mainly focussed towards machinebuilders. Most complex deployments i've seen is control of 97 servo axis (productionline) (very task heavy on communication and cycle time of the PLC); with this load on the PLC, PC ran without issues","",""
"795725198980677734","diederik9434","2024-04-08T23:22:43.1660000+08:00","It comes with F rated versions of the hardware + software","",""
"795725198980677734","diederik9434","2024-04-08T23:24:10.7890000+08:00","to give you an idea on specs; they exist in normal, T, TF and F versions
Linux and Windows","https://cdn.discordapp.com/attachments/815945777452941313/1226915502257868961/image.png?ex=68df41da&is=68ddf05a&hm=1042c6814ab90ba80114a1c1fd5fdebc8ad446cf60d4b02361e603bd9ebc9577&",""
"795725198980677734","diederik9434","2024-04-08T23:25:44.3070000+08:00","F means Failsafe, info on the tuv certification here: https://support.industry.siemens.com/cs/document/109825198/information-on-t√ºv-certification?dti=0&lc=en-BE","",""
"795725198980677734","diederik9434","2024-04-08T23:28:19.9150000+08:00","They have SIL2 (as most of siemens safety hardware); is this the same as TUV performancelevel rating?
I only saw SIL3 before at a nuclear centre and in tunnle infrastructure so i think this safety level fits 99,99% of the usecase","",""
"795725198980677734","diederik9434","2024-04-08T23:28:22.4760000+08:00","s","",""
"537493750621143041","hisma","2024-04-08T23:33:00.8120000+08:00","SIL2 would be performance Level C, SIL3 would be Performance Level D/E.  Cool that these can be used in safety applications as well.  Versatile product!","",""
"537493750621143041","hisma","2024-04-08T23:36:06.9940000+08:00","SIL is typically used in process industry & performance-level is the standard for machines.  The reason is that calculating SIL is quite complex and can lead to ""fudging numbers"".  Performance Level is much simpler and you can use automated tools to spit out a performance-level.  I'm TUV certified in machinery and even though I learned how to perform SIL & performance-level calculations, we tend to stick to performance-level for machine safety.  ISO 13849","",""
"795725198980677734","diederik9434","2024-04-08T23:38:42.7070000+08:00","nice! I'm not very experienced in safety. I learned something! üôÇ","",""
"795725198980677734","diederik9434","2024-04-08T23:38:48.4070000+08:00","Thank you","",""
"537493750621143041","hisma","2024-04-08T23:41:12.4380000+08:00","no problem :).  We all come from different industries/backgrounds here, what makes this place so great","",""
"1073312001788477471","sparkylarks","2024-04-09T00:32:36.3230000+08:00","EN 62061, the Machinery related SIL standard only has 3 SIL levels. I thin 61511 only has 3 too
EN 61508, the parent standard, has 4 levels, and I think the Daughter rail and nuclear standards have SIL 4, but I think something rated for SIL 4 rail would not meet the nuclear standards.
I was not involved in either but 

the general approach for machines and processes is if you require risk reduction to the level of SIL 4 you need to go back and look at removing or reducing the hazards through other means first","",""
"1073312001788477471","sparkylarks","2024-04-09T00:44:18.7760000+08:00","@Diederik the Open Controller looks very nice. I was looking for exactly this for a customer but my Google-fu must have been weak.","",""
"1154812895457185812","rutger_18900","2024-04-09T00:53:42.3980000+08:00","Interesting, I did not know Siemens made such devices! Never seen any in the wild.
Did you see many of them get sold during your time at Siemens?
Like @Richard Meyer said curious what the downsides are, what would be a reason to buy a normal S7-1500 now that this exists?

Btw take a look at Beckhoff if you like this concept.","",""
"795725198980677734","diederik9434","2024-04-09T00:55:30.8210000+08:00","Downside is people don't know them & some people don't need the all in one","",""
"795725198980677734","diederik9434","2024-04-09T00:56:55.9620000+08:00","if you don't need the compute power or you don't need a PC, why would you want an opencontroller? We sold a lot of them but only to OEM","",""
"795725198980677734","diederik9434","2024-04-09T00:59:13.7290000+08:00","people buy what they know, that's one of the main reasons. 

OEM costumers get very generous support/product introductions/very extended studies from siemens experts what would fit their machines perfectly. Mostly it's a siemens recommendation to use an opencontroller instead, then they try it and stick to it.","",""
"795725198980677734","diederik9434","2024-04-09T00:59:46.5800000+08:00","Siemens introduces this product at OEMs to keep them away from beckhoff indeed","",""
"795725198980677734","diederik9434","2024-04-09T01:00:15.4720000+08:00","Beckhoff is 5 years ahead in these kind of solutions","",""
"1154812895457185812","rutger_18900","2024-04-09T01:00:44.0410000+08:00","If it's cheaper why not? Although maybe not a concern for Siemens customers üòõ","",""
"1154812895457185812","rutger_18900","2024-04-09T01:01:21.8790000+08:00","Makes sense, I wasn't aware it existed. TIL!","",""
"795725198980677734","diederik9434","2024-04-09T01:09:55.8150000+08:00","It's a cross selling strategy; if you buy an open controller you choose to go all in on Siemens (you buy into the PLC but also the HMI and IPC env), not everyone wants that","",""
"817835202746253344","IIoT#4707","2024-04-09T01:09:56.1130000+08:00","GG @Diederik, you just advanced to level 6!","",""
"795725198980677734","diederik9434","2024-04-09T01:10:37.8600000+08:00","but for the advanced OEMs this product is intended for, they mostly stick to one supplier. (because of bulk discounts)","",""
"537493750621143041","hisma","2024-04-09T01:15:38.8020000+08:00","yeah when I got certified I learned 62061.  But it was the opinion both of Rockwell, and my company I worked for when I got certified (as well as others such as tesla, which I also worked at) to stick to ISO 13849/PL and only use 62061 when the required machine safety function is too complex to be evaluated using the simpler performance level approach","",""
"537493750621143041","hisma","2024-04-09T01:17:04.1510000+08:00","but I should have mentioned you CAN use SIL in machine safety, its just not typical, from my experience.  Whereas in process its all you see.  Though I am happy to be proven otherwise :).","",""
"537493750621143041","hisma","2024-04-09T01:18:22.1130000+08:00","thats my argument. Why pay more to get less? üòÇ I suppose its more for customers that want something familiar and are resistant to change, which there's no short supply of in our industry.","","üíØ (1)"
"795725198980677734","diederik9434","2024-04-09T01:20:17.9410000+08:00","indeed; a disadvantage is indeed the product lifecycle. They will not support the opencontroller for 25y as they do with the regular S7-15xx series","",""
"795725198980677734","diederik9434","2024-04-09T01:23:11.2180000+08:00","At a very big automotive brand everyone knows they only use S7-1517Fs (the thirth most expensive regular PLC siemens has), even for the dumbest applications. This because of hot swapibility. ""You only need to have one in stock"" For them it's cheaper to reduce their maintance costs then it costs to go for the more expensive product each time. So sometimes it makes sense to go for ""more expensive for less features""","","üëç (1)"
"795725198980677734","diederik9434","2024-04-09T01:24:23.6120000+08:00","standarization is worth the extra bucks üòâ","","üíØ (1)"
"537493750621143041","hisma","2024-04-09T02:46:16.6150000+08:00","ah yes this is another important factor - spares/operations (ie maintenence team familiarity) etc","","üëç (1)"
"882106463013711903","barbaram2070","2024-04-09T20:10:39.9490000+08:00","I think this might not be the right channel to ask this question but to follow up with @Diederik‚Äôs example of a system for OEMs. What do you guys think are key metrics and data OEM systems must provide in industry 4.0? Or I should say information based on the difference between data and information that @Walker Reynolds explains.","",""
"867075936054149191","rickbullotta","2024-04-09T20:22:45.0880000+08:00","I don‚Äôt know if has already been shared here, but HighByte now supports a free two hour, resettable demo mode. They listened to customer feedback and responded!","","‚ù§Ô∏è (9),highbyte (2)"
"1111719898482212874","d_leblanc","2024-04-09T20:27:41.9570000+08:00","awesome!!","https://cdn.discordapp.com/attachments/815945777452941313/1227233477389320282/image.png?ex=68df187d&is=68ddc6fd&hm=5b482e6346a64440610770d6bdcbf395b9c9cecfd32eaccd232387158db0f558&","üëç (2)"
"898217314741280828","hobbes1069","2024-04-09T21:08:34.5700000+08:00","About time!","",""
"1073632885153730621","vaughnturner","2024-04-09T22:09:50.5950000+08:00","They told us they are making the announcement public on 4/10","","‚ù§Ô∏è (2)"
"693309801589112862","_dyland","2024-04-09T22:15:48.3700000+08:00","I saw it on Linkdln this morning.","","üî• (3)"
"382941357699760129","walker.reynolds","2024-04-09T23:15:46.9050000+08:00","No question they listen and respond.  I‚Äôm glad this announcement is public now.  üôè This will have a big impact.","","üëè (2)"
"230441548653789184","r.pop","2024-04-10T00:04:04.7250000+08:00","I've heard Highbyte is quite expensive. How does it stack up with some of the alternatives?","",""
"230441548653789184","r.pop","2024-04-10T00:04:59.6050000+08:00","Aso, if I'm doing all the modeling at the edge via something like Ignition or the proposed future state of OPC-UA over MQTT - why do I need Highbyte?","",""
"867075936054149191","rickbullotta","2024-04-10T00:31:02.6060000+08:00","Impedance mismatch with the receiver/consumer, connectivity to cloud apps/sources/databases, connectivity to historians, etc...","","üíØ (2)"
"1057737574287945899","xamp4248","2024-04-10T00:35:57.5340000+08:00","Let's wait for litmus UNS","","üíØ (1)"
"230441548653789184","r.pop","2024-04-10T03:26:32.2340000+08:00","Highbyte over Snowflake?","",""
"230441548653789184","r.pop","2024-04-10T03:30:32.6150000+08:00","Or are you suggesting I take my factory data into Highbyte, and then into Snowflake?","",""
"230441548653789184","r.pop","2024-04-10T03:34:56.0900000+08:00","Same question. If I have Ignition in my factory, and I'm using it to model my data as I send it up, why do I need Litmus?","","üëç (1)"
"898217314741280828","hobbes1069","2024-04-10T03:43:14.6580000+08:00","Yes, my understanding is you model it in Highbyte so it's actually useful instead of pumping raw data into Snoflake. Also, using pipelines you can store up a specific amount of data first to reduce your data transfer costs.","",""
"230441548653789184","r.pop","2024-04-10T03:44:49.6870000+08:00","So it's use-case is for when I don't have something ""in factory"" to model data?","",""
"230441548653789184","r.pop","2024-04-10T03:45:07.6960000+08:00","For example, Ignition.","",""
"867075936054149191","rickbullotta","2024-04-10T05:18:20.1080000+08:00","No, it‚Äôs much more than that. Modeling is a multi directional process the external apps that you send the data to have models also. And something needs to orchestrate and transform between those.","","üíØ (3)"
"1154812895457185812","rutger_18900","2024-04-10T05:27:21.9810000+08:00","That something can be Ignition right? üòà","",""
"230441548653789184","r.pop","2024-04-10T06:38:53.8820000+08:00","Our projects typically leverage data platforms that are better designed to accommodate multiple data sources - typically Snowflake. We deploy Ignition in factory to act as a data platform. It is my data modeler for factory assets, whether those assets are machines, operators, or other software systems. From that point, we egress data out through MQTT and the Cirrus Link modules into an endpoint. The endpoint varies based on the customer, but lately has been A LOT of Snowflake. With the IoT Bridge for Snowflake being designed to ‚ÄúETL‚Äù SpB messages, I can dynamically create my ‚ÄúUNS‚Äù on the fly with from my Ignition data source, Snowpipe streaming is beautifully designed for this purpose. Snowflake being the massive data platform it is has extensive tools for all those pesky IT applications I may also need data from. Zero-Copy Cloning and Dynamic Tables allow me to access all my ‚ÄúIT‚Äù data without having to ETL it. Nothing against Highbyte, but I don‚Äôt see a use for it if I do a good job deploying Ignition. Like I‚Äôve said before though, my use cases may be different than most.","","üëçüèº (2)"
"867075936054149191","rickbullotta","2024-04-10T07:21:49.1280000+08:00","Of course!  But last time I checked HighByte had a broader set of native outbound  connectors.","","üëç (2)"
"867075936054149191","rickbullotta","2024-04-10T07:22:31.3350000+08:00","You lost me at Sparkplug. ü§£","","üíØ (2)"
"867075936054149191","rickbullotta","2024-04-10T07:23:20.1560000+08:00","You can do anything with a C compiler too. ü•∏","","üòÇ (1)"
"230441548653789184","r.pop","2024-04-10T07:33:10.6970000+08:00","Ok","",""
"230441548653789184","r.pop","2024-04-10T07:38:11.3610000+08:00","You can swap out for another Spec if you like, but like I mentioned, when using Snowflake, it makes it really easy.","",""
"817835202746253344","IIoT#4707","2024-04-10T07:38:11.6820000+08:00","GG @RemusPop, you just advanced to level 8!","",""
"230441548653789184","r.pop","2024-04-10T07:38:40.3860000+08:00","I prefer tools on platforms instead of code on operating systems, but you do you.","","üî• (2),üëºüèº (1)"
"894527802316046366","nickn5549","2024-04-10T17:16:54.9110000+08:00","what's a typical monthly bill for small to medium customer that sends all the data to Snowflake? roughly...","",""
"230441548653789184","r.pop","2024-04-10T18:48:27.5310000+08:00","For manufacturing data - depending on the size of the data store and frequency of use $750-$1500","","üëçüèª (1)"
"230441548653789184","r.pop","2024-04-10T18:52:42.7470000+08:00","I think this is also why I mention my projects may be different than most. Many of my customers are already utilizing some cloud data platform, and this is just part of their strategy of building out a modern data platform.","",""
"894527802316046366","nickn5549","2024-04-10T19:13:30.4520000+08:00","I have all the data on-premise on 4 VMs and I'm talking with HQ IT to move it to the cloudy Cloud....and they bombard me with questions and requests for cost estimates...it's like I have a magic wand to see all these... It is all happening before I get any approved budget to do it...sometimes you just wonder... but, I know, wisdom begins in wonder...üòÜ","",""
"230441548653789184","r.pop","2024-04-10T19:58:20.8250000+08:00","What are you moving it to the cloud for? AWS? Azure? The reason they ask for estimates on cost is because they‚Äôll take that back to AWS or Microsoft to see if there‚Äôs funding available. Microsoft has a program called ECIF (End customer investment fund) which makes available 10%-20% of projected spend as cash or credits to you. So if your projected spend on Azure is going to be $1M a year, you can get $100-$200k to fund your lift and shift. AWS offers this as well.","","üëçüèª (1)"
"894527802316046366","nickn5549","2024-04-10T20:04:04.3800000+08:00","I asked for more servers that's why they sent me hunting. Delay tactics? Serious about it? Remains to be seen.","",""
"230441548653789184","r.pop","2024-04-10T20:07:24.5480000+08:00","Typically, just moving a factory VM to AWS is a very expensive way to utilize cloud. I would work with your IT group to see if there isn‚Äôt some services you could leverage to keep the cost down. This is where it helps to bring in experts. Talking directly to AWS they‚Äôre going to push consumption on you, they want your bill to be as high as possible (source: I worked for AWS). Find a good partner and they‚Äôll help you navigate the costs.","","üëçüèª (3)"
"756543760028139720","aronsemle","2024-04-10T20:26:47.1130000+08:00","I've seen the Ignition --> Cirrus Link (spb) --> IoT Core --> Cirrus Link/Snowflake Bridge --> Snowflake architecture quite a few times. Arlen is going to demo it this Friday I think, and we're going to talk about where we need to take SPB/MQTT to make it even better. I will say, for small/medium size factories it seems to work really well. It's still early, but we've had a few large orgs try it, struggle, and then come back to ""dataOps"". More specifically trying to manage/make UDTs consitent across sites is hard (for some at least), and the ingest cost  gets expensive because of the stored procedures running on the raw SPB data in Snowflake. So most of the hard part is around cost and management at scale it seems. Also purely as an architect, it's using a lot of tech (SPB/MQTT/Bridge) to tunnel data into Snowflake. When a new requirement comes in to get data into new system A, B, C it can be hard to adapt to. My two cents, but I do think there is value in the approach, as I've seen customers succeed with it.","","üëç (1)"
"230441548653789184","r.pop","2024-04-10T20:40:27.3560000+08:00","We should set up some time to compare notes. We've made some adjustments to overall architecture, but have had a lot of luck with it at scale for large corporations. Decoupling parts of the architecture seem to work really well.","","üëç (2)"
"756543760028139720","aronsemle","2024-04-10T20:44:28.1290000+08:00","Absolutely, I'd definitely be interested in digging into what you've learned. I'll send you a direct message and we can sync up.","","üëç (2)"
"867075936054149191","rickbullotta","2024-04-10T21:47:15.9690000+08:00","That seems an order of magnitude (or more) low based on published pricing.","",""
"867075936054149191","rickbullotta","2024-04-10T21:48:40.0830000+08:00","Yikes - why should a customer require AWS IoT for this?  Not only does it add costs, it adds complexity, failure points, and locks you into AWS.  Snowflake is available on GCP and Azure as well.  I prefer the way HighByte does it.","","üíØ (2)"
"568913935147728896","zeratall","2024-04-10T21:54:28.7450000+08:00","That is extremely low, if your using managed services in cloud for data storage, if your doing thousands of queries a day and have PB of data your looking at 10k-100k easily. From an architecture point of view you need to have a strategy for what and how data gets sent to cloud vs a local EDC","",""
"867075936054149191","rickbullotta","2024-04-10T21:55:55.2350000+08:00","EASILY.  Just dumping data in and doing some basic aggregates now and then is relatively cheap (storage costs approach zero).  But while Snowflake pricing is very transparent for compute, it's almost impossible to estimate how many compute units you'll need!  Totally use case specific.  And if you're doing any type of real-time visualization on analytics, you're going to get SLAUGHTERED with compute costs.","","üò© (1)"
"568913935147728896","zeratall","2024-04-10T21:56:33.1200000+08:00","Yep exactly","",""
"766684226455207996","bright_hummingbird_31342","2024-04-10T22:24:31.5210000+08:00","To make an outbound connection from the site to cloud, there needs to be some broker to publish to as an endpoint.  The CL Bridge needs to make a subscription to topic(s) to unpack all those SpB metrics and create the staging tables in Snowflake.  The broker could technically be any broker, anywhere.  It doesn't necessarily have to be IoT Core.  Given that an AWS shop would already have a fair amount of consumption using Snowflake and would need to host the CL Bridge in EC2, sticking with a native service like IoT Core could make sense.","",""
"867075936054149191","rickbullotta","2024-04-10T22:29:09.2260000+08:00","Why not unpack and transform them upstream and send via Snowpipe?","",""
"230441548653789184","r.pop","2024-04-10T22:31:47.6270000+08:00","This was on an entire plants manufacturing traceability data. I'm not just pulling numbers out of thin air. When architected correctly, you can keep costs low.","https://cdn.discordapp.com/attachments/815945777452941313/1227627094662578328/image.png?ex=68df3593&is=68dde413&hm=3c9a979d9ebbb4a06589f201efd4aa03780bd2cfd342ddac4fa67ca09a26970e&","üëçüèº (3)"
"867075936054149191","rickbullotta","2024-04-10T22:35:48.9430000+08:00","Ah, traceability data, not operational data.  Makes more sense. You rarely query traceability data in real time.","",""
"867075936054149191","rickbullotta","2024-04-10T22:37:31.3120000+08:00","I've seen people suggest putting time series data (historian-like) in Snowflake.  While that might be OK for analytics and feeding AI/ML, if you were querying/accessing that in real time to support operations, you would be paying way, WAY, WAAAAAAY more than that.","","üíØ (1)"
"230441548653789184","r.pop","2024-04-10T22:39:01.8650000+08:00","Architecture is critical. All use-cases have a dozen or more architectures you could implement. It's important to keep all these things in mind when designing said architecture.","","üíØ (1)"
"867075936054149191","rickbullotta","2024-04-10T22:39:24.1900000+08:00","If only more people could apply that logic to their UNS too... üòâ","",""
"230441548653789184","r.pop","2024-04-10T22:39:59.8550000+08:00","Like all things in tech - design decisions have to be intentional","",""
"766684226455207996","bright_hummingbird_31342","2024-04-10T22:43:55.8250000+08:00","Great question.  It does not seem wise to have a device-level protocol impose architectural constraints on a data warehouse.

The CL Bridge does use Snowpipe Streaming for ingest.  It publishes to a raw table that a transform gets run on to stage tables that match the SpB template definitions.","",""
"867075936054149191","rickbullotta","2024-04-10T22:50:58.3100000+08:00","That's why I said ""transform""","","üëç (1)"
"766684226455207996","bright_hummingbird_31342","2024-04-10T22:56:06.8430000+08:00","Well said. Constantly ""waking up"" compute really drives up cost.","",""
"801561312861618236","jon.forbord","2024-04-12T06:08:25.1110000+08:00","I dont get how managing those UDTs is so hard? Shouldnt Ignitions EAM module make this a breeze?","",""
"1063829764164563026","mariano.beracochea","2024-04-13T02:45:08.0790000+08:00","Someone have experience with Siemens Desigo CC (BMS) and integrating it to a UNS? In this case you take the data from the floor or just from the BMS?","",""
"756543760028139720","aronsemle","2024-04-13T04:47:59.0490000+08:00","I honestly have never tried it, so maybe? I think in general UDTs have historically been used to make building screens easy, but that's changing. I'm not sure of the tooling Ignition has in place to help with management across instances. I know you export them, so maybe just managing them in a github repo is easy enough.","","üëç (1)"
"931748475543097435","nkhalasi","2024-04-13T21:43:37.2050000+08:00","Has anyone done telegraf plus influxdb combination at a small shop floor and enabled the stakeholders with data visibility for next steps ?","",""
"867075936054149191","rickbullotta","2024-04-13T22:13:16.1610000+08:00","Personally I'd skip telegraf and use Node-RED instead if you're trying to do it at low cost.  And I'd probably use ""regular"" Grafana. That said, by the time you spend all of your effort trying to make this stuff work, you probably could have just bought a simple HMI solution from Aveva or Inductive and been done quickly, plus a solution that is easier to maintain.","",""
"568913935147728896","zeratall","2024-04-13T22:14:42.0490000+08:00","Totally agree with Rick on the telegraf part, I often find it easier to just code something up over setting up telegraf lol","",""
"931748475543097435","nkhalasi","2024-04-13T22:30:07.9170000+08:00","I am trying to suggest just data collection to a small setup so that they can get a first hand feel of possibilities as a result of going down digital transformation path.
Hence look for something easy to setup and low cost.

Since I am not from this space I was struggling to find a good starting point.

Based on your suggestions I will explore the node-red combo as well.
In terms of db, i am just thinking of influxdb since it will be a throw away architecture anyway given that I want to introduce the concept right now.","",""
"867075936054149191","rickbullotta","2024-04-13T22:31:26.9870000+08:00","Google ""MING stack"" and this should help get you started on the path.","","‚ù§Ô∏è (2),üíØ (1)"
"772321230719811595","thomassorensen_","2024-04-14T00:01:21.0300000+08:00","Desigo CC has a OPC DA server, and I think it also has a BACNet server - that would be the easiest way to get data.. You could also connect directly to the PXCM controller if they have the newer BACNet firmware.. If your controllers use Siemens Legacy/Proprietary Token Ring Protocol P2, then you need expensive protocol converter software if you want to connect directly to the controllers.","",""
"401050128317808640","lopa0679","2024-04-14T03:54:18.8530000+08:00","I use telegraf to get sytem metrics (RAM,CPU %) to Mqtt. Do you use other ways to get those data?","",""
"1057737574287945899","xamp4248","2024-04-14T04:58:01.4410000+08:00","I used it to collect data from a portable data logger using modbus protocol.","",""
"898217314741280828","hobbes1069","2024-04-14T19:59:56.6190000+08:00","Node Red. I could get a screenshot of my flow once I'm back on my work computer tomorrow.","",""
"685604620810322017","mattventer.","2024-04-29T05:37:24.9720000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1234257187547906169/IMG_1602.jpg?ex=68def094&is=68dd9f14&hm=578c13b663888c790c8680b3190876ff4e3fb0935427c8d1b5fdd264a241c60f&",""
"685604620810322017","mattventer.","2024-04-29T05:37:52.6520000+08:00","Taken from HM.","",""
"867075936054149191","rickbullotta","2024-04-29T05:49:29.5010000+08:00","Literally no one would ever use that architecture.","","ü§£ (1),üëç (1)"
"685604620810322017","mattventer.","2024-04-29T06:01:55.9610000+08:00","I knew you would react, haha.","","üòÇ (1)"
"867075936054149191","rickbullotta","2024-04-29T06:03:53.0220000+08:00","Those eye charts from each of the cloud vendors are kinda silly.","",""
"867075936054149191","rickbullotta","2024-04-29T06:28:51.8700000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1234270134974021682/IMG_0759.webp?ex=68defca3&is=68ddab23&hm=54b2eedbebcd2e36e1ae8e8e511fad621a73643b7463aa4056254801ba41fca9&",""
"867075936054149191","rickbullotta","2024-04-29T06:29:36.8800000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1234270323348738078/image0.jpg?ex=68defcd0&is=68ddab50&hm=9d67893d33420bd3c564a50860991a14b1306fe52a5031b04f89a5513543725d&",""
"867075936054149191","rickbullotta","2024-04-29T06:30:37.9950000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1234270580048527420/image0.gif?ex=68defd0d&is=68ddab8d&hm=4ce54bdd829584d70e844f81de2e66cef354daef73eb48362c8c1c468a18ac38&",""
"568913935147728896","zeratall","2024-04-29T06:36:22.4640000+08:00","I‚Äôm convinced most of those reference architectures are created and published to get people to sign up for as many AWS services as possible.","","üíØ (1),üòÖ (1)"
"867075936054149191","rickbullotta","2024-04-29T06:37:45.6720000+08:00","You would be correct.","",""
"867075936054149191","rickbullotta","2024-04-29T06:39:04.7590000+08:00","Reduce it to one box in the cloud: https://www.twinthread.com/platform/overview","","üëç (1)"
"867075936054149191","rickbullotta","2024-04-29T06:45:50.8360000+08:00","Virtual PLCs in the cloud and I/O at the edge? Lol.  Who writes that stuff.","",""
"812295088348200960","patanj2","2024-04-29T08:41:38.8900000+08:00","Maybe ChatGPT","",""
"230441548653789184","r.pop","2024-04-29T08:49:17.8080000+08:00","As a former Partner Solution Architect for AWS - that‚Äôs exactly what they‚Äôre created for. They want you to buy as many icons as possible.","","üëçüèº (1)"
"568913935147728896","zeratall","2024-04-29T09:21:19.1370000+08:00","Hahah not surprised, I mean, I get it but come on! ü§£","",""
"894527802316046366","nickn5549","2024-04-29T10:16:29.2430000+08:00","much easier to sell icons than using your brain to identify and solve problems for your customers...","",""
"697134502148964423","trentc","2024-04-29T18:37:08.8470000+08:00","Hi rick, i have seen you post and promote twinthread more than once. I am curious, what is your involvement and experience with this platform? What other tools would one need to pair with it to achieve successful application at scale? Where would I definitely not want to use twinthread?","",""
"795725198980677734","diederik9434","2024-04-29T18:47:32.7580000+08:00","I must say; Audi is migrating their PLCs on the shopfloor to cloud based (their own datacenter) virtual plcs üôÇ","",""
"795725198980677734","diederik9434","2024-04-29T18:47:58.8040000+08:00","less maintance and way more cybersecure","",""
"795178288330440704","youri.regnaud","2024-04-29T18:54:24.6580000+08:00","Some, all?","",""
"867075936054149191","rickbullotta","2024-04-29T19:33:47.4610000+08:00","Investor/advisor/fanboi/believer. At present TwinThread is cloud only (with the exception of the edge agents), so if you need to run low latency, highly critical ML algorithms at the edge, you can‚Äôt do that at present. Also only on Azure and AWS right now, but recently rearchitected for K8S so GCP and on prem are technically feasible too.  Lastly, the out of the box connectors are not for direct-to-device comms.  You‚Äôd still need a kepware or litmus for the ‚Äúlast foot‚Äù.","",""
"867075936054149191","rickbullotta","2024-04-29T19:34:20.5500000+08:00","Yikes","",""
"697134502148964423","trentc","2024-04-29T20:29:17.3100000+08:00","Perfect, thanks for the info. No ml at the edge ‚Äúat present ‚Äú‚Ä¶. Hopefully we see more edge impulse type solutions for edge ml‚Ä¶ having the feature built in can make for better user experience and workflow","",""
"766684226455207996","bright_hummingbird_31342","2024-04-29T21:13:03.0340000+08:00","It may or may not have inspired some Jackson Pollock derivative works.  The lines were just a coincidence.","https://cdn.discordapp.com/attachments/815945777452941313/1234492647591247892/HM24_AWS_Mfg_Annotated.jpeg?ex=68df231e&is=68ddd19e&hm=b9c28728cab25cf666f1938f02b265710a07948caa2e1ae7e099e86bc6a97efe&","üòÇ (2)"
"867075936054149191","rickbullotta","2024-04-29T21:14:34.1890000+08:00","So many things to criticize in this diagram though...","",""
"766684226455207996","bright_hummingbird_31342","2024-04-29T21:17:20.0520000+08:00","Is SDA a virtual PLC offering?  I thought it was hosting the IDE and lifecycling the programs?","",""
"867075936054149191","rickbullotta","2024-04-29T21:20:15.1400000+08:00","Both.  And look at the silly box with Tulip, Aveva, Inductive, etc... - those apps aren't going to be going through 250 layers of AWS services to get to the stuff they need.","",""
"795725198980677734","diederik9434","2024-04-29T21:44:39.4060000+08:00","some atm; i saw it in practice. I was pretty impressed.
They have taken the firmware of the 1517 and put it in a docker container

https://www.siemens.com/global/en/company/stories/industry/factory-automation/virtual-plc-audi.html","",""
"795725198980677734","diederik9434","2024-04-29T21:46:23.6230000+08:00","not yet supported is safety and motion. (so T & F versions of the PLC) but it's coming! 
They are creating a rollout strategy for a full plant in B√∂llinger H√∂fe in germany","",""
"568913935147728896","zeratall","2024-04-29T21:49:37.4560000+08:00","That‚Äôs quite interesting, I‚Äôd love to see Audis analysis on that, I could see a lot of benefits using virtualization, but idk my initial knee jerk reaction is I‚Äôm with @RickBullotta I would think the cons/risks outweigh the pros. Would love to see what Audi is seeing I‚Äôm not.","",""
"795725198980677734","diederik9434","2024-04-29T21:50:06.6090000+08:00","management","",""
"795725198980677734","diederik9434","2024-04-29T21:50:48.6230000+08:00","they have +- 3000 plc's per plant; keeping governance is very difficult
if you can remote manage them; that's already way easier","",""
"795725198980677734","diederik9434","2024-04-29T21:51:29.5950000+08:00","firmware updates/orgestration/spinning up a new one/hardware independant/...","",""
"795725198980677734","diederik9434","2024-04-29T21:51:37.7540000+08:00","i can name quite a few advantages","",""
"867075936054149191","rickbullotta","2024-04-29T21:51:54.4910000+08:00","...and a data center at or near the facility isn't the same as ""the cloud""","","üíØ (1)"
"568913935147728896","zeratall","2024-04-29T21:52:07.2550000+08:00","Yeah that‚Äôs what I‚Äôm taking about above when I mention the benefits, config management, management, deployment, etc. can do all the cool devops things with virtualization but idk, I think there are a lot of disadvantages and I‚Äôd be curious to see why Audi doesn‚Äôt think they are blockers.","",""
"795725198980677734","diederik9434","2024-04-29T21:53:09.2630000+08:00","indeed; it's a datacenter around 2 km from the factory itself","","üëçüèº (1)"
"795725198980677734","diederik9434","2024-04-29T21:53:18.1180000+08:00","connected over direct fiber connection","",""
"795725198980677734","diederik9434","2024-04-29T21:55:32.3680000+08:00","i have also played with the vplc on a siemens industrial edge device","",""
"795725198980677734","diederik9434","2024-04-29T21:55:37.3800000+08:00","works wel","",""
"795725198980677734","diederik9434","2024-04-29T21:55:39.8000000+08:00","well*","",""
"568913935147728896","zeratall","2024-04-29T21:58:12.9900000+08:00","That‚Äôs really interesting I‚Äôd love to play with that myself lol.","",""
"867075936054149191","rickbullotta","2024-04-29T21:59:00.2870000+08:00","I can think of quite a few disadvantages as well : a more concentrated point of failure (one hardware rack failing could take out a large # of ""PLCs"", greater attack surface for cyberattacks, at least two more degrees of freedom in failure mode analysis (hardware + network), perhaps latency/jitter issues for time sensitive control (e.g. motion control), and so on.  Always a tradeoff.","","üëç (1)"
"795725198980677734","diederik9434","2024-04-29T22:00:25.1700000+08:00","turning CAPEX into OPEX is the biggest advantage i would say üòâ a SaaS license for a vplc is more interesting then buying hardware for ever","","üíØ (1),ü§î (1)"
"568913935147728896","zeratall","2024-04-29T22:01:59.3800000+08:00","Absolutely thats exactly what dell is targeting with their MTAS solution that Walker has been talking about.","",""
"568913935147728896","zeratall","2024-04-29T22:02:19.7620000+08:00","Turning your entire IT/OT architecture into OPEX because the entire architecture is now consider a service lol","",""
"1073312001788477471","sparkylarks","2024-04-29T22:10:12.1080000+08:00","That is essentially on site. I've worked on sites larger than 2k. Is it their own datacenter/ their hardware in someone else's data centre
@RickBullotta I'd have Fault tolerant servers, not just HA, so 2 HA nodes per application, on two different rack in two different buildings, that was the standard approach in Terminals.

It would be interesting to see if they use the ET200 controllers on the RIO to have a local mode.

but if the issue is device management  there are tools for that, and given that I still see S5 PLC working in the wild, it will cost a lot more to host.
The CPU isn't most of the ""PLC"" cost.","","üíØ (1)"
"1129435706285101076","ted.garrison","2024-04-29T22:23:37.8170000+08:00","as @RickBullotta  goes and rents a mini excavator..","","ü§£ (2)"
"1154812895457185812","rutger_18900","2024-04-29T22:24:14.0600000+08:00","Interesting for sure, but indeed I wonder if the advantages outweigh the disadvantages/risks.
Also where is the line between software application and ""virtual PLC""?","",""
"867075936054149191","rickbullotta","2024-04-29T22:27:20.9170000+08:00","Would you accept it if your IT department wanted to give you only a ""Virtual Laptop""?","","üòÇ (1)"
"568913935147728896","zeratall","2024-04-29T22:28:59.9600000+08:00","If the performance is good, would be completely transparent, but if your out on in the field with a 3g connection, you‚Äôd probably want to throw whatever your running your remote client on out the window lol","",""
"1154812895457185812","rutger_18900","2024-04-29T22:32:38.5310000+08:00","If it's on prem and I have a good connection, why not? Not sure what your point is.
That a PLC is nothing without IO? Not a big difference between PLC + RIO and ""vPLC"" + RIO right?","",""
"867075936054149191","rickbullotta","2024-04-29T22:34:02.9680000+08:00","I guess I'm just a control freak when it comes to...control.","","üòÑ (3)"
"1154812895457185812","rutger_18900","2024-04-29T22:37:52.3570000+08:00","Agree, so I'm curious how it's actually implemented and performing, and where the line is between application and ""vPLC"".
If it's RT control running on specific HW / kernel similar to a Beckhoff IPC, interesting, but I wonder what the network looks like.
If it's an app where the ""benefit"" is you get to use TIA Platform, not so interesting.","","üíØ (1)"
"568913935147728896","zeratall","2024-04-29T22:39:10.4080000+08:00","Exactly what I‚Äôm curious about tbph","",""
"795725198980677734","diederik9434","2024-04-29T22:39:40.6070000+08:00","There is no application advantage 
They are porting over existing plcs in the field to vplcs they can use in their datacenter","",""
"795725198980677734","diederik9434","2024-04-29T22:40:23.9320000+08:00","I hope to see a lot of audi 2th hand s7-1517s coming to the market hahaha","","ü§£ (1)"
"1073312001788477471","sparkylarks","2024-04-29T22:43:14.5670000+08:00","A Chromebook so with all my apps webbased and all my storage in the cloud.
a lot of companies are doing that already","","üëç (1),üíØ (1)"
"1154812895457185812","rutger_18900","2024-04-29T22:44:17.0540000+08:00","Yes but like Zach said good luck out in the field","",""
"568913935147728896","zeratall","2024-04-29T22:44:28.0970000+08:00","I don‚Äôt do any local dev anymore it‚Äôs all on remote environments","","üíØ (1)"
"867075936054149191","rickbullotta","2024-04-29T22:44:43.5360000+08:00","I know.  And I fight back against the control of the IT borgs.","",""
"568913935147728896","zeratall","2024-04-29T22:47:00.3500000+08:00","To me this gets back to our IT and OT convergence discussion we had in #üí¨-general the philosophy and underlying things virtualization (IT) enables/address could greatly benefit mfg. that being said MFG has specific nuance you have to account for. To me this could be amazing to improve deployability, management, etc. but at the same time if the reliability, availability isn‚Äôt rock solid then that‚Äôs a big deal for mfg.","",""
"867075936054149191","rickbullotta","2024-04-29T22:49:08.8710000+08:00","In some ways, doesn't this trend dramatically increase the attack surface for cyberattacks on OT systems?","",""
"1073312001788477471","sparkylarks","2024-04-29T22:49:17.9450000+08:00","I suspect, if they are
1 - Porting over Existing code
2 - Leaving the safety and Motion code 

They might not be removing the PLC's any time soon and they could relatively easily switch back, all they need to do is disable the relevant rungs with a common bit.","",""
"568913935147728896","zeratall","2024-04-29T22:51:36.2470000+08:00","I think it ultimately depends on your network architecture, aka if your doing a traditional subnetted architecture absolutely, if your deploying some of the newer zero trust solutions out there, maybe not, I need to read more about how vPLCs actually work, but that‚Äôs definitely something that should be considered, and what I was mentioning when I was saying I was skeptical.","",""
"867075936054149191","rickbullotta","2024-04-29T22:52:12.4980000+08:00","I always figured that burying stuff in the plant was like putting it in a bunker.","",""
"795725198980677734","diederik9434","2024-04-29T22:53:36.5580000+08:00","nono, you got me wrong.
motion and safety versions of the PLC are not yet supported. Currently they are porting over PLCs that don't have these","",""
"568913935147728896","zeratall","2024-04-29T22:53:52.3330000+08:00","Hahaha yeah I think that‚Äôs why OT typically have always been on air gapped networks from IT, atleast in my org, which is where a lot of the data silos stim from (no actual network path). I‚Äôm actually in the middle of deploying SDA from Cisco which does micro segment and some cool L7 inspection, so you can get away with some really interesting new architectures in a secure way since it‚Äôs all trying to incorporate zero trust.","",""
"1073312001788477471","sparkylarks","2024-04-29T22:59:30.2960000+08:00","Ok, but If i was responsible for that plant, I'd still leave the PLC's in the Panel","",""
"867075936054149191","rickbullotta","2024-04-29T22:59:53.0420000+08:00","I would never ""migrate"" anything at the control layer if it was working fine.","",""
"568913935147728896","zeratall","2024-04-29T23:02:39.9250000+08:00","I wonder if you could do blue/green","",""
"867075936054149191","rickbullotta","2024-04-29T23:04:55.2440000+08:00","I think gradual and partial changeover is difficult and risky for real-time control.  Kind of an all-or nothing switch I'd think.","",""
"568913935147728896","zeratall","2024-04-29T23:05:51.2670000+08:00","Yeah thinking blue/green in more of a validation type deployment strategy. Once you feel confident could then hit the switch so to speak, these zero downtime type deployments are where I think this tech could shine","","üíØ (1)"
"867075936054149191","rickbullotta","2024-04-29T23:08:17.4200000+08:00","And when you hit the switch you suddenly realize all of the dependencies that slipped through testing. üò±","","ü§£ (1)"
"568913935147728896","zeratall","2024-04-29T23:08:53.1300000+08:00","Hahahah unfortunately. Deployment strategies only mitigate risk they don‚Äôt eliminate it entirely.","",""
"1154812895457185812","rutger_18900","2024-04-29T23:13:03.3440000+08:00","I don't see the benefit (yet)

When I look at marketing materials seems like the biggest selling point is ""you get to use TIA platform still, but run on any hardware"".

If I buy Siemens HW to go with it at the edge it's not gonna end up being much cheaper than a PLC, the benefit I could see is to run other edge stuff on the same HW.
If I'm gonna run it in a virtualized environment in my data center I'm losing RT advantages so why would I want TIA platform, and why would I pay Siemens thousands per virtual controller?

What am I missing here?","",""
"1050051809789624320","eoinmurphy","2024-04-29T23:38:16.9430000+08:00","I think the idea of virtual PLCs is an interesting one, but it's statements like what is shown in the screenshot (from the Siemens S7-1500 Virtual Controller manual) that would have me worried if I was an end user thinking of using this tech. I guess this is the early days version of the product, so maybe over time some of these considerations won't seem as scary...","https://cdn.discordapp.com/attachments/815945777452941313/1234529196525617193/image.png?ex=68df4528&is=68ddf3a8&hm=b73e25b2241dc61925b89c487bc8511b91d6ba82c1aefc69c848e1b7bd2ec958&","üíØ (1)"
"817835202746253344","IIoT#4707","2024-04-29T23:38:17.5040000+08:00","GG @Eoin Murphy, you just advanced to level 2!","",""
"801561312861618236","jon.forbord","2024-04-30T04:07:06.1230000+08:00","It was as usual hard to understand from the marketing material what the virtual PLC actually was.. how is it different from soft PLCs? Whats actually new?","",""
"801561312861618236","jon.forbord","2024-04-30T04:10:16.4980000+08:00","Huh? The ability to update PLCs on the fly is one of the cornerstones of PLCs. Or can you clarify what you mean?","",""
"568913935147728896","zeratall","2024-04-30T04:26:19.0440000+08:00","In distributed architecture there‚Äôs different 0 downtime deployment strategies, Rick mentioned that the migration for something that‚Äôs supporting production is always tricky, I mentioned a vPLC could be a prime candidate for blue/green deployment, aka you could run your physical plc at the same time as a vPLC and see if you get any deltas between the two, if not then you have pretty good confidence. I think Rick thought I was talking about a rolling deployment which in software is where you slowly migrate from one application to another by moving functions from one application to another application, function by function, aka during migration technically both are responsible for providing the full capability. Which is where his partial/gradual changeover comment is coming from.","",""
"867075936054149191","rickbullotta","2024-04-30T05:10:43.9600000+08:00","I was responding to blue/green deployment models where the functionality often gets split across multiple systems during the transition.   Not ideal for PLCs","","üëç (1)"
"721401184715276290","durinwinter","2024-04-30T08:17:14.9080000+08:00","You are not wrong @RickBullotta but for OT I would do it differently than how IT does kt. Instead the demarc is at the I/O layer and you could test and deliver the ""blue"" virtual  to run for a while ingesting the data but it's decisions get written to nowhere. This way you can see it's responses to the actual systems stimuli  with the new logic alongside the live green controller. Assuming blue controller passes the test you can swap it in.  I think I just invented the vSIS","","ü§£ (1),üëçüèº (1)"
"867075936054149191","rickbullotta","2024-04-30T08:18:59.3090000+08:00","vSIS‚Ñ¢Ô∏è","",""
"721401184715276290","durinwinter","2024-04-30T08:19:32.8470000+08:00","But my understanding about vPLC is it's a heck of a lot easier to develop new logic and apply it. Especially because some people really really want to still use TIA Portal. Which is fine. But I suppose that's all it is. It's Codesys whose engineering tool is TIA Portal.","",""
"568913935147728896","zeratall","2024-04-30T08:23:20.0410000+08:00","Agreed that‚Äôs exactly what I was suggesting above https://discord.com/channels/738470295056416930/815945777452941313/1234521035970187306","",""
"721401184715276290","durinwinter","2024-04-30T08:24:10.7320000+08:00","@Zach E  yeah I figured I was replying to Ricks comment on blue/green","","üëç (1)"
"721401184715276290","durinwinter","2024-04-30T08:24:50.9150000+08:00","As he was commenting on the rolling nature of the IT variant","","üíØ (1)"
"810171324764258326","luisn8316","2024-05-04T17:59:28.6050000+08:00","- you don't need one IED per virtual PLC, you can have multiple instances per IED (saving cost). 
- performace scalability dependant on hardware (IPC) performance
- co-processing in parallel with other edge apps (AI inference server,  analytics,  energy monitoring, etc)
- truly hardware agnostic. While the preference is Siemens IPCs, you don't have to run industrial edge on a ""Siemens"" branded IPC.  from an availability standpoint this lends itself some advantages if your ipc goes down,  you can spin up a spare laptop to be a temporary IED while you wait for spares..","",""
"1154812895457185812","rutger_18900","2024-05-04T18:02:33.8360000+08:00","Do I have RT capabilities on any HW?
If not, why would I want a Siemens vPLC (with associated license cost and TIA)?","",""
"810171324764258326","luisn8316","2024-05-04T18:30:53.1600000+08:00","Yes, that is what I mean by ""hardware-agnostic"". With the exception that the IPC hardware meets minimum technical requirements (e.g. RAM, storage, CPU type/cores, etc.)","",""
"810171324764258326","luisn8316","2024-05-04T18:33:39.4730000+08:00","There is a list of ""approved"" Industrial Edge devices (which aren't exclusively Siemens IPCs) and then there is IEVD (Industrial Edge Virtual Device) which essentially allows you to run the Industrial edge runtime on any device.","","üëç (1)"
"1154812895457185812","rutger_18900","2024-05-04T18:34:48.4860000+08:00","Aha now that's more interesting! Wasn't immediately clear from the marketing materials I found.
Still only relevant to edge devices then right, you lose that once you move it to a virtualized environment.

Any detailed info on how this works? Or an overview like the Beckhoff one here: https://infosys.beckhoff.com/english.php?content=../content/1033/te1010_tc3_realtime_monitor/6828869003.html&id=","",""
"810171324764258326","luisn8316","2024-05-04T18:39:48.5240000+08:00","I belive there are capabilities or plans to run industrial edge on virtual environments (K8s) as well, but I have to admit I'm not entirely familiar with limitations here. Maybe @AjBh2o knows?","",""
"810171324764258326","luisn8316","2024-05-04T19:16:02.9810000+08:00","Ooh, looks like there is some guide on implementing Industrial Edge Management (IEM) on kubernetes

https://github.com/industrial-edge/iem-on-k3s?tab=readme-ov-file#industrial-edge-management-on-k3s","",""
"1154812895457185812","rutger_18900","2024-05-04T21:43:16.9690000+08:00","Correct me if I'm wrong, all new to me, only just been looking it up.

If I understand correctly Siemens Industrial Edge is a solution for managing (IEH+IEM) edge devices (IED) with a (Debian based) Siemens OS that can run Siemens apps, partner apps and docker containers. 
Sounds interesting but also seems like a good way to lock yourself into the Siemens ecosystem once again, with a locked down OS and IED+IEM license subscription for every edge device ü§î

The link you shared I think is to set up IEM on k3s (!= IED), so just the management tool and not the actual app runtime, correct?

Siemens vPLC is an app that can run on either windows, linux, or Siemens IED OS.
And I still can't seem to find any info on RT capabilities even for Siemens brand IED.
So far the selling point still seems ""you get to use TIA portal"".

Am I missing something?","",""
"867075936054149191","rickbullotta","2024-05-05T00:03:55.5890000+08:00","AFAIK that's part of what the Margo.org initiative is claiming they'll help with (avoiding lock in via a common management and admin plane).","","üëç (1)"
"867075936054149191","rickbullotta","2024-05-05T00:46:08.6050000+08:00","Here's an interesting article/paper on how to handle changeover of virtualized control using K8S with ""theoretically"" no downtime.

https://koziolek.de/docs/Koziolek2024-JSS-preprint.pdf","",""
"568913935147728896","zeratall","2024-05-05T00:55:55.1960000+08:00","Yeah something like this is kind of what I was imaging the value of a virtual controller, but that‚Äôs a really good read! Thanks for sending that over.","",""
"810171324764258326","luisn8316","2024-05-06T07:15:24.7570000+08:00","You pretty much got the gyst of it as far as architecture.. Although, the value of ""Industrial Edge"" platform is the management piece and the apps available. While the IED +  IEM are proprietary distributions, there are several advantages to having this over ""open source"" software (that's for a separate debate).

With V-PLC, the biggest value-add I see is that you can run other edge computing tasks (e.g. data processing, filtering, logging, AI, ML, visualization, etc.) in parallel to the PLC runtime without consuming PLC processing resources (i.e. memory, scan time, etc.). If you want to do this today with normal PLC, you'd either be consuming PLC compute resources, or have a separate edge compute device (that isn't centrally managed) or an edge gateway moving this to cloud-based processing. 

As far as documentation on vPLC, I struggle to find the documentation you'relooking for as well, however note that it is also under 'limited release' so that could be why there is also limited documentation.. 

Full disclosure: while I am a Siemens employee, I'm not the ""expert"" on Industrial Edge but mostly an enthusiast at the moment.","","üëç (2)"
"795725198980677734","diederik9434","2024-05-06T15:33:22.6050000+08:00","@Rutger Van Aelst Siemens industrial Edge has 3 layers: 
1. Appstore managed by Siemens (buying apps, licensing,...)
2. Costumer specific Management system (local or cloud based) (= IEM) (repo for apps you bought, centrally configuring IEDs,...)
3. Industrial edge device (= IED)  (devices in the field that collect data/run apps/...)","",""
"795725198980677734","diederik9434","2024-05-06T15:34:05.9160000+08:00","vendor lock in is obviously still there (but in compared to the past it's already ""open"" because it's docker based)","",""
"795725198980677734","diederik9434","2024-05-06T15:37:50.0670000+08:00","license model is indeed very tricky; starts of cheaply (to get marketshare) but doesnt scale well in my opinion (without discounts its a linear system); at scale it's expensive in compare with other systems.","",""
"795725198980677734","diederik9434","2024-05-06T15:39:00.2360000+08:00","An deployment of a  vPLC could indeed be as an app (=docker container) on a edge device","",""
"795725198980677734","diederik9434","2024-05-06T15:39:45.2550000+08:00","Selling point hmmmmm, Edge is not configured from TIA portal so thats not true i would say","",""
"1154812895457185812","rutger_18900","2024-05-06T15:40:31.6470000+08:00","the vPLC is, no? 
They mention that in their marketing materials, definitely one of the selling points for that ""app"" = use the tools you're familiar with (TIA)","",""
"795725198980677734","diederik9434","2024-05-06T15:41:26.9510000+08:00","vPLC is indeed configured with TIA (it's a docker version of a S7-1500)
An IED is configured from the webinterface of the device/ from the IEM","",""
"1154812895457185812","rutger_18900","2024-05-06T15:46:26.5250000+08:00","Right I understand.

Industrial edge definitely sounds interesting! I just would be worried about lock-in and scaling indeed.
Curious to see competitors, and as @RickBullotta said what Margo will be.

There's Litmus edge in a way (but no RT PLC apps afaik), there's Portainer that's still on my list to look into.
Anything else comparable?","",""
"1154812895457185812","rutger_18900","2024-05-06T15:47:48.7500000+08:00","Learning k8s basics is also still on my todo list, I'm barely comfortable with docker atm, definitely an area to focus on bc everything is headed in that direction.","",""
"795725198980677734","diederik9434","2024-05-06T15:47:58.7140000+08:00","Picture is different. Siemens Edge tries to do it all. (with selfmade + 3th party apps) No real other brands are doing that.","",""
"795725198980677734","diederik9434","2024-05-06T15:48:28.3110000+08:00","Litmus for example does support 3th party docker containers; that's kind of the same thing","",""
"1154812895457185812","rutger_18900","2024-05-06T15:49:46.9100000+08:00","Right but once you add in PLC you got to be able to offer RT kernel access, and I don't think Litmus has that atm.
Correct me if I'm wrong @Vatsal Shah, you also seem to be doing just about anything üòÖ","",""
"1154812895457185812","rutger_18900","2024-05-06T15:52:23.1970000+08:00","And Siemens is cheaper than Litmus for smaller sites it looks like, but atm I don't see any apps available yet, or drivers to other systems like Litmus offers.","",""
"795725198980677734","diederik9434","2024-05-06T15:54:33.8320000+08:00","that's a good question. The hardware does support it. (all IED have profinet interfaces)
For now it's a driver/software thing i think but they are working on it and it will come for sure! üôÇ 
IoT2050 (cheap Siemens IPC has the PN driver/realtime os already available for example; https://support.industry.siemens.com/cs/document/109741799/downloads-for-simatic-iot20x0?dti=0&lc=en-BE)","https://cdn.discordapp.com/attachments/815945777452941313/1236949213439459359/image.png?ex=68df8139&is=68de2fb9&hm=bc0764583460eaf4f0802a19bf7155a1f5693ddf15e37151f4e0615825134c70&",""
"1154812895457185812","rutger_18900","2024-05-06T15:54:54.6640000+08:00","So if you're already a Siemens plant, seems like a logical next step? Maybe to swap it out for something more generic later on.","",""
"795725198980677734","diederik9434","2024-05-06T15:56:18.3300000+08:00","yes üôÇ for 1000eu initial investment (IED hardware) + 200eu license/year (IED + IEM yearly license) you can get started
No other platform i know offers such a cheap getting started package","",""
"1154812895457185812","rutger_18900","2024-05-06T15:57:18.6500000+08:00","True but don't forget the additional 1-2k per vPLC app license üòú
But if it's as performant as a regular PLC, still very interesting!","",""
"795725198980677734","diederik9434","2024-05-06T15:58:15.5970000+08:00","yes, very interesting product; i see it coming","",""
"795725198980677734","diederik9434","2024-05-06T15:58:30.5440000+08:00","the wet dream of siemens is that you use the full Siemens IIoT stack","https://cdn.discordapp.com/attachments/815945777452941313/1236950205803401247/MicrosoftTeams-image-5-1024x576.png?ex=68df8226&is=68de30a6&hm=543b803611ceec68ec7a401029e330ad0d8e39aa46ee2956ae8bad3b6ef923ca&","ü§£ (1)"
"795725198980677734","diederik9434","2024-05-06T15:59:00.7980000+08:00","Siemens PLC, drives / IED, IEM, IEHub / Insights hub / Mendix","",""
"795725198980677734","diederik9434","2024-05-06T15:59:53.4080000+08:00","vPLC with Siemens AX allows for decent DevOps in my opinion
That's going to be very impressive (ive seen it in demo already)","",""
"817835202746253344","IIoT#4707","2024-05-06T15:59:53.6980000+08:00","GG @Diederik, you just advanced to level 8!","",""
"1154812895457185812","rutger_18900","2024-05-06T16:00:11.8280000+08:00","Long ways to go I think with the way their other products like PCS7, batch, OpCenter etc are architected today.","",""
"817835202746253344","IIoT#4707","2024-05-06T16:00:12.1490000+08:00","GG @Rutger Van Aelst, you just advanced to level 9!","",""
"1154812895457185812","rutger_18900","2024-05-06T16:00:17.2310000+08:00","Yea very excited about AX","",""
"795725198980677734","diederik9434","2024-05-06T16:01:13.5540000+08:00","PCS7 becomes PCS Neo (which is really different)","",""
"1154812895457185812","rutger_18900","2024-05-06T16:01:50.3840000+08:00","Started a thread.","",""
"795725198980677734","diederik9434","2024-05-06T16:01:55.1510000+08:00","Batch/OpCenter i cant judge, not really my core knowledge
I dont know those products very well","",""
"1154812895457185812","rutger_18900","2024-05-06T16:02:53.6680000+08:00","Interesting times for sure üôÇ","",""
"795725198980677734","diederik9434","2024-05-06T16:03:15.5280000+08:00","i've send a linkedin message btw üôÇ","","üëç (1)"
"1027653517386727548","jorgenk1000","2024-05-07T05:04:19.0450000+08:00","Any thoughts on the Medallion architecture approach from DataBricks? If you follow a UNS approach in a factory, and want to publish this to the enterprise, does it give added value to use the medallion architecture on the enterprise side?","",""
"721401184715276290","durinwinter","2024-05-07T05:56:15.1890000+08:00","Actually @J√∏rgen Kvinge  The medallion architecture is the best way to think about it all the way to the OT layer even if it means you have to change how you think of UNS to accommodate it","",""
"721401184715276290","durinwinter","2024-05-07T05:57:09.3340000+08:00","Because if you divide everything into two customers, one is for any ""control"" and the other is ""analytics/reporting""","",""
"721401184715276290","durinwinter","2024-05-07T05:57:48.8800000+08:00","Then The medallion architecture is just how you handle it for those two endpoints one of which would prefer no data to bad data and the other wants any and all data no matter what","",""
"721401184715276290","durinwinter","2024-05-07T06:03:49.8730000+08:00","I usually call this the ""control frame"" and the ""analytics frame"" because even when talking about a PLC some of the data you would want people to subscribe to is from the control frame. Others, the analytics frame. Because even though all data is originated from the PLC, there are different paths to different customers as to how you process it out.","",""
"810171324764258326","luisn8316","2024-05-07T11:37:08.4410000+08:00","Connectors available for Industrial Edge are:
- Siemens S7+
- Profinet
- Modbus TCP
- Ethernet/IP
- Beckhoff ADS
- SLMP (Mitsubishi)
- Basler Camera
- OPC UA
- MQTT

So no, it's not only for factories running Siemens","","üíØ (1)"
"1027653517386727548","jorgenk1000","2024-05-07T12:48:46.6900000+08:00","Does this mean you structure your UNS into control layer and analytics layer, and the subscribe into the medallion layer each of them? Or how would the total architecture look like?","",""
"721401184715276290","durinwinter","2024-05-07T22:23:34.0100000+08:00","@J√∏rgen Kvinge  here is what I do. I implement three buses with transparent brokers. I use Heptapod as the middle bus (orchestration control bus) a deterministic control bus (usually DDS) and MQTT as the analytics bus. Any control frame tagged items get published too or subscribed from the deterministic control bus. CF topics can also be subscribed too from the Orchestration Control bus. The analytics bus subscribes to topics that are stored on the orchestration buses associated data store (via backend plugin) Then, on each bus there are Control Frame bronze layers (generated directly from sensors or as raw metrics, and analytics bronze layers. This is because in a microservices based system the bus even extends to between applications on an edge computer.  I will make a better diagram with the namespaces.","https://cdn.discordapp.com/attachments/815945777452941313/1237409496846827681/Screenshot_20240507-081624.png?ex=68df33a6&is=68dde226&hm=a1fec513f954446c74361993e5195428da1fd85abc503a2323595235267fdb10&","üëç (1)"
"721401184715276290","durinwinter","2024-05-07T22:27:31.5670000+08:00","Not particularly special or ground breaking. I borrowed it from the software defined vehicle architecture. Which for control systems involving different layers of latencies but also having high bandwidth sensors such as vision systems","https://cdn.discordapp.com/attachments/815945777452941313/1237410493052751965/Screenshot_20240507-082639.png?ex=68df3493&is=68dde313&hm=3a36b34a2abc3c6614819f8a35f572acecad46953d34d6f0461c90d793392ad6&",""
"721401184715276290","durinwinter","2024-05-08T03:09:35.1730000+08:00","making this a little more actionable","https://cdn.discordapp.com/attachments/815945777452941313/1237481475767795812/unrestricted-architecture-DCF.jpg?ex=68df76af&is=68de252f&hm=0a0829437644a353126388ce386cf5e5dba2ac8fe455b3786c461594dc78272a&",""
"721401184715276290","durinwinter","2024-05-08T03:11:03.1410000+08:00","this considers how data movement happens in the following scenarios. How a machine vision model is trained from camera data. How a machine vision camera interfaces with two docker containers in an edge device, the first for data transformations and the second for the machine vision model that then sends a comand back to the PLC","",""
"721401184715276290","durinwinter","2024-05-08T03:13:00.3400000+08:00","how PLC data is published and subscribed.  Now, it's very important to understand that the technology leveraged in each of these ""busses"" matters. technologies that can harness both pub/sub and query/response models are necessary in both the orchestration control bus as well as the analytics bus.  This allows us to ask the question of which ""state"" something is in.","",""
"1027653517386727548","jorgenk1000","2024-05-08T04:31:49.7840000+08:00","Thanks for the illustrations and explanation. I‚Äôm still confused but definitely at a higher level üòÇ jokes aside though, I still struggle to see where the UNS fits in. Or - is this a UNS-less architecture and another way of solving digital transformation?","",""
"721401184715276290","durinwinter","2024-05-08T04:40:54.9170000+08:00","depends on how you see UNS. - the architecture does not assume a single broker but neither does UNS. as it relates to ""converting all sources to pub/sub and having a specific hierarchy"" it does. Basically I am representing that with the star. If you look at most implementations of UNS, you will notice that the _blah indicates a schema for a specific payload. that is what I am using here. so a full namespace would be something like","",""
"721401184715276290","durinwinter","2024-05-08T04:41:43.0620000+08:00","uns/v1/enterprise/site/area/line/workcell/originid/_dcf_bronze","",""
"721401184715276290","durinwinter","2024-05-08T04:42:16.5380000+08:00","and then inside the payload for _dcf_bronze you get a specific json payload that can be parsed using that schema.","",""
"1027653517386727548","jorgenk1000","2024-05-08T04:45:09.4720000+08:00","Got it, thanks for elaborating! What I‚Äôm struggling to understand is, if you organize all your data on the edge, structure them, contextualize and normalize, why do you need the three layers in the medallion architecture? Is it just a better way to separate business side from operations side? And why would you want to do that if you want to be able to see your whole enterprise as a whole?","",""
"1027653517386727548","jorgenk1000","2024-05-08T04:45:34.2980000+08:00","What‚Äôs the added value?","",""
"721401184715276290","durinwinter","2024-05-08T04:48:37.6250000+08:00","great question. simply put, latency domains. bronze silver and gold are different if the end customer is a PLC vs. if its a report for a user.  on the Deterministic Control Bus, Gold outputs are geared towards a output specific to a PLC, while in the Analytics Data Bus, gold outputs are specific to optimal queries for soemthing like PowerBI.","",""
"721401184715276290","durinwinter","2024-05-08T04:50:38.4350000+08:00","this is to cover all the use cases I see manufacturing companies trying to attempt. also each bus has specific architectural principals associated with it. You don't necessarily want the historian grabbing stuff directly off of the deterministic control bus, nor do you want to send all deterministic control stuff back through the same broker handling long term time series data","",""
"721401184715276290","durinwinter","2024-05-08T04:51:21.9070000+08:00","now does this make it possible for all subscribers to access all topics from all areas? without access controls, yes. But I assume there are access controls here.","",""
"721401184715276290","durinwinter","2024-05-08T04:53:10.9140000+08:00","the added value is enabling the future control system, each individual application in a microservices cluster can subscribe to each individual bus. Also if your control loops exit the PLC because you are using a machine vision camera to collect the data and an edge computer to process it. You now need a common bus to tie them together, and in my experience if thats the same bus batching data in and out of the historian, you run into a conflict of qos demands and performance concerns for the control loop","",""
"721401184715276290","durinwinter","2024-05-08T04:54:09.7840000+08:00","the central difference between this and most reference architectures I have seen is the acknowledgement that there are different types of latency domains, but you can still implement one semantical structure across them.","","üëç (1)"
"1027653517386727548","jorgenk1000","2024-05-08T04:55:27.0370000+08:00","Great insights and I really appreciate the added information. Now I have a much clearer understanding of the concept and a better basis to discuss with the platform team -
Thanks again!","",""
"721401184715276290","durinwinter","2024-05-08T04:58:41.1480000+08:00","no problem!","",""
"1214242167640424619","zack.scriven","2024-05-23T04:31:22.7790000+08:00","don't be shy!","https://cdn.discordapp.com/attachments/815945777452941313/1242937877642477609/Zack_Meme-2.png?ex=68dee11a&is=68dd8f9a&hm=6f8ca709f21f19bbceb2f751eb7593c0834bc8ac9f5e788d5c39813187b56bd7&","ilaugh (2),üëç (1)"
"1063829764164563026","mariano.beracochea","2024-05-24T01:09:28.8530000+08:00","Im looking for a place to study ""semantic architecture"" to plan a UNS implementation. I already plan on use the enterprise/site/area/line/cell structure, but dont know what else could add value. 
I looked online and all that i get about semantic data model is about cloud and web configuration for search engines. Does the book ""Semantic modeling for data avoiding pitfalls and breaking delemmans"" have the answers i look for or it is not applicable to industrial UNS?
If someone have any youtube channel or books i would appretiate it","",""
"801561312861618236","jon.forbord","2024-05-24T04:20:59.8050000+08:00","Semantics is just something with meaning. A semantic hierarchy is a way of organizing information in levels, for instance going from general to specific. Such that something‚Äôs place in the hierarchy tells us something about its purpose or meaning. The anti to this is organizing the hierarchy somewhat randomly. It‚Äôs really saying nothing other than organize you hierarchy such that users can imply meaning from some thing‚Äôs place in the hierarchy. 

Semantic architecture I‚Äôm not sure makes much sense? (Just asked ChatGPT to explain semantic architecture, and it kind of described a UNS where data is organized in a functional hierarchy across business applications, instead of within each business application).","",""
"1243271145390866623","safasaib_10899","2024-05-25T17:42:07.4680000+08:00","could anyone give me an example of how to build an UNS?","",""
"1214242167640424619","zack.scriven","2024-05-27T02:25:31.7910000+08:00","Here is the UNS Genology https://youtu.be/1WXPsGAv298","",""
"1214242167640424619","zack.scriven","2024-05-27T02:26:00.6520000+08:00","If you want to learn how to build a UNS. you should consider joining our 16-Week Mastermind Accelerator Program. It's starting in 10 days.","",""
"696530862413578301","martinc9133","2024-06-07T19:22:23.8100000+08:00","couple months ago following hannover messe there was a discussion about the reference architectures amazon and some others shared but dont think we ever talked about this one","https://cdn.discordapp.com/attachments/815945777452941313/1248597927538987098/image.png?ex=68df092f&is=68ddb7af&hm=2dfb7a606977984b9efda881d2286ee5cc25f8ecc0f4e432ef1ef079b7f1ad33&","üëç (1)"
"817835202746253344","IIoT#4707","2024-06-07T19:22:24.3500000+08:00","GG @MartinC, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2024-06-08T17:34:15.3490000+08:00","‚ÄúSELL MOAR CLOUD‚Äù","","ü•≤ (1)"
"795725198980677734","diederik9434","2024-06-08T23:19:58.7950000+08:00","i like the ""take action (digital feedback loop)"" hahaha just fix it by yourself","",""
"528668306690015284","vatsalshah","2024-06-12T02:29:16.1180000+08:00","You can actually try and deploy this one now üôÇ 
It is end-to-end from Industrial connectivity (Litmus), Native integration (Litmus + EventGrid), Standardization of data/relationships (Azure Pipeline + lakehouse), storage (Fabric Lakehouse / Databrick) and end apps (14 platforms or ready apps as far as remember)","",""
"1081971075971289148","jose.granero","2024-06-12T02:32:23.6590000+08:00","https://n3uron.com/connecting-industrial-assets-azure-event-grid-n3uron-mqtt-client/","","üíØ (1)"
"789507385194053632","thooor9411","2024-06-19T18:39:11.0150000+08:00","Hello, i wonder where can i find some different architectures of UNS and how different products fit in different cases? so like different data ops or historians or different brokers for an exemple. maybe there is sone studies made but i cant find anything o nthe internet.","",""
"898217314741280828","hobbes1069","2024-06-20T01:26:16.5050000+08:00","More than a bit too broad of a question. There's a million ways to do it, some good, some bad, and a whole lot in between. One of the key advantages to a UNS is swapping out pieces is easier than with traditional point-to-point integrations.

Start with what you know, or what you have, or what's free. Then learn and iterate. That will answer a lot of questions and if not, you'll be able to ask much more specific questions here. üôÇ","",""
"898217314741280828","hobbes1069","2024-06-20T01:49:22.2700000+08:00","@js, I decided to experiment with running Highbyte as an Azure Container Instance (ACI). I can tell you that if you're doing much you'll want to max the vCPU count (which is 4) but so far I've gotten away with only 4GB of memory. 

Here I'm running a modified version of this simulation:
https://guide.highbyte.com/kb/performance/modeling-opc-ua-data/

I'm my case I'm using Kepware Server running the simulations (Kepware didn't like some of the simulations so I only got up to 81,920 tags). Highbyte is running in an ACI with 4 vCPUs and 4GB memory. Mosquitto is running in a separate ACI with 2 vCPUs and 3GB memory.

The Highbyte ACI is pretty much maxed out. I'm starting to see slight latency when navigating the UI. Mosquitto is barely breathing hard at about 10% of one CPU (it's not multithreaded).","",""
"898217314741280828","hobbes1069","2024-06-20T01:49:28.8330000+08:00","Highbyte ACI","https://cdn.discordapp.com/attachments/815945777452941313/1253043995026915398/image.png?ex=68df63e8&is=68de1268&hm=92b4134d7ce42483bbbd7a94c544bf9383edfa988dffb7b4ec42c97f30fe7e25&",""
"898217314741280828","hobbes1069","2024-06-20T01:49:55.2210000+08:00","Mosquitto ACI:","https://cdn.discordapp.com/attachments/815945777452941313/1253044105462812672/image.png?ex=68df6403&is=68de1283&hm=cb435dc69acfda6132bbf0d019eeed3477201561b53f18a47fc64db01204f31b&",""
"898217314741280828","hobbes1069","2024-06-20T01:50:35.6370000+08:00","Currently I'm not running TLS for Mosquitto so I'm going to re-run the test with TLS on in the near future.","",""
"756543760028139720","aronsemle","2024-06-20T22:57:14.2450000+08:00","This is cool! I'll be interested to see how 4.0 performs, as we've sped up instance reads quite a bit as well as other performance gains. You'll be able to use the same test project. I'd be curious if it's our flows or connection threads that are consuming more CPU. As a slight over simplification, MQTT is a packet router, so I'm not suprised that it consumes very little resource. It doesn't need to touch the bits, and just forwards them from one socket to the next.","",""
"898217314741280828","hobbes1069","2024-06-20T23:23:22.2740000+08:00","I'll give an update here after re-testing with TLS but yeah, depending on your use case HB seems to run well in an ACI.","",""
"898217314741280828","hobbes1069","2024-06-21T03:31:22.1720000+08:00","Testing is concluding now üôÇ Mosquitto utilization jumped to about 30% of a vCPU but I couldn't tell any difference on the HB side.","",""
"756543760028139720","aronsemle","2024-06-21T22:40:47.3560000+08:00","Ha! Decryption is a lot of work","",""
"1214242167640424619","zack.scriven","2024-06-22T12:35:36.5750000+08:00","Dell NativeEdge reference architecture","https://cdn.discordapp.com/attachments/815945777452941313/1253931374092619837/IMG_4010.png?ex=68df5298&is=68de0118&hm=36202bf1bc6188bb81839e86a15502a82d6ad66fb1c09c208ef776bcd8f32397&",""
"867075936054149191","rickbullotta","2024-06-22T20:20:32.4560000+08:00","Indistinguishable from any of the other 934 edge ""architectures""...","",""
"1214242167640424619","zack.scriven","2024-06-22T21:58:14.4050000+08:00","They have a zero touch provisioning system. Drop ship the unit, plug it in, and provision it. Architectures In 934 A.D. this wasn‚Äôt possible.","","üòÇ (1)"
"867075936054149191","rickbullotta","2024-06-22T22:07:12.9850000+08:00","That‚Äôs because X.509 certificates were made of stone then.","",""
"528668306690015284","vatsalshah","2024-06-22T22:33:05.7440000+08:00","Yepp Dell Native Edge is a pretty solid orchestration system. We have been working with them for while - every release it is improving a bunch. 

1. They made factory Root of Trust seamless. Not easy for any other SW only products
2. Drop shipping and auto loading works. Marketplaces of various apps doesn‚Äôt work very well for Hw vendors so Dell took validated design approach
Every single app preloaded is well validated by Dell and Vendors together 

https://infohub.delltechnologies.com/en-us/t/dell-technologies-validated-design-for-manufacturing-edge-with-litmus-techbook/","","üî• (1)"
"1214242167640424619","zack.scriven","2024-06-22T23:13:46.3920000+08:00","Thank you for sharing","",""
"830193224504705035","marc.jaeckle","2024-06-28T14:12:13.3500000+08:00","and the Dell EMC Edge Gateway 5200 starts at just 3000 Euros (without value added tax) and doesn't even bring a dedicated Lights Out Management port. Yay","","üò≥ (1)"
"568913935147728896","zeratall","2024-06-29T03:44:16.4730000+08:00","Wait seriously‚Ä¶..wow","",""
"867075936054149191","rickbullotta","2024-06-29T09:06:29.8250000+08:00","Yes but it comes with a free mouse pad.","","ü§£ (1)"
"898217314741280828","hobbes1069","2024-06-29T09:18:09.1000000+08:00","Scratch that off my list... I'll keep going on my ""roll your own"" IAC solution.","",""
"568913935147728896","zeratall","2024-06-29T09:18:59.6600000+08:00","hahah yeah I was just surprised it didn't come with a management port, even my PowerEdge R630 that I bought off ebay has enterprise iDRAC enabled lol","",""
"898217314741280828","hobbes1069","2024-06-29T11:26:42.9570000+08:00","I only need port 22 üôÇ","","ü§£ (1)"
"830193224504705035","marc.jaeckle","2024-07-02T16:33:16.8730000+08:00","Well, you need a LOM + PXE Boot  (and its more secure friends) if you want to provision everything remotely via IaC/GitOps including the operating system. We follow a immutable infrastructure approach to avoid typical package management issues / drift between nodes. Therefore we always provision complete images to make sure all hardware nodes are identical. If you are using an immutable, container optimized Linux like Flatcar Linux, this is a great combination. When it comes to rugged edge devices, unluckily there are not many options featuring a LOM. Supermicro offers some options for example.","",""
"1063829764164563026","mariano.beracochea","2024-07-02T22:26:04.3410000+08:00","Im building a UNS, watched the videos of functional namespace, would detail information of every sensor of the machine be usefull of the UNS? It would be a definitional namespace, wouldnt update. Im thinking of something like 
temperature_sensor/value=value
temperature_sensor/location=cabinet number/PLC number/module/contact
temperature_sensor/model=model information
temperature_sensor/calibration=date of last calibration
temperature_sensor/seller=last seller
I think this information could be valuable for future interventions, knowing where sensors are connected is useful to troubleshoot. 
The issue i see with this is that the UNS grow on depth and complexity","",""
"867075936054149191","rickbullotta","2024-07-02T22:55:35.9330000+08:00","This is why I really want the UNS (and MQTT) to support durable metadata on topics rather than causing ""topic bloat"" as you describe.  And if you could query/subscribe based on that metadata, it would be super powerful.","","üëç (1)"
"161671622166577153","aphexddb","2024-07-02T23:09:02.4440000+08:00","This is my inner unix philosophy speaking, perhaps a MQTT broker should not be a metadata store since MQTT was designed to be lightweight and efficient for IoT. Kind of the beauty of running Mosquitto, etc. is they do one thing well. Some sort of transparent MQTT proxy that does metadata / digital twin really well in addition to a broker might solve for that. e.g. MING + metadata / digitial twin thing","",""
"1248229600853758073","sptha_27377","2024-07-02T23:15:07.4740000+08:00","Can't we use the retain flag to make some information stay 'forever' in the broker?","",""
"817835202746253344","IIoT#4707","2024-07-02T23:15:07.7400000+08:00","GG @Herbert, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2024-07-02T23:19:20.0520000+08:00","Perhaps not the MQT broker, but the IOT platform surrounding it should.","",""
"1203453953115693159","stephenbryant_89711","2024-07-02T23:23:50.3300000+08:00","I'd absolutely be up for this!

I was looking at exactly this for a tech demo to transport MQTT over TSN.  (Yes, I know MQTT isn't real-time.)
How about this?
- Topic user props (static stuff):
  - Content-Type
  - Unit (for numeric payloads)
  - Description
- Payload user props:
  - Timestamp

That leaves only the scalar value inside the payload - so it's not even a JSON object.

You could also put a quantity type in the topic props, such as time, length, luminous intensity, mass etc.  Now you can select all the topics containing a length.  Except you can't, as MQTT doesn't support that... yet?

I'd _really_ like to see some more precise definition in UNS about this sort of thing.  At the moment UNS seems to me to be primarily about the topic structure.  (Or did I miss something?)","",""
"867075936054149191","rickbullotta","2024-07-02T23:27:22.5740000+08:00","And it should be possible to use metadata in queries and subscriptions","",""
"817835202746253344","IIoT#4707","2024-07-02T23:27:22.8010000+08:00","GG @RickBullotta, you just advanced to level 36!","",""
"1203453953115693159","stephenbryant_89711","2024-07-02T23:42:18.9700000+08:00","A few months ago, Walker was talking about getting queries (among other things) added to the MQTT spec.  Does anybody know if there was any movement on that?

Thinking out loud: it wouldn't be a stretch to adapt the XPath query language to query topics and their props, @RickBullotta.","",""
"867075936054149191","rickbullotta","2024-07-04T01:10:57.4640000+08:00","It's not going to happen in any reasonable timeframe, if ever.","",""
"867075936054149191","rickbullotta","2024-07-04T01:11:32.3510000+08:00","The key is to no longer focus on MQTT brokers as the center of the UNS - what we need is robust and full featured IIoT platforms that can use MQTT as part of the stack.","","üíØ (1),üëç (1)"
"801561312861618236","jon.forbord","2024-07-04T01:51:46.2400000+08:00","This is also my position on how to ¬´do UNS¬ª with current technology, and also where I see an important role for the IIoT platform (ie, to bridge the gap between what mqtt does well and what it doesnt).","",""
"801561312861618236","jon.forbord","2024-07-04T01:53:36.9460000+08:00","Eg do you need queryable Namespace, let the IIoT platform expose the API to query the MQTT Namespace..","",""
"801561312861618236","jon.forbord","2024-07-04T01:54:47.6910000+08:00","I prefer publishing metadata as json on a separate topic. Parsing some jsons for metadata isnt a big deal as they dont update very often.","",""
"1203453953115693159","stephenbryant_89711","2024-07-04T03:25:59.2590000+08:00","That seems like a very pragmatic fallback solution.  I'd be fine with that for topic metadata.  It would be nice if we could have formal (or at least centralised) agreement on how to name such topics.

Where would you put the timestamp though?  In the primary payload (JSON object?) or in a parallel topic?","",""
"801561312861618236","jon.forbord","2024-07-04T03:28:58.1680000+08:00","Timestamp value and quality in one payload. Json.","","üëç (1)"
"801561312861618236","jon.forbord","2024-07-04T03:29:34.0170000+08:00","Otherwise, how can you know you have the right timestamp foe the right value.. ?","",""
"1203453953115693159","stephenbryant_89711","2024-07-04T03:31:20.6360000+08:00","Yeah, now that I've turned my brain back on, that wouldn't be good.  No transactions in MQTT, so no guarantee the TS matches the value.","","üëç (1),üòÇ (1)"
"1073312001788477471","sparkylarks","2024-07-04T03:41:05.1230000+08:00","As long as it maintains the focus on the Technology and not the product.
and my Test case here is, changing my IoT platform should be as easy as changing any node in my Broker based eco system, or changing the broker itself.
It is my big fear having an IIoT platform as by hub instead of a Broker.","","‚ûï (1)"
"867075936054149191","rickbullotta","2024-07-04T06:01:01.6610000+08:00","Which actually isn‚Äôt that easy.","",""
"1154812895457185812","rutger_18900","2024-07-04T14:08:16.3920000+08:00","Am i witnessing the reinvention of opc ua here? üòà","",""
"801561312861618236","jon.forbord","2024-07-04T14:53:45.4270000+08:00","Ooooor Sparkplug?","","üëç (1)"
"830193224504705035","marc.jaeckle","2024-07-04T16:37:28.4950000+08:00","Some tools like Litmus Edge just make it a lot easier to make the meta data part of the data messages. Their ""Digital Twin"" models are built to contain both. You can still do something else but you have to put more effort into it.","",""
"1203453953115693159","stephenbryant_89711","2024-07-04T17:07:03.3290000+08:00","I like that SparkPlugB formally addresses how to identify participants, and the concept of a primary host application seems like an effective strategy to mitigate against data loss.

However, having to actively ask who the participants are rubs me the wrong way.  I'd rather have a retained message for each participant which is altered or even removed when they disconnect.  In my head, that seems closer to edge driven and report by exception.

The lack of direct UNS integration has been mentioned many times, but I've also noted how a lot or people struggle with non human readable formats.  I know protobuf is much more compact, but it would be more consumer friendly to start with JSON and flip a config switch to use a binary format once we see a setup is working.  It's the same reason why humans like ISO8601 over a plain number for a timestamp.

These things would provide great practical usefulness, but appear to be resisted by the standardisation body.  It's not clear to me why that is.  The result is exactly this sort of discussion.","",""
"801561312861618236","jon.forbord","2024-07-04T17:35:12.8100000+08:00","Dont use Sparkplug unless you use applications that support it out of the box. that being said, a lot take inspiration from Sparkplug to make their own mqtt convention. Thats what I mean by that. 

There are reasons for the mechanisms and it has to do with statefulness, ie the consumer being sure that it has an accurate picture of the current state of all the Edge nodes.","","üëç (1)"
"801561312861618236","jon.forbord","2024-07-04T17:36:03.6550000+08:00","I see SpB as tangent to UNS. That doesnt mean it cant be used, but it is tangent to UNS much how OPC UA is too.","","üíØ (1),üëç (1)"
"801561312861618236","jon.forbord","2024-07-04T17:36:31.1150000+08:00","You have to convert it at some point or another.","",""
"937934908666576926","ninaad09878","2024-07-08T20:48:00.8440000+08:00","Hi can you share the recording?","",""
"1139269147126153216","suran23.","2024-07-08T22:56:56.7560000+08:00","@Ninaad Hi, here's the recording: https://litmus.io/litmus-uns/webinar/","",""
"1139269147126153216","suran23.","2024-07-08T22:57:41.4280000+08:00","You might find this useful as well: https://litmus.io/uns-dos-and-donts/","",""
"1139269147126153216","suran23.","2024-07-08T22:58:09.3090000+08:00","Always happy to huddle and learn more and share our own findings as well.","",""
"1057737574287945899","xamp4248","2024-08-05T20:19:04.8090000+08:00","Hi, do you have any mqtt broker price comparison chart?. How much it will cost for  5 million tags.","",""
"801561312861618236","jon.forbord","2024-08-06T03:42:07.4340000+08:00","Mqtt brokers are rarely priced per tag. They‚Äôre priced on clients, or message throughput, as well as plugins and additional features. 

There are open source brokers that can handle quite a lot of messages and clients.","",""
"1160083906004004924","bachan1868_11442","2024-08-06T06:21:07.5150000+08:00","Thanks I was thinking about asking what the sticker shock might be.","",""
"1063829764164563026","mariano.beracochea","2024-08-06T19:28:41.0110000+08:00","HiveMQ quote for amount of tags","","ü§Ø (3)"
"812295088348200960","patanj2","2024-08-07T07:41:12.5390000+08:00","How would an mqtt broker even know whata ‚Äútag‚Äù is","",""
"1214242167640424619","zack.scriven","2024-08-07T08:01:13.2390000+08:00","like topics?","",""
"1214242167640424619","zack.scriven","2024-08-07T08:01:38.4720000+08:00","great question.","",""
"1214242167640424619","zack.scriven","2024-08-07T08:02:02.6270000+08:00","I think this brings up a bigger debate on the concept of own vs. rent. Perpetual license vs SaaS. Thoughts?","",""
"1214242167640424619","zack.scriven","2024-08-07T08:02:23.6990000+08:00","@Walker Reynolds would say you want to own as much of the core infrastructure as possible.","",""
"1057737574287945899","xamp4248","2024-08-07T14:18:09.3200000+08:00","Do MQTT brokers provide perpetual licenses? One of my friends said he received quotes from reputable brokers, ranging from $200,500 to $400,500 per year. He quoted for 5 million tags.","","ü§Ø (1)"
"898217314741280828","hobbes1069","2024-08-07T19:38:45.1800000+08:00","Here we're using topics and tags interchangeably since topics brought in to Ignition would be treated as tags.","",""
"812295088348200960","patanj2","2024-08-07T19:43:36.7940000+08:00","Recommend getting quotes from other vendors.","","üíØ (1)"
"1057737574287945899","xamp4248","2024-08-07T19:46:39.6050000+08:00","HineMQ and EMqX were he enquired. Any other recommended one?","",""
"898217314741280828","hobbes1069","2024-08-07T19:47:02.3950000+08:00","Cedalo (Mosquitto Pro)","",""
"528668306690015284","vatsalshah","2024-08-08T04:19:28.8380000+08:00","DM me - don't pay that 200k - 400k / year. That's insane. 
Depending on your usecase, Litmus MQTT/UNS might be a good fit.","","üíØ (1),üëç (1)"
"867075936054149191","rickbullotta","2024-08-08T07:12:44.0030000+08:00","5 million tags?  That seems a bit ridiculous, for a number of reasons.  What's the use case?","",""
"1073312001788477471","sparkylarks","2024-08-08T13:54:39.1770000+08:00","And summarize and share what you find please.","",""
"1057737574287945899","xamp4248","2024-08-08T18:22:57.4900000+08:00","What he is trying to do is share raw data from all PLCs to the UNS. He is working in a vertical metal industry with many streams and almost 800 PLCs. He might need to transfer all this data through the broker.","",""
"1073312001788477471","sparkylarks","2024-08-08T18:37:55.1680000+08:00","was that for on prem or cloud?

my understanding was pricing is often dependant on connections more so that topics, so maybe the same amount of topics with less connections
On cloud the cost is per message so a million topics updating once a day is 80c a day( ~$300)
if those million messages update every second the cost if $2880 a day ( ~ 1 million)

Not sure if my maths is correct.","",""
"1057737574287945899","xamp4248","2024-08-08T18:39:21.7350000+08:00","On prem","",""
"1203453953115693159","stephenbryant_89711","2024-08-08T20:30:19.4170000+08:00","Hey everybody,
A colleague was asking if there was any publicly available documentation on how Amazon and Tesla use MQTT+UNS in their production architecture (including digital supply chain).  They get mentioned often, but it would be nice to have something written to use as a reference.

I Googled, and found stuff about connecting cars via MQTT, and AWS products - neither of which are quite what I'm after.

Does anyone here have any tips for me?  Or better still, links?
Thanks...","",""
"801561312861618236","jon.forbord","2024-08-09T03:37:01.5590000+08:00","There‚Äôs plenty of decent open source options to get you started. Two of them at least support clustering, RabbitMq and VerneMQ. Don‚Äôt pay for a Ferrari if you need a Honda. 

If you use SpB the number of topics and messages will also be much lower and may or may not make the need for a high performance broker like HiveMQ unnecessary.","",""
"867075936054149191","rickbullotta","2024-08-12T06:45:24.6290000+08:00","Still, that seems very high even for 800 PLCs.  That's over 6000 data points per PLC.  I would be very surprised if they're all worth putting in the UNS.  Does he want history data for those streams also?","","üíØ (1)"
"1057737574287945899","xamp4248","2024-08-12T12:18:04.9310000+08:00","Yes, they want to historize all tags. This gives them the option to unify the data within the historian for all types of analytics.","",""
"1203453953115693159","stephenbryant_89711","2024-08-12T15:17:16.2840000+08:00","Nobody knows?  @Zack Scriven? @Vaughn Turner?  Do you guys have any references stashed away somewhere perhaps?","",""
"867075936054149191","rickbullotta","2024-08-12T20:59:11.0820000+08:00","I highly doubt that all 6000 data points on each PLC are of value, but if they are, then yes, it's going to be very expensive.  They'll either spend money on packaged software that is easy to administer and ""just works"" or on lots of resources to maintain a bunch of best of breed or open source offerings.  And they'll still need compute and storage to make it all work.  Lastly, administering systems at that scale is VERY VERY difficult, but proper cybersecurity and access control hygiene is essential, even if it is difficult.  Simple things like browsing the available namespace require a different type of architecture when the ""law of large numbers"" comes into play.  Everything from the technical architecture to the user experience needs to be designed with this in mind IN ADVANCE.  Also, when historizing that much data, you need to consider how that data will be used/queried, how long it will need to be retained, and so on. A very common mistake I see is when people size their data storage for ingest rates and fail to consider that at some point when you hit the maximum retention period, you will be DELETING exactly as much data as you are INGESTING each day.  And then they wonder why performance suddenly deterioriates.  A strategy involving a blend of hot/warm/cold storage is essential.  Lastly, you want to design for performance, availability, and resiliency also.  Having a single broker or a single historical data store can be an antipattern in that case.","","üëç (7)"
"1057737574287945899","xamp4248","2024-08-13T01:46:24.8290000+08:00","Thanks for your insights; I completely agree with your points. The system they are  dealing with is a large, vertically integrated manufacturing setup, with each upstream process acting as the customer for the downstream. Although SAP is the common ERP across the system, and  dealing with legacy PLCs.

My suggestion was to implement a dedicated UNS for each stream to ensure that only the necessary data is managed and utilized effectively. However, I agree that an enterprise historian is essential for overarching data management.

The challenge arises from the perspective of the leadership, particularly since the boss comes from an Oil & Gas background with experience in using OSI PI historian to handle massive datasets across various fields. From his viewpoint, introducing additional resources like IoT gateways to convert data from legacy PLCs and implementing a UNS seems redundant and adds unnecessary expense.","",""
"867075936054149191","rickbullotta","2024-08-13T04:47:31.4570000+08:00","Even with OSI PI, there were ""gateways' to convert data from legacy PLCs.  Every single time.","","üíØ (1)"
"1057737574287945899","xamp4248","2024-08-13T16:19:34.5310000+08:00","All are controllogix  PLCs. So FTView gateway required.","",""
"230441548653789184","r.pop","2024-08-13T21:49:57.5700000+08:00","Tesla has a rather strict NDA, possibly why theres not much of that floating around.","",""
"1203453953115693159","stephenbryant_89711","2024-08-13T21:52:11.4230000+08:00","That's also a valid answer.  I half expected that would be the case, but was hopeful anyway.  Still, thanks.","",""
"230441548653789184","r.pop","2024-08-13T21:55:27.4230000+08:00","If you're looking for something extremely generic that companies like tesla may use, feel free to use this -","https://cdn.discordapp.com/attachments/815945777452941313/1272916433227087882/image.png?ex=68df2d0f&is=68dddb8f&hm=fa973ac454e782f780867cb8f2e69748020605877a7110c00909be924c8c1edc&",""
"1203453953115693159","stephenbryant_89711","2024-08-13T22:05:18.2230000+08:00","That's good, thanks, and I shall use that as an example too.

We were after written ""proof"" that these very successful companies are actually using that open architecture, as people like to ask how we can be sure they actually do that.  The answer ""Walker said so"" doesn't pull much weight with them.","",""
"817835202746253344","IIoT#4707","2024-08-13T22:05:18.4480000+08:00","GG @Stephen Bryant, you just advanced to level 5!","",""
"230441548653789184","r.pop","2024-08-13T22:06:43.4900000+08:00","Yea, we get that question quite a bit. We have permission from a number of customers to share things privately, but can't publicly post or name them.","",""
"230441548653789184","r.pop","2024-08-13T22:07:50.1400000+08:00","Depending on the project/customer, you can find public case studies from AWS or HiveMQ - they may often times be ""fluffed"" but it will give executives the warm and fuzzies that large orgs are doing these things","",""
"1203453953115693159","stephenbryant_89711","2024-08-13T22:41:49.0560000+08:00","Ahhh... Hive was a good tip.  They have a bunch of case studies here: https://www.hivemq.com/case-studies/","","üëç (2)"
"1057737574287945899","xamp4248","2024-08-14T03:31:33.8470000+08:00","Which OPC UA gateway would be most effective for connecting 800 ControlLogix PLCs simultaneously to publish data to a Unified Namespace (UNS)? Each PLC has around 2,500 tags. I believe using an OPC UA server with Ignition might be the best approach for implementing a large-scale UNS architecture, but I'd appreciate any insights or recommendations","",""
"230441548653789184","r.pop","2024-08-14T03:49:49.4580000+08:00","How much data and how frequent are they publishing?","",""
"1273118314612264991","wlee_78150","2024-08-14T17:49:22.8210000+08:00","reading few articles regarding UNS, it seems to me that the Purdue Model is no longer relevant.. Am I correct?","",""
"1073312001788477471","sparkylarks","2024-08-14T19:09:46.8870000+08:00","I think it is very close to true, and I have claimed similar, but I still don't like to say the Purdue Model is no longer relevant.
It certainly is no longer the foundational concept to our architecture that it was. And especially the idea of the 3.5 DMZ as the epicenter of security is not the best approach for modern architectures.

It was coming under a lot of stress regardless of the UNS between Edge computing, IT/OT convergence and even Digital Thread based architectures that went from the Edge to the Cloud. Was adding Cloud the Jumping the Shark moment?

But we still need some way to differentiate between different groups of nodes in the eco system. IT might be defining the QoS for he network traffic between ""Level 1 "" devices. So I still group my nodes as Level 1 to 4 typically, even if they are in an UNS architecture.","",""
"1073312001788477471","sparkylarks","2024-08-14T19:12:22.0920000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1273237778884329502/Screenshot_2024-08-14_121122.png?ex=68df06d6&is=68ddb556&hm=2a02b885194c3d1605f58796923649ecf7f1aeac5bcf32b1863b7e17ba555916&","üëç (1)"
"795178288330440704","youri.regnaud","2024-08-14T19:31:57.6670000+08:00","I often use this slide to explain the move from Purdue Model to UNS","https://cdn.discordapp.com/attachments/815945777452941313/1273242709364052031/image.png?ex=68df0b6d&is=68ddb9ed&hm=d76b197d9ca0e70129cf6c7ff1b38a782044a83959a87802862828f433d05a74&","üëç (4),‚ù§Ô∏è (1)"
"1044299684803530832","willemrs","2024-08-15T04:21:20.0720000+08:00","I have a question in reference to this.  I think i have a pretty good understanding of how to get to the middle image from the far left.  Were doing this now with building out a UNS, connecting different levels and performing data operations however I wonder what the approach is to make the jump to the far right?  This essentially means cutting links that have been in use for potentially a long time...    How are folks making the argument to do this across an organization?  

We have a POC going that would put us right in the middle image however were finding that working within the existing infrastructure is difficult and at times hard to move things forward.  An example would be interfacing with an old SQL based MS Access front end MES system.  Were taking basic functions over that were previously done manually through Access and performing them automatically in our dataOps platform however its slow going.  Maybe we need to get better at showing the benefits at each step?  Interested to hear if others are doing it.","",""
"1273118314612264991","wlee_78150","2024-08-15T07:00:08.6540000+08:00","that's interesting. If you still group the nodes as Level 1 to 4, then how did you address the security part which is inherent in the Purdue model? I'm trying to understand this UNS. From UNS model, the nodes in level 2 can push the data directly to any level that has lower security profile.","",""
"795178288330440704","youri.regnaud","2024-08-15T10:32:56.8830000+08:00","The view on the right is that any application can communicate with another by connecting to the infrastructure. This architecture requires a complete Even Driven Architecture approach, complementary to UNS. In this case, MQTT can't be the only protocol, because it's difficult to use it to integrate transactions. A solution like Solace is a good example of a broker that supports multiple protocols, including MQTT.  NATS is also a good option for example.","",""
"1073312001788477471","sparkylarks","2024-08-15T16:20:43.8700000+08:00","When I say group the nodes, it might only be grouping them in my mind. I may have rules about connecting Level 1 devices together.

e.g. in my UNS specifications communication between Level 1 Devices is not allowed for control , but is mandatory between Level 3 Nodes.

After  concept/Model architecture , we will need to look at network segmentation and create VLANS and define zones and routes, 

Essentially I am taking the bits I find useful, and leaving the rest, but I would not claim that my architectures are Purdue complaint.

I do have Clients where the Broker is in the  DMZ and if they want to push data from a Level 2 node to a level 4 node, it goes through the DMZ. I had another client that had a ""Plant"" broker in the OT zone and Level 2 to Level 3 nodes would communicate with that, and it was bridged to an Enterprise Broker in Level 4.

 and I don't have the words necessary to convey the above paragraph without the concept of Purdue Levels, which I think was my point.","",""
"830193224504705035","marc.jaeckle","2024-08-23T20:25:52.5300000+08:00","Depending on what requirements you have for transactions, you might be able to use MQTT Manual Acknowledgements. Manual acknowledgements allow you to make sure that a message has been persisted before you send the acknowledgement to the MQTT broker. This way you can guarantee that every message gets persisted. It just doesn‚Äôt work if you want to store data in batches because you can‚Äôt keep open that many acknowledgements. But for storing individual, transactional messages it works fine. If you need end to end acknowledgements you would have to implement it on the application level though.","",""
"817835202746253344","IIoT#4707","2024-08-23T20:25:52.8210000+08:00","GG @Marc J√§ckle, you just advanced to level 12!","",""
"83543342171815936","technicality","2024-08-31T00:03:04.3870000+08:00","zScaler has a great writeup of Purdue vs security zones: https://www.zscaler.com/resources/security-terms-glossary/what-is-purdue-model-ics-security","","üëç (1)"
"83543342171815936","technicality","2024-08-31T00:04:16.5100000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1279109445451911198/image.png?ex=68df4b40&is=68ddf9c0&hm=7feb0f2245b39aa142ebd847a0b4ee4db977f91fa6be3fb3404178596355cae7&","üíØ (2)"
"477355192375967747","kiwimalice","2024-09-02T06:04:48.6500000+08:00","Alas it does not, not at all really, 

it does an OK job at explaining the purdue levels, but it doesn't explain how you use Zoning and Sub-Zoning within and across the Purdue levels","",""
"83543342171815936","technicality","2024-09-02T15:11:55.0490000+08:00","I meant the lower section, mostly","",""
"817835202746253344","IIoT#4707","2024-09-02T15:11:55.3690000+08:00","GG @Bart Silvius, you just advanced to level 2!","",""
"1063829764164563026","mariano.beracochea","2024-09-02T21:00:16.9270000+08:00","Hello, I a use case where im looking to collect data from many systems of a plant and would like to get recomendations on how to do it
- I have many siemens PLCs (easy, node red or kepware will get data from them)
- A SCADA intouch
- A SCADA Factory Talk View
- A Somove system conected to PLCs Schneider
How could i deal with the SCADA systems? does they have an OPC server i could browse like the win CC?","","highbyte (1)"
"817835202746253344","IIoT#4707","2024-09-02T21:00:17.1590000+08:00","GG @Mariano B, you just advanced to level 10!","",""
"1073312001788477471","sparkylarks","2024-09-02T21:12:43.6740000+08:00","IT depends on the versions a bit and how old the SCADA are
You can certainly configure InTouch as an OPC server( What version are you looking at). I have done it quite a few times. Newer InTouch can publish directly to MQTT if your interested in that,.
If I recall correctly, you need to use Factory Talk Gateway to allow an OPC client connect to Factory talk applications, maybe FTOptix can do it natively

not a clue about the Somove, but is that not for configurein drives? Can you communicate directlyt o the PLC's with Kepware?","",""
"444415644801171467","markpitout","2024-09-03T03:04:14.0540000+08:00","Most devices setup with SoMove have Modbus/TCP. So you could use the same Node-RED or kepware approach as with the Siemens PLC's.
What SoMove system are you talking about?
And are the PLC's connected to that SoMove system also Schneider or from another brand?

My approach would be to have the PLC collect the data you want from the SoMove motor starters and/or drives, and then have kepware (or something similar) fetch the data from the PLC. With this approach you can combine the data from the motor control device, with process control data from your PLC code, into a single UDT for the motor object.","",""
"230441548653789184","r.pop","2024-09-06T06:49:30.0470000+08:00","Highbyte","","üíØ (2)"
"1063829764164563026","mariano.beracochea","2024-09-11T02:16:28.5240000+08:00","How would this be done?","",""
"230441548653789184","r.pop","2024-09-11T10:21:48.5350000+08:00","I‚Äôll let @aronsemle give you the specifics","",""
"867075936054149191","rickbullotta","2024-09-11T20:41:00.9430000+08:00","‚ÄúAny sufficiently advanced technology is indistinguishable from magic‚Ä¶‚Äù","","üíØ (2)"
"756543760028139720","aronsemle","2024-09-15T23:05:24.3330000+08:00","Hey Mariano, sorry just seeing this. And thank you @RemusPop! Mariano, feel free to send me a DM on discord and happy to help.","",""
"712090571556126871","bunchofbytes","2024-09-17T20:43:07.4320000+08:00","Hello Everyone! I got my first client! They have a FactoryTalk View SCADA system with FactoryTalk Historian. I am beginning to architect a UNS but was wondering what to do with the existing historian data. 

I am able to query the FactoryTalk Alarms and Events database with no issues but with the time series data, this seems to require additional mechanisms. I understand this could be a technical debt situation and I may need to ask the customer to buy some sort of driver from rockwell to allow SQL connectivity to the timeseries data.

I am wondering how best to leverage this data within the context of the UNS. Would it only be good for ad hoc queries later on or ML applications later? How do you guys typically handle historian data? Is it usually just a transactional transfer to a datalake or warehouse for analysis and let the events published to the UNS be real-time focus?

I am still learning everyday so i apologize if this has been covered before. I'm really looking forward to the 3-Day UNS event and maybe things will be more clear to me. My main focus is to help my client and not cause them to spend a lot of money without providing a clear path forward to get out of the existing technical debt.","",""
"867075936054149191","rickbullotta","2024-09-17T21:19:03.9160000+08:00","A typical MQTT-based UNS is actually awful for ""ad-hoc queries"" of anything - not good for querying metadata, current data, or historical data.","","üíØ (2),üëç (1)"
"712090571556126871","bunchofbytes","2024-09-17T21:25:32.1990000+08:00","Thank you Rick! That makes sense‚Ä¶ i feel like i may be thinking about this the wrong way. 

How are historians typically handled in UNS implementations?","",""
"817835202746253344","IIoT#4707","2024-09-17T21:25:33.4490000+08:00","GG @bunchofbytes, you just advanced to level 1!","",""
"1073312001788477471","sparkylarks","2024-09-17T21:32:32.4960000+08:00","I was looking at this with a client once.

They had a really great SCADA setup, identical on every machine in every plant and doing a lot of good work so the plan was

- Set up the FTView as an OPC -DA server
-Create a gateway to map the data from OPC to MQTT( kepware, node-red, Ignition, Litmus)
- Leave the existing link to the FT historian ( for now)
- New Devices can either
      - connect natively to the Broker
      - Connect directly to the Gateway, 
      - Connect directly to the FT View( not recommended but allowable by exception)

Most new L1 equipment would connect to the Gateway and FTview would consume it from there, 
Data and information from other L2 or L3/L4 systems would be Broker->Gateway->FTview

the goal we wanted was that any system that was looking for information from Level 1 devices , or SCADA would use FT view.
A new historian would be needed that could consume the MQTT data directly and the FT historian would be phased out over time.
We knew there would be a point in the future where the critical mass would require that we switch over

Any system that need historical data would, either, query the historian directly, or subscribe to the broker and keep it;s own local historical copy

Our Conclusion is doing a UNS with FTview is a pain.","",""
"1073312001788477471","sparkylarks","2024-09-17T21:33:43.6790000+08:00","excuse the crudeness of the drawing","https://cdn.discordapp.com/attachments/815945777452941313/1285594540325212242/PXL_20240917_133306725.jpg?ex=68df27f7&is=68ddd677&hm=473cbd3abd4549fcd2f8e8f58720fe4ae9f71080841e11d34d4f1660675857c3&","üëç (1)"
"712090571556126871","bunchofbytes","2024-09-17T21:36:31.1320000+08:00","Mark, thank you so much! This is really helpful. I appreciate the detail and the diagram! 

Did you go with canary for the new historian or would you recommend any other?","",""
"1073312001788477471","sparkylarks","2024-09-17T21:48:00.7220000+08:00","It was a project where I was brought in just to advise, and I do not know the final decision.
The Historians we discussed were Influx and Canary, and given the companies approach , i.e. they built a lot of their own Level 3 systems with a SQL backend, I guess that they went with Influx( or maybe TimeScale, the guys at UMH recommend that over Influx, and they do know their stuff).

That said, I come from the OT world and I can use SQL pretty well, and very rudimentary Influx, but I prefer an OT-Style Historian,
I have found Canary great, but the pricing has gone up a lot recently.

depending on scale, I would be thinking  can Ignition act as your Broker, Gateway and Historian?

But if someone here does know of a way to integrate a FTView historian into a UNS architecture that might be the way to go .
I suppose you could use a gateway for MQTT to OPC conversion. I think we just didn't like the idea of 
FTview-> Gateway->Broker->Gateway-> Historian","","üëç (1)"
"712090571556126871","bunchofbytes","2024-09-17T21:56:01.5680000+08:00","Thank you again! I am planning to use ignition to provide a poc, maybe this is the best way to go. I have used influxdb but will look into timescale as well.","",""
"401050128317808640","lopa0679","2024-09-17T23:02:18.4260000+08:00","If you were using InfluxDB as your historian and Ignition as your SCADA, would you recommend using the InfluxDB module in Ignition to both retrieve and put the data into InfluxDB, or would it be better to use a data modeling tool to put the data into the database and then query it in Ignition, either via the API or using the InfluxDB module?

I haven't tested the InfluxDB module yet (it's not available in the Maker Edition, and I haven't set up a standard version yet. Also, as far as I know, it's not officially supported for version 8.1).

What are your best practices with this architecture and the module?","",""
"795178288330440704","youri.regnaud","2024-09-19T02:30:37.3120000+08:00","What do you think of the ""Shift Left"" architecture concept as a complement to UNS? https://youtu.be/FiZmyl1Npg0?si=XWc_M_iUfophVmBL","","üôåüèº (1)"
"898217314741280828","hobbes1069","2024-09-19T03:52:12.9600000+08:00","Added to my watch list...","",""
"876559193417597000","og_grendyl","2024-09-19T07:58:43.3990000+08:00","Interesting video, but it seems to me that most of the benefit of the ""Streams and Tables"" would be achieved by having a historian subscribed to your UNS.  Both cases are dependent on doing your data ops at or close to the edge, which I thought was the most significant change in the ""Shift Left"" architecture.","",""
"568913935147728896","zeratall","2024-09-19T13:41:20.7370000+08:00","That last part is exactly right, its honestly of the many reasons why I'm constantly advocating for DataOps near the edge. In my opinion, shift left is all about leveraging streams to reduce the latency incurred from serial ETL pipelines, and moving some of that data modeling and DataOps closer to ingestion (or in our case, the edge). Having structured data earlier in the chain provides a lot flexibility from an architecture point of view.","",""
"867075936054149191","rickbullotta","2024-09-19T21:07:19.3830000+08:00","I need to use AI to translate Canuck to English.","",""
"1111719898482212874","d_leblanc","2024-09-19T22:40:22.4250000+08:00","sounds normal to me eh. üôÇ","","üòÇ (1)"
"795178288330440704","youri.regnaud","2024-09-19T22:44:31.5630000+08:00","And after translation, what do you think?","",""
"867075936054149191","rickbullotta","2024-09-19T22:47:59.6020000+08:00","I agree with pushing data transformation (and contextualization) left (down?)","",""
"957775996856180737","evjakec","2024-09-19T23:05:02.3080000+08:00","I was thinking this architecture was pretty common. Maybe not the streaming piece, but absolutely agree to shift left. My favorite setup was one where ops and engineering just used a read only replica of the production database. IT and their data lake was an after thought and barely used.","",""
"898217314741280828","hobbes1069","2024-09-20T00:11:02.1050000+08:00","There's some marking speak... Are you really ""shifting left"", or are you changing from essentially a polling architecture (kind of, really timer based) to an event driven architecture? Which is a good thing! But the whole ""left vs right"" is a made up construct where it implies the relative location between the producer and consumer of data is important.","",""
"795178288330440704","youri.regnaud","2024-09-20T00:16:04.8990000+08:00","Let me give you a bit more context. We‚Äôve built an Event-Driven architecture based on Solace to support both IT integrations and build a UNS (Unified Namespace) in parallel. Currently, our Advanced Data Platform strategy aims to push all data into Google Cloud Platform (GCP). However, in many cases, such as with Supply Chain Planning applications, we also realize that we need historical data to run these applications effectively.

In general, if we push this historical data into tools like GCP, we would need to do a sort of reverse ETL to feed operational solutions that require historical data, like stock movements, forecasts, etc.

My main point with this Left Shift Architecture is to understand what most people do when they store UNS data. Some UNS data will naturally be stored in time series databases or similar storage, but for more transactional data, what strategy do you follow? Do you adopt a neutral storage strategy, like in Shift Left Architecture, that feeds both analytics solutions like GCP, AWS, or Databricks? If so, how do you handle situations where transactional solutions need not real-time data but some history?

That‚Äôs the core of my question and the discussion I‚Äôm looking to have.","",""
"957775996856180737","evjakec","2024-09-20T00:25:44.2170000+08:00","I‚Äôve seen Amazon examples where everything goes to S3 first and then a knowledge graph is built in Neptune to make these connections. Bonus, use LLM to write natural language queries against the graph","",""
"1073312001788477471","sparkylarks","2024-09-20T01:42:05.2290000+08:00","So when I had my data transformation and contextualisation in InTouch on a Windows XP machine on the plant floor.
Was I actually ahead of my time and ""shifting left""?","","ü§£ (3)"
"1073312001788477471","sparkylarks","2024-09-20T02:05:26.1690000+08:00","Not sure if this helps but I tend to focus on the functionality 

the current state is in the UNS.
Applications and functions can subscribe and store the data they need to, in the form they need it. 

I'll integrate a Historian so I can review historical data quickly and easily for maintenance or other immediate needs.
And for sum functions. i.e. generating a report, I can leverage that data 
In other cases I subscribe to what I need and store that.","",""
"568913935147728896","zeratall","2024-09-20T02:20:37.3940000+08:00","This summarizes my thoughts perfectly, there are often similar issues and design patterns for IT and OT, we‚Äôre just constantly calling them different things and trying to recreate the wheel, while the underlying Idea is very similar.","",""
"867075936054149191","rickbullotta","2024-09-20T05:36:11.4050000+08:00","You were a pioneer braving the wilderness Mark!","",""
"1073312001788477471","sparkylarks","2024-09-20T20:24:34.5520000+08:00","That is what I always thought, and IT said I was a Troglodyte.

Slightly more seriously I think I lacked the vocabulary, and perhaps the confidence to fully articulate to the IT Teams ( various internal, external same company different company)  why I wanted that Data Ops at the Edge.

now I can say ""The edge paradigm significantly reduces the time to insight by eliminating delays associated with centralized processing models"" and heads nod and away we go.","",""
"568913935147728896","zeratall","2024-09-20T22:56:17.7310000+08:00","Now you‚Äôre sounding like a consultant! Hahaha","","üòÇ (1)"
"1073312001788477471","sparkylarks","2024-09-20T23:13:29.9290000+08:00","That is a bit uncalled for. 

I am an engineer who consults, perhaps, but to call me a consultant, you have wounded me sir,","","ü§£ (5)"
"1073312001788477471","sparkylarks","2024-09-20T23:14:12.2360000+08:00","I looked up chat GPT","https://cdn.discordapp.com/attachments/815945777452941313/1286706989631541309/image.png?ex=68df3f84&is=68ddee04&hm=6669042c3ea29d7ce9c73eaffe03561a159bbc901a6cf56950c280d9f62b57cc&","üòÇ (4)"
"908341993820811295","chris.demers","2024-09-26T23:57:50.6110000+08:00","The shift left architecture hinges on the use of Apache Kafka to my understanding. Kai Waehner has a bunch of great blog posts on this and has spoken at the HiveMQ user conference before on the complimentary nature of MQTT and Kafka. The way I interpreted it as a stream processing engine is its basically a distributed log file with data organized into Topics. The nice part about it being essentially a log file is you have access to a buffer of historial data (user determined) so you could combine data coming in at two very different rates. Maybe some of the UMH folks @Jermuk could chime in as their product has both Kafka and an MQTT broker at the core of their architecture.","",""
"867075936054149191","rickbullotta","2024-09-26T23:59:31.5810000+08:00","I think it's more of a logical concept than a specific set of technologies.","","üëç (3)"
"277515221885779970","jermuk","2024-09-27T00:02:31.6100000+08:00","happy to answer any specific questions üôÇ","",""
"568913935147728896","zeratall","2024-09-27T23:28:40.8640000+08:00","Hey guys,

I've been in a lot of debates at my job lately around standardization, and I'm curious about everyone's thoughts on application standardization in a heterogeneous enterprise. Our company has grown through numerous acquisitions, and as a result, we have a patchwork of different tools and systems across various business units. Each unit often uses different applications‚Äîor even the same applications in different ways‚Äîwhich has made integration a significant challenge. Most of these businesses have been using some of these applications for years, and they're critically integrated with their operations.

Leadership is now pushing for forced standardization across the enterprise. However, some business units have heavily invested in their existing tools and are resistant to change due to the deep integration with their workflows. I believe that forcing standardization might not be the best approach‚Äîit isn't scalable and could lead to more issues than it solves. I've been very vocal that this is the wrong approach. I think some standardization is okay, but some businesses have specific needs for certain applications, and we need to have an open architecture that allows sites to integrate the business specific applications aka extend the architecture.

I've been telling the company we should be designing and thinking of our enterprise architecture similar to a microservices architecture and adopt some of the same best practices/design patterns for MSA. I think the only true way to scale is to embrace a distributed approach but in a structured way where interfaces are well-understood and configuration-managed.

What are your thoughts on this? Has anyone dealt with a similar situation? Is forced standardization feasible in such a heterogeneous environment, or is embracing a distributed approach a better path forward? I think the best approach is a hybrid where there might be a common infrastructure core that's open by design, allowing sites to extend and integrate applications required for specific business needs. But I feel that idea has fallen on deaf ears at my company.","","üëç (2)"
"1129435706285101076","ted.garrison","2024-09-27T23:39:01.1770000+08:00","I don't think forced standardization is a good way to go.  I agree with you on most of your points.  It's definitely worth looking to see where you CAN standardize, and where it makes sense to.  The biggest hurdle is overcoming the ""we HAVE to do it this way"" mentalities.  See that a lot here.  2 groups/plants that manufacture the same basic product, but thinking they have to use different processes for Procurement/Logistics/etc.  Um, no..   Once you start to get the processes aligned, then the application standardization gets easier.","","üíØ (2)"
"1129435706285101076","ted.garrison","2024-09-27T23:39:49.8800000+08:00","Value Stream Mapping is where I'd start.  Do that, and then compare.","","üëç (2)"
"1129435706285101076","ted.garrison","2024-09-27T23:40:30.2870000+08:00","when it really comes down to it, manufacturing is manufacturing.    Raw material in, do some processing, product out.","","üíØ (2)"
"568913935147728896","zeratall","2024-09-27T23:40:56.6150000+08:00","Totally agree, I think the forced standardization is leaderships knee jerk reaction at feeling overwhelmed by the problem space, and it feels like the only way to move forward but I'm not convinced, I think it needs to be a hybrid approach, we need to standardize where possible but still acknowledge business have different needs, and we need to have a strategy for how we support that.","",""
"1129435706285101076","ted.garrison","2024-09-27T23:41:03.9780000+08:00","the VSM activity is where you can also find best practices and expand them to the other facilities/groups","","üíØ (2)"
"1073312001788477471","sparkylarks","2024-09-27T23:53:21.1970000+08:00","The key is to figure out what needs to be standardised and what does not,
metric calculations, reports etc.
the application etc may not.

but it is a good idea to look at standardising going forward also,
Define you Digital Strategy, it will have some standardisation aims maybe.
Define standard Architecture( though the applications might be different,)

I made this image to show a client, that when we wanted to use a different applications in a new ( much small plant) we were sticking to out standard model","https://cdn.discordapp.com/attachments/815945777452941313/1289253557190525019/image.png?ex=68df48b1&is=68ddf731&hm=cdf5e71ca5f48bcf867e2e59179a4ee6b35b373c79a7ca253b80dc1ff3a1dd6f&","üíØ (2),üëç (2)"
"568913935147728896","zeratall","2024-09-27T23:58:53.7500000+08:00","Yep totally agree, allgined with what Ted and I were saying above","",""
"957775996856180737","evjakec","2024-09-28T00:16:47.7380000+08:00","Global orchestration, local execution. Also consider in terms of manufacturing style. Trying to fit the same system on a continuous process vs complex discrete is never easy. Okay to have two systems that support the specific need and just ensure the master data is globally aligned.","",""
"568913935147728896","zeratall","2024-09-28T00:27:41.2620000+08:00","Absolutely, this problem manifests itself time and time again, data models, process, applications, etc. lol","",""
"568913935147728896","zeratall","2024-09-28T00:29:40.1980000+08:00","I think enterprise, specifically ones that have grown through acquisitions have it especially difficult. In a lot of startups its pretty standard practice to start with a simple standard/monolithic stack to reduce complexity and then move to distributed when the domains are better understood to improve scale, but with enterprise they are essentially at a big ball of mud architecture and trying to figure out how to clean that up is hard, and thats why its so important to have a well thoughout digital strategy and the right experttise to help develop/execute that strategy is so important. I think that is one of our problems is that strategy is only lead by business without the input of technical (which is more of a problem with A&D) vs traditional tech.","","üëç (2)"
"1129435706285101076","ted.garrison","2024-09-28T01:50:27.3620000+08:00","Also, stanardize thru attrition.   Plant B needs a new MES as the old one is obsolete and unsupported?  Time to standardize to what Plant A is using for MES.","",""
"783917475128410112","geoffnunan","2024-09-28T06:11:22.2330000+08:00","Conway's law applies. Regardless of what management want, unless they centralise the responsibility for designing applications, the applications will evolve to copy the goverance structure.
https://en.wikipedia.org/wiki/Conway%27s_law#:~:text=In%20colloquial%20terms%2C%20it%20means,apply%20to%20most%20technical%20fields.","",""
"568913935147728896","zeratall","2024-09-28T06:18:20.9320000+08:00","100%, Conways law is actually one of the main influences of why I have the stance I have. A year or so back I read this book that really emphasis that point","",""
"568913935147728896","zeratall","2024-09-28T06:24:03.5790000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1289351881251885097/IMG_0078.png?ex=68defb83&is=68ddaa03&hm=d77045b44f9f366219ef43baa2a05c7f09d56a3c7fff5f67f23865424e7c3665&","üëç (4),üî• (1)"
"894527802316046366","nickn5549","2024-09-28T08:49:46.0760000+08:00","in the future, when we fully digitally transform our businesses, we must integrate our digital factory with the supply chain. Then you will get into a similar situation with lots of heterogeneous systems. Present the problem in this way to your management.  How would you integrate your digital business with external suppliers? Can you force them to 'standardise'? Not an option. What can you do then? Probably, a hybrid approach emphasizing open architecture and microservices principles can provide an adaptive path forward that respects both enterprise-wide integration needs and individual unit requirements.","","üíØ (2),üëç (3)"
"568913935147728896","zeratall","2024-09-28T11:46:07.1660000+08:00","That‚Äôs actually a really good point about suppliers.","",""
"894527802316046366","nickn5549","2024-09-28T13:42:17.3300000+08:00","used it a couple of times to change perspective","",""
"908341993820811295","chris.demers","2024-09-28T20:05:29.1300000+08:00","Sorry I‚Äôm digging this back up. Conversations move on so quickly I can‚Äôt keep up!

On the shift left piece my take is it‚Äôs about moving analytics closer to the machine/edge/whatever. This would require doing some math or some sort of regression analysis which requires access to a buffer of data. To me this is where we need additional tooling like Kafka since just the MQTT broker alone won‚Äôt give you the ability to shift the analysis left since we will only have access to current state. 

I guess one could argue that having a local historian might serve the same function. You would still need some sort of a small application to run at or near the edge to take in both historical and current state.","",""
"1073312001788477471","sparkylarks","2024-09-28T20:33:26.4100000+08:00","Just wondering if this is over complicates it

20 years ago,  in a PLC I was taking an Analog reading for flow, using a summation routine that approximated integration, t=100m not 0 and using that to give me a flow total every minute, and then using some more logic to get my total flow , this hour, last hour, today, yesterday, this week, last week.

and it was all on a SCADA running on Pentium 4 with 1GB or RAM, or is it would be called today my Edge Node with it's low code platform with additiona scripting capabilities for higher functionality.

Analytics at the Edge is not new, I think some people just never did it. The tools were crude, I used to have set of  SCADA in different Plants that woudl, email a daily set of figures as a .csv, to a mail box that would strip the file out, process the .csv file and store the data in a Database, lets call this our Enterprise Historian, Data Warehouse?? and present and Aggregated report , is that Connected Operations.

I am actually currently loading my IIOT 2050 with 1 GB ram, with the MING stack, and that connects to the Cloud broker, but it;s actually pulling data down mainly, and doing the analytics there. It will publish back up data and it will get logged for long term storage eventually.

But if the Data to be Analysed is on the Edge, and the result of the analysis is on the Edge, why would you not analyse on the Edge.","",""
"1073312001788477471","sparkylarks","2024-09-28T20:34:11.9810000+08:00","as an Aside, the last company I contracted with the Edge was the Datacenter on each site, with about 4million in Cisco Gear, 20 to 30 VMS with 16 to 64 GB, all Quad HA Setup with PetaBytes of Storage, I used to ask them, if that is the Edge, what do we call the PC's running closer to the process?  Oh and a Product and Test identical setup.","",""
"867075936054149191","rickbullotta","2024-09-28T22:29:59.7110000+08:00","...and the data transformation/contextualization closer to the edge, at least as I've interpreted that video.","",""
"568913935147728896","zeratall","2024-09-28T23:30:42.7550000+08:00","@RickBullotta  is 100% correct, it‚Äôs more about removing some of the stages in a typical pipeline (by modeling data closer to edge) instead of dumping unstructured data into a data store and then cleaning up later. It‚Äôs also about removing some of the latency from serial scheduled jobs by turning some of them into streams. You can absolutely do shift left with something like intelligence hub at the edge and then having your historian subscribe to the contextualized data for persistence.","","üëç (5),üëçüèº (1)"
"696530862413578301","martinc9133","2024-09-30T23:38:02.7320000+08:00","Came across this blog post recently https://fs.blog/ken-iverson-nucor/
Feel like the section 'Extreme Decentralization' may be relevant and could serve as a case study for the side of non standardization","",""
"568913935147728896","zeratall","2024-10-01T02:00:36.5430000+08:00","Ooooh thanks for sending that over, I‚Äôll definitely read through that when I get a chance!","",""
"692810394862878771","galileo86","2024-10-01T13:44:34.5200000+08:00","Hi, for a OEE implementation for a small client (< 50 people, 5 machines), is the MING stack still the way to go? Target is to start small (low invest) and still be able to grow from that. Or would you recommend an other stack? UMH + NodeRed + Grafana? What is your oppinion/best practise on that?","",""
"1073312001788477471","sparkylarks","2024-10-01T14:17:33.8490000+08:00","- It depends 

I would be careful here, Node-Red & Grafana are great, but there are a few potential drawbacks.
- the Visuals are limited compared to other approaches
- There is more development needed to connect, collect, publish to the MQTT broker and the do the relevant calculations
- Because each machine is independent every change or tweak or change in commission in might need to be made 5 times.
- Data input is a bit tricky, if you want to put in things like Downtime codes.

If you are already up to speed with Ignition, or InTouch even., you would probably develop a better solution , much faster.

I have been burned by people agreeing to the visuals for Node Red and Grafana, and then not really being happy with them,","",""
"692810394862878771","galileo86","2024-10-01T19:24:48.2830000+08:00","üòÑ it always ""depends"" 
Thanks for your answer. I totally see your point regarding visuals on grafana compared to tools like tableau or power bi, it always looks a little outdated.
And yes, there are more convenient solutions out there. 
But client is not 100% convinced, and therefor is asking for a budget solution, do you know of any on-prem, open-source replacements that can improve the MING stack?
Thanks","",""
"867075936054149191","rickbullotta","2024-10-01T20:59:28.2790000+08:00","Reconsider if OEE is the right metric to be capturing.","",""
"692810394862878771","galileo86","2024-10-01T21:10:52.5760000+08:00","what do you mean by that? What would you recommend?","",""
"1073312001788477471","sparkylarks","2024-10-01T21:49:36.1070000+08:00","I'm not sure how cheap you can go with Ignition, but 2.5k for a InTouch 1000 Tag licence. 
No Historian , but I thinks it includes MQTT.

Might be an option.

Check out Listo.
Really good Dashboard ing, fast to set up
They are going to Prove It.

Great guys too. Tell them I sent you. Not sure on pricing but don't think it's too steep","",""
"693309801589112862","_dyland","2024-10-01T22:14:40.2940000+08:00","Ignition Headless can be as simple as the Core with the MQTT Transmission Module - $2,550.

Unlimited Perspective is $11,225
Web Dev is $1,890 
Historian is $2,365

You can do a lot with just the Core and Transmission Modules though. Add an MQTT Broker, SQL Database, Maybe a Time Series Database, and something like appsmith or Grafana if you want to start cheap.

* All of these prices are from their website at the time of this comment.","",""
"693309801589112862","_dyland","2024-10-01T22:17:22.2140000+08:00","https://inductiveautomation.com/pricing/ignition#","",""
"1073312001788477471","sparkylarks","2024-10-02T00:02:41.6820000+08:00","When you say Headless, I assume that someone would need something else for visualisation?","",""
"693309801589112862","_dyland","2024-10-02T00:05:23.2020000+08:00","Yes - I mean no Visualization through Ignition. Starting cheap, its an option that allows for adding Vision / Perspective later if desired. Either as a seperate Gateway or as a module on the existing Gateway.

The other option - If you don't need storage (SQL or Historian) is Ignition Edge IIoT. That can be as cheap as $900.","",""
"693309801589112862","_dyland","2024-10-02T00:07:14.7360000+08:00","Not recommending this necessarily but Edge IIoT to connect to devices - Feed your MING stack with MQTT.","",""
"1129435706285101076","ted.garrison","2024-10-02T20:23:24.6090000+08:00","A lot of folks try to jump straight into OEE (we tried - FAIL).  Most of the time there is a ton of value to be gained well before you get to using OEE.  OEE doesn't SOLVE anything.  It's just a number that is meaningless unless you have a ton of data below it that you can actually solve problems with.  Start with that stuff.","","üëç (1)"
"692810394862878771","galileo86","2024-10-02T20:31:42.2380000+08:00","Maybe a stupid question, but I can't find the info anywhere on their page: That is the monthly fee, right?","",""
"693309801589112862","_dyland","2024-10-02T20:35:20.2950000+08:00","No, it's a perpetual license. 

The redundancy is an extra 50% if you want it and the support is a percentage annually - lowest tier is 16% and the highest is 24%","","üëçüèª (1)"
"693309801589112862","_dyland","2024-10-02T20:37:29.0680000+08:00","If you select the modules you want and click next, you will get the whole picture. When you get to a form that asks your info for an ""Official Quote"" that's the last page. No need to fill that in until you're ready to buy.","",""
"867075936054149191","rickbullotta","2024-10-02T21:30:33.4440000+08:00","I hope they NEVER get to using OEE...they've failed if they did.","",""
"692810394862878771","galileo86","2024-10-02T22:23:47.0640000+08:00","Sure, OEE does not solve anything by itself, but it gives transparency about how your production runs and where your bottlenecks are. 
What would be other examples of good initial projects with a quick time to value?","",""
"230441548653789184","r.pop","2024-10-02T22:41:38.1750000+08:00","OEE = A*P*Q --- The OEE number doesn't mean all that much other than making executives happy (or sad)...but the A,P,Q are absolutely critical in understanding where you can make an impact in your manufacturing processes","",""
"230441548653789184","r.pop","2024-10-02T22:44:00.1660000+08:00","For @RickBullotta we are making OEE (more A P Q) part of our ProveIt! use case","",""
"230441548653789184","r.pop","2024-10-02T22:45:13.7940000+08:00","OEE is the gateway drug for manufacturers, it gets them addicted to data, after they're addicted, we can show them all the better drugs out there","",""
"867075936054149191","rickbullotta","2024-10-02T22:56:40.6210000+08:00","A, P, Q (if it can be truly measured - most companies can't measure quality inline) are fine.  Add safety, energy/resource usage, and on-time order completion and we'll talk.  OEE unfortunately is more like heroin than a gateway drug - it makes you stupid, unable to do anything productive, wastes money, and will kill you eventually.","","ü§£ (1)"
"867075936054149191","rickbullotta","2024-10-02T22:57:20.6860000+08:00","Does it really?  Try talking to the operators first.","",""
"692810394862878771","galileo86","2024-10-02T22:57:52.3510000+08:00","Ok sorry, OEE includes APQ in my definition, otherwise it rally deliveres no benefit","",""
"867075936054149191","rickbullotta","2024-10-02T22:58:26.6140000+08:00","Also, OEE is just a STUPID way to calculate work center/machine performance.  There is ZERO REASON why a machine/operator's measurement should be negatively impacted by upstream or downstream issues, material shortages, etc...that makes NO SENSE AT ALL.","",""
"867075936054149191","rickbullotta","2024-10-02T23:01:33.9540000+08:00","Also, OEE does not factor in the *COST* of rework, energy, labor, restarting a process, etc...in fact it's a lousy indicator for the profitability of a manufacturing entity.  Maximizing OEE in NO WAY guarantees optimal manufacturing performance.","",""
"1073312001788477471","sparkylarks","2024-10-02T23:05:46.5810000+08:00","Downtime reasons( don't have too many reasons
Energy Usage
Water Usage
Waste water health
Just measuring Waste. Not always easy but I'm a fan of scales under Bins.","",""
"230441548653789184","r.pop","2024-10-02T23:08:57.2690000+08:00","If done right, I would argue against you. OEE can be measured at a work center/machine level, it doesn't always have to be an aggregated metric. 

It may not benefit operators, but it's not a metric intended to benefit operators. It's a management metric and a lag one at that, and again, when used correctly, as I have seen it done, it can be a very useful tool. OEE is not intentnded to factor in cost, so why would it? It's strictly a metric to measure how well a machine/cell/line is operating against its theoretical maximum. If I buy an assembly line that is supposed to pump out a widget every 54 seconds, but it's only pumping them out every 72 seconds, OEE (more APQ) can be a useful too in determining why I am not hitting that 54 second target. Is it availability? Is it Quality? is it Performance?

OEE comes into play when your looking at a higher level to understand where to focus your attention. If I'm a COO, and I have good data presenting OEE for a product line, and I see that plant 1 is operating at a 55% OEE, and plat 2-5 are at 70%, I can use that as a high level metric to see that I should go look at plant 1 first.

Like I argued though, APQ, the metrics that make up OEE are far more valuable.","","üëçüèº (1),üíØ (1)"
"867075936054149191","rickbullotta","2024-10-02T23:09:08.7840000+08:00","There are a RARE FEW processes where 100% inline quality inspection can be performed and that accurate stop and microstop reasons are captured.  The moment you ask operators to enter than data however, you're immediately reducing accuracy significantly.","","üëç (1)"
"867075936054149191","rickbullotta","2024-10-02T23:09:50.1170000+08:00","Again, I don't think that penalizing a work center for upstream or downstream issues makes any sense whatsoever.","",""
"230441548653789184","r.pop","2024-10-02T23:10:15.3550000+08:00","Who says we're penalizing it? I'm using it as a tool to understand where I need to spend more evaluation time.","",""
"867075936054149191","rickbullotta","2024-10-02T23:10:42.5330000+08:00","BTW, even if plant #1 is at 55% OEE and plant #2 is at 70%, it doesn't imply that plant #2 is performing better from an economic or cusotmer POV.","",""
"230441548653789184","r.pop","2024-10-02T23:11:01.1240000+08:00","OEE is not a metric to evaluate those things","",""
"230441548653789184","r.pop","2024-10-02T23:11:15.2730000+08:00","It is strictly for measuring machine performance against its theoretical maximum. Full stop","",""
"867075936054149191","rickbullotta","2024-10-02T23:11:43.4670000+08:00","Ha - you might not be, but as everyone says above, it's a ""management tool"" - and if I'm the operator on a machine that is at 45% OEE because the assh*le on the upstream machine keeps letting it jam, yeah, it's a problem, because someone is going to bitch at me.","",""
"230441548653789184","r.pop","2024-10-02T23:12:56.6410000+08:00","If measured correctly, you would see the other machine with a worse number.","","üëçüèª (1)"
"867075936054149191","rickbullotta","2024-10-02T23:13:23.2890000+08:00","One solution is to treat stoppages that are not directly related to a machine or workcenter as ""non productive time"" and removed from the OEE calculation.","",""
"230441548653789184","r.pop","2024-10-02T23:13:43.0990000+08:00","And also, this would still deliver on what I want OEE to, we would head to that machine that is 45% and dig into whats going on, which would point to the upstream machine","","üëçüèª (1)"
"867075936054149191","rickbullotta","2024-10-02T23:13:49.0970000+08:00","Two wrongs don't make a right. üòà","","üòÄ (1)"
"867075936054149191","rickbullotta","2024-10-02T23:14:07.8040000+08:00","So would spending an hour on the shop floor!","",""
"692810394862878771","galileo86","2024-10-02T23:14:14.5400000+08:00","and if you have the same metrics for upstream machine you will find the issue there and/or find out if you dig into the reason for the bad metrics on machine A, its not for bitching, its for pointing you in the direction of the issues","",""
"230441548653789184","r.pop","2024-10-02T23:14:49.4860000+08:00","At Dana, Fort Wayne, IN plant was 1.5M sq ft, we had 4000 assets in that plant. How is 1 hour on the floor better at evaluating a foot print that size than a well built OEE system","",""
"692810394862878771","galileo86","2024-10-02T23:16:20.9130000+08:00","without the OEE, you propably don't even know, that you have to be there and/or where to start looking","",""
"230441548653789184","r.pop","2024-10-02T23:16:24.8690000+08:00","This is where an Operating system plays a critical role -- Our OEE framework allows for entering these items in such a way that you can design the metrics for your business and not some ""Golden OEE"" rule. Understanding the reason OEE exists, we cna adapt it to specific customers environments. 

Like most things, it's a guideline on how to measure machine performance.","",""
"230441548653789184","r.pop","2024-10-02T23:17:46.7580000+08:00","As Voltaire says, ""The perfect is the enemy of the good"" -- or more commonly reference, don't let perfect get in the way of better.","","‚ù§Ô∏è (1),üíØ (1)"
"867075936054149191","rickbullotta","2024-10-02T23:29:24.1010000+08:00","How about material shortages?  That won't show up anywhere else.","",""
"867075936054149191","rickbullotta","2024-10-02T23:29:38.4920000+08:00","Could not disagree more.","",""
"867075936054149191","rickbullotta","2024-10-02T23:30:03.6410000+08:00","It's metaphorical.","",""
"867075936054149191","rickbullotta","2024-10-02T23:31:40.5940000+08:00","As I've said, measure output.  If it goes south, dive in to find out why.  But don't just measure those three things.  Safety can have an inverse relationship with throughput and energy/resource consumption can have a geometric correlation to productivity.  Gotta look at the big picture.  Just like you don't drive a car just staring at the speedometer.","",""
"867075936054149191","rickbullotta","2024-10-02T23:32:39.3330000+08:00","Obviously I'm just trying to stir things up, but I do hope OEE dies forever and we just measure APQ and stop multiplying them together, and that we add other important metrics to the mix.","",""
"867075936054149191","rickbullotta","2024-10-02T23:35:32.3210000+08:00","Also, if you have a collaborative culture, the operators and supervisors will be proactively raising production issues they encounter.","",""
"867075936054149191","rickbullotta","2024-10-02T23:43:32.4610000+08:00","A guideline that became a cult.","","üòÇ (1)"
"230441548653789184","r.pop","2024-10-02T23:48:07.6180000+08:00","No argument there","",""
"867075936054149191","rickbullotta","2024-10-02T23:48:26.8580000+08:00","We're in violent agreement, as usual.","","‚ù§Ô∏è (1)"
"230441548653789184","r.pop","2024-10-02T23:48:42.1260000+08:00","You know I love violent arguments with you Rick!","","ü§£ (1),‚ù§Ô∏è (1)"
"230441548653789184","r.pop","2024-10-02T23:50:36.0740000+08:00","If we can't disagree amicably, why are we here!","",""
"230441548653789184","r.pop","2024-10-02T23:51:00.3630000+08:00","Or even in agreement, have different methods","",""
"957775996856180737","evjakec","2024-10-03T00:38:21.0970000+08:00","How often is everyone reclassifying defects to the correct asset? I see this as a gap sometimes and unfortunately, a collaborative culture is not easy to achieve. Being able to reclassify the defect helps clean up the data concern. Maybe you‚Äôre all doing that already.","",""
"817835202746253344","IIoT#4707","2024-10-03T00:38:21.5030000+08:00","GG @Jake Cunningham, you just advanced to level 3!","",""
"867075936054149191","rickbullotta","2024-10-03T01:32:49.6920000+08:00","Very rarely, if ever.","","üëç (1)"
"230441548653789184","r.pop","2024-10-03T02:02:33.1600000+08:00","We have an engine built into our framework to do that generally, but its not classified to a specific serial number. For instance, if I recorded 5 scrap in my shift, a Quality Engineer can go in after the fact and reclassify 3 of those scraps as a specific reason.

At Dana, we could reclassify down to the serial number, but we had a much more advanced MES system built by RedViking. https://www.redviking.com/solutions/production-data/argonaut-platform/","",""
"957775996856180737","evjakec","2024-10-03T02:51:39.4360000+08:00","Nice. Thanks for sharing. Out of curiosity, were you based out of Maumee? I live in the area and they let me tour there to see their SPC product.","",""
"1073312001788477471","sparkylarks","2024-10-03T03:32:31.2310000+08:00","Is that not true of any metric you measure.
most industrial Energy meters measure about 6% less than the actual Energy usage , more in some cases. 

I've seen lots of companies struggle to measure output accuracy, but I don't think that is a good reason not to use the metric. And having some operators defined downtime reasons is a great help when doing root cause even if there is an inbuilt inaccuracy.

Even if you take the approach to monitor the output do we not need to compare it to a theoretical value. Otherwise if we are only looking for a rate of change( i.e. dive) then we will miss assets that have always performed poorly.","","üëçüèº (1)"
"867075936054149191","rickbullotta","2024-10-03T04:35:41.4390000+08:00","If you have a lot of downstream quality issues detected as a result of upstream processes, OEE is not very insightful.","","üëç (1)"
"1073312001788477471","sparkylarks","2024-10-03T04:46:29.3380000+08:00","Is output, better at detecting downstream quality issues?
Is taking a walk for an hour on the plant floor?

Surely we should look at taking as many easily available metrics, even if they are imperfect, AND combining them NOT choosing one OR the other??","",""
"1129435706285101076","ted.garrison","2024-10-03T05:16:49.6290000+08:00","I think it's just that the Q part of OEE makes it ""useless"".  The A & P are good - you can *generally* get them fairly accurate.  But Q is nearly impossible to do in near-realtime.","",""
"817835202746253344","IIoT#4707","2024-10-03T05:16:49.9370000+08:00","GG @Ted Garrison, you just advanced to level 15!","",""
"230441548653789184","r.pop","2024-10-03T08:43:05.0210000+08:00","I was based out of the Maumee office, but I live in the Detroit area.","","üëç (1)"
"894527802316046366","nickn5549","2024-10-03T18:55:46.4840000+08:00","OEE chat.....hmmm, IMIN","","üòÇ (1)"
"1088631859509989426","jpmac.s","2024-10-03T19:22:46.9270000+08:00","Don't mention OEE or SparkplugB or dad gets angry.","","üòÇ (5)"
"867075936054149191","rickbullotta","2024-10-03T20:27:55.4590000+08:00","No dessert for you.","","ü§£ (2)"
"452467225098715154",".autok","2024-10-04T02:12:13.3050000+08:00","Hi everyone,

I‚Äôm working on a project where I need to install MQTT brokers locally on several sites at Level 3, and bridge them to an enterprise broker in the cloud. The brokers need to support Sparkplug B and specifically handle the bridging of Sparkplug B messages between local and cloud brokers.

Does anyone have recommendations for MQTT brokers that support Sparkplug B bridging?","https://cdn.discordapp.com/attachments/815945777452941313/1291462831484436573/IMG_5571.png?ex=68df693d&is=68de17bd&hm=b1bc33ce65738ee7f2c68b5338f2109633b909bb082d9adb948ddc8f9dfe2874&",""
"867075936054149191","rickbullotta","2024-10-04T02:15:56.3250000+08:00","I have to ask ""why""?","","ü§£ (1)"
"452467225098715154",".autok","2024-10-04T02:21:35.7930000+08:00","The reason for this setup is due to strict cybersecurity guidelinesüôÉ 

We‚Äôre using Ignition on Level 2, but I was unsure if I could ‚Äúforward‚Äù SpB-messages from MQTT Engine to level 3 with transmission. And then forward to enterprise-broker","",""
"1088631859509989426","jpmac.s","2024-10-04T03:58:24.1570000+08:00","It would make my day if it was for OEE  üòÜ","","üòÇ (5),ü§£ (2),üòÄ (2)"
"1088631859509989426","jpmac.s","2024-10-04T04:39:31.4090000+08:00","@RickBullotta serious question, if you were setting up a plant L1-L3 - PLC -SCADA-Historian-MES . What protocols are you selecting?","",""
"867075936054149191","rickbullotta","2024-10-04T05:18:42.4500000+08:00","Depends on the SCADA, but I'm probably not introducing an MQTT broker as the hub of it all (just my preference - for failure mode considerations).  OPC/OPC UA/native protocol from PLC to SCADA.  Whatever the SCADA wants from SCADA to historian. Depends on the MES for that link, but it definitely wouldn't be sparkplug.  If I'm using an MQTT broker, it'd be above all that.  And I'd use a simple JSON format for topics (value/timestamp).  I'd also have a REST API mechanism for accessing metadata/topics, current state, and historical data.  So I'd be using some type of IIoT platform to do that.  Sparkplug would be nowhere in my architecture as it stands today.","","üíØ (2),üëç (2)"
"867075936054149191","rickbullotta","2024-10-04T05:19:35.7590000+08:00","From my IIoT platform (which might include an MQTT broker) I'm allowing TCP and Websocket pub/sub, as well as HTTP APIs.","","üëç (1)"
"867075936054149191","rickbullotta","2024-10-04T05:21:06.6500000+08:00","And I'd likely have a data ops product to help handle populating the IIoT system (again, depending on the IIoT platform's built-in capabilities) and to shuttle data from sites to the data center or cloud for my data lake and data sharing layer.","","üëç (2)"
"1088631859509989426","jpmac.s","2024-10-04T05:52:42.6580000+08:00","Thanks for your thoughts. Im using Ignition with TimescaleDB/Canary when the client can afford it and Tillit for my MES/front line operations.

 Interesting you would still go with OPC v Spb for PLC to SCADA, i have really been wrestling with what to recommend to clients of late.","",""
"568913935147728896","zeratall","2024-10-04T05:54:36.8850000+08:00","Your going to recreate thingworx aren‚Äôt you lol, joking aside what were  some of the insight from your time with thingworx that you would do differently this time around jc","",""
"867075936054149191","rickbullotta","2024-10-04T19:52:26.7270000+08:00","Would depend on what the PLC/device supports natively if possible.  I honestly could care less at that layer - it's just plumbing.  Whatever is most efficient, secure, and cost-effective and doesn't burden the PLC/device with unnecessary work.","",""
"867075936054149191","rickbullotta","2024-10-04T19:55:49.5790000+08:00","Well, there are a couple changes for sure - a scaleout architecture based on a lambda pattern, pub/sub approach (which has been removed from ThingWorx), I would add GenAI for configuration and for ""uber search"" (the evolution of what was called SQUEAL), no in-proc extensions, native container and K8S support for everything, polyglot datastore (probably based on Postgres this time around), probably Redis for shared state, and a true persistent queue for event processing and historical data storage.","",""
"867075936054149191","rickbullotta","2024-10-04T19:56:47.1050000+08:00","I would also support true ""graphs"" of assets, I'd add new entities for processes and ""stuff that flows through processes"" (work order, service ticket, batch, etc)","",""
"867075936054149191","rickbullotta","2024-10-04T19:57:19.5710000+08:00","And I'd make export to Parquet for cold storage and data lake(s) a built-in capability.","",""
"867075936054149191","rickbullotta","2024-10-04T19:57:49.9380000+08:00","Lastly I'd make it a ""one click"" option to publish state to an MQTT broker or an OPC UA proxy.","",""
"867075936054149191","rickbullotta","2024-10-04T19:58:18.0080000+08:00","All of which I could probably do from the ThingWorx source code base in about 5 person years with the right people.","",""
"867075936054149191","rickbullotta","2024-10-04T19:58:28.7610000+08:00","So at most one clock year.","",""
"568913935147728896","zeratall","2024-10-05T01:46:14.8860000+08:00","Native K8s support and graph based model has for me hot and heavy! That makes a lot of sense the things you listed though, those are things that I‚Äôm constantly seeing missing from platform offerings today.","",""
"795178288330440704","youri.regnaud","2024-10-05T15:37:23.4550000+08:00","I understand that PTC's offer at the time was hard to refuse, but don't you sometimes have regrets about what THX has become, or more exactly hasn't become?","",""
"867075936054149191","rickbullotta","2024-10-05T20:18:45.9040000+08:00","I absolutely do.  I made an effort to ""not care"" early on, but it greatly saddens me that the platform actually regressed over the years rather than evolving.  I've offered specific feedback and recommendations, but no one really seems to have any passion to do great things - I guess just collecting a paycheck.  So now I'm back to ""not caring"".  As the Dalai Lama once said, ""If you can control the outcome, why worry?  If you cannot control the outcome, why worry?""","","‚ù§Ô∏è (3)"
"568913935147728896","zeratall","2024-10-06T01:28:49.8490000+08:00","It‚Äôs next to impossible not to care about something when it‚Äôs your passion.","","üíØ (1)"
"801561312861618236","jon.forbord","2024-10-09T02:59:15.2020000+08:00","You need brokers that support bridging. there‚Äôs no special requirement for bridging SpB from broker to broker AFAIK.","",""
"801561312861618236","jon.forbord","2024-10-09T03:00:51.8600000+08:00","And with the exception of Sparkplug aware brokers, there is no specific requirement for a broker to support SpB. Brokers do not care what the payload contains. and SpB aware broker is a Nice to have, not strictly necessary.","","üíØ (1),üëå (1)"
"745476105221308547","markyfreeds","2024-10-10T20:36:16.2140000+08:00","I‚Äôve been thinking about architectures differently lately since I built the most recent architecture in Tulip‚Äôs experience center with a UNS. I was wondering if you had any thoughts on how fully you‚Äôd care to carry these ‚Äúthings that flow‚Äù through to the UNS. I keep arguing with myself as I think through it. Clearly I want the state-machine aspect of it, but do I really want to go to my UNS for any given work order? Maybe yes, maybe no","",""
"1073312001788477471","sparkylarks","2024-10-10T20:40:07.3620000+08:00","That is a great way of saying it, things flow through the UNS.
When people here a single source of truth, they think of a library where they can go to get the information.
But it is more like a magazine subscription bundle, you subscribe to data, the magazines come into the sorting centre and packedeg together and sent out to you.

Data does not live in a typical UNS. It is a pipe, or a ""Steam Pipe Trunk Distribution Venue""","",""
"867075936054149191","rickbullotta","2024-10-10T20:42:08.6610000+08:00","let's chat.","",""
"745476105221308547","markyfreeds","2024-10-10T20:42:08.7470000+08:00","At a certain point I want the power of a relational database, especially when work orders are children of larger orders, etc. I don‚Äôt want to reschema my entire information system in a more intuitive and accessible UNS structure. Eventually there are diminishing returns and redundant entries because of the interrelated nature of objects in a valuestream.

I‚Äôm thinking of UNS right now as sort of like my organization‚Äôs RAM.","","üëç (2)"
"817835202746253344","IIoT#4707","2024-10-10T20:42:08.9990000+08:00","GG @freedman, you just advanced to level 1!","",""
"745476105221308547","markyfreeds","2024-10-10T20:42:57.6360000+08:00","Would love to","",""
"867075936054149191","rickbullotta","2024-10-10T20:43:34.2270000+08:00","...and of course the significant limitations of an MQTT-based UNS lead to poor usability (no ability to discover or query topics or their metadata, no good way to expose methods/services as nodes/topics, etc.)","","üí° (3),üëç (1)"
"745476105221308547","markyfreeds","2024-10-10T20:45:16.7150000+08:00","The implications of intuitive, real time operational data , analyses, and references - I suspect - are significant as it relates to democratization. Would be problem solvers could theoretically spend more time focusing on the actual problem instead of wrangling data sources and syntax. So the value is there for sure","",""
"957775996856180737","evjakec","2024-10-10T21:59:39.4140000+08:00","Thoughts on the new HighByte release where you can query the UNS? Is this a step in the right direction or should we be solving this problem elsewhere","",""
"867075936054149191","rickbullotta","2024-10-10T22:17:50.3860000+08:00","It's a great step forward, but I'm admittedly biased.","","üëç (5),üßÄ (1),ü¶∑ (1)"
"957775996856180737","evjakec","2024-10-10T22:19:47.4080000+08:00","Mark, I think your mind is in the right place. There will still be use cases outside of UNS that work well, such as leveraging your historical data. 

Great work on the TEC by the way. Awesome demonstration!","","üôè (1),üëç (1)"
"745476105221308547","markyfreeds","2024-10-10T23:36:49.8600000+08:00","I‚Äôve only seen the new intelligence hub briefly but I was giddy when I did, it looks more user friendly / beautiful and I love that you can run an api call to get the UNS as a json object. I haven‚Äôt explored the other features but api access to the UNS seems like a winning feature to me.","",""
"745476105221308547","markyfreeds","2024-10-10T23:37:52.2130000+08:00","Admittedly I‚Äôm less concerned with high frequency data as my obsession is serving humans and we‚Äôre pretty low bandwidth creatures haha","","üëç (1)"
"568913935147728896","zeratall","2024-10-11T12:03:02.4840000+08:00","4.0 is a game changer to say the least.","","üëç (1)"
"745476105221308547","markyfreeds","2024-10-11T21:05:24.9880000+08:00","What sticks out to you as the best new feature(s)?","",""
"568913935147728896","zeratall","2024-10-12T00:26:10.6150000+08:00","For me the new UX around modeling/instancing was much neeeded, and I really like the direction they went with it. The improvements to pipelines and removing flows, makes a lot more sense and I love the focus they have on pipelines as we have done some really powerful stuff witih pipelines in my deployments.","",""
"745476105221308547","markyfreeds","2024-10-12T00:29:28.7540000+08:00","Thanks, yeah I'd like to play with the new pipelines. So far I've only used pipelines when I *have* to.  I tend to try to optimize my templates/parameterization of inputs, instances, flows, outputs and have found there are a million ways to do it and each time I come up with a new way I like it better than the previous way I was doing it.","",""
"568913935147728896","zeratall","2024-10-12T00:37:20.0420000+08:00","Yep that's true with anything, can't tell you have many projects I've written 10k+ lines of code, and then when its deployed, I want to do a complete rewrite knowing what I know after the fact.","","‚ù§Ô∏è (1)"
"795178288330440704","youri.regnaud","2024-10-13T15:23:42.7720000+08:00","That why we have built our architecture around two building blocks 1) Event Hub (UNS in fact) based on Solace / Highbyte /NodeRed / Kepware 2) Data Hub based on Rhize that merge a graph database and a time series database. Every thing is expose on our Sync/Async developer portal where citizen engineer can request or subscribe to real time date (Event Hub) or (Historical Data)","","üëç (1),üí° (2),üôè (1),üî• (1)"
"745476105221308547","markyfreeds","2024-10-13T22:49:43.7350000+08:00","Just watched a handful of youtube videos trying to figure out what Rhize is, would you mind dropping a little knowledge from experience?  I was able to gather that you can create models of things in your environment (kind of like I would build out a UNS tree) as well as use graphql to do lots of things upon my data.  What I think I'm missing is how and where the ERP comes in, as well as various operational data stores like, for example if you are using Tulip tables or some ad hoc SQL db for operational data.  Does Rhize offer a single point of entry into those disparate systems?","",""
"795178288330440704","youri.regnaud","2024-10-14T00:31:45.3110000+08:00","When I explain what Rhize is, I usually describe it like this: Rhize brings together three key capabilities.

    1.    First, it‚Äôs a ‚Äúheadless‚Äù MES/MOM, meaning it‚Äôs a back-end that can manage the data and business rules of a traditional MES/MOM without a user interface.
    2.    Second, Rhize acts as a DataHub, storing data from other MOM systems (such as QES, CMMS, etc.) to provide a complete operational context.
    3.    Finally, Rhize integrates a time series database, serving as a historian for tracking and analyzing data over time","","üôè (1)"
"1088631859509989426","jpmac.s","2024-10-14T04:30:03.5740000+08:00","Are you locked into a certain db vendor? Or can you select them?","",""
"867075936054149191","rickbullotta","2024-10-14T04:41:02.4650000+08:00","For something like this, shouldn‚Äôt it be transparent and you shouldn‚Äôt care?","",""
"1088631859509989426","jpmac.s","2024-10-14T04:48:13.3530000+08:00","I always think back to Ignition giving you the option to select which DB. IT departments wanting certain vendors etc

Can you please expand on why you shouldnt care?","",""
"867075936054149191","rickbullotta","2024-10-14T04:50:54.4500000+08:00","Certainly for SaaS you shouldn‚Äôt care. But asking your app vendors to support multiple DBs sucks up a lot of dev and test resources that could otherwise be used to add features and capabilities,","","üëç (1)"
"1088631859509989426","jpmac.s","2024-10-14T04:55:09.4050000+08:00","That makes sense.","",""
"867075936054149191","rickbullotta","2024-10-14T05:01:10.8620000+08:00","It‚Äôs one reason Postgres intrigues me. Most if not all of the cloud vendors offer some form of managed Postgres and of course it can be deployed on prem on in your own data center too - but what I like is that it can serve as a SQL, KV, graph, time series, and geospatial data store (and others).","","üëç (2)"
"1088631859509989426","jpmac.s","2024-10-14T05:04:32.7530000+08:00","We have started using TimescaleDB in our Ignition projects also where clients dont want to pay for Canary.","","üëçüèº (1)"
"1088631859509989426","jpmac.s","2024-10-14T05:06:32.6220000+08:00","Is the flexibility the reason everyone is using it ?","",""
"867075936054149191","rickbullotta","2024-10-14T05:38:33.9030000+08:00","And the price, if on prem.  üí∞","","üëå (1)"
"795178288330440704","youri.regnaud","2024-10-14T14:01:39.9410000+08:00","Knowledge graph DGraph and QuestDB are underline databases included in the product. I know that for historian/TS, Rhize want to offer both options (embedded QuestDB or connection to external historians) but you need to discussion with Rhize team for better informations. @GeoffNunan can answer","","üëç (1)"
"1081971075971289148","jose.granero","2024-10-25T22:54:46.0290000+08:00","Does anyone know if QuestDB offers a fully managed service on AWS or Azure, like Timescale or MongoDB Atlas?","",""
"693309801589112862","_dyland","2024-10-25T22:58:09.9820000+08:00","I believe that is what QuestDB Enterprise is but the website doesnt detail it too well. I would go through the contact us form and ask them.","",""
"693309801589112862","_dyland","2024-10-25T22:58:13.2810000+08:00","https://questdb.io/enterprise/","",""
"1081971075971289148","jose.granero","2024-10-25T22:59:58.9870000+08:00","Thank you very much, Dylan. I will contact them to see what they say.","",""
"795178288330440704","youri.regnaud","2024-12-07T15:36:14.7220000+08:00","Hello everyone,

I‚Äôm looking for methodologies to proactively analyze potential failures in IT systems. My goal is to better understand how a system behaves when a component malfunctions and to anticipate these failures.

Do you know of any specific analysis methods (e.g., FMEA, FTA, Chaos Engineering, etc.) that help evaluate risks and plan mitigation measures? If you have any experience with tools or approaches you‚Äôve used in similar contexts, I‚Äôd love to hear about it!

Thank you in advance for your insights and advice!","","üçø (1)"
"795178288330440704","youri.regnaud","2024-12-15T21:30:05.2750000+08:00","No answer?","",""
"1073632885153730621","vaughnturner","2024-12-16T00:53:43.3110000+08:00","Youri, I‚Äôm no expert, but I'd be happy to put this to someone that is. Let me get some feedback for you","",""
"905729927968612382","fishburger3430","2024-12-16T19:59:10.4180000+08:00","@youri.regnaud Fault domains and failure model analysis are one of the most useful concepts I‚Äôve found in architecting reliable systems, that often do get enough focus. If you want to make your infrastructure and software reliable, including measuring your reliability risk, then it‚Äôs an extremely useful concept to read through. I've included some reference below which are cloud specific but the core concept remain the same across any environments.

A fault domain is a collection of functionality, services or components with a shared single point of failure. A fault level is a set of one or more fault domains serving the same purpose, for example if you ran active-active across multiple sites (datacentres or cloud locations).

I hope this help. If you have any specific questions feel free to DM me.

Useful references
https://learn.microsoft.com/en-us/azure/well-architected/reliability/
https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/welcome.html","","üëç (1)"
"817835202746253344","IIoT#4707","2024-12-16T19:59:10.9330000+08:00","GG @Fishburger, you just advanced to level 2!","",""
"795178288330440704","youri.regnaud","2024-12-28T17:08:42.9190000+08:00","Hello everyone,

I‚Äôm curious to know if anyone in this community has implemented an approach to unify the commands of their industrial equipment using an API Gateway or a similar pattern.

The idea I‚Äôm exploring is to create an abstraction layer, which I‚Äôd call a Factory API. This API would act as an intermediary, enabling the sending of commands to all the equipment in a manufacturing plant, regardless of the underlying protocols (OPC-UA, Modbus, MQTT, etc.).

The goal is to have a single, simplified interface that abstracts away the diversity of machines and their technical particularities. This could streamline integration with other systems (MES, ERP, or custom applications) while simplifying equipment control and maintenance.

Has anyone here explored or implemented such an approach? What tools, frameworks, or best practices would you recommend for achieving this?

Looking forward to hearing your thoughts and experiences!","",""
"783917475128410112","geoffnunan","2024-12-28T18:03:55.6030000+08:00","Hi Youri,
We are working with a med-device company who is also trying to achieve this. I can connect you.","","üëç (1)"
"568913935147728896","zeratall","2024-12-28T20:14:13.8590000+08:00","Slightly different use case, (we use it to decouple services not machines) but I‚Äôve been using intelligence hub as an API gateway. 

One big tip is how you handle monitoring/logging, as you decouple nodes observability becomes a little harder, so having something like grafana Loki can be really valuable. Also be mindful of how much business logic you‚Äôre putting in the gateway. Like orchestrators it‚Äôs easy to start putting too much logic in the gateway. Figure out what logic should be in the gateway (mostly routing)  vs what logic can and should reside in the service.","",""
"867075936054149191","rickbullotta","2024-12-28T21:11:04.2070000+08:00","Yes. It was called ThingWorx.","",""
"795178288330440704","youri.regnaud","2024-12-28T21:13:34.6070000+08:00","Thanks, now most of the logic (Fanuc API orchestration for example) is done with NodeRED/Highbyte/Kepware, so not on the API gateway","",""
"795178288330440704","youri.regnaud","2024-12-28T21:14:16.1640000+08:00","Have you seen that PTC renamed Thingworx Navigate to Windchill Navigate‚Ä¶","",""
"867075936054149191","rickbullotta","2024-12-28T21:17:02.5900000+08:00","Ha. I‚Äôm so over PTC. They‚Äôre accumulating a bunch of bits and pieces built on radically different architectures and platforms.  Customers will end up bearing the cost of integrating them.  It‚Äôs pretty much just a financial entity now.","",""
"795178288330440704","youri.regnaud","2024-12-28T21:26:04.7340000+08:00","Given that THX is no longer an option, what advice could the founder of THX give? Modeling a machine as a Thing? ‚Ä¶","",""
"867075936054149191","rickbullotta","2024-12-28T21:32:08.0540000+08:00","Pick a single data format (JSON based)

Pick an API pattern for the core functions (read/write, invoke/execute, query/browse)

Choose a common metadata format and a repository for your models and data structures 

Provide a CRUD API for that repository 

Select a current state store and a historical data store, but allow delegation of historical queries to an external source also 

Create both push and pull connectors","","üëç (1)"
"795178288330440704","youri.regnaud","2024-12-28T21:54:52.9990000+08:00","Do you think that metadata and the model should be managed and structured in an agnostic solution? A bit like a ""schema registry"" (Kafka) Which Market tool do you think comes closest to these best practices?","",""
"867075936054149191","rickbullotta","2024-12-28T22:14:59.5930000+08:00","Absolutely. The model is an important abstraction layer as well.","",""
"867075936054149191","rickbullotta","2024-12-28T22:16:16.3740000+08:00","I also think that the model should support basic OOP principles. Types, inheritance, polymorphism, etc.","","üëç (1)"
"568913935147728896","zeratall","2024-12-28T22:30:21.6500000+08:00","The separation of concern for data modeling and governance (including metadata) from other platform functionality such as visualization, analytics, notifications, is why DataOps is so popular and why we have and seen an increase in products like IH, Rhize, etc, Industry collectively has determined that there should be a node with that single responsbility.","",""
"795178288330440704","youri.regnaud","2024-12-28T22:50:11.3100000+08:00","We‚Äôre early adopters of HighByte and Rhize. Both platforms are quite good when it comes to abstracting services for reading or querying data. However, they‚Äôre much less capable when it comes to executing actions on devices. Should I rely on these platforms to evolve in this direction, or take an agnostic approach instead?","",""
"568913935147728896","zeratall","2024-12-28T23:01:31.1700000+08:00","That is a very good question, my take is I'm hoping for the former, but if the use case doesn't really make sense to implement in the platform in its current state I'm building my own services (luckily I haven't had many of these where I needed to do a bunch of development).

The issue really comes down to how much complexity are you and your org ready to handle, as things go more distributed you add a lot of complexity, Your trading flexibility for complexity. There's a balance there and its going to be different for every org based on their maturity.  That's why I'm hoping the DataOps platforms will move into that are, I'm okay breaking out datamodeling/orchestration into its own node, but I don't want to have a dataops tool for devices and a dataops tool for services. 

That balance in complexity is why platforms were so popular a few years ago, they were your traditional monoliths.","",""
"867075936054149191","rickbullotta","2024-12-28T23:02:57.7890000+08:00","The work that Aron and crew at HighByte are doing to allow you to expose flows as APIs is super interesting to me.  Have you talked to them about it?","",""
"795178288330440704","youri.regnaud","2024-12-28T23:48:35.8040000+08:00","Yes of course! The point is how organize this API Flows around ¬´¬†a thing¬†¬ª","",""
"795178288330440704","youri.regnaud","2024-12-28T23:54:15.9570000+08:00","The good news is that with these platforms we have many options to support the business. The question is always how to find the balance between solving a use case and building a scalable ""platform"" or ""stack"".","",""
"817835202746253344","IIoT#4707","2024-12-29T01:05:40.9890000+08:00","","",""
"795178288330440704","youri.regnaud","2024-12-29T01:56:17.9060000+08:00","Can't we deactivate this thing! There's enough human intelligence in this community üôÇ","","ü§£ (1)"
"766684226455207996","bright_hummingbird_31342","2024-12-29T03:03:15.8490000+08:00","@Zack Scriven This has happened to me as well. The spam detection is very sensitive. It does not like any messages in with a common sequence of characters. List, code snippets, etc trip it. I‚Äôve had to alter messages for it to accept.","",""
"1214242167640424619","zack.scriven","2024-12-29T03:04:43.0670000+08:00","It‚Äôs our tightening down for the restriction of bots","",""
"1214242167640424619","zack.scriven","2024-12-29T03:05:20.0860000+08:00","This was a direct response to @RickBullotta complaint about bots. False positives were the thing we were concerned about and hence why we didn‚Äôt have it stricter before","","üëçüèº (1)"
"1214242167640424619","zack.scriven","2024-12-29T03:05:24.1610000+08:00","We will make a note of it.","",""
"1214242167640424619","zack.scriven","2024-12-29T03:05:53.1960000+08:00","can remove duplicated text from the restrictions. @Vaughn Turner","","üëç (1)"
"1073632885153730621","vaughnturner","2024-12-30T23:28:30.4540000+08:00","This has been done.","","‚ù§Ô∏è (1)"
"867075936054149191","rickbullotta","2024-12-31T00:16:14.3260000+08:00","Now I can post the comment I wanted to make.  In ThingWorx we had a well defined pattern for accessing/querying/invoking/updating things and their properties/services, including current and historical values.  Results can be returned JSON, XML, binary, or human friendly HTML

GET /Thingworx/Things = list things (with optional query expression to filter the list)
GET /Thingworx/Things/<ThingName> = summary information/metadata about a thing
GET /Thingworx/Things/<ThingName>/Properties = list of properties and their metadata
GET /Thingworx/Things/<ThingName>/Properties/* = current value(s) for all properties
GET /Thingworx/Things/<ThingName>/Properties/<PropertyName> = current value for a specific properties

POST /Thingworx/Things/<ThingName>/Properties/* = update value(s) for one or more properties
POST /Thingworx/Things/<ThingName>/Properties/<PropertyName> = update value for a specific property

POST /Thingworx/Things/<ThingName>/Services/<ServiceName> = invoke service with optional input parameters and returned value(s)

Note that querying history for propert(ies) is done as a service call

POST /Thingworx/Things/<ThingName>/Events/<EventName> = fire event with optional event parameters

There are also a bunch of other variants on this for more detailed metadata, permissions, configuring things, etc...

And there is a very sophisticated query API that lets you query the entire namespace blending values, metadata, types, etc...","","üëè (6)"
"794020366536146977","mparris","2025-01-01T16:28:20.8090000+08:00","I believe this is the intent with the CESMII API:

https://github.com/cesmii/API

@youri.regnaud I'm curious to hear your thoughts on how much overlap you see here...","",""
"867075936054149191","rickbullotta","2025-01-02T01:27:51.1110000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1324066573601734706/image0.jpg?ex=68df5ed7&is=68de0d57&hm=7cf8def4f710033037e398c81824c98cdae136479a03352c29778bd3c5557cd6&","üòÇ (3),üòÜ (1)"
"794020366536146977","mparris","2025-01-02T02:03:04.6400000+08:00","""... that covers everyone's use cases.""

That was the folly of OPC UA","",""
"867075936054149191","rickbullotta","2025-01-02T07:28:05.5840000+08:00","Perhaps, but in 2006 it was a real opportunity","",""
"795178288330440704","youri.regnaud","2025-01-03T14:17:36.7310000+08:00","Thank you for this information. I'm a fervent sponsor of OT/IT convergence to ensure that Manufacturing is fully integrated into the enterprise and the supply chain. When I see the various protocols and patterns in the IT world, such as GraphQL, REST, SOAP, ... EDA, Event Sourcing, Webhook, ... API Facade, ... I tell myself that, in the end, everything already exists, but that we need to ""force"" ourselves to apply these best practices in the industrial world. I see a convergence in the various exchanges between the need for UNS (DataOps + EDA), with the need to historicize data and their contexts in polyglot architectures (Graph, Vector, Time Series, ...) add to a simplification/uniformization of access to this data, whether in real time or historical. I'd like to add that the promises of AI cannot be realized without the progressive construction of a Knowledge Graph, which implies working on ontology, for example. I like Thingwork's initial approach, where we have to imagine each machine as a ""thing"" that exposes data, metadata, services, etc. Even if doing so requires a certain amount of complexity, the end result should be as simple as that.","","üëç (1),üíØ (1)"
"867075936054149191","rickbullotta","2025-01-03T20:04:13.3720000+08:00","The other key piece of the puzzle is exposing a meta model that describes the relationships between ‚Äúthings‚Äù.  In retrospect I also would have modeled processes and the ‚Äústuff‚Äù that goes through processes (production orders, maintenance orders, etc).","","üëç (2)"
"795178288330440704","youri.regnaud","2025-01-03T20:06:49.7140000+08:00","The more we work with Rhize, the more I see these relationships becoming a reality through the joint use of the ISA-95 object model and GraphDB/GraphQL","","üëçüèº (1),‚ù§Ô∏è (1)"
"1154812895457185812","rutger_18900","2025-01-03T22:47:07.0230000+08:00","StuffWorx‚Ñ¢","","ü§£ (2)"
"867075936054149191","rickbullotta","2025-01-03T22:50:37.2740000+08:00","I actually wrote a spec for it at one point!","","‚ù§Ô∏è (1)"
"794542235676180500","akoscs","2025-01-13T16:25:38.0010000+08:00","Has anyone used Zenoh at scale (5k endooints) https://zenoh.io/","",""
"795178288330440704","youri.regnaud","2025-01-14T01:54:39.2800000+08:00","@diogo_brandao You can start from here exchange around command/factory API","",""
"795178288330440704","youri.regnaud","2025-01-14T01:55:26.5020000+08:00","I missed your message Geoff! With pleasure","",""
"230441548653789184","r.pop","2025-01-17T00:20:11.7390000+08:00","We are working on something similar for a customer and using GraphQL (Neo4j) as the relationship manager, but it feeds us back with API endpoints that have the data we're looking for.","",""
"693309801589112862","_dyland","2025-01-17T00:24:29.1880000+08:00","Out of curiosity, are you using the Neo4j_GraphQL library or building out your own backend service with a GraphQL endpoint?","",""
"230441548653789184","r.pop","2025-01-17T00:32:33.8620000+08:00","Library","","üëç (1)"
"568913935147728896","zeratall","2025-01-17T01:51:04.5270000+08:00","Having something like GraphQL that returns an endpoint is different then an API gateway that abstracts typical gateway functions such as routing, etc from the client though? They typically work together but they have different responsbilities, unless I‚Äôm missing something?","",""
"475955754788978688","jdingus","2025-01-17T01:58:34.7060000+08:00","Didnt the added phone verification likely take care of the spam situation?","",""
"817835202746253344","IIoT#4707","2025-01-17T01:58:34.9310000+08:00","GG @Josh Dingus, you just advanced to level 11!","",""
"230441548653789184","r.pop","2025-01-17T02:21:11.5590000+08:00","Correct. Typically together, though for us we built the routing in Ignition","",""
"568913935147728896","zeratall","2025-01-17T02:24:31.1410000+08:00","Yeah that makes sense, kind of what I figured you guys might be doing, I would love to pick your brain on that sometime. I find myself very divided on low code vs bespoke when talking about adopting more of these modern design patterns and bringing them over to OT.","",""
"230441548653789184","r.pop","2025-01-17T02:26:41.2620000+08:00","Any time","","‚ù§Ô∏è (1)"
"1296382727582515276","erry1ne_36260","2025-01-31T20:54:27.6600000+08:00","Actually, you can do both. You can both read dynamic/telemetry data and go to read or exchange data with other systems (MES, Historian, ERP). They call these Non-IIoT flows. There is also the possibility to create ML flows to be executed on edge devices (never tested). As for the fees, you pay based on the number of tags you use, as well as the number of active Non-IIoT flows.

The usage is quite simple. It really is a Low-Code / No-Code platform. There's always the option to write code in both Python and C#. Excellent support and, from personal experience, they are also responsive in implementing new features. Use cases tested so far:

- Reading dynamic data mainly from Siemens S7, Allen-Bradley, Rockwell, Schneider (Modbus), and OPC-UA, both in MQTTS and HTTPS. Tested on both Linux and Windows OS (we had some issues with a module sending to IoT Core, promptly resolved in 2 weeks). It runs on Docker, which is great for those like us who wanted a hardware agnostic solution. This way the customer can decide to use one of the gateways we offer or a VM or industrial PC
- data acquisition and transformation from and to ERP/Historian (mainly tested for outbound interfaces). Tested on PI (if I'm not mistaken, there is a native module, so it's just configuration), SQL Server (native), and soon we will test it on S4 Hana","",""
"1088631859509989426","jpmac.s","2025-02-03T18:24:51.0370000+08:00","Hi All,

I have an architecture question regarding setting up a multi-site SCADA (Ignition) system.

I have a client with 40 sites, each with ~3,500 tags, and each site will have dashboards for:

EMS
BMS
LCS with DALI/KNX connector
Sustainability Dashboard
Enterprise server overview of their sites at HQ
Each site has a dedicated OT network with a 4G modem for remote access, and all servers will be on-prem for each site.

My questions are:

Does each site need a historian, or can I just transmit the data to the Enterprise server?
I was thinking this would be a good use case for converting OPC UA to Sparkplug B‚Äîthoughts on that?
Any suggestions for converting DALI/KNX to MQTT?
Should the enterprise server be hosted in Ignition Cloud or on-prem at HQ?
I know there are a lot of variables in this overview, so the answers will likely be ""it depends,"" but I‚Äôm working with limited details until the NDAs are sorted. Any best-guess recommendations would be appreciated.

Thanks!","",""
"1073312001788477471","sparkylarks","2025-02-03T19:53:19.1180000+08:00","Well, as you say It depends.

Do the 40 sites already have a SCADA (Ignition)on site?

If the do I would
I would probably build a system with
- Ignition on each site publishing to a site Broker
- Local Ignition Historian for local historian stuff

- Publish the relevant subset of data to a historian cloud Broker
- Historize that in the Cloud
- Build my dashboards in that.

But If you want to have Enterprise Dashboards, I don't know if I would use Ignition as that Central Platform? Especially if you are looking at a different historian,

I would certainly not have a single Ignition historian on a VM somewhere looking to try to be an enterprise historian?

If you don't have Ignition already in each site, I am not sure if it is the best tool , unless you have more use cases? to me in particular where you need to do actual control. In that Case there are probably better options to do central dashboarding.

Litmus & Tulip ?? 
Listo's Agad Portal ?
Just build Google Cloud Dashboards?


Sparkplug?? IF you have Ignition in each plant, then converting to Sparkplug might be useful ,or if you have bandwidth concerns, absolutely.
But I would probably look to have a MQTT based broker, one per site and an enterprise one probably and use Vanilla MQTT","","üëç (1)"
"1088631859509989426","jpmac.s","2025-02-04T04:08:58.0630000+08:00","Thanks Mark,

The sites only have BMS systems, they are looking for a SCADA for each site, 1st stage wont have any control just connecting to gather data on each site. 

I was thinking of using the EAM at HQ to monitor all sites and have a central dashboard.

Tossing up if i should use TimeBase , TimescaleDB or Ignitions historian.

Im guessing this setup will push into a paid tier of MQTT broker, Any thoughts on what to use?","",""
"751492163233382430","andyott33","2025-02-04T04:22:58.3010000+08:00","Will each site be using Ignition edge and the HQ using standard Ignition? If so, maybe you could find a KNX to OPC UA converter/gateway and bring in the OPC UA to Ignition that way then using Ignition Edge Transmission publish to the main system?","",""
"1088631859509989426","jpmac.s","2025-02-04T04:27:47.0720000+08:00","I did concider using edge but the session limit and 2 PLC limit will  prohibit that option. Each site will have its own Ignition server.

 I had a similar thought with a conversion gateway to OPC, but what company? Cheers","",""
"751492163233382430","andyott33","2025-02-04T04:30:06.6120000+08:00","Where is this device limit (It used to be 2 but changed recently)? I think Edge is now unlimited devices?
https://forum.inductiveautomation.com/t/ignition-edge-licensing-unlimited-devices/83229
https://inductiveautomation.com/ignition/edge","https://cdn.discordapp.com/attachments/815945777452941313/1336071240116342894/image.png?ex=68dee0ce&is=68dd8f4e&hm=ada8160a920553a1b23be2db09de2c4e8e7fd38d5cfc3174a1787ab8f8ba9c48&",""
"1088631859509989426","jpmac.s","2025-02-04T04:37:22.0490000+08:00","Interesting i wasn't aware of that , thanks. The session limit is still an issue. It might be okay for the smaller sites.","",""
"751492163233382430","andyott33","2025-02-04T04:38:16.0070000+08:00","Ahh gotcha, ya only 2 sessions would be limiting","",""
"1088631859509989426","jpmac.s","2025-02-04T04:40:24.7130000+08:00","But if it turns out they dont need more its a cost effective soultion!","",""
"1088631859509989426","jpmac.s","2025-02-04T04:45:50.2650000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1336075197757001738/image.png?ex=68dee47e&is=68dd92fe&hm=3e5c82b992700e6094f6245920ec3887ad12c3aaa7dfec14665fbaffb5c6dc7d&","üíØ (1)"
"751492163233382430","andyott33","2025-02-04T04:47:07.5980000+08:00","Ya perhaps a different use case for us then. For one project we are using Ignition Edge at the well sites with a central server at HQ. EAM is nice for pushing tasks/resources. We initially used GAN but it was a bit slow and moved to MQTT. We created a new tag provider with reference tags that is used for historizing and creating the namespace. We are also testing bringing the alarms in via MQTT to see if that reduces the load on the GAN. For this project we use MQTT Distributor Plus from Cirrus Link.","","üëå (1)"
"693309801589112862","_dyland","2025-02-04T07:40:35.4960000+08:00","I mean, Edge was really their way of competing with traditional HMIs. 

Edge Panel being limited to 2 sessions of Vision or Perspective is still well above the competition in its price range for an HMI. 

It's a drop in replacement for a PanelView for example. And usually cheaper... 

Edge IIoT is another story, with 0 sessions. Basically competing with the edge gateways. 

If a proper SCADA system is what's needed then they want you to purchase their SCADA license.

Similar reasoning for the limitations of restricting the database connectivity.

That said, it's a very powerful tool for its price.  Unlimited Device Connections, Transmission Module, and Web Dev baked in. 

Having used Edge standalone without a central gateway it can still be a really great tool but it is def made to extend the main product, not replace it.","","üëç (1)"
"693309801589112862","_dyland","2025-02-04T07:41:06.4790000+08:00","And the current pricing model is way nicer than the old one they had a few years back","",""
"1088631859509989426","jpmac.s","2025-02-04T07:58:51.8350000+08:00","Couldn't agree more! its a horses for courses situation.","","üíØ (1)"
"1088631859509989426","jpmac.s","2025-02-04T13:14:53.0760000+08:00","so, I have more details they need control as well as monitoring for each site.","",""
"1073312001788477471","sparkylarks","2025-02-07T05:56:50.3040000+08:00","Ignition so , Unlimited licence you can probably get away with the Ignition Historian.
- if you go with a site broker approach, I would ass in time Scale( or time base) and you can use that to allow IT folks access something they are more familiar with for any dashboards or reports they need.                                                                                           
                                                         
so sort of     PLC ‚Üí Gateway‚Üí UNS‚Üí Historian
                                                      ‚Üì
                                              TimeSeriesDB

That architecture , is what I plan to write about in LinkedIn tomorrow, I wrote a few posts about historians and ""blew up""ü§∑ 

I would certainly recommend a Historian for Plant Maintenance people available on site, but you might need something more powerful at the Enterprise Level.  Not sure if Ignitions historian woudl manage it well. Canary could for a price, but , your more likely to be using Business tools at that level so Time Series I think is fine. I know you can put Ignition in the Enterprise server ,but is that the best approach?

I'm not sure where timebase fits in, certainly it could replace the Ignition , plant one. I don't know if that is a good idea, 
If I had a 40 plant initiative, I would try it out at the first one, Ignition in the second and see how they go","","üëç (1)"
"1088631859509989426","jpmac.s","2025-02-07T06:01:21.1840000+08:00","Cheers Mark, the two sessions is perfect for them, so edge will be used on site with an Ignition cloud at the enterprise. Need to check if TimeBase can run in the cloud","","üî• (1)"
"898217314741280828","hobbes1069","2025-02-07T06:43:11.9340000+08:00","Timebase is container based so kind of ""cloud ready"" be default. I'm currently testing it out though on a RHEL 8.6 server running the full stack on one machine. Working fine for testing purposes but might break things out in production. 

I'm really looking at Dell Native Edge at ProveIt! to see if that's a potential way to run the collectors and then have the historian run in the cloud.","","üëå (1)"
"1088631859509989426","jpmac.s","2025-02-07T06:53:43.8260000+08:00","Let me know how you go.

 Ive never used docker in a production environment so I would be nervous doing it for such a big client.","",""
"817835202746253344","IIoT#4707","2025-02-07T06:53:44.1370000+08:00","GG @Josh Mac, you just advanced to level 12!","",""
"580888289171734559","jamesgresql","2025-02-11T16:05:09.6620000+08:00","Containers in production is a double-edged sword. Well and truly a solved problem now, but the trade-off is Kubernetes (or whatever scheduler you use) will be the most complex and opaque thing in your stack.","","üëç (1),üíØ (1)"
"794020366536146977","mparris","2025-02-12T11:00:49.0850000+08:00","We use containers to run level2 processes on the plant floor.

They are the way of the future. With traditional apps, think of the effort it takes to get back to a ""clean install""? With containers, that can happen every restart if you want... Which is also the danger in containers üòâ

Also, the upgrade/ reversion process is unmatched","","üíØ (1),üëç (1)"
"1073312001788477471","sparkylarks","2025-02-12T14:35:22.0740000+08:00","What Applications. Home built or something COTS

I love containers but don't need to get back to a clean install that often","",""
"794020366536146977","mparris","2025-02-12T15:23:13.5000000+08:00","Both COTS (broker, database, monitoring, management, etc) as well as home grown applications

Starting with a clean install is actually too narrow is a use case. It's actually that docker allows you to start the container/application to a known state. With applications installed on a bare metal PC, that's harder to do with all the potential interactions that are happening between that application and other application/other OS, etc","","üíØ (1),üëç (1)"
"1088631859509989426","jpmac.s","2025-02-12T16:16:01.5000000+08:00","How do you manage the memory increases? Using a historian for an example.","",""
"1088631859509989426","jpmac.s","2025-02-12T17:51:31.5560000+08:00","@RickBullotta do your thing","","üòÇ (1),ü§£ (2)"
"867075936054149191","rickbullotta","2025-02-12T23:32:47.8540000+08:00","I will help you douse yourself in gasoline and I‚Äôll light up a cigarette for ya. ‚õΩÔ∏è üî•","",""
"898217314741280828","hobbes1069","2025-02-13T00:38:16.4760000+08:00","Hopefully I did that right. First time to ban someone.","",""
"794020366536146977","mparris","2025-02-13T10:44:42.7450000+08:00","Docker can make use of the full disk that is available to the OS for storage. 

Could you describe this more?","",""
"1088631859509989426","jpmac.s","2025-02-13T10:48:18.7660000+08:00","I think you described it with what i was asking.","",""
"830193224504705035","marc.jaeckle","2025-02-13T23:56:40.8620000+08:00","Quick ChatGPT query:
- Lines of code Kubernetes: 1.5 million
- Lines of code VMWare VSphere (estimated): ""several million lines of code, potentially ranging from 10 million to 15 million lines of code or even more""
- Lines of code Linux kernel: 30 million

So in that stack, Kubernetes is probably the least complex part üôÇ","",""
"867075936054149191","rickbullotta","2025-02-14T23:10:26.7030000+08:00","‚Ä¶which you should never do.","","this (1)"
"794020366536146977","mparris","2025-02-15T02:33:06.1600000+08:00","","https://cdn.discordapp.com/attachments/815945777452941313/1340028060086304789/image0.gif?ex=68df6e22&is=68de1ca2&hm=a3dd441b6f69d744c4fcb164842ab92d00e8c9d1b8d8a5b1143b0327b7e7de14&","ü§£ (3)"
"1088631859509989426","jpmac.s","2025-02-15T04:14:58.4820000+08:00","Why?","",""
"867075936054149191","rickbullotta","2025-02-15T04:32:30.6320000+08:00","One hungry container can kill all of the others. Quotas plus monitoring and maintenance are essential.","","üëç (1)"
"867075936054149191","rickbullotta","2025-04-13T05:00:45.7290000+08:00","Just came across this gem - from *1989*.","https://cdn.discordapp.com/attachments/815945777452941313/1360721328360915115/DEC-BASEstarIntergrationPlatform.pdf?ex=68dee7fd&is=68dd967d&hm=5156d0991a21f774f3fae83e19768de88b2191acda4ad0b3516e117d6fc1ca7f&","üî• (2),üëè (1)"
"528668306690015284","vatsalshah","2025-04-13T22:35:42.1310000+08:00","Same concepts, approaches and expected outcomes. Only tech changes!","","üíØ (1)"
"867075936054149191","rickbullotta","2025-04-25T20:58:09.2360000+08:00","Looks like the future of NAT is very much in jeopardy.  It seems like it would be risky to utilize it right now:

https://www.cncf.io/blog/2025/04/24/protecting-nats-and-the-integrity-of-open-source-cncfs-commitment-to-the-community/

Reminds me of the OPC lawsuit many years ago.  Synadia should be ""cancelled"" for this stunt.","","ü§î (1),üíØ (2),üòÆ (1)"
"783917475128410112","geoffnunan","2025-04-25T21:30:36.5490000+08:00","Risky indeed!","",""
"1073632885153730621","vaughnturner","2025-04-26T01:18:42.5940000+08:00","Synadia showed their hand.","",""
"1214242167640424619","zack.scriven","2025-04-26T02:14:48.6390000+08:00","UNS","","üíØ (1)"
"528668306690015284","vatsalshah","2025-04-26T03:35:06.3770000+08:00","It is going to be interesting how this fight pans out.","","üíØ (2)"
"693309801589112862","_dyland","2025-04-26T05:50:12.8980000+08:00","https://www.synadia.com/blog/synadia-response-to-cncf

Will be fun to see how this plays out.","","üëç (1)"
"867075936054149191","rickbullotta","2025-04-26T23:33:16.6770000+08:00","Switching to BSL after a couple years of a true open license is evil and wrong.  It's a bait and switch.  If a vendor wants to put a project under BSL, do it from day one.","",""
"693309801589112862","_dyland","2025-04-26T23:35:05.2450000+08:00","Doesn't it leave the old version in tact though? Maybe that's what I am missing? What's stopping the development community from forking this version? 

Not sure the licensing side but it doesn't feel that different from MySQL and MariaDB?","",""
"528668306690015284","vatsalshah","2025-04-27T00:12:57.2170000+08:00","The way i understood is that they are creating an additional version with BSL . No one should be affected. 
They very well should create a BSL version and get sustainable as a company.","",""
"693309801589112862","_dyland","2025-04-27T00:13:57.2200000+08:00","This was my understanding too...","",""
"693309801589112862","_dyland","2025-04-27T00:14:30.8130000+08:00","I think that CNCF has a lot to lose though if they let NATS pull out - this smells political to me.","",""
"528668306690015284","vatsalshah","2025-04-27T00:17:46.3640000+08:00","Their CEO is getting death threats as per his LinkedIn . That is beyond unacceptable. Hopefully they are doing okay.","","üíØ (1)"
"693309801589112862","_dyland","2025-04-27T00:18:25.2980000+08:00","Yeah - That in my eyes is ""Evil"". Far less so than any licensing change...","",""
"693309801589112862","_dyland","2025-04-27T00:18:44.8470000+08:00","I hope him and his family are able to stay safe.","","üíØ (4)"
"867075936054149191","rickbullotta","2025-04-28T20:16:44.2400000+08:00","Except the features in the BSL version will not show up in the open source version for 2-4 years, and some are somewhat essential features.  Anyway, I think the whole thing was handled so poorly.","","üíØ (2)"
"1073632885153730621","vaughnturner","2025-04-28T22:25:59.9630000+08:00","Agreed, I think the bigger thing here is the way it was handled. When reading both pressers, it's clear that CNCF is feeling like the rug is getting pulled. Synadia has every right to as they still own the IP as to my knowledge, at least they still do on the USPTO website, but it doesn't look good for Derek Collison's leadership","",""
"528668306690015284","vatsalshah","2025-04-28T22:28:49.9650000+08:00","Yeah that might be the case, but the existing NATS server and Streaming server + all other addons (queue, monitoring, clients) are more than enough and probably 5x number of feature sets of any MQTT server out there : ) 
Not defending their actions of license bait and switch but it's not end of the road for them either. If CNCF lets this happen, people will lose trust in them, and that's a bigger problem.","","üíØ (2)"
"693309801589112862","_dyland","2025-04-28T22:29:43.0650000+08:00","CNCF appears to have a lot more on the line than NATs does in this fight.","",""
"867075936054149191","rickbullotta","2025-04-28T23:59:12.1890000+08:00","That guy appears to be very, very wealthy BTW.","",""
"1073632885153730621","vaughnturner","2025-04-29T01:00:55.0870000+08:00","I thought so, just from what I saw of his background","",""
"873009180938743828","sim_sam3","2025-05-01T07:27:29.6440000+08:00","Solaia, one of the original patent trolls! 

https://www.controlglobal.com/home/blog/11363628/solaia-loses-rockwell-winswhat-does-it-mean","",""
"937881104575238154","reuelstaples46112","2025-05-06T09:09:39.9590000+08:00","When I got connected to a CESMII architect and asked them for reference documents or materials on their proposed platform they sent me to some YouTube videos with a couple hundred views. Does anyone know of a better place to read about their approach?","",""
"522568576830537729","codepoet80","2025-05-06T21:04:51.7770000+08:00","CESMII doesn‚Äôt really do reference architectures - we aren‚Äôt that prescriptive. Every manufacturer is different, and we don‚Äôt/can‚Äôt require specific software.

You probably saw a reference *implementation*, ThinkIQ. Other implementations are in-progress. A reference implementation addresses the three technical imperatives:
1) exchangeable information templates, which CESMII calls Smart Manufacturing Profiles. You can learn about those here:
https://github.com/cesmii/SMProfiles
2) knowledge graphs. This is a ‚Äúsoft‚Äù imperative to get platform vendors (and their customers) to move beyond hierarchical organization of data
3) a common, rich, modern API for all kinds of data. You can learn more about that (evolving) initiative here:
https://github.com/cesmii/API","",""
"937881104575238154","reuelstaples46112","2025-05-11T01:00:58.5580000+08:00","Thank you  @Jonathan Wise for the very thorough and helpful answer, and for framing the question differently. I‚Äôll read into these more before asking any clarifying questions. I appreciate you!","","‚ù§Ô∏è (1)"
"867075936054149191","rickbullotta","2025-05-29T21:00:38.8190000+08:00","Kind of cool new capability in Influx 3: embedded Python.

https://www.infoworld.com/article/3992458/influxdbs-new-model-for-time-series-workloads.html","","üëç (4),ü§î (3)"
"829502128191045652","joshuastover","2025-08-04T20:34:18.8840000+08:00","## QOTW ##

# What‚Äôs your biggest frustration when trying to integrate REST APIs into OT environments? #

@everyone RESTful APIs are everywhere‚Äîbut in OT environments, it‚Äôs rarely plug-and-play.
From inconsistent schemas and vendor-specific quirks to authentication headaches and firewall policies,
bridging the gap between modern interfaces and legacy infrastructure can be‚Ä¶ painful.

What blockers have you run into? And how did you work around them (or not)? Let‚Äôs hear the gritty details.","",""
"867075936054149191","rickbullotta","2025-08-04T20:57:07.8680000+08:00",""" inconsistent schemas and vendor-specific quirks to authentication headaches and firewall policies"" - that pretty well sums it up!","","üëç (5),üíØ (5),üòÇ (2)"
"657361690379288596","du5tins","2025-08-04T21:25:48.5760000+08:00","Legacy platforms really have little support for http calls and API. Doing API calls and auth (particularly oauth2.0) using vbscript suuuucks if you can do it at all (somewhat platform dependent).","",""
"448323303598325812",".killnine","2025-08-04T21:32:34.3440000+08:00","1. **""REST API""**: Vendors use this term but few actually are writing true, RESTful APIs. At best, it's an approximation, but if you're integrating a dozen APIs from different vendors, keeping those differences internalized is a really hard job. Each API is going to have quirks. If you have a software development team that can help, sometimes you can trade off velocity for consistency by having them proxy the calls with a more consistent API. It will slow you down potentially, but can help make sure your organization has consistent conventions for authz, verbs, etc.

2. **Schemas/Versions**: The double-edged sword of web APIs is that they're flexible. If you're looking for a _contract_ between your system and the API, there's other technologies that can be better in that respect. (gRPC, GraphQL, WCF). Keeping clients in sync can be challenging as an API matures. Some vendors or internal teams have a very loose concept of versioning APIs (to be fair, it's challenging), so that leads to breaking changes unless they're careful.

3. **Testing**: Many vendors don't supply sandbox environments unless you want to pay for a whole separate instance. That leads to either testing on prod, or not testing at all (well_do_it_live.jpg)

4. **Error-Handling**: This hits on both sides of the fence. Equipment / Edge don't handle issues consistently (ex: auth issues, how are those exposed when there's problems?). Similarly, vendor APIs sometimes avoid exposing too much debugging info when errors happen but also don't surface useful errors to know how to address issues. That means tickets into the vendor and slowing down until it's resolved. 

FWIW - I rarely have edge devices do any calls directly to vendor APIs. Almost everything is wrapped in an org-internal service/api so I can better handle errors, log, and control flow. It's a tradeoff.","https://cdn.discordapp.com/attachments/815945777452941313/1401920754483859477/giphy.png?ex=68df27b2&is=68ddd632&hm=e1cb056c7fc9fdd4b2d0dbef54a9a4b8baa440390ef626760ba0a7a19429ff42&","üí° (2)"
"873009180938743828","sim_sam3","2025-08-04T21:39:56.1550000+08:00","A stable surface for constant reinvention.. 

.. of the same wheel.","",""
"825084676066246677","anibalvelarde","2025-08-05T00:14:01.0430000+08:00","Apologies if this was asked and answered already, but for workloads at the edge (running at the plant floor) are you using any container orchestration or VMs, actual PCs?

Did you start with an approach or did it evolve?  And how was the journey to get IT on board with the current state?","",""
"447990348204212224","b_dawg_17","2025-08-05T01:33:44.0060000+08:00","Definitely a **lack of documentation** on how to use the API is my biggest headache. I‚Äôll often have to reverse engineer how I think I should use it based on patterns and conventions I see elsewhere.

A less often but more annoying problem is when they change the API without telling you üëÄ","","üíØ (2),üî• (1)"
"766684226455207996","bright_hummingbird_31342","2025-08-05T07:32:48.2140000+08:00","Exposing database procedures or internal methods designed for UIs as APIs.

These aren't intent-based. They're usually some sort of generic interfaces that, more-or-less, thinly wrap the CRUD operations on database objects. The problem is that what seems like one thing as a user (e.g., Part/SKU) is actually like a handful or more of normalized tables. Accomplishing simple transactions to run operations (e.g., record production, move inventory) can require sequencing/looping through multiple endpoints. It becomes more like building a new frontend with business logic than bridging systems. The APIs don't abstract much and require deep knowledge of the underlying resources.

This isn't really an OT problem per se. Enterprise/B2B software can be extremely configurable. It can be tough to nail down API patterns that work in all scenarios. It's not unusual to encounter this in accounting, hr, supply chain, crm, shipping/receiving, etc integrations.","","üíØ (1),ü§î (1)"
"1355423226955694080","wolfgangpu_31887","2025-08-12T03:33:19.1000000+08:00","Large scale deployments

Does anyone have a good example/reference for a large deployment 
- UNS with 2.5 million nodes (pure iot sensors from multiple factories across all continents
- about 150k events per seconds 
- about a few peta bytes datalake
- partly low latency 90% < 5 seconds
- best deployed arround AWS
- fully integrated change process (validated) for the namespace based on ISA 95 / ISA 88 equipment model but also additional for process and batch model
- knowledegraph support to link it together and add it with CMMS, EIMS data","",""
"957775996856180737","evjakec","2025-08-12T04:17:59.6780000+08:00","My answer is no regardless, but how many factories? Assume each factory has a plant level UNS and you want to roll up to one global UNS?","",""
"528668306690015284","vatsalshah","2025-08-12T04:40:08.9030000+08:00","Yeah we have a few examples of something similar. 
2.5 MM nodes or topics? What's the throughput of 150k events? How many plants or are these remote assets? Knowledgegraph for what?","","‚ù§Ô∏è (1)"
"1355423226955694080","wolfgangpu_31887","2025-08-19T00:47:20.4850000+08:00","30 factories, yes one global uns to be historized in a data lake for 10 years","",""
"1355423226955694080","wolfgangpu_31887","2025-08-19T00:48:34.7200000+08:00","2,5 sensors   ... 150k events  per seconds","",""
"230441548653789184","r.pop","2025-08-19T02:41:07.2500000+08:00","AWS, but is there any local compute?

Multi-broker deployment is likely the play, broker per site, then enterprise broker.","",""
"230441548653789184","r.pop","2025-08-19T02:44:52.9080000+08:00","If you're energy something like this:","https://cdn.discordapp.com/attachments/815945777452941313/1407072779810897940/image.png?ex=68df70e4&is=68de1f64&hm=dd89fb3e81ff79f2f66924ddd928f62b96701f877e5c2edc51e1cbe5f17b8b59&",""
"230441548653789184","r.pop","2025-08-19T02:45:58.7810000+08:00","generic factory architecture:","https://cdn.discordapp.com/attachments/815945777452941313/1407073055993237566/image.png?ex=68df7126&is=68de1fa6&hm=8cee9fb1a35c65c9db6d8799f69416dde30cad0919fc83d1bfe187759a117759&","üëç (1)"
"528668306690015284","vatsalshah","2025-08-19T07:41:30.5610000+08:00","Yehh if the goal is go central 
1.  One Edge Aggregators each site - should be able to handle 80-100k sensors (tags)/second 
2. Use Edge-to-Kafka 
3. Kafka to Datalake that you are looking for.

150k events/second would be fine for any Kafka or Pubsub or most MQTT brokers.","",""
"528668306690015284","vatsalshah","2025-08-19T07:43:50.0610000+08:00","Avoid messy broker-to-broker layouts. They add limited to no value unless you have MQTT apps you are consuming from it at every level.","","üíñ (1)"
"1355423226955694080","wolfgangpu_31887","2025-08-19T13:03:20.0770000+08:00","The question has someone done this with this size ... size adds complexity for example to store it into a datalake you need to have a path to id table which is already 250mb big ... this needs to used at every message to find the ID. 

And this happens on both sides.. so maybe mqtt is maybe not the way to go because it becomes very inefficient 

Some brokers have limits - are there are actual examples where this is done at the scale

We are using aspentech dataworks for integration on the site level but also a global integration node but the question is now how to hand it over to the IT world (datalake, realtime snapshot)","",""
"230441548653789184","r.pop","2025-08-19T18:24:30.3960000+08:00","Yes. I‚Äôll see if I can find the case study, but there is one for oil and gas of over 10M tags flowing from sensor/site and eventually to data lake.","",""
"867075936054149191","rickbullotta","2025-08-19T18:24:36.8670000+08:00","Both HiveMQ and EMQ have solutions for large scale MQTT architectures. Obviously there‚Äôs associated cost and complexity","",""
"230441548653789184","r.pop","2025-08-19T18:25:41.8080000+08:00","Also, all connected vehicle infrastructure is done over MQTT. Stellantis for example uses a white labeled version of HiveMQ for all their vehicle telemetry data.","",""
"446595721706078210","rooney101135","2025-09-17T17:06:16.7450000+08:00","What's a good reference-architecture for machine-level deployments where the oem wants to track and visualize their equipment across different sites?","",""
"495568599721967631","bytemage66","2025-09-18T14:16:30.3250000+08:00","I think a little more information would be good. Like what kind of machines? What do you have in mind?","",""
"1073312001788477471","sparkylarks","2025-09-18T14:34:31.9170000+08:00","Lets Build it out. The big questions at each step for me are
How many machines how many sites

1 - Connect : how similar are the machines and their data, i.e. if all the machines are turbines the data set and deployment can be very structured,
Where  on the machines in the data, PLC( are all PLC's the same) Database, CSV file etc. 
2:  Collect : Are you looking to go Machine -> OEM Cloud or are you leveraging the customer site infrastructure. 
 
Is there already a remote connection for maintenance etc. How sensitive are your customers to having an third-party connection to their infrastructure
3: Store: Where are you Storing your data? What is in the Customer Cloud.
4:  Analyse and Visualise - What do you want to do with the data, are you doing ML/PM, providing dashboards to the OEM, dashboards for customer, 

When you say reference architecture what are you expecting? Network Architecture showing the devices and VLAN and routing, System Architecture showing the software running in Devices, Information Architecture showing how information flows between software.

p.s. you should delete your question in the General thread as you will get better responses if they are all in one place.","","üëç (3)"
"446595721706078210","rooney101135","2025-09-18T15:19:20.5130000+08:00","We're system integrators and we've been doing controls for the last 25 years - I just started out with a background in cs + ml and I'm setting out to build data ops and IT to expand our offerings into visualizations, analytics, and AI systems.

I'm trying to understand architecture more generally, but I understand this would depend based on the type of customer (oem vs end user), type of machine and data, volume etc.

1. To start off with this case specifically, they make surface finishing systems with all of the data sitting in the PLC.  (All machines don't generate the same kind of data, but should be fairly simple to structure)
2. Start off with our cloud, providing access to the OEM as a tenant -> move to OEM/Customer cloud (based on the solution) when proven to scale.
3. There is already a remote connection for maintenance etc. The data is currently stored in an IoT device - no cloud infra yet.
4. Start off with dashboards for OEM - eventually build dashboards for customer. Once data infra is solid, build a service expert to capture domain knowledge + engineer know-how to aid the OEM in service.

When I say reference architecture - I want to understand best practices and what's used for collecting the data, contextualizing it and storing it in a production ready database: small deployments vs large scale executions (I've found more information about the latter).

I've been doing a lot of reading and experimenting with open-source, but thought this would be a better place to get pointed towards the right direction.","",""
"446595721706078210","rooney101135","2025-09-18T15:53:03.3740000+08:00","My bad if that was too broad.

From what I've understood: node-red to make flows and scenarios - mqtt to communcicate between systems - sparkplugb for unifying/contextualizing the data - timescaledb for storage, grafana for dashboards and AWS to host (Would you say this architecture is production grade?). HiveMQ seems like a great option for larger deployments, but is it overkill for a smaller deployment?","",""
"817835202746253344","IIoT#4707","2025-09-18T15:53:03.7730000+08:00","GG @Shreyank Hebbar, you just advanced to level 1!","",""
"1073312001788477471","sparkylarks","2025-09-18T16:05:36.0670000+08:00","It depends on Scale
If you want to connect a few machines, the MING Stack is great, mine currently is Node-Red, Grafana, HiveMQ CE, ( hive Edge would work nicely for you here too) and Tieme Scale DB, with Time Base historiant so a TTNGH Stack.  Currently connected to 6 machines , Everything hosted Locally but we a linking though a Hive Cloud Broker to a third Party ( [KyzenTree](https://www.kyzentree.com/)) building the Operator interfaces.

I have another system with a Node Red runnin on A siemens IIot  Device connected to some modbus Devices, and doing some local dashboarding, and with an OPC connection back to headquartes to integrate tin o Pi

I also have a CC7 from Siemens connected to PLC's and Modbus Devices publishing to a Cloud broker, very nice and secure if there are cyber concerns around connections.

For a fleet deployment, with 10's growing to hundreds of devices, I am looking at an FrameworX Edge running on an small IPC back to a cloud hosted Broker, and Canary with Axiom running Centrally

If I was looking at hundreds of machines, I would be looking at something like Litmus and building custom Rust dashboards

If you are at POC stage, I would say small PC running Node-Red and HiveMQ edge.  With TailScale for remote access. Or use Flowfuse I prefer that To be honest)
Node red connects to the PLC and publishes the data to MQTT( can go Directly to a Cloud Broker, or to a local one and Bridge it)
you could just connect with hiveMQ Edge and bride that to a Cloud Hive Broker and then use a cloud Node red.


What is your Cloud?","",""
"1073312001788477471","sparkylarks","2025-09-18T16:07:23.5980000+08:00","If you are really looking at scale in the future you could build you POC with the Developer version of Litmus, with the 2 hour trial, but you would need to know you are connecting to a lot of devices.

if you are a SI what platforms do you use, can you use Ignitoin Edge as the Connect and publish to your cloud?","",""
"446595721706078210","rooney101135","2025-09-18T16:20:40.7720000+08:00","This is super helpful, thank you!

No cloud infra set up yet, I was thinking AWS as I have the most experience working with it.

We're a Siemens channel partner, so mostly use everything Siemens.","",""
"1405866167494774886","chrismisztur_43648","2025-09-18T16:30:22.8140000+08:00","Will you also be looking at MES, ERP data to build context?","",""
"446595721706078210","rooney101135","2025-09-18T17:02:46.4140000+08:00","Not for this specific project, atleast with the outcomes we've discussed, MES or ERP data wouldn't really fit in, but in a more general context, yes for sure!","",""
"1073312001788477471","sparkylarks","2025-09-18T17:10:10.3430000+08:00","Siemens to AWS
https://www.siemens.com/global/en/products/automation/industrial-communication/industrial-ethernet/industrial-iot-gateway-simatic-cloudconnect-7.html
CC712 for one device about 800euro 716 connects to 7 device  about 1200 https://cache.industry.siemens.com/dl/files/675/109766675/att_1018360/v1/109766675_CloudConnect_AWS_DOC_en_V20.pdf

- Don't try to publish MQTT from the Simens PLC, its not great, and will drive you insane

Hive MQ to AWS very common approach too https://www.hivemq.com/solutions/the-best-mqtt-broker-for-aws/

or compleatly open source Mosquitto to AWS https://aws.amazon.com/blogs/iot/how-to-bridge-mosquitto-mqtt-broker-to-aws-iot/","","üëç (3)"
"446595721706078210","rooney101135","2025-09-18T17:18:46.1350000+08:00","I'll take a look at this, thanks","",""
