AuthorID,Author,Date,Content,Attachments,Reactions
"352642563255042059","takko_the_boss","2020-08-05T22:14:09.9260000+08:00","This is also where I need to be.","",""
"737819173631033454","faction2.0","2020-08-05T22:16:20.4410000+08:00","Does anyone have any good resources on cybersecurity best practices when using the cloud for ics applications? Ideally something a little more detailed than just saying “defense in depth.”","",""
"352642563255042059","takko_the_boss","2020-08-05T22:17:02.2360000+08:00","That's a good question.","",""
"352642563255042059","takko_the_boss","2020-08-05T22:18:51.7210000+08:00","Which solution are you entertaining @David Hoysan ?","",""
"352642563255042059","takko_the_boss","2020-08-05T22:20:29.8010000+08:00","You're talking like some sort of ""SCADA In the Cloud"" or ""HMI in the Cloud"" or something like that?","",""
"352642563255042059","takko_the_boss","2020-08-05T22:30:58.0980000+08:00","@David Hoysan 

So I spent a year and half researching, presenting at conferences and giving talks on how to conduct ""IT/OT Convergence"" in a secure manner.

During one of my talks I cover this topic at more length. At 26:37 of this video, I explain some solutions you can employ to enact a secure transmission.

https://www.youtube.com/watch?v=bUo3fj3HyZk&t=2631s","","👍 (1)"
"737819173631033454","faction2.0","2020-08-05T22:33:44.6950000+08:00","@MikeCurnow.com thanks! I’ll check it out","",""
"352642563255042059","takko_the_boss","2020-08-05T22:34:52.6370000+08:00","Full disclosure, this is me talking about the usefulness of a specific product/solution. But I besides the vendor-ey stuff, I think it'll be of value to you.

It's also presented to a group of listeners that wasn't ICS-Specific. So I tend to talk-high level here.","",""
"740395452842639441","sreni3799","2020-08-06T00:15:54.2070000+08:00","I just thought of bringing the topic which is not relevant to above topic
Digitization means .. equipments should be in the factory followed by io marshalling panels plus Gateways and rest all to be on cloud..
Like what all executions done by plc to be done at cloud except critical computing rest all to be moved to Cloud..
Hope Tesla one factory have such implementation","",""
"740395452842639441","sreni3799","2020-08-06T00:16:14.2020000+08:00","Please share your comments","",""
"194289793905983489","zackscriven","2020-08-06T00:43:47.6070000+08:00","thank you for adding value here @MikeCurnow.com","",""
"741044056154439750","heshr_","2020-08-07T06:20:00.8770000+08:00","Hi @MikeCurnow.com  would the topology you are describing on your webinar be similar to how Tosibox would work through their hardware offers.?","",""
"382941357699760129","walker.reynolds","2020-08-07T06:22:39.0100000+08:00","> Hi @MikeCurnow.com  would the topology you are describing on your webinar be similar to how Tosibox would work through their hardware offers.?
@HeshR  could you link the webinar here?","",""
"343452320216121345","hanno23","2020-08-07T14:47:02.1750000+08:00","Where does something like AWS IOT fit in? Is it best used when you are running your own unified namespace/ SaaS platform and want IoT capabilities (Or maybe AI/ML services)? Can it, for instance, be replaced by something like HighByte, or any other service that can function as a unified namespace platform that already contains the means for IOT communication?","",""
"353220715983536128","e0ph","2020-08-07T21:01:40.3480000+08:00","AWS offers a fairly complete stack","",""
"353220715983536128","e0ph","2020-08-07T21:02:01.2290000+08:00","i dont think they have a great solution for OPC data yet, but Greengrass supports modbus natively","",""
"711109466761986078","dostiharise","2020-08-07T21:11:42.6900000+08:00","You can do OPC failrly easy by deploying an edge lambda over HTTP with a python/nodejs OPC library. 

I have done with with our product.","",""
"711109466761986078","dostiharise","2020-08-07T21:12:16.9400000+08:00","I am referring to AWS GreenGrass","",""
"353220715983536128","e0ph","2020-08-07T21:12:37.6580000+08:00","right, you can pipe data to it from wherever","",""
"353220715983536128","e0ph","2020-08-07T21:12:54.8430000+08:00","by ""great solution"" i mean point it to an OPC server and select the tags you are interested in","",""
"382941357699760129","walker.reynolds","2020-08-07T21:13:09.9580000+08:00","> Where does something like AWS IOT fit in? Is it best used when you are running your own unified namespace/ SaaS platform and want IoT capabilities (Or maybe AI/ML services)? Can it, for instance, be replaced by something like HighByte, or any other service that can function as a unified namespace platform that already contains the means for IOT communication?
@Hanno The goal really needs to be getting the edge data into an IIoT transport protocol on the edge -- scaling really matters and is a huge hurdle in Digital Transformation... converting to IIoT in the cloud is too late.","",""
"382941357699760129","walker.reynolds","2020-08-07T21:14:26.4860000+08:00","That doesn't mean you cant use OPC to get SOME data to the cloud, but that can't be the foundation of the architecture -- the payload is too verbose.","",""
"352642563255042059","takko_the_boss","2020-08-07T21:18:27.7650000+08:00","> Hi @MikeCurnow.com  would the topology you are describing on your webinar be similar to how Tosibox would work through their hardware offers.?
@HeshR *Kind.................of*.  Sorry for late reply. I realized I like this Discord Server a **lot**, and if I don't get off of it, I will do nothing but sit and talk on here.

So from very far away, they do look familiar. However Tosibox is industrial VPN who's firewall/gateway mechanism is outside of the OT's LAN. However the thing I talk about in the webinar is a mechanism that sits *inside* of the LAN, meaning your SCADA or other control devices don't need any kind of external exposure, port forwarding or NAT'ing to recieve VPN translation.

Now the capability is pretty similar regarding specific device-access policy. However *what's under the hood* is pretty different. You don't need to install any agents or anything like that. Just pass one-liner iproute command to ensure a split-routing mechanism from the local private OT network can speak to ""the other side"" via the DefiantOS.","","👍 (1)"
"352642563255042059","takko_the_boss","2020-08-07T21:18:48.9520000+08:00","I'm also biased against VPN","",""
"711109466761986078","dostiharise","2020-08-07T21:19:07.4610000+08:00","> by ""great solution"" i mean point it to an OPC server and select the tags you are interested in
@praetor- 

Sorry I don't understand. 

Like just deploy and configure with coding?

How does modbus happen? Is it different in GreenGrass","",""
"353220715983536128","e0ph","2020-08-07T21:21:03.9240000+08:00","here's the modbus connector documentation: https://docs.aws.amazon.com/greengrass/latest/developerguide/modbus-protocol-adapter-connector.html, i'd expect an OPC integration to operate the same way before i'd call it a great solution","",""
"711109466761986078","dostiharise","2020-08-07T21:22:30.7710000+08:00","I see what you mean","",""
"711109466761986078","dostiharise","2020-08-07T21:22:38.8590000+08:00","Thanks for clarifying.","",""
"711109466761986078","dostiharise","2020-08-07T21:23:17.0990000+08:00","Security wide I tried implementing my VPN server but ended using AWS VPN tunnelling solution .

Bad thing thier ARM architecture support is super  painful. And you need to build the binary for yourself from code. May take days to get it to work.","",""
"711109466761986078","dostiharise","2020-08-07T21:24:32.1920000+08:00","Reverse SSH tunnel with zero ports open I mean. With Mqtt Handshake.","",""
"352642563255042059","takko_the_boss","2020-08-07T21:27:07.0080000+08:00","Wait.... @dostiharise you're saying you ran the reverse tunnel....through the MQTT broker to route it?","",""
"711109466761986078","dostiharise","2020-08-07T21:27:22.2680000+08:00","Nope.","",""
"352642563255042059","takko_the_boss","2020-08-07T21:27:34.8340000+08:00","Ok, still - my ears are perked.","",""
"711109466761986078","dostiharise","2020-08-07T21:27:59.7680000+08:00","I use a Mqtt to request a reverse tunnel to the server. 

And connect to that server from my laptop to mange the gateway","",""
"711109466761986078","dostiharise","2020-08-07T21:28:31.6780000+08:00","The Mqtt Handshake establishes a native TCP connect to my server over VPN","",""
"352642563255042059","takko_the_boss","2020-08-07T21:28:48.1580000+08:00","Ok, that makes sense. Different from what I was initially thinking.","",""
"711109466761986078","dostiharise","2020-08-07T21:31:49.8590000+08:00","1. Laptop -> http tunnel request -> Server -> Mqtt tunnel request -> Gateway

2. Gateway -> ssh tunnel -> Server 
3. Laptop -> SSH to Server. 

4 Laptop <Server> Gateway

Zero ports open on Gateway. No attack vector over Internet.","","👍 (3)"
"352642563255042059","takko_the_boss","2020-08-07T21:33:02.1800000+08:00","That's pretty badass. Definitely one cool way of remote-access. Is this a novel technique you stumbled upon, or is it already well-documented?","",""
"711109466761986078","dostiharise","2020-08-07T21:33:30.7300000+08:00","I am a little paranoid about security. 🙂","",""
"711109466761986078","dostiharise","2020-08-07T21:34:09.9740000+08:00","It's kind of a advanced concept. 

It took me weks of head banging to get it to work.","",""
"711109466761986078","dostiharise","2020-08-07T21:34:24.6500000+08:00","Not very novel, but involved to execute.","",""
"352642563255042059","takko_the_boss","2020-08-07T21:34:53.6880000+08:00","Well, I suppose it's **only ** *paranoia until you're right*, lol.","","👍 (2),😋 (1)"
"711109466761986078","dostiharise","2020-08-07T21:36:41.4500000+08:00","🙂 I do cloud DevOps and Site Reliability Consulting.

So I have had the amazing opportunity to clean up unauthorised crypto mining servers on Clients accounts that costed 20,000 USD in matter of days. 

This happened 2 times. 

So I am sure it's inevitable.

Murphy's Law","","💯 (2)"
"352642563255042059","takko_the_boss","2020-08-07T21:38:57.6170000+08:00","Ha! I wish I got to talk to you when I did all this remote-connectivity research & presentations last year. I'm sure you could've contributed to some real interesting use-cases then!","",""
"711109466761986078","dostiharise","2020-08-07T21:41:29.4650000+08:00","Oh sure. 

Anytime.

So the way it works is.

Even you keep you IPs secret, AWS and other tools create some DNS entries in public domain. 


So there are bots that scan these entries say like

xxxx-iot-endpoint.useast-1.aws.amazon.com etc..

And once they register a new endpoint, ip entry the bots get to work.

Most people don't know because they don't monitor any network/TCP flow logs.","",""
"711109466761986078","dostiharise","2020-08-07T21:41:36.5170000+08:00","But it's always the case.","",""
"711109466761986078","dostiharise","2020-08-07T21:42:38.9820000+08:00","And they try all kinds of attacks starting with port scans. 

Once a open port is found. They things get interesting","","👍 (1)"
"352642563255042059","takko_the_boss","2020-08-07T21:43:10.0510000+08:00","Yeah, SOC & MDR are expertises of mine, and I've seen some interesting stuff due to AWS mismanagement lol. Pretty much in-line with what you're saying.","",""
"711109466761986078","dostiharise","2020-08-07T21:43:41.8820000+08:00","SoC as in System on Chip?","",""
"352642563255042059","takko_the_boss","2020-08-07T21:44:00.5070000+08:00","Security Operations Center","",""
"711109466761986078","dostiharise","2020-08-07T21:44:05.6390000+08:00","Sorry I am new to Industry specific stuff. My knowledge is limited.","",""
"711109466761986078","dostiharise","2020-08-07T21:44:13.8630000+08:00","Oh. Sure. Makes sense.","",""
"352642563255042059","takko_the_boss","2020-08-07T21:44:30.8910000+08:00","That's fine. I'm glad to see other folks with networking chops on here.","",""
"711109466761986078","dostiharise","2020-08-07T21:44:32.2580000+08:00","Great.","",""
"711109466761986078","dostiharise","2020-08-07T21:44:56.4110000+08:00","Yup. Thanks to @Walker Reynolds  for making this community happen. 

Amazing guy.","","👍 (2)"
"352642563255042059","takko_the_boss","2020-08-07T21:45:23.7850000+08:00","Yes, he's created the best distraction for me in 2020 lol","",""
"352642563255042059","takko_the_boss","2020-08-07T21:45:32.8950000+08:00","To which I'm grateful for.","",""
"711109466761986078","dostiharise","2020-08-07T21:45:32.9230000+08:00","Ha ha.","",""
"711109466761986078","dostiharise","2020-08-07T21:45:43.4130000+08:00","And it's contagious I am sure","",""
"352642563255042059","takko_the_boss","2020-08-07T21:45:50.5780000+08:00","Definitely","",""
"735494945103675394","claudiu.sima","2020-08-08T02:01:47.1960000+08:00","> Yeah, SOC & MDR are expertises of mine, and I've seen some interesting stuff due to AWS mismanagement lol. Pretty much in-line with what you're saying.
@MikeCurnow.com  can you comment more on this Topic? It's for IT or OT the SOC/MDR topic? I'm curious because I'm working on a project to define SOC for an OT environment is quite difficult to assess the needs for it. My experience with SOC/MDR is mainly to IT therefore , for the time being, I'm struggling with the OT side. Mainly the issue is how to get the data at least from L1 Purdue level.","",""
"352642563255042059","takko_the_boss","2020-08-08T10:40:12.3770000+08:00","Hi @Claudiu SIMA Sorry for late reply. OT SOC is a different animal. One thing to keep in mind is that you need a tailored solution to the environment you're monitoring.

For example, you can't monitor device connections with regular IDS, but you *can* employ IDS at network/communications choke points.

Also, any monitoring for SOC you'll do for OT networks and equipment will look different regarding the industry and tech being monitored. Indicators of compromise to security posture and the safety of the equipment will look different between pharmaceutical manufacturing vs water treatment.

Joe Weiss has some good articles and materials regarding level 0-1 devices.","",""
"735494945103675394","claudiu.sima","2020-08-09T17:24:07.3710000+08:00","> Hi @Claudiu SIMA Sorry for late reply. OT SOC is a different animal. One thing to keep in mind is that you need a tailored solution to the environment you're monitoring.
> 
> For example, you can't monitor device connections with regular IDS, but you *can* employ IDS at network/communications choke points.
> 
> Also, any monitoring for SOC you'll do for OT networks and equipment will look different regarding the industry and tech being monitored. Indicators of compromise to security posture and the safety of the equipment will look different between pharmaceutical manufacturing vs water treatment.
> 
> Joe Weiss has some good articles and materials regarding level 0-1 devices.
@MikeCurnow.com Hi Mike, indeed for Ot Monitoring I'm using and IDS (like Nozomi/Forescout) and I'm sending the data into a traditional IT SIEM, but still, I'm using it on the traditional network side on the switch side, and I'm not really confident that I'm getting all relevant data. Could you please share a link related to Joe Weiss. articles.","",""
"194289793905983489","zackscriven","2020-08-10T03:55:28.1440000+08:00","Loving these #cloud discussions! Thanks @MikeCurnow.com for all your input here","","🙌 (2)"
"352642563255042059","takko_the_boss","2020-08-10T22:16:26.7520000+08:00","@Claudiu SIMA Good morning. Is the monitored environment built on purdue model?","",""
"352642563255042059","takko_the_boss","2020-08-10T22:17:25.5540000+08:00","> Loving these #cloud discussions! Thanks @MikeCurnow.com for all your input here
@zackscriven Thanks man. For the longest time I wanted to have discussions like this, but now there is a **place** for it.","",""
"735494945103675394","claudiu.sima","2020-08-10T22:38:32.0420000+08:00","@MikeCurnow.com Good morning as well Mike, yes the environment is built on Purdue model level.","",""
"735494945103675394","claudiu.sima","2020-08-11T16:27:46.9660000+08:00","> @MikeCurnow.com Good morning as well Mike, yes the environment is built on Purdue model level. @MikeCurnow.com Basically I was thinking to bring an IIoT sensor next to the PLC and to the sensors and send the data to either a cloud platform, and or a private cloud, and from there to collect it to teh SIEM. But the main issue, is that adding aditional sensors, is bringing aditional cybersecurity complexity in temr of how to secure the IIoT devices next to the sensors, and as well make sure that the devices are not sending wrong data. Another issue is that I don't have access to the PLC data directly and I'm not able to access the sensors as well. As from the time being the enviroment is quite safe being separated from the IT side of the enteprise.","",""
"352642563255042059","takko_the_boss","2020-08-13T03:12:19.9530000+08:00","I feel tackling the access issue is paramount to achieving the rest.","","💰 (1)"
"743204284153462786","andresgonzalezmarcelo8528","2020-08-14T00:42:26.1170000+08:00","Hello everyone, I have a question for you. Has anyone been able to work on or test the SoftwareAG Cumulocity IoT solution? What do you think about it?","","👂 (2)"
"737819173631033454","faction2.0","2020-08-18T19:47:17.8930000+08:00","Does anyone have any good architecture examples for developing an IIoT cloud platform? I'm mainly curious which services you would use (either AWS or Azure) and how those services link together","",""
"382941357699760129","walker.reynolds","2020-08-18T21:39:22.7030000+08:00","> Does anyone have any good architecture examples for developing an IIoT cloud platform? I'm mainly curious which services you would use (either AWS or Azure) and how those services link together
@David Hoysan That  requires a very long answer -- we should shoot a video on that","",""
"737819173631033454","faction2.0","2020-08-18T21:47:35.1970000+08:00","@Walker Reynolds I totally agree!","",""
"737819173631033454","faction2.0","2020-08-18T21:48:18.7110000+08:00","This is probably the best IIoT reference architecture I could find, but I'd say it's a little over kill for most applications.","https://cdn.discordapp.com/attachments/740336311671586968/745277902932803594/unknown.png?ex=68df2b62&is=68ddd9e2&hm=abb93b1affb7f16b43e35ee3bf769921fc58444d335fafc911d6912dc1120d1d&","🙌 (2)"
"737819173631033454","faction2.0","2020-08-18T21:50:22.0270000+08:00","I'm also curious when does it make sense to use off-the-shelf services from AWS or when to replace them with those from third parties. Both from a cost perspective and a functionality perspective","","👍 (1)"
"382941357699760129","walker.reynolds","2020-08-18T21:52:25.8680000+08:00","Its missing a UNS -- it has app to app discrete connections inside of AWS.  There is an edge UNS at Greengrass but some of the abstraction in AWS is lost in the ether because of the architecture.","","👍 (3)"
"737819173631033454","faction2.0","2020-08-18T22:01:39.5960000+08:00","Maybe I was giving the IoT Core more credit than it deserved, but in this example I assumed the IoT Core to be the UNS since it gives devices the ability to publish and subscribe to topics. What is the IoT Core missing that prevents it from being a true UNS?","","👍 (1)"
"382941357699760129","walker.reynolds","2020-08-18T22:04:46.4020000+08:00","A structure that fits into a UNS -- there is no context in the AWS IoT core that fits into a UNS for industry -- the context is AWS application specific, you need to treat AWS as a node, preferably each application, and abstract it for an Industry UNS built on ISA-95","","👍 (2)"
"737819173631033454","faction2.0","2020-08-18T22:07:23.4540000+08:00","ah makes sense. Thanks!","","👍 (2)"
"743347439972515894","mrjain.","2020-08-19T09:46:26.7690000+08:00","> Does anyone have any good architecture examples for developing an IIoT cloud platform? I'm mainly curious which services you would use (either AWS or Azure) and how those services link together
@David Hoysan I've used AWS for the past 10 years just because it was the first truly cloud platform. Over the past 2 years I've started to use their AWS IoT Core service.  We have a bunch of sensors in the field that are connected to IoT Core and transmitting data via MQTT. Then on IoT Core we have that data moved to a DynamoDB. Then we use Lambda to run reports and and EC2 instance for powering the dashboards.","","👍 (2)"
"743347439972515894","mrjain.","2020-08-19T09:50:05.4950000+08:00","@David Hoysan I wrote a blog piece on the AWS architecture - **https://celestri.org/2019/12/19/aggregation-building-an-iot-device/**","","👍 (1)"
"737819173631033454","faction2.0","2020-08-19T10:01:03.6960000+08:00","> @David Hoysan I wrote a blog piece on the AWS architecture - **https://celestri.org/2019/12/19/aggregation-building-an-iot-device/**
@mrjain.  thanks, I’ll check it out!","",""
"352642563255042059","takko_the_boss","2020-08-19T11:56:12.2130000+08:00","AWS Green Grass seemed real cool from all the videos I watched and docs I read, up until I saw they use HTTPS for ingress/egress.

It's my professional stance that using HTTPS to transfer such info is irresponsible. Obviously the devs there never heard of SSL-Splitting, lol.","",""
"352642563255042059","takko_the_boss","2020-08-19T12:02:57.3350000+08:00","Which is something that SIEMENS does with their Mindsphere platform too. And it's expected you hook up your SCADA WIN CC <XX> machine to internet.","","👍 (2)"
"743347439972515894","mrjain.","2020-08-19T12:19:02.1440000+08:00","> AWS Green Grass seemed real cool from all the videos I watched and docs I read, up until I saw they use HTTPS for ingress/egress.
> 
> It's my professional stance that using HTTPS to transfer such info is irresponsible. Obviously the devs there never heard of SSL-Splitting, lol.
@MikeCurnow.com So what is your recommended method?","","💯 (2)"
"352642563255042059","takko_the_boss","2020-08-19T12:21:53.6860000+08:00","Routing through an overlay network should be the standard. But employing a shim network above OSI Layer 3 is what I'd recommend.

I'm also heavily biased since I run a company that does this. But I trully believe overlay networking that breaks away from standard IP routing is the answer for securing Industry 4.0's system integration tenet.","",""
"352642563255042059","takko_the_boss","2020-08-19T12:22:44.2330000+08:00","When allowing networking at a lower level, you open yourself up to attacks, though you're using a ""secure"" TLS/SSL hardened comms method.","",""
"743347439972515894","mrjain.","2020-08-19T12:26:08.0950000+08:00","I hear ya, I spent 4 years at Cisco but sadly security is an after thought for most. What you are talking about would add more complexity but also more security...and that's the rub.","",""
"352642563255042059","takko_the_boss","2020-08-19T12:31:30.1720000+08:00","I definitely can understand that. We've created an open-source no-strings-attached and non-paywalled tool for this. It's a non-invasive, drop-in, bump-in-the-wire solution that's a gateway operating system which uses 1 of the 4 open identity-defined-networking protocols.

It's basically a virtual or a physical <thing> that you route your traffic through. It's been tested on rugged edge devices that get deployed to facilities with industrial functions. I can DM you if you want. Though it's an open-source offering we don't make $$ on (just wanted to give something to the community), I still feel too vendor-ey.","",""
"743347439972515894","mrjain.","2020-08-19T12:35:08.9860000+08:00","Yes, I would like to take a look. please DM me","",""
"352642563255042059","takko_the_boss","2020-08-19T12:41:25.3180000+08:00","@mrjain. Cisco has their own protocol that's a cool one for identity-based networking and multi-homing called Locator/ID Separation Protocol (LISP). Though I'm sure you're familiar already.","",""
"743347439972515894","mrjain.","2020-08-23T15:26:51.8700000+08:00","> @mrjain. Cisco has their own protocol that's a cool one for identity-based networking and multi-homing called Locator/ID Separation Protocol (LISP). Though I'm sure you're familiar already.
@MikeCurnow.com It's been 15 years since I was at Cisco! I'll check it out, thanks.","","👍 (1)"
"693505873775165530","aadil687","2020-08-24T23:07:08.8230000+08:00","> I definitely can understand that. We've created an open-source no-strings-attached and non-paywalled tool for this. It's a non-invasive, drop-in, bump-in-the-wire solution that's a gateway operating system which uses 1 of the 4 open identity-defined-networking protocols.
> 
> It's basically a virtual or a physical <thing> that you route your traffic through. It's been tested on rugged edge devices that get deployed to facilities with industrial functions. I can DM you if you want. Though it's an open-source offering we don't make $$ on (just wanted to give something to the community), I still feel too vendor-ey.
@MikeCurnow.com  Would like to check this out!","",""
"194289793905983489","zackscriven","2020-08-26T07:15:43.5800000+08:00","great resource @David Hoysan! Thanks for sharing it here!","",""
"194289793905983489","zackscriven","2020-08-26T07:15:56.2800000+08:00","> This is probably the best IIoT reference architecture I could find, but I'd say it's a little over kill for most applications.
@David Hoysan 🙌","",""
"737819173631033454","faction2.0","2020-08-26T07:19:06.4390000+08:00","> great resource @David Hoysan! Thanks for sharing it here!
@zackscriven  happy to help contribute so we can all learn from each other!","","👍 (2)"
"194289793905983489","zackscriven","2020-08-26T07:20:02.1270000+08:00","It would be cool to do an video or series of videos where we focused on cloud architectures","","👍 (2)"
"737819173631033454","faction2.0","2020-08-26T07:23:55.6200000+08:00","> It would be cool to do an video or series of videos where we focused on cloud architectures
@zackscriven  I think that would create a ton of value. There’s a million ways to develop the architecture but it can be difficult to start when you don’t fully understand best practices","","👍 (2)"
"745009912160976977","marioishikawa","2020-08-26T19:53:37.2220000+08:00","> I definitely can understand that. We've created an open-source no-strings-attached and non-paywalled tool for this. It's a non-invasive, drop-in, bump-in-the-wire solution that's a gateway operating system which uses 1 of the 4 open identity-defined-networking protocols.
> 
> It's basically a virtual or a physical <thing> that you route your traffic through. It's been tested on rugged edge devices that get deployed to facilities with industrial functions. I can DM you if you want. Though it's an open-source offering we don't make $$ on (just wanted to give something to the community), I still feel too vendor-ey.
@MikeCurnow.com I'd like to learn more about it and I'm checking your website now. What about a meetup about the topic?","",""
"745009912160976977","marioishikawa","2020-08-26T20:18:22.3030000+08:00","> This is probably the best IIoT reference architecture I could find, but I'd say it's a little over kill for most applications.
@David Hoysan Nice. It is indeed very complete and although is extremely focused on AWS PaaS, we can have an overview and understand what other blocks from other Clouds or even open source source could fit to do the job. But it is important to note that every project is singular. This architecture is complete and could serve a highly scalable service. But I'd not recommend to start any project that complex, specially if you are talking about a POC at your plant or a MVP for a product. In a smaller scale you can validate the idea with much less complexity.","",""
"352642563255042059","takko_the_boss","2020-08-27T21:35:07.5880000+08:00","@Mario Ishikawa just seeing this now, my bad. I've been a tad busier than normal this week.

I typically don't host meetups myself, just due to time constraints and typically neck-deep in projects almost all the time (like most folk here lol). But I do ***speak*** at meetups.","","👍 (2)"
"698244484302897323","lmtx","2020-09-01T19:21:53.0960000+08:00","hello, I posted a tweet in my AWS IoT basic series, please let me know what do you tink about it or if you have any questions regarding AWS IoT https://twitter.com/lmtx1/status/1300754787726749698?s=20","",""
"749777337410912276","matt4.05570","2020-09-01T19:27:52.4450000+08:00","@LMtx - looks good! I would be curious to hear if you have played around with hardware security modules or TPMs for storing the private keys? Are the worth it? Companies like Zymbit offer this for Raspberry Pis, but they are quite expensive and add a lot of cost to the device (https://www.zymbit.com)","",""
"698244484302897323","lmtx","2020-09-01T19:29:59.3380000+08:00","@matt4.0 in production I always use standalone HSMs, for personal projects TPM is sitll on my (very long) todo list 😦","",""
"749777337410912276","matt4.05570","2020-09-01T19:32:19.7750000+08:00","👍. So pilot / POC without HSM to prove value, then introduce HSM when you’re ready to scale?","",""
"698244484302897323","lmtx","2020-09-01T19:33:21.2040000+08:00","exactly","",""
"698244484302897323","lmtx","2020-09-01T19:33:34.4150000+08:00","this might be a good read for you https://aws.amazon.com/blogs/iot/using-a-trusted-platform-module-for-endpoint-device-security-in-aws-iot-greengrass/","","👍 (1)"
"382941357699760129","walker.reynolds","2020-09-01T20:54:44.9240000+08:00","Question of the day: Which cloud based tools are you using?  When do you decide to go to the cloud for a solution?","","👍 (2)"
"382941357699760129","walker.reynolds","2020-09-01T20:54:50.8500000+08:00","Pinned a message.","",""
"688675337785311245",".muhammadatif","2020-09-01T20:56:42.8500000+08:00","> Question of the day: Which cloud based tools are you using?  When do you decide to go to the cloud for a solution?
@Walker Reynolds IBM, Microsoft Azure","",""
"743686318353022988","philseboa","2020-09-01T21:04:13.5700000+08:00","> Question of the day: Which cloud based tools are you using?  When do you decide to go to the cloud for a solution?
@Walker Reynolds  We have a free cloud service available to our customers, you can sign up for free, this allows to build dashboards, manage your data sent via our iot gateways and PLCNext technology, it’s called “Professional Cloud” or Proficloud for short. Check out at www.proficloud.net","",""
"698244484302897323","lmtx","2020-09-01T21:23:08.8340000+08:00","> Question of the day: Which cloud based tools are you using?  When do you decide to go to the cloud for a solution?
@Walker Reynolds I use AWS, mostly GreenGrass for the edge and other AWS cloud services depending on project needs","",""
"749725463915528283","joelp0822","2020-09-01T21:48:22.3150000+08:00","@Walker Reynolds I use Microsoft Azure with Maestrotek/Weintek/Zenon as Edge devices","",""
"194289793905983489","zackscriven","2020-09-01T23:01:52.7760000+08:00","@Walker Reynolds  I'll give my answer but on the digital media side.

1. Dropbox for file storage
2. Trello for project management
3. Slack for communications
4. Canva for design
5. Adobe Creative Cloud
6. Kajabi for website/email marketing/ course hosting
7. Social medias... LinkedIn YouTube instagram facebook
8. Stripe and Paypal for payments
9. GSuite for productivity","","👍 (2)"
"698244484302897323","lmtx","2020-09-01T23:11:07.4460000+08:00","@zackscriven I'd add draw.io for design","","👍 (1)"
"382941357699760129","walker.reynolds","2020-09-01T23:39:17.0270000+08:00","> @Walker Reynolds I use AWS, mostly GreenGrass for the edge and other AWS cloud services depending on project needs
@LMtx Are there any specific reasons you choose AWS over Azure?  Have you leveraged tools other than AWS options? (I'd like to get a convo started about this)","",""
"750008314170966156","jerryreeves9207","2020-09-01T23:43:47.4360000+08:00","> @LMtx Are there any specific reasons you choose AWS over Azure?  Have you leveraged tools other than AWS options? (I'd like to get a convo started about this)
@Walker Reynolds When you say tools are you referring to applications or systems that are independent of a cloud environment but are deployed in AWS, Azure, or others to build a comprehensive cloud system in additional to the tools already provided?","",""
"698244484302897323","lmtx","2020-09-01T23:44:23.2390000+08:00","I've got commercial experience using both Azure and AWS; I decided to switch to AWS only but I'm not saying that Azure is wrong or anything","",""
"698244484302897323","lmtx","2020-09-01T23:46:30.5200000+08:00","in my opinion we should not compare one cloud provider to the other without exact business use case","",""
"698244484302897323","lmtx","2020-09-01T23:47:42.6190000+08:00","on the flip side you will end up with two different solution designs for both of clouds","",""
"698244484302897323","lmtx","2020-09-01T23:48:23.3320000+08:00","and I prefer to use AWS toolbox in most cases I saw","",""
"382941357699760129","walker.reynolds","2020-09-02T00:37:49.4840000+08:00","I agree @LMtx , I like both solutions -- but I lean toward AWS for really just one reason... Azure steers you toward Microsoft OS whenever possible and AWS seems to be more agnostic -- and that provides flexibility for me.","","👍 (2)"
"230441548653789184","r.pop","2020-09-02T00:46:30.8960000+08:00","I tend to lean more toward Azure. They’ve recently added a lot of support for Linux, even as far as supporting Kubernetes. Also, in the enterprise case, majority of customers are already on Azure. Agree with the point though that it’s unfair to compare them apples to apples. I think it really depends more on the use case than anything.","","💯 (1)"
"688675337785311245",".muhammadatif","2020-09-02T01:17:18.6880000+08:00","> @Walker Reynolds  I'll give my answer but on the digital media side.
> 
> 1. Dropbox for file storage
> 2. Trello for project management
> 3. Slack for communications
> 4. Canva for design
> 5. Adobe Creative Cloud
> 6. Kajabi for website/email marketing/ course hosting
> 7. Social medias... LinkedIn YouTube instagram facebook
> 8. Stripe and Paypal for payments
> 9. GSuite for productivity
@zackscriven cool!","",""
"194289793905983489","zackscriven","2020-09-02T02:49:37.9060000+08:00","> @zackscriven I'd add draw.io for design
@LMtx For engineering and design documents I loved using lucidcharts","","👍 (1)"
"194289793905983489","zackscriven","2020-09-02T02:50:43.8880000+08:00","@Walker Reynolds could assets like digital media exist within the Unified Namespace? And applications like draw.io or canva.com publish into and out of the UNS?","","👍 (1)"
"194289793905983489","zackscriven","2020-09-02T02:51:21.1780000+08:00","Sorta like how they can already do with Dropbox or Drive acting as a ""Filesystem Unifed Namespace""","",""
"382941357699760129","walker.reynolds","2020-09-02T03:43:55.2180000+08:00","> @Walker Reynolds could assets like digital media exist within the Unified Namespace? And applications like draw.io or canva.com publish into and out of the UNS?
@zackscriven of course -- the UNS is built on a technology stack, not a software stack -- as long as your digital media solutions support the technology stack then you are good to go.  (We will talk more about this paradigm in future vids).","","👍 (3)"
"698244484302897323","lmtx","2020-09-02T19:08:50.6950000+08:00","A short tweet to distinguish the difference between AWS Greengrass Core and AWS IoT Core (maybe it is just me but it took me some time to fully understand the concepts behind those two services). Feel free to reach out in case of any questions. https://twitter.com/lmtx1/status/1301113878663888896?s=20","",""
"382941357699760129","walker.reynolds","2020-09-02T20:47:28.5520000+08:00","> A short tweet to distinguish the difference between AWS Greengrass Core and AWS IoT Core (maybe it is just me but it took me some time to fully understand the concepts behind those two services). Feel free to reach out in case of any questions. https://twitter.com/lmtx1/status/1301113878663888896?s=20
@LMtx we generally don't get into the weeds with our clients -- we explain greengrass as edge lamda and IoT Core as the cloud platform.","",""
"382941357699760129","walker.reynolds","2020-09-02T20:57:00.1840000+08:00","> Question of the day: Which cloud based tools are you using?  When do you decide to go to the cloud for a solution?
@Walker Reynolds my answer: I go to the cloud when I need resources that bare metal can't provide, or I need a platform that I can't leverage on-prem.  I'm using many cloud based tools -- AWS, Azure, Kafka, Sorba IoT, Aveva Connect, etc etc.  What is important to note is that I focus on the technology the solution is built on and supports and not the features the solution markets.  I focus on technology -- IIoT, edge driven, report by exception, lightweight, web service... than I do the actual functions of the solution (we can build those).  Pick the right technology first, then pick the solution that fits your problem.  The right technology will connect the unique solutions together (and that is IIoT, under the hood)","",""
"698244484302897323","lmtx","2020-09-03T04:14:29.7860000+08:00","> @LMtx we generally don't get into the weeds with our clients -- we explain greengrass as edge lamda and IoT Core as the cloud platform.
@Walker Reynolds I guess it depends on a client how specific you want to go (and it never harms to educate your client). I'm sharing some basic knowledge on twitter, I'm sure that most of this community knows this already.","",""
"382941357699760129","walker.reynolds","2020-09-03T04:25:54.6650000+08:00","> @Walker Reynolds I guess it depends on a client how specific you want to go (and it never harms to educate your client). I'm sharing some basic knowledge on twitter, I'm sure that most of this community knows this already.
@LMtx This is true -- depends on who the audience is.  There are some engineers we work with (who work for our clients) that we get way into the weeds with... but, in general, we try to keep things in terms that a broader audience can consume.  Most people who talk high, use fancy words, hit on all the buzz words, are more often trying to sound smarter than they actually are.  I've consulted for a lot of vendors, integrators, firms... sat in on their pitches to clients, and just shook my head.  Its smoke and mirrors in a language the client doesn't speak.  We try to use analogies that anyone can understand -- and we stay away from the technical talk whenever possible.","","👍 (2)"
"194289793905983489","zackscriven","2020-09-03T05:09:59.4690000+08:00","> @zackscriven of course -- the UNS is built on a technology stack, not a software stack -- as long as your digital media solutions support the technology stack then you are good to go.  (We will talk more about this paradigm in future vids).
@Walker Reynolds The Unified Namespace contains the solution to the grand unified theory.","",""
"743347439972515894","mrjain.","2020-09-03T19:21:39.8120000+08:00","> hello, I posted a tweet in my AWS IoT basic series, please let me know what do you tink about it or if you have any questions regarding AWS IoT https://twitter.com/lmtx1/status/1300754787726749698?s=20
@LMtx This is great stuff, thanks for sharing","",""
"698244484302897323","lmtx","2020-09-03T19:23:28.8770000+08:00","@mrjain. glad you like it","",""
"698244484302897323","lmtx","2020-09-03T19:27:15.5410000+08:00","let me know if there is something specific regarding AWS IoT that you are interested in - I can cover it in my posts","",""
"456226577798135808","Deleted User","2020-09-03T22:54:52.7380000+08:00","> Hello everyone, I have a question for you. Has anyone been able to work on or test the SoftwareAG Cumulocity IoT solution? What do you think about it?
@Andres Gonzalez Marcelo  im wondering the same, did you receive any feedback on this?","",""
"382941357699760129","walker.reynolds","2020-09-03T23:24:12.4970000+08:00","> @Andres Gonzalez Marcelo  im wondering the same, did you receive any feedback on this?
@Deleted User Sorry -- I didn't respond yet.  Here are my thoughts... they have the definition of IIoT all wrong, their pricing model is suspect and they are leveraging primarily proprietary technology in their stack -- that isn't IIoT.  I shiver to think how much of a 'sponsorship' they paid for to get their Gartner ranking.  On the upside, they are approaching I 4.0 from a hub and spoke perspective -- treating solutions as nodes, that is good.  They leverage cloud -- good.  They are modular -- good.  Engineers and solutions architects will not be happy with their offering... they are going to the market top down (C-level) and their 'solutions' reflect that approach.","",""
"382941357699760129","walker.reynolds","2020-09-03T23:27:37.8390000+08:00","You can build solutions with their offering -- no doubt, but selecting Cumulocity is a decision to leverage their software stack over a decision to leverage a technology stack.  They don't fit into many of the solutions we provide but that doesn't mean they won't fit for others.  Software AG wants to be Rockwell for IoT and they are competing against PTC for that position in the market -- if that clarifies for you how they are handling things strategically.  ""Be everything to everyone""","","👍 (1)"
"456226577798135808","Deleted User","2020-09-04T01:16:19.9940000+08:00","i guess a plus factor for using them is if you use some of their other cloud products - in particular the webmethods integration and API management cloud products.","","👍 (1)"
"382941357699760129","walker.reynolds","2020-09-04T01:17:49.9780000+08:00","Exactly... its a choice to use their stack.  There are upsides and downsides to that decision.  I dont see the point of using anyone’s complete stack because no one company can be everything to everyone.","",""
"743204284153462786","andresgonzalezmarcelo8528","2020-09-04T01:34:27.5570000+08:00","Hi @Deleted User. I'm working for a company here in Colombia that is an Cumulocity Partner but we are thinking to move to another IoT Platform for some reasons:
* As @Walker Reynolds said, the price model is suspect, Cumulocity use a model called MEA`s (Measurements - Events - Alarms) that you can send in a period of time, that classifies the devices in a Class, based in that Class you get diferente prices, this is confuse for the customers.
* Develop complex behaviors for the platform involves the use microservices (charged separately).
* Widgets like Alarms Panel is too basic, our development team needs to rebuild it from scratch to add features like filters.
* Cumulocity said that they have the option of ""Cumulocity Edge"" for locations where the connections to Internet it is not possible, but the information it is not clear.
* I don´t know if it is a problem with Latin America market, but we don`t get a fast answer from Cumulocity support. In most cases, we resolve the problems by ourselves.
* You need solutions like Webmethods or Trendminer for Analytics.","",""
"456226577798135808","Deleted User","2020-09-04T02:46:33.0650000+08:00","thats great feedback, thanks @Andres Gonzalez Marcelo @Walker Reynolds . they are huge here in Germany obviously and with all their products it can sound like they do everything therefore its really useful to get some real insights. on the event streaming / stream processing side of things, from what i could read in documentation, they also seem very focussed on their own Apama technology rather than connecting to other technologies like Kafka or Azure EventHub.","","💯 (1)"
"743347439972515894","mrjain.","2020-09-04T13:43:23.4100000+08:00","> let me know if there is something specific regarding AWS IoT that you are interested in - I can cover it in my posts
@LMtx The two areas I'm really keen to learn about are 2 recent features they announced:
Fleet Provisioning - https://aws.amazon.com/blogs/iot/how-to-automate-onboarding-of-iot-devices-to-aws-iot-core-at-scale-with-fleet-provisioning/
IoT Custom authorizers - https://docs.aws.amazon.com/iot/latest/developerguide/custom-authorizer.html (no need for certs, just a user/pass)","",""
"698244484302897323","lmtx","2020-09-04T13:47:29.6190000+08:00","@mrjain. noted that, I will get to those topics later - for you I want to cover basics because without good understanding of basic concept it is hard to use more advanced tools in a proper way","",""
"698244484302897323","lmtx","2020-09-04T13:50:03.6380000+08:00","based on my experience, most of IoT systems that were compromised had some very basic misconfiguration issues which lead to big problems once deployed to production","",""
"698244484302897323","lmtx","2020-09-04T13:51:58.7360000+08:00","fleet provisioning and management is adding complexity to system design because now we are talking about working at a huge scale (there is nothing wrong about huge scale IoT deployments but potential mistakes cost more)","",""
"698244484302897323","lmtx","2020-09-04T13:53:50.9610000+08:00","with a fleet provisioning comes proper certification management and rotation strategy - that is a huge topic on its own. I will cover that but probably as a blog post because that is very complex subject.","",""
"698244484302897323","lmtx","2020-09-04T13:54:35.5310000+08:00","feel free to suggest any topics that you are interested in - I will add them to my ""roadmap""","",""
"698244484302897323","lmtx","2020-09-04T13:56:35.5640000+08:00","ps. I would recommend using certificates instead of user/pass in 99,99% of IoT deployments","",""
"456226577798135808","Deleted User","2020-09-04T15:50:35.9520000+08:00","> let me know if there is something specific regarding AWS IoT that you are interested in - I can cover it in my posts
@LMtx  hi, in your experience, has the topic of risks/pitfalls for engineers relying on Lamdas come up much? Ive seen it in other spaces but wondering if its a topic in IIoT too. Heres an example article: https://dzone.com/articles/aws-lambdas-major-limitations","",""
"698244484302897323","lmtx","2020-09-04T16:47:42.4700000+08:00","@Deleted User my notes as I read above article: 
""what Lambda does, it’s obvious that any code written for it will not be portable across other computing platform"" - that is simply not true; you can reuse 99% of your Lambda code and run it on any other platform, you can use any sdk in Lambda function to execute actions on any other cloud/API provider when you need to
"" integration with services like IAM, Amazon S3, API Gateway, or Amazon EC2 means that switching to a different provider may be impossible. "" - that is not true, you can switch to any other storage provider instead of s3 if you want (just use proper sdk); integration with other AWS services let's you use IAM to manage permissions granted to Lambda in a easy way but if you want to keep your code ""portable"" then you do not have to use it and manage access in other way","",""
"698244484302897323","lmtx","2020-09-04T16:48:08.4090000+08:00","""Stored procedures were similar to Lambda (...) it became very difficult to move away from a specific database provider"" - I used to be PL/SQL developer long time ago, comparing Lambda to Stored procedures simply does not make any sense (in Lambda you can use many high-level languages like pyhon or node, there is very little that is tightly specific for Lambda runtime and you can ignore that during migration to other platform)
""A local environment running on your laptop can be difficult to arrange when it comes to AWS"" it seams that author of this article never heard of SAM (https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html), it is possible to develop most of your code locally; there are some services that can not be emulated locally but if you know what you are doing you can setup a hybrid environment that will work fine with limited cost added","",""
"698244484302897323","lmtx","2020-09-04T16:48:14.1010000+08:00","""difficult to debug because you can’t access the server with a terminal in the traditional way to quickly figure out what the problem is."" - that is very common approach, someone is trying to develop serverless application with ""classical mindset""; that simply can not work; I educate my customers on differences in concepts between server based and serverless application design before we write a single line of cose; if someone does not understand the idea behind serverless will complain that he/she can not ""ssh into lambda to check logs/output""
""Using Lambda doesn’t mean that you can ignore questions about managing IAM roles and the fine-grained permissions needed to run Lambda functions safely. You will still need to think..."" - yes, you still need to think what you are doing even if you are using Lambda (no comment...)
""Technical Limitations and Cost"" - you should pick the right tool for a job, Lambda was not designed to solve all possible cases; I wonder if author of that article heard about other AWS services...
conclusion - I do not agree with that article; it was clearly written by someone who does not have proper knowledge and experience to cover this topic","",""
"698244484302897323","lmtx","2020-09-04T16:49:10.6650000+08:00","above is my personal opinion based on hands-on experience","","👍 (2)"
"698244484302897323","lmtx","2020-09-04T16:49:46.1490000+08:00","I'm open for any feedback","",""
"698244484302897323","lmtx","2020-09-04T20:21:45.2200000+08:00","My new tweet thread about Greengrass Subscriptions. I was thinking that it is going to be a short one but I managed to cover only basics in multiple tweets. I will get back to this topic because things like MQTT schema design are extremely important and hard to make right for complex deployments. As always any feedback is very welcome and let me know if I should cover some specific topics. https://twitter.com/lmtx1/status/1301856973026201600?s=20","",""
"743347439972515894","mrjain.","2020-09-04T21:52:24.6460000+08:00","> ps. I would recommend using certificates instead of user/pass in 99,99% of IoT deployments
@LMtx I would say 99.9999% dont use user/pass. I only mentioned it because it's a new way to send data to AWS IoT core. The use case is that you have devices in the field and you can't load AWS certs on them but you can send data via MQTT over TLS.","",""
"743347439972515894","mrjain.","2020-09-04T21:53:54.5360000+08:00","> @LMtx  hi, in your experience, has the topic of risks/pitfalls for engineers relying on Lamdas come up much? Ive seen it in other spaces but wondering if its a topic in IIoT too. Heres an example article: https://dzone.com/articles/aws-lambdas-major-limitations
@Deleted User To Lambda or not, that is the question. I have been involved in a couple of discussions where the edge devices are dumb and they want to send all the data into AWS IoT Core and then have Lambda do the processing to make sense of the data. Someone else I know wants todo the processing at the edge and then just send the data to AWS IoT Core and dump it into DynamoDB.","",""
"698244484302897323","lmtx","2020-09-04T21:57:02.5240000+08:00","> @Deleted User To Lambda or not, that is the question. I have been involved in a couple of discussions where the edge devices are dumb and they want to send all the data into AWS IoT c
@mrjain. sending all data to the cloud is not a good idea from cost, security and bandwidth reasons among others","",""
"743347439972515894","mrjain.","2020-09-04T21:58:23.1220000+08:00","> @mrjain. sending all data to the cloud is not a good idea from cost, security and bandwidth reasons among others
@LMtx hmm...We are ""all in"" on the cloud","",""
"698244484302897323","lmtx","2020-09-04T21:58:46.6250000+08:00","but not if you are talking about the raw data","",""
"382941357699760129","walker.reynolds","2020-09-04T21:59:06.8440000+08:00","I would encourage you to use the terms 'off-prem cloud' and 'on-prem cloud'","",""
"698244484302897323","lmtx","2020-09-04T21:59:12.6270000+08:00","pre-processing at the edge is usually a good idea","","💯 (1)"
"382941357699760129","walker.reynolds","2020-09-04T21:59:32.2790000+08:00","> pre-processing at the edge is usually a good idea
@LMtx agreed","",""
"698244484302897323","lmtx","2020-09-04T22:03:08.3760000+08:00","> I would encourage you to use the terms 'off-prem cloud' and 'on-prem cloud'
@Walker Reynolds to be honest I never heard those terms; I'm not sure if 'on-prem cloud' is the right way to put it - most of the time the customer is responsible for the IT hardware on the shop floor (you use cloud to avoid hardware related issues so 'on-prem cloud' is a wierd mix)","",""
"382941357699760129","walker.reynolds","2020-09-04T22:04:01.6200000+08:00","off-prem cloud means you are using someone else's metal, in the cloud, often times along side other people's data, separated by vm layers.","",""
"382941357699760129","walker.reynolds","2020-09-04T22:06:02.5900000+08:00","on-prem cloud means you are either: paying for metal (to AWS or Azure or other), in the cloud, with your data being the only thing on the metal, separated by an air-gap.  OR you have installed a cloud solution inside your network, on your metal.  They are very different.  Using the term cloud connotes that you are sending your data to some place on the internets, outside of your business -- and that isn't always the case.","",""
"698244484302897323","lmtx","2020-09-04T22:09:03.5590000+08:00","S3 is 'off-prem' or 'on-prem' in that case?","",""
"382941357699760129","walker.reynolds","2020-09-04T22:09:14.7320000+08:00","That depends","",""
"382941357699760129","walker.reynolds","2020-09-04T22:09:19.9630000+08:00","Typical S3 is off-prem","",""
"382941357699760129","walker.reynolds","2020-09-04T22:09:53.4440000+08:00","BUT... you can purchase on-prem solutions from AWS -- you still use their services, but the metal in the background is just for you.","",""
"382941357699760129","walker.reynolds","2020-09-04T22:10:01.8910000+08:00","That would be on-prem","",""
"698244484302897323","lmtx","2020-09-04T22:10:40.9890000+08:00","'That depends' - the only answer of a true professional (not a joke)","",""
"382941357699760129","walker.reynolds","2020-09-04T22:10:52.1210000+08:00","All of the big-boys use on-prem solutions from AWS and Azure because of Sarbanes-Oxley","",""
"382941357699760129","walker.reynolds","2020-09-04T22:11:42.6750000+08:00","They call it different things -- dedicated services, on-prem, yada yada","",""
"698244484302897323","lmtx","2020-09-04T22:12:21.4480000+08:00","got it, makes sense; that is true that for a heavy IIoT you bring the cloud to the ground","","💯 (2)"
"743347439972515894","mrjain.","2020-09-05T03:37:40.7470000+08:00","> All of the big-boys use on-prem solutions from AWS and Azure because of Sarbanes-Oxley
@Walker Reynolds AWS calls it EC2 Dedicated Hosts","","👍 (2)"
"751491203798925452","spanner.john.720","2020-09-05T05:19:03.9810000+08:00","I worked for FogHorn as Covid hit and they have an interesting IP in that they bring ML to the edge and hit the cloud only if they need to retrain, so kind of best of both worlds - limits the data going in and out, but available when needed, and keeps processing where it belongs - closest to the source.  Some amazing things you can do when you embed the ML into a device like a camera or sensor sized item","","👍 (2)"
"382941357699760129","walker.reynolds","2020-09-05T05:54:06.8600000+08:00","> I worked for FogHorn as Covid hit and they have an interesting IP in that they bring ML to the edge and hit the cloud only if they need to retrain, so kind of best of both worlds - limits the data going in and out, but available when needed, and keeps processing where it belongs - closest to the source.  Some amazing things you can do when you embed the ML into a device like a camera or sensor sized item
@John Sullivan  This is the ideal architecture for ML — Litmus and Sorba IoT take the same approach.","","👍 (2)"
"751491203798925452","spanner.john.720","2020-09-05T05:55:44.8190000+08:00","@Walker Reynolds Yeah I've talked to Litmus a couple of times over the last year or two about working with them as well.  They have some sharp folks with good backgrounds and you're right about how fast they crank out drivers - more than Kepware had last I heard and that was late last year I think!","",""
"382941357699760129","walker.reynolds","2020-09-05T06:31:38.8760000+08:00","Litmus is top notch... amazing IP they have on the driver dev side... they basically reverse engineer the native protocol to generate the driver automatically, instead of writing from scratch.","",""
"556602159513468951",".dhess","2020-09-07T04:24:20.6140000+08:00","Litmus IOT  https://youtu.be/kFI72BMJGzc","",""
"556602159513468951",".dhess","2020-09-07T04:27:44.8050000+08:00","I got to say the analytics look cool.","",""
"556602159513468951",".dhess","2020-09-07T04:35:22.7650000+08:00","I see you already have a podcast for Sorba (podcast #12). Basic info link...https://youtu.be/WXHR7MJ1DKc","",""
"698244484302897323","lmtx","2020-09-07T19:56:17.3610000+08:00","A short thread about running the Greengrass Core as a Docker container. It seams to be a simple task but you need to be aware of one configuration change needed to make this setup work: https://twitter.com/lmtx1/status/1302938048561319936?s=20","","💯 (1)"
"556602159513468951",".dhess","2020-09-08T04:21:54.5740000+08:00","Perhaps this has been discussed - please point me to a BKM if you have one. How do you guard your business against a loss of your internet connection? The internet connection appears to be the Achilles Heel. If it breaks the whole enterprise goes down. Thank you.","",""
"698244484302897323","lmtx","2020-09-08T04:24:12.5990000+08:00","@EgoNoBueno what do you mean by BKM?","",""
"556602159513468951",".dhess","2020-09-08T04:24:37.4170000+08:00","> @EgoNoBueno what do you mean by BKM?
@LMtx Best Known Method","","👍 (1)"
"698244484302897323","lmtx","2020-09-08T04:26:31.1990000+08:00","I use Greengrass as a gateway between factory and cloud; it can operate offline in case of internet issues","",""
"698244484302897323","lmtx","2020-09-08T04:27:24.6650000+08:00","GG can buffer data at send it to the cloud when regain internet access","",""
"698244484302897323","lmtx","2020-09-08T04:28:23.7330000+08:00","it can also do processing at the edge","",""
"556602159513468951",".dhess","2020-09-08T04:31:54.4010000+08:00","@LMtx I'm sure we are going to get into redundant internet feeds, caching of the data lake, and redundant back up systems at some point. The solution has to be ultra robust, because no business is going to tolerate being down because of a single line feed, single source to their data pool, or any other critical bottle neck.","",""
"556602159513468951",".dhess","2020-09-08T04:33:06.8650000+08:00","> GG can buffer data at send it to the cloud when regain internet access / Processing at the Edge.
@LMtx I'll look into those... Thank you.","","👍 (1)"
"698244484302897323","lmtx","2020-09-08T04:36:35.4920000+08:00","> @LMtx I'm sure we are going to get into redundant internet feeds, caching of the data lake, and redundant back up systems at some point. The solution has to be ultra robust, because no business is going to tolerate being down because of a single line feed, single source to their data pool, or any other critical bottle neck.
@EgoNoBueno I can understand that, you need to design a reliable system that can handle multiple types of issues","",""
"698244484302897323","lmtx","2020-09-08T04:37:47.2310000+08:00","if you decide to use AWS feel free to reach out in case of any questions","","😀 (1)"
"556602159513468951",".dhess","2020-09-08T06:10:35.8970000+08:00","So... I'm starting a BKM for myself to resolve the issue of how to protect the Enterprise from networking connection loss. As you brought up @LMtx , AWS GG will cache until a connection can re-establish itself. I know Canary Labs does something similar between the data Sender, and data Receiver, caching data until until it can be uploaded. With the prediction of rolling power brown outs in California, businesses are susceptible to power bumps, power outages, and of course other issues i.e. denial of service attacks, etc.. So this is a broad topic. If you love Biz 4.0, then it has to get addressed. No one wants all their employees filing their finger nails for 30 minutes waiting for the internet to come back on. So this is worth some time and effort to figure out. It can be a business down time monster. Working on it....","","👍 (1)"
"698244484302897323","lmtx","2020-09-08T08:37:38.0520000+08:00","@EgoNoBueno that is an interesting case, use technology that meets your requirements and you know best (I suggested aws because I know it but that is for sure not the only option). power outages are tricky to deal with - you need to design a system that will get back to the stable state in case some parts of it goes off/reboot","",""
"698244484302897323","lmtx","2020-09-08T08:43:37.3030000+08:00","you have to decide if you need mqtt qos 1 or 2 - if that is the case then please be aware that greengrass does not support it between greengrass connected devices and greengrass core.","","✅ (1)"
"556602159513468951",".dhess","2020-09-08T09:03:40.2310000+08:00","Every time we have a power bump, security overheads to check equipment.  I always think bullshit.  If there is a problem PROD will log it down. Which brings up the point..SCADA should be auto logging these events to the CMMS so techs can zero in on real problems. Likewise config your power monitor as it should auto publish the fault. The CMMS can subscribe and notify the line techs. *Voltage sag to 105.2VAC for 233 msec* is a lot more useful that an overhead notication. This is low hanging fruit.","",""
"698244484302897323","lmtx","2020-09-08T09:18:29.9940000+08:00","you can consider using aws sns service to send this kind of notifications via mail or sms","",""
"698244484302897323","lmtx","2020-09-08T09:19:40.3090000+08:00","that approach usually works for application support team but might be interesting in your case as well","","💯 (1)"
"698244484302897323","lmtx","2020-09-08T09:20:40.3030000+08:00","https://aws.amazon.com/sns/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc","",""
"698244484302897323","lmtx","2020-09-08T13:26:42.9430000+08:00","@EgoNoBueno if you are interested in persistent sessions in AWS IoT you can take a look at this documentation https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-core.html#mqtt-persistent-sessions

IMPORTANT:  You must use the AWS IoT Greengrass API to configure persistent sessions. You can't do this in the console.","",""
"698244484302897323","lmtx","2020-09-08T13:27:49.8540000+08:00","please also check the various qos levels for mqtt communication - this is a good diagram that explain it: https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-core.html#message-quality-of-service","",""
"698244484302897323","lmtx","2020-09-08T13:36:40.8410000+08:00","please mind that persistence in communication is handled a bit differently depending on the direction (`GGC`->`AWS IoT` and `AWS IoT`->`GGC`)","",""
"556602159513468951",".dhess","2020-09-08T15:55:17.0730000+08:00","@LMtx Thank you. I thought quality of service levels 0, 1 , and 2 were always available with the MQTT protocol. Thanks for bring to my attention this might not always be the case. 😎","",""
"698244484302897323","lmtx","2020-09-08T17:04:22.2780000+08:00","the protocol specification and particular implementation differ sometimes ;)","","👍 (1)"
"698244484302897323","lmtx","2020-09-09T00:26:45.9000000+08:00","What is your biggest cloud challenge?","",""
"538677655000842260","na23909","2020-09-09T02:20:06.4180000+08:00","@LMtx that should be a question of the day","",""
"538677655000842260","na23909","2020-09-09T02:23:24.4440000+08:00","For me there is multiples challenge but the biggest is the portability between different cloud provider and maintaining a unique namespace :ilaugh:","",""
"751484333101023384","acesdan9630","2020-09-09T02:34:09.3960000+08:00","I find that, the customer is the biggest challenge. you get a new customer with very little infrastructure, they embrace clouds like a warm blanket right out of the dryer! But if you have a customer with a decades old ""tried and true"" control system that they upgraded in the 80's that has not given them enormous problems, they are the worst to try and win over. No ROI number in the world is going to get them to come into this century!","","🤣 (2)"
"698244484302897323","lmtx","2020-09-09T02:40:49.0910000+08:00","> @LMtx that should be a question of the day
 could you promote my question so we cloud gather more cloud related challenges? later we cloud iterate over them and I will provide my hints","","👇 (1)"
"698244484302897323","lmtx","2020-09-09T02:41:54.2420000+08:00","@zackscriven 👆","",""
"698244484302897323","lmtx","2020-09-09T12:10:46.1830000+08:00","> I find that, the customer is the biggest challenge. you get a new customer with very little infrastructure, they embrace clouds like a warm blanket right out of the dryer! But if you have a customer with a decades old ""tried and true"" control system that they upgraded in the 80's that has not given them enormous problems, they are the worst to try and win over. No ROI number in the world is going to get them to come into this century!
@ACEsDan that attitude is very common for ""old and big"" companies and that is why we should educate them. I am not saying that you need to get all of your systems/servers/applications and move then to the cloud because that would make you more money or something. It is not about ""lift and shift"" the same attitude from one place (on-prem) to the cloud. Using cloud as part of the organizational ecosystem is more a business change than purely technological switch.  One can argue why they should do any business changes - their business is very successful since 80's. And now we are ready to start the real conversation (we shifted topic from technology to business) - the business model that made them successful since 80's till now will make them totally obsolete  in next 5 years. Even the ""old and big"" companies can fall and you should help them see that. So the thing is not to convince them to move everything to the cloud (because that might does not make any sense) but to extend their capabilities/portfolio/efficiency by leveraging the modern cloud services (by modern I'm not talking about having a fleet of virtual machines in the cloud). This way you are not disturbing their business model but rather help them generate bigger value from the assets their already have (and are so proud of). IoT is not about technology, it is about new business opportunities.","",""
"698244484302897323","lmtx","2020-09-09T12:14:05.5140000+08:00","> For me there is multiples challenge but the biggest is the portability between different cloud provider and maintaining a unique namespace :ilaugh:
@Na2$ could you elaborate a bit more about this issue? I do not fully understand how having multiple cloud providers impact the unique namespace. I guess that you are taking about very specific cloud providers.","",""
"538677655000842260","na23909","2020-09-09T16:22:33.5700000+08:00","@LMtx📡 yes I thought about the transfer of big historic data securely for migration of old system to new ones.In fact my English wasn't correct: I meant 2 issues. The second one is maintaining a global unique namespace in an international company. For more details about this, you could find some information on the Namur website which defines how to tackle this challenge since years.","","👍 (1)"
"698244484302897323","lmtx","2020-09-09T18:50:23.9000000+08:00","@Na2$ data migration between systems/clouds is usually a complex and painful project. I have an experience in migrating both IoT related and not related data - if you have any specific question I can try to give you some tips. I do not have any experience with Namur so I won't be able to help with that one.","",""
"382941357699760129","walker.reynolds","2020-09-09T20:47:45.1150000+08:00","> Perhaps this has been discussed - please point me to a BKM if you have one. How do you guard your business against a loss of your internet connection? The internet connection appears to be the Achilles Heel. If it breaks the whole enterprise goes down. Thank you.
@EgoNoBueno WAN uptimes are in the 99.9999% (yes, 6 nines) range for most businesses in the U.S. -- so this does not happen very often, what does happen is a failure of the corp infrastructure (hardware failure or closing of ports).  We use MQTT Sparkplug and DNP3 primarily for this reason -- they support store and forward, so we don't have data loss as long as the connection is restored before we run out of edge disk space.","","😎 (2),ismile (1)"
"698244484302897323","lmtx","2020-09-10T12:06:13.5620000+08:00","I you ever wanted to have a dark theme in your AWS Console there is an easy hack to get it: https://twitter.com/lmtx1/status/1303906892981436418?s=20","","👍 (2)"
"556602159513468951",".dhess","2020-09-14T01:41:49.7120000+08:00","@Mario Ishikawa I had to look up Google Kubernetes Engine (GKE - with Photon platform (lol)). All these companies have to come up with their own marketing language to differentiate themselves. In short it sounds like Kubernetes is a well thought out object model to manage work flow and load. https://youtu.be/Rl5M1CzgEH4","",""
"745009912160976977","marioishikawa","2020-09-14T02:05:10.6490000+08:00","> @Mario Ishikawa I had to look up Google Kubernetes Engine (GKE - with Photon platform (lol)). All these companies have to come up with their own marketing language to differentiate themselves. In short it sounds like Kubernetes is a well thought out object model to manage work flow and load. https://youtu.be/Rl5M1CzgEH4
@EgoNoBueno 
Kubernetes is a technology to manage containers and services. The advantage of Google is that you don't pay for the Master node which in AWS will cost $75 per month.","",""
"745355591513407602","mdowdell","2020-09-15T03:40:30.7280000+08:00","Does anyone have experience with Siemen´s Mindsphere?","",""
"745355591513407602","mdowdell","2020-09-15T03:41:49.9670000+08:00","I am interested in comments related to cost, flexibility, ease-of-use, etc.","",""
"688675337785311245",".muhammadatif","2020-09-15T21:39:15.4260000+08:00","MindSphere Start for free is now available (and yes, it is really free) !!!
https://siemens.mindsphere.io/content/mindsphere/en/start.html
After having learned in guided tours - step by step - how #MindSphere works, you can try to connect your assets and analyze data with preinstalled apps.
Just as simple as it sounds !
Browse the preinstalled apps and get started:
1. Asset Manager
2. Visual Analyzer
3. Visual Flow Creator
4. Developer Cockpit
5. Fleet Manager","","👍 (2)"
"698244484302897323","lmtx","2020-09-17T15:48:52.6710000+08:00","AWS IoT for Manufacturing webinar series - sharing in case anyone is interested: https://pages.awscloud.com/reg_webinar_series_IoT_smart_manufacturing.html","",""
"352642563255042059","takko_the_boss","2020-09-21T10:52:07.1440000+08:00","https://tenor.com/view/time-out-hold-up-gif-9763542","",""
"352642563255042059","takko_the_boss","2020-09-21T10:54:35.1090000+08:00","> Does anyone have experience with Siemen´s Mindsphere?
@mdowdell Mindsphere uses only TLS for communicating over WAN, and their agent requires you to close the air-gap by just allowing the SCADA to talk on internet. I'm not a fan of this practice, as it's poor way of enacting secure interconnectivity.","","ismile (2)"
"698244484302897323","lmtx","2020-09-22T13:50:01.7400000+08:00","Hello everyone 🙂 I created a github repo with sample solution for following business use case:

Obtain data from a local Data Base running on isolated network without access to the public internet and transfer it to the AWS cloud.

Additional requirements:
* do not store the password to the local Data Base as a clear text at any point in time
* do not share the password to the local Data Base with developers
* encrypt data during transfer to the cloud

You can find a detailed description and source code here: https://github.com/LMtx/aws-ggc-secret-example-01

Feel free to contact me in case of any questions 🙂","","ismile (2)"
"240257487746367489","mtcderek","2020-09-23T10:53:57.9090000+08:00","👋 new here, i've been building out some k8s workloads (managed by rancher/k3s) in AWS for manufacturing data management. it's been quite a journey!","",""
"352642563255042059","takko_the_boss","2020-09-23T11:41:33.7790000+08:00","@LMtx conceptually this looks nice. But I feel it makes a lot of assumptions about the state of the private network the DB sits on.

If you ever want to run through the security implications this presents, I'd love to!!","",""
"698244484302897323","lmtx","2020-09-23T11:43:20.0110000+08:00","@MikeCurnow.com what do you mean by ""the state of the private network the DB sits on""?","",""
"352642563255042059","takko_the_boss","2020-09-23T11:52:25.4390000+08:00","Disclaimer/Context: I'm a security guy. So I find flaws in about 99% of every proposed IIoT + Cloud integration deployment (**ever**). I gave a lot of presentations on this very topic lololol.

It bears repeating that I think the concept is cool.

But...........
...........
(To me) This model assumes a perfect world scenario where the *private network* is robust enough to handle peering over the network segments in a way that's intuitive enough to integrate these AWS methods just fine. I guess..............................................I've been exposed to industrial setups where you can't touch a **single thing** sitting in the  industrial side of the network, and I don't see this concept working well unless it's part of the IIoT/ICS conception and standup. It'd be hard to ""bolt this on"" an already existing network in my opinion. But there are many many different situations where I can be wrong. So don't take it to heart. My job is to find out how people fuck everything up, so I see everything in that lense.","",""
"352642563255042059","takko_the_boss","2020-09-23T11:54:19.4580000+08:00","But I do love the fact you incorporated Docker in here. I don't see that much.","","ismile (1)"
"698244484302897323","lmtx","2020-09-23T12:05:04.8260000+08:00","I agree with you that there are a lot of restrictions regarding private network and legacy systems when you talk with big customers (i.e. factory); at the same time many of this type of organizations realized that local data silos block them from leveraging that data as a competitive advantage (they can extract a great value when joining data in one place); I've been implementing similar architecture in real life - it is flexible enough to meet specific requirements (password rotation, key management etc.); I real file deployment the architecture was a bit more complex (a proxy servers, firewalls etc.) but the concept is the same; the biggest challenge is providing security of the edge server - not only for initial installation but also during ongoing maintenance (which might be done by less experienced people); I am always curious how others secure edge servers - happy to hear if you are willing to share your best practices @MikeCurnow.com","",""
"352642563255042059","takko_the_boss","2020-09-23T12:06:17.0450000+08:00","I love this answer.","",""
"352642563255042059","takko_the_boss","2020-09-23T12:06:52.4060000+08:00","Do you mind if I get back with you on here tomorrow. I'm currently engaged in some work at the moment, but I'd love to chat with ya for sure. I like where your head's at.","",""
"698244484302897323","lmtx","2020-09-23T12:07:23.3370000+08:00","sure, have a great day 👍","","🌮 (1)"
"745009912160976977","marioishikawa","2020-09-24T08:34:52.0520000+08:00","For those into low code, what's your favorite platform? I've tried Bubble, wave maker, AppGyver and Mendix. Mendix is the most powerful but AppGyver seems quite promising. https://www.geekwire.com/2020/low-code-competition-grows-microsoft-integrates-power-apps-github-teams/","",""
"772976664271257611","sasanka9171","2020-11-09T02:03:49.0340000+08:00","@Walker Reynolds I remember you saying in one of your talks that Digital Twins in Manufacturing have failed the reason being they are static while this can be overcome with UNS. Am I right? If so, is the alignment of UNS to ISA 95 facilitating the extensibility.","",""
"740531920907010118","jmckeon","2020-11-09T05:30:14.8510000+08:00","We are currently working on a Acopos track solution with four delta robots, this solution would be virtually impossible to realise as a integrated system without the use of the digital twin due to the speed and complexity of the poduct format output.
This is the first time we have used the digital twin and are still working through the design phases.
Will update on the positive and negative as we move through the project. Currently closing the concept phase with the client.

We are also introducing the principles of IND 4.0 as part of the design process.","","👍 (2)"
"740531920907010118","jmckeon","2020-11-09T05:30:36.3550000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/775110046089609216/tmp_1604598369306.jpg?ex=68deeefb&is=68dd9d7b&hm=9ebc5bc392aa7b5ddbb9951c452a0250fc14b1fafbb9fb04ea783774040fd28b&",""
"772976664271257611","sasanka9171","2020-11-09T11:13:21.8130000+08:00","@jmckeon excited to hear your progress on Acopos Solution!!! Please keep us posted on the Challenges too so that we can ponder over it.","",""
"740531920907010118","jmckeon","2020-11-09T15:20:03.1230000+08:00","@sasanka  Will do ..might write a project summary on the application need, the selection and integration of the technology and data extraction..","",""
"740531920907010118","jmckeon","2020-11-09T15:43:49.5590000+08:00","One to note on this type of project, it is the first opportunity to bring a completely integrated solution that can provide the ""batch size one"" production. I believe our community needs to think about and promote the evolution of manufacturing on every level both the horizontal and the vertical. We will learn off each other, we can share the positive and the negative while maintaining contractual integrity to our endusers, the benefits of this shared learning as integrators has the potential for positive outcome for people and the environment where we live.","",""
"382941357699760129","walker.reynolds","2020-11-10T00:41:19.7640000+08:00","> @Walker Reynolds I remember you saying in one of your talks that Digital Twins in Manufacturing have failed the reason being they are static while this can be overcome with UNS. Am I right? If so, is the alignment of UNS to ISA 95 facilitating the extensibility.
@sasanka yes -- digital twins fail because they are static, not stateful, the correct technology stack with a UNS fixes that","",""
"740531920907010118","jmckeon","2020-11-10T02:05:50.1870000+08:00","@Walker Reynolds we are using the digital twin to simulate the timing of events in order to proof the design to a tolerance of +/- 5% of product target, we then plan to build and link the solution with the digital twin to predict performance improvement on the design and for new requirements upgrade. What is your 10k ft view on this approach","",""
"766684226455207996","bright_hummingbird_31342","2020-11-10T02:11:42.6770000+08:00","I'd love to hear how people are approaching this in brownfield environments.  You know, when the documentation is best described as ""lol wut"".","",""
"772976664271257611","sasanka9171","2020-11-10T15:59:52.6850000+08:00","> @sasanka yes -- digital twins fail because they are static, not stateful, the correct technology stack with a UNS fixes that
@Walker Reynolds can't the Digital Twins be made Stateful. What stops from moulding it. I am coming from the perspective that there might have been considerable investment put into creating and deploying the Digital Twin Solution.","","👍 (1)"
"740531920907010118","jmckeon","2020-11-11T02:45:34.8070000+08:00","Some update....the results from the production simulation has shown that we cannot achieve the production line speed, based on this we have changed to a twin lane solution where it indicates that we can achieve the production speed with a 20% addition capacity....the negative is a capex cost increase....","","👍 (1)"
"740531920907010118","jmckeon","2020-11-11T02:45:45.9330000+08:00","Some update....the results from the production simulation has shown that we cannot achieve the production line speed, based on this we have changed to a twin lane solution where it indicates that we can achieve the production speed with a 20% addition capacity....the negative is a capex cost increase....","",""
"556602159513468951",".dhess","2020-11-30T06:02:49.4670000+08:00","A great video by Industry40tv. Cloud Selection considerations: What tools you need for the situation you are addressing. Locality - a nearby data center may have lower latency times. Is the provider capable of dealing with the massive amounts of data ingestion that industrial equipment generates? Cloud cost can be very difficult to estimate in advance. What advanced analytics do you need?
Increasingly it is becoming a Multi-Cloud world, depending on what you need done. The video cites perhaps having SalesForce on one cloud, and back office SAP somewhere else.  https://youtu.be/2HUVAoD1mjw","","ismile (2),💯 (1),👍 (2)"
"194289793905983489","zackscriven","2020-12-03T02:06:53.8940000+08:00","Thanks for sharing @EgoNoBueno!","",""
"783917475128410112","geoffnunan","2020-12-03T13:08:49.6010000+08:00","We do a lot of development with both Mendix and OutSystems. They are both hugely powerful, and both have their strengths and weaknesses","",""
"745009912160976977","marioishikawa","2020-12-04T20:24:21.2240000+08:00","Great. Do you use it for things you would in the past do it on SCADA or MES customization? Are you the end user?","",""
"783917475128410112","geoffnunan","2020-12-05T03:41:02.8110000+08:00","We build bespoke MES applications and inventory management applications with low-code for our customers. We are systems integrators and software developers","","🎆 (1),👍 (1)"
"756277491433341030","dewayne_warden","2020-12-13T04:04:48.8890000+08:00","https://www.linkedin.com/posts/matthewwopata_reinvent-aws-iiot-activity-6740392620469583872-TASh","","👍 (2)"
"756277491433341030","dewayne_warden","2020-12-13T04:05:42.6600000+08:00","Could this be a game changer?","",""
"756565963520081950","andersgustav","2020-12-13T04:59:10.5550000+08:00","Thats one straight on my ""have2explore-list""","",""
"756277491433341030","dewayne_warden","2020-12-13T05:00:24.5470000+08:00","@Anders Gustav Saddle up Pardner! Let’s go find out.","",""
"756565963520081950","andersgustav","2020-12-13T05:04:59.6320000+08:00","Looks like I have to wait a little..","https://cdn.discordapp.com/attachments/740336311671586968/787424787643367424/2020-12-12_22-03-25.png?ex=68dee8fb&is=68dd977b&hm=fb4a01b374c30d06ba7c21297eb458c7668177c9c882ab08fe1271693ddf9148&","😒 (1)"
"343075694903033857","michael.brown","2020-12-13T06:03:00.2280000+08:00","Should be back in stock now....they were just released...","https://cdn.discordapp.com/attachments/740336311671586968/787439386626097152/unknown.png?ex=68def693&is=68dda513&hm=6f958b66d9ae19e671fd8eca5bdfc0934765c0dd6d3550b1125d581b0e8aa0fa&",""
"343075694903033857","michael.brown","2020-12-13T06:04:45.6360000+08:00","Additionally, if you dont need the hardware, already have the data - you can run it through https://aws.amazon.com/lookout-for-metrics/","",""
"343075694903033857","michael.brown","2020-12-13T06:05:24.4580000+08:00","and https://aws.amazon.com/lookout-for-equipment/?nc2=h_ql_prod_ml_lfe","",""
"743347439972515894","mrjain.","2020-12-16T13:11:56.9580000+08:00","Looks like another flurry of IoT announcements from AWS - https://aws.amazon.com/about-aws/whats-new/2020/12/announcing-support-alarms-preview-aws-iot-events-aws-iot-sitewise/","",""
"743347439972515894","mrjain.","2020-12-16T13:12:03.2120000+08:00","https://aws.amazon.com/about-aws/whats-new/2020/12/aws-iot-device-management-introduces-fleet-hub/","",""
"743347439972515894","mrjain.","2020-12-16T13:12:10.1940000+08:00","https://aws.amazon.com/about-aws/whats-new/2020/12/aws-iot-core-device-advisor-now-available-in-preview/","",""
"743347439972515894","mrjain.","2020-12-16T13:12:51.8050000+08:00","https://aws.amazon.com/blogs/iot/ml-detect-for-device-defender/","",""
"743347439972515894","mrjain.","2020-12-16T18:36:37.0050000+08:00","https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-aws-iot-core-lorawan/","","‼️ (3)"
"343075694903033857","michael.brown","2020-12-18T04:25:11.7540000+08:00","Mindmap summary of select announcements from AWS ReInvent","https://cdn.discordapp.com/attachments/740336311671586968/789226713863290970/AWS_Industry_focused_Announcements.pdf?ex=68dedfa7&is=68dd8e27&hm=b0791b27bd2682db900a580561de995464f567d285eda0c5a2876b89d11bb4f2&","💯 (1)"
"743545122201010236","scottf4208","2020-12-18T05:42:57.8160000+08:00","Solid drop!! Thanks","","👍 (1)"
"743545122201010236","scottf4208","2020-12-19T03:05:31.2660000+08:00","My good friend and colleague Carlos Lemus just published his IoT thoughts about this year's AWS re:Invent - https://www.trek10.com/blog/thoughts-on-reinvent-internet-of-things","","ismile (3),👀 (2),👍 (3)"
"194289793905983489","zackscriven","2021-02-16T23:29:13.0040000+08:00","Good article from James Joy on creating a cloud Ignition Instance!

https://jarautomation.io/blog/posts/2019-06-09-public-facing-ignition","",""
"743347439972515894","mrjain.","2021-02-17T15:40:33.7340000+08:00","https://aws.amazon.com/blogs/architecture/architecture-monthly-magazine-manufacturing/","","💯 (1),☁️ (1)"
"343075694903033857","michael.brown","2021-02-17T22:02:13.8950000+08:00","This is interesting - an analyst took the IDC Enterprise storage revenue numbers and dropped in estimated storage revenue from AWS & Azure - results? AWS and Azure are the largest storage vendors in the world....that's interesting alone, but they did it WITHOUT buying a single disk from the old guard.. https://blocksandfiles.com/2021/02/16/aws-top-enterprise-storage-suppliers-by-revenue/","",""
"343075694903033857","michael.brown","2021-02-17T22:14:14.8010000+08:00","Just another datapoint if anyone wants to understand what I mean by "" buy vs build and the pace of innovation"" - listen to James Hamilton - he talks about switching to custom routers and servers starting @ 23Min thru about 45min. 
https://www.youtube.com/watch?v=AyOAjFNPAbA","","ismile (1)"
"194289793905983489","zackscriven","2021-02-19T00:46:26.1120000+08:00","Thanks for sharing the Insight Michael! What's your thoughts on the whole AWS pulling the rug from under Parlor thing?","",""
"343075694903033857","michael.brown","2021-02-19T01:19:49.2730000+08:00","Yeah, at my level and context that's not a situation I have any visibility so wouldn't be able to provide comments. However, personally I am really happy to see my Parler app back up and running.","",""
"194289793905983489","zackscriven","2021-02-19T02:40:02.0880000+08:00","I agree!","",""
"194289793905983489","zackscriven","2021-02-19T02:40:29.6630000+08:00","My list of tasks today include mirroring our YouTube channel to lbry.tv 😁 it's not smart to have all your eggs in one basket with any big tech company.","","💯 (1),👍 (1)"
"743347439972515894","mrjain.","2021-02-22T16:04:52.6810000+08:00","Very good article about IoT and AWS Costs - https://www.trek10.com/blog/three-cost-effective-design-patterns-for-aws-iot-data-ingestion","","💯 (3)"
"194289793905983489","zackscriven","2021-02-23T15:04:21.1340000+08:00","Great article. Thank you for sharing!","","👍 (1)"
"745009912160976977","marioishikawa","2021-02-24T01:23:56.8670000+08:00","Hard times for data centers in Texas: https://datacenterfrontier.com/texas-data-centers-rely-on-generators-amid-power-emergency/","",""
"778288647521828874","joelmessina","2021-02-25T01:38:35.3620000+08:00","https://www.plcnext-community.net/en/hn-makers-blog/465-how-to-turn-an-axc-f-2152-into-an-aws-greengrass-device.html were using docker or Balena engine here to pull in greegrass into our PLCnext hardware which is running a Yocto linux OS variant. I haven't seen this issue. thanks for sharing!","",""
"698244484302897323","lmtx","2021-02-25T03:18:30.6230000+08:00","your welcome, feel free to reach out in case of any questions regarding Greengrass or AWS IoT in general","",""
"698244484302897323","lmtx","2021-02-25T03:19:44.7250000+08:00","anyone tried the Greengrass v2? what do you think about it?","",""
"343075694903033857","michael.brown","2021-02-25T10:26:29.3630000+08:00","Just saw this... Up to 50 Amazon Workspaces until July for free... forhttps://aws.amazon.com/blogs/desktop-and-application-streaming/amazon-workspaces-free-tier-extension-2021/","","💯 (1),ismile (1)"
"745009912160976977","marioishikawa","2021-02-25T18:53:57.1440000+08:00","That is also great for Mentorship. Thanks!","",""
"382941357699760129","walker.reynolds","2021-02-26T08:07:03.8490000+08:00","Great post","",""
"456226577798135808","Deleted User","2021-02-27T04:04:43.1220000+08:00","A good and deep analysis about the future of Cloud by McKinsey","","ithink (1)"
"456226577798135808","Deleted User","2021-02-27T04:05:00.8260000+08:00","https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/clouds-trillion-dollar-prize-is-up-for-grabs","",""
"194289793905983489","zackscriven","2021-03-11T05:31:14.5470000+08:00","Editing a Video... relevant Ad Targeting on our Channel. LOL","https://cdn.discordapp.com/attachments/740336311671586968/819321525056438302/Screen_Shot_2021-03-10_at_2.30.29_PM.png?ex=68deef21&is=68dd9da1&hm=1d9e0ad1b98271dee4768881ce019bdd88900cf47eb9a3123fe150108ddc6a2f&",""
"794020366536146977","mparris","2021-03-11T12:22:24.5060000+08:00","Like @Mario Ishikawa said... They are always listening to him.","","😆 (1)"
"794020366536146977","mparris","2021-03-11T12:24:17.0070000+08:00","By the way, Aron at HighByte confirmed that the PostgreSQL interface on cockroachDB would work with Intelligence hub out of the box.

Thanks again for the recommendation @BrownAWS#4287","","ishocked (1)"
"741044056154439750","heshr_","2021-03-11T12:47:34.8720000+08:00","Hi guys just letting you know Cirrus link have developed a couple of AWS modules that help with asset model autodiscovery into and out of AWS IoT SiteWise.","","💯 (1)"
"741044056154439750","heshr_","2021-03-11T12:49:23.2830000+08:00","First is the IOT Bridge for site wise which basically allows UDTs created in Ignition to be auto discovered into AWS SiteWise as asset models and instances. https://aws.amazon.com/marketplace/pp/B08L8KNCNN?ref_=srh_res_product_title#pdp-usage","",""
"741044056154439750","heshr_","2021-03-11T12:49:37.9870000+08:00","https://www.cirrus-link.com/aws-cloud/#","",""
"741044056154439750","heshr_","2021-03-11T12:55:04.1520000+08:00","the second one is called AWS Engine for Sitewise, which can enable ignition to auto-discover  assets and data models from SiteWise and create corresponding UDTs and Tags in Ignition. Should come handy for people working with Sitewise and Ignition.","",""
"194289793905983489","zackscriven","2021-03-11T22:39:55.1230000+08:00","Thanks for sharing @HeshR","",""
"194289793905983489","zackscriven","2021-03-12T00:40:34.3650000+08:00","In response to the AWS vs Azure IoT platform video","https://cdn.discordapp.com/attachments/740336311671586968/819610764016222258/Screenshot_20210311-093958.png?ex=68df53c1&is=68de0241&hm=60a8a35672262314bec1827b44ece60b63d72e8c5b3ff76fa6a8790b58106eb1&",""
"194289793905983489","zackscriven","2021-03-12T00:40:40.2420000+08:00","Pinned a message.","",""
"745009912160976977","marioishikawa","2021-03-12T04:54:34.3000000+08:00","haha. GCP does not make use of Sparkplug B also.","",""
"745009912160976977","marioishikawa","2021-03-12T04:55:33.6390000+08:00","And some other limitations:
Note: The MQTT standard is defined for implementing a full publish/subscribe broker. However, the managed MQTT bridge run by Cloud IoT Core does not support all publish/subscribe operations, such as creating arbitrary topics that devices can use to send messages between them. (Filtering can be accomplished with downstream processes running on Cloud Pub/Sub.) Cloud IoT Core uses a predefined set of topics and specific topic formats.","","ithink (1)"
"745009912160976977","marioishikawa","2021-03-12T04:55:44.2400000+08:00","https://cloud.google.com/iot/docs/how-tos/mqtt-bridge","",""
"745009912160976977","marioishikawa","2021-03-12T04:59:30.4840000+08:00","And from https://medium.com/swlh/mqtt-in-a-nutshell-3340c61a639d
Google Cloud IoT Core support for MQTT is based on v3.1.1 but does not support all features. Not supported are Quality of Service (QoS) 2, arbitrary MQTT topics and subscriptions, Last Will and Testament (LWT), retained messages and persistent sessions.","",""
"745009912160976977","marioishikawa","2021-03-12T04:59:59.9570000+08:00","So, I use actually Google IoT Core but I'm testing its limitations as we a moving to Sparkplug B","","🔥 (1),👍 (1)"
"794020366536146977","mparris","2021-03-12T12:49:53.4870000+08:00","Great information!!","","👍 (2)"
"821044538709114900","ianskerrett.","2021-03-16T23:10:53.6670000+08:00","fyi, HiveMQ just announced a free version of HiveMQ Cloud that allows for up to 100 MQTT clients to connect for free. We support Sparkplug so it is ideal for small deployments.  https://www.hivemq.com/mqtt-cloud-broker/","","👍 (4),💯 (1)"
"194289793905983489","zackscriven","2021-03-17T02:44:16.2100000+08:00","Thank you for sharing Ian! Your ears must have been burning from the 500 Free Canary License dropped today 😎","",""
"745796393855352953","thedavidschultz","2021-03-17T03:15:10.3470000+08:00","Just shared this in another channel","",""
"821044538709114900","ianskerrett.","2021-03-18T01:25:58.6210000+08:00","I missed the Canary announcement. I need to go find it. 🙂","",""
"194289793905983489","zackscriven","2021-03-18T03:01:57.6610000+08:00","I got you!","",""
"743347439972515894","mrjain.","2021-03-18T14:08:00.7400000+08:00","https://www.youtube.com/watch?v=WdDtM3NJbMA AWS IoT Digital Roadshow: Industry 4.0 Acceleration
Episode 1: Modernize Industrial Operations with AWS IoT","",""
"743347439972515894","mrjain.","2021-03-18T14:08:48.8140000+08:00","The slides from the above talk - https://pages.awscloud.com/rs/112-TZM-766/images/2021_VW_s08e01-IOT_Slide-Deck.pdf","",""
"745009912160976977","marioishikawa","2021-03-18T23:44:17.0690000+08:00","Thanks!","","👍 (1)"
"743347439972515894","mrjain.","2021-03-19T14:21:53.5450000+08:00","Episode 2: https://www.youtube.com/watch?v=9YPs-lFxcMU","",""
"698244484302897323","lmtx","2021-03-23T18:13:29.7370000+08:00","Hello, I am preparing a training on IoT implementations using AWS services. I would like to find the technical level relevant to most people. Could you please vote in my tweeter poll or comment below? Feel free to DM me with any questions/ideas regarding that training. Thank you!
https://twitter.com/lmtx1/status/1374302043842678784?s=20","","🔥 (1)"
"817835202746253344","IIoT#4707","2021-03-23T18:13:29.9740000+08:00","GG @LMtx, you just advanced to level 1!","",""
"745009912160976977","marioishikawa","2021-03-23T19:51:12.2900000+08:00","Done","","👍 (1)"
"815267392905150465","venkyiaf753280","2021-03-23T22:59:41.9900000+08:00","Done","","👍 (1)"
"343075694903033857","michael.brown","2021-03-23T23:56:37.9770000+08:00","I'd like to know more about that! 🙂
let me know if you need/want any assistance.","",""
"698244484302897323","lmtx","2021-03-24T00:05:31.4970000+08:00","I plan to make a series of trainings related to IoT and AWS on different levels; I will cover IIoT and CIoT specific architectures (including possible attack vectors and device management)","",""
"698244484302897323","lmtx","2021-03-24T00:06:54.2920000+08:00","want to start with scope most relevant to interested people and prepare further trainings based on gathered feedback","",""
"343075694903033857","michael.brown","2021-03-24T00:10:27.5530000+08:00","Wait? You want to start small and iterate based on consumer feedback? I'm not sure that's gonna work.....ive been doing this 127 years and that's not how we do things.","",""
"698244484302897323","lmtx","2021-03-24T00:16:28.3550000+08:00","IoT services offered by AWS are a very broad topic, I want to cover services and overall architecture in great details - so I need to adjust the scope","",""
"343075694903033857","michael.brown","2021-03-24T00:17:31.1670000+08:00","I feel your pain... Add in the speed of development of new things its kinda insane","",""
"698244484302897323","lmtx","2021-03-24T00:18:43.4940000+08:00","that is why I will not cover GGv2 for now","",""
"812295088348200960","patanj2","2021-04-03T02:09:41.2380000+08:00","What are some approaches for persisting  a UNS into an AWS datalake, if it resides in an on-premises MQTT broker in as SparkplugB payloads. I have seen some examples online that convert the payload to json, which seems counterintuitive.","",""
"698244484302897323","lmtx","2021-04-03T02:23:19.9320000+08:00","I guess they convert the payload to json because aws iot core expects json as a payload for mqtt message","",""
"812295088348200960","patanj2","2021-04-03T02:39:00.3800000+08:00","It seems like in converting to json, the size of my data would explode.  What I really want to do is just persist the data to S3 and then do some follow on processing if I decide to convert something to a columnar format.","",""
"698244484302897323","lmtx","2021-04-03T02:44:17.5120000+08:00","@John Patanian if you are using greengrass to obtain data at the edge you can use the stream manager functionality to transfer data directly to s3 https://docs.aws.amazon.com/greengrass/v1/developerguide/stream-manager.html","",""
"817835202746253344","IIoT#4707","2021-04-03T02:44:17.7720000+08:00","GG @LMtx, you just advanced to level 2!","",""
"698244484302897323","lmtx","2021-04-03T02:45:18.9340000+08:00","https://docs.aws.amazon.com/greengrass/v2/developerguide/manage-data-streams.html (if you are using GGv2)","",""
"812295088348200960","patanj2","2021-04-03T02:50:34.4050000+08:00","@LMtx Thank you. This is something I will try out. Just designing architecture now so nothing is set up yet.  AWS architect suggested batch querying data from historian, which also did not make sense to me, as I think we would lose our asset structure.","",""
"698244484302897323","lmtx","2021-04-03T02:52:36.5600000+08:00","if you want to keep asset structure then you might consider the SiteWise https://docs.aws.amazon.com/iot-sitewise/latest/userguide/what-is-sitewise.html","",""
"698244484302897323","lmtx","2021-04-03T02:53:54.5960000+08:00","it works on top of greengrass","",""
"698244484302897323","lmtx","2021-04-03T02:54:40.5830000+08:00","so anyway start with greengrass 😉","",""
"698244484302897323","lmtx","2021-04-03T02:55:27.0530000+08:00","I'd suggest the greengrass v2 (but please mind that is a new service and might be not as mature as v1)","",""
"745009912160976977","marioishikawa","2021-04-08T08:18:10.7910000+08:00","Google IO is back, free and online https://events.google.com/io/?utm_source=linkedin&utm_medium=organicsocial&utm_campaign=svd-2021-og&lng=en","","👀 (1)"
"343075694903033857","michael.brown","2021-04-09T02:29:20.1990000+08:00","FYI - Amazon Lookout for Equipment is now Generally Available and ready to go. Managed service to monitor for abnormal behavior and predict failures in manufacturing and industrial equipment.
https://aws.amazon.com/about-aws/whats-new/2021/04/detect-abnormal-equipment-behavior-amazon-lookout-equipment-generally-available/
https://www.youtube.com/watch?v=UbgoMDjXF40

https://aws.amazon.com/lookout-for-equipment/","",""
"745009912160976977","marioishikawa","2021-04-09T02:55:03.5970000+08:00","One of the products that impressed me the most is Panorama. I see it as Amazon Go for the shop floor, in the sense that just with cameras you can tell the overall status of a plant (machines that are running/stopped, stopped because there is no operator - and he's having a snack). Am I thinking too far? https://aws.amazon.com/panorama/","",""
"343075694903033857","michael.brown","2021-04-09T02:56:56.3230000+08:00","Nope... 🙂","",""
"745009912160976977","marioishikawa","2021-04-09T03:00:55.2250000+08:00","I'm not crazy then","",""
"343075694903033857","michael.brown","2021-04-09T03:05:33.6130000+08:00","The cool thing is that you can use existing cameras - no requirement to buy new ones. So if you already have cameras looking at a machine or process - you can add Computer Vision","","💯 (1)"
"698244484302897323","lmtx","2021-04-10T03:01:30.4250000+08:00","That is a great news for many IoT deployments. Additionally this feature simplifies the migration from other platforms to AWS. https://aws.amazon.com/about-aws/whats-new/2021/03/configurable-endpoints-with-custom-domains-now-generally-available/","",""
"702921103147794444","dobermai","2021-04-10T03:22:23.0650000+08:00","Migrating to AWS from real MQTT systems is still not really possible as AWS IoT does support standards compliant ISO MQTT. Sparkplug for example is not possible due to lack of retained messages (+ non standard MQTT). See e.g.: https://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html#mqtt-differences","",""
"817835202746253344","IIoT#4707","2021-04-10T03:22:23.4380000+08:00","GG @Huber, you just advanced to level 1!","",""
"745009912160976977","marioishikawa","2021-04-13T03:06:23.6650000+08:00","https://news.ycombinator.com/item?id=26780848 Happening on the Open Source world right now","",""
"343075694903033857","michael.brown","2021-04-13T06:05:51.9150000+08:00","https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/","",""
"343075694903033857","michael.brown","2021-04-13T06:12:42.4450000+08:00","I don't speak for AWS and have no knowledge of all the goings on in this space - but as an individual I think its interesting in that if you call something OPEN SOURCE and license it using OPEN SOURCE - then its OPEN, right?
Anyone at anytime can fork the OPEN code and do whatever they want....
Company A builds a business on Open source Apache Lucene and produces an opensource and enterprise version of Elasticsearch - then Company B decides to Fork the OPEN code and do their thing with it....Didn;t they both do the same thing? just a thought for conversation","",""
"745009912160976977","marioishikawa","2021-04-13T06:43:10.3500000+08:00","That's a very sensitive topic in which I personally have divided opinions. I appreciate your disclosure about your opinion. And I have divided opinions because if AWS invest in the code, then it's good for the community. On the other hand, it's bad for any for profit company in which the business model is to offer their solution on the cloud which is  very common case and it happens with companies like MongoDb and Elastic. There is a huge engineering investment and they cannot compete with the biggest cloud players specially when they also use it. So, nothing legally wrong but it can affect future decisions on open source ventures. What gets the attention is how AWS has been handling it. As stated by Elastic, it was even wrongly published in the past as a partnership with Elastic. So, not a personal or professional attack to you :), just sharing the discussion that has been happening.","","👍 (1)"
"745009912160976977","marioishikawa","2021-04-13T06:46:07.5720000+08:00","So in the case of companies like Elastic, MongoDb and Timescale they have the code as open source, but with a special license to avoid the competition with cloud providers. So basically you can do anything unless provide the platform as a hosted service.","",""
"745009912160976977","marioishikawa","2021-04-13T06:49:03.7310000+08:00","This is Elastic post on their license change. https://www.elastic.co/blog/why-license-change-AWS","",""
"698244484302897323","lmtx","2021-04-14T15:49:04.1370000+08:00","Great resource if you are interested in IoT deployments on the AWS cloud https://aws.amazon.com/architecture/iot/","","👍 (2)"
"817835202746253344","IIoT#4707","2021-04-14T15:49:04.3770000+08:00","GG @LMtx, you just advanced to level 3!","",""
"743347439972515894","mrjain.","2021-04-15T12:08:06.8090000+08:00","This is more hardware related but I didn't know where to put it - https://memfault.com/ Looks very interesting","",""
"795178288330440704","youri.regnaud","2021-04-21T11:55:09.4910000+08:00","My company's IT strategy for IT data analysis and storage is to use the Google Cloud Platform with big query, big table, Looker, ... Do you have any comments, recommendations, experiences on using GCP for OT/IT data analysis and storage? Our approach would be to collect data and structure in Highbyte UNS and push it into GCP via Google IoT Core. Thanks for feedback","",""
"698244484302897323","lmtx","2021-04-21T13:26:13.6590000+08:00","unfortunately I can help only with aws","",""
"698244484302897323","lmtx","2021-04-21T14:43:01.4490000+08:00","good material if you are interested in IoT at AWS https://aws.amazon.com/quickstart/architecture/iot-device-connectivity/","","🙏 (1)"
"828707787717476392","lukesmaul","2021-04-22T00:20:45.4000000+08:00","Hi @Andres Gonzalez Marcelo - did you end up moving to a different platform? I'm helping a customer evaluate Cumulocity, we see some of the same issues, but would like some alternatives.","",""
"815267392905150465","venkyiaf753280","2021-04-22T12:43:37.1400000+08:00","https://us02web.zoom.us/webinar/register/4616183914828/WN_cKXw6GXEQ4eoDT22xy64PQ","",""
"343075694903033857","michael.brown","2021-05-04T22:21:29.1230000+08:00","Ok, I'm deploying this right now in my account.. Just released:
https://aws.amazon.com/blogs/architecture/digitally-transform-your-factory-with-machine-downtime-monitor-on-aws/
All the code it opensource so you can see how its done - use it in your own solutions:
https://github.com/awslabs/machine-downtime-monitor-on-aws","","aws (5)"
"820097580665929808","pvmagacho","2021-05-05T20:19:04.9970000+08:00","Hi @Michael Brown I found Amazon Lookout for Equipments. Any example available like the one you just shared above 😀?","",""
"194289793905983489","zackscriven","2021-05-05T21:43:41.7160000+08:00","Amazing. I was looking into that. Would be interested in learning more / doing a podcast w/ @Walker Reynolds on the Channel to discuss all things AWS with Michael Brown.","",""
"343075694903033857","michael.brown","2021-05-05T21:49:39.6180000+08:00","@Paulo Vitor Here's a few items that may help.
A colleague of mine Michael Hoarau created a full walk-through demo for using Lookout for Equipment.
https://github.com/aws-samples/lookout-for-equipment-demo

And here's a blog post showing how to to use Lookout for Equipment and A2I (Amazon Augmented AI)
A2I is a automated pipeline service that can be added to ANY AWS ML workflow to add Human review and feedback to model training. : https://aws.amazon.com/augmented-ai/
Here's the blog:
https://aws.amazon.com/blogs/machine-learning/detect-abnormal-equipment-behavior-and-review-predictions-using-amazon-lookout-for-equipment-and-amazon-a2i/","","aws (2)"
"820097580665929808","pvmagacho","2021-05-05T22:03:39.4740000+08:00","Thank you very much @Michael Brown. Will take a look","",""
"820097580665929808","pvmagacho","2021-05-06T06:22:37.7930000+08:00","Hi @Michael Brown can we hook up a thermography camera into this https://aws.amazon.com/panorama/ ?Example: https://www.flir.com/products/ax8-automation/","",""
"343075694903033857","michael.brown","2021-05-06T06:30:23.6690000+08:00","@Paulo Vitor  Short answer is yes. Panorama appliance uses RTSP protocol to ingest video - so in the config when you add a camera - you would point it to the RTSP URL of the local FLIR Camera.  Based on the Flir specs :
Ethernet/IP, Modbus TCP, TCP, UDP, SNTP, RTSP, RTP, HTTP, ICMP, IGMP, sftp, SMTP, SMB (CIFS), DHCP, MDNS (Bonjour)
RTSP is supported","","👀 (1)"
"820097580665929808","pvmagacho","2021-05-06T06:31:57.1210000+08:00","Thanks. Do I need to send the data to the cloud or I can build a local application? I will read more about this product next week.","",""
"817835202746253344","IIoT#4707","2021-05-06T06:31:57.3730000+08:00","GG @Paulo Vitor, you just advanced to level 7!","",""
"343075694903033857","michael.brown","2021-05-06T22:04:56.8730000+08:00","AWS Panorama supports models built with PyTorch, Apache MXNet, and TensorFlow. The models run LOCALLY on the appliance but can be built and trained anywhere including Amazon SageMaker and import them from a SageMaker job or build/train yourself and upload to an Amazon Simple Storage Service (Amazon S3) bucket. For more information, see Computer vision models.","","💯 (1)"
"766684226455207996","bright_hummingbird_31342","2021-05-06T22:27:36.0450000+08:00","This is interesting. 

Is there some sort of gateway or appliance that connects to the cameras? Does this support GigE, USB3, and GenTL devices? 

2D only? 3D point clouds?","",""
"343075694903033857","michael.brown","2021-05-07T03:01:28.3090000+08:00","@js So if the camera platform supports 3D - we support labeling and training 3D Point clouds that can be compiled and pushed back down to the appliance.
https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud.html

More specifically - Yes - There is an on-premise Panorama Appliance packed with a GPU for inference. It includes a Vision SDK and supports RTSP H.264 streaming cameras (think cameras already in place)

Upload video/images to AWS, use Sagemaker to train the model, compile the model - push the model down to the Panorama appliance for edge inference.","",""
"343075694903033857","michael.brown","2021-05-07T03:52:00.0490000+08:00","Or train your own model on your computer - then upload to AWS S3 - then the panorama appliance can pick it up from there and you can use the SDK for telemetry etc...","",""
"194289793905983489","zackscriven","2021-05-09T23:27:56.2900000+08:00","Free AWS Cloud Training Events on Twitch 😎
https://pages.awscloud.com/Global_traincert_AWS_Power_Hour_Cloud_Practitioner_FY21.html?sc_icampaign=event_twitch_certcp2_launch_tnc_global_traincert_200-cert&sc_ichannel=ha&sc_icontent=awssm-7790&sc_iplace=ribbon&trk=ha_awssm-7790","","ishocked (1)"
"456226577798135808","Deleted User","2021-05-12T17:15:15.3700000+08:00","Hi all! Let's say I have data in an Azure IoT hub and after doing some ""predictions"" I want to get that data back to my UNS. What would be the best way of doing that? I have Highbyte and an MQTT broker running. Documentation is... euh... not so clear for me. @Omar  Highbyte seems to have only outputs to Azure IoT hub how would Highbyte solve this? Or is their no other option then to develop a custom app that takes my data and provides it either through an endpoint or publish it to MQTT?","",""
"766684226455207996","bright_hummingbird_31342","2021-05-12T19:08:39.0700000+08:00","It’s been a while since I’ve looked at Azure IoT Hub. This may have changed. I always got the sense they made it easier to bring data into their ecosystem than out and not just because that’s what most use cases are.

In terms of egress interfaces, MQTT (and AMQP) is possible through an Azure SDK. OPC-UA is possible through the OPC Publisher or Edge products. These act as gateways that convert the native Azure message queues to OPC-UA at the edge. Unfortunately, these all have different throughput limitations and product skus.

I believe HB supports inbound OPC-UA, MQTT, and REST. You would need to leverage one of these interfaces. There is not a built in connector for consuming Azure.","","👍 (1)"
"756543760028139720","aronsemle","2021-05-12T21:16:10.6600000+08:00","Azure's Cloud to Edge story is a little less clear then AWS. Currently HighByte only supports Azure specific outputs, but it would be pretty easy to turn this around and support inputs as well. Where is the message coming from inside of Azure? Event Hub? Azure Function? What would be your preferred way to ingest it into HighByte? IoT Hub supports direct messaging but it's a little weird because it's treated like a remote method call. But HighByte could create an input that generates this method call. A more generic route would be to use an Event Hub, where you push to the Event Hub inside Azure and HighByte can listen on an input and pull the message down. Let me know, and we're happy to porotype something for you to try out.","","👍 (2)"
"194289793905983489","zackscriven","2021-05-13T07:42:36.7130000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-05-13T07:44:49.7580000+08:00","Thanks for jumping in there @aronsemle & @js  I would echo what they said about bringing the context from cloud back down to edge being more cumbersome with Azure IoT versus a platform like AWS that supports MQTT SPB Publishing and Subscribing.","",""
"456226577798135808","Deleted User","2021-05-13T15:25:13.0970000+08:00","Sorry for the delayed response all. Thanks you @aronsemle and @js  for your input!
Since we are just doing pre PoC work (learning) I will need to have a better use case first. I’ll come back to you asap.","",""
"812295088348200960","patanj2","2021-05-15T21:18:31.7290000+08:00","@Michael Brown Thank you for sharing. I had seen the announcement, but also thank you very much for the link to the code used to implement.","",""
"812295088348200960","patanj2","2021-05-15T21:22:18.7820000+08:00","I've heard mentioned in some of the 4.0 Solutions videos @zackscriven  that AWS natively supports SparkPlug B. Is that in reference to the CirrusLink AWS modules for Ignition or is there a different core AWS IoT capability that I am not aware of?  @Michael Brown","",""
"343075694903033857","michael.brown","2021-05-15T22:35:29.8120000+08:00","@John Patanian both CirrusLink and Highbyte provide  a direct path from SpB to AWS' IoT core, sitewise and greengrass (highbyte)","","👌 (3)"
"807682982109904925","ericschummer","2021-05-16T06:38:19.4570000+08:00","Regarding the predictive maintenance my approach has been by Integration of lora specialized sensors( vibra, temp, ultrasound,,) and then from the iot mediation platform we  can route dynamically ( on demand) to unsupervised machine learning and micro trend series analytics, in addition to descriptive analytics and usage reports","",""
"807682982109904925","ericschummer","2021-05-16T06:38:38.2970000+08:00","Assembling as we speak 😋","",""
"194289793905983489","zackscriven","2021-05-17T00:38:50.1490000+08:00","Thanks for sharing Eric!","",""
"727965710772600894","phil_s2342","2021-05-19T04:43:09.7770000+08:00","What platform are you using/do you plan to host, run, and automate the unsupervised machine learning  programs? Commercial solution or in house specialty?","",""
"194289793905983489","zackscriven","2021-05-19T09:34:11.4430000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/844387425903706142/Screenshot_20210518-183331.png?ex=68df2812&is=68ddd692&hm=fb500fea1067d85ddb47c47d5446c06ec56049e6dd20638d39c53cd2aed34cf4&",""
"194289793905983489","zackscriven","2021-05-19T09:34:17.1270000+08:00","Pinned a message.","",""
"807682982109904925","ericschummer","2021-05-19T10:36:23.5730000+08:00","Its a mix. Same that ericsson uses  for its global network, suscribers, loyalty, promotions and churn","","👍🏼 (1),💯 (1)"
"807682982109904925","ericschummer","2021-05-19T10:37:36.0220000+08:00","I just integrated that with our iot mediation platform so we can route data in real time and on demand from sensor to "" virtual data scientist""","",""
"807682982109904925","ericschummer","2021-05-19T10:38:26.9800000+08:00","@Phil_S ..","",""
"698244484302897323","lmtx","2021-06-02T04:29:13.9220000+08:00","Hello, I created a post about the concept of AWS IoT Thing.

https://www.pexl.xyz/iot_thing/

I explain how to:

* represent a physical device (like a temperature sensor) in AWS IoT Thing Registry
* manage the metadata of IoT Devices in a consistent and scalable way
* organize IoT Devices in Logical Groups (for instance to efficiently manage all IoT Devices attached to the same piece of factory equipment)
* create the x509 Certificate and attach it to the IoT Thing as a proof of an identity

Let me know if this post was interesting for you!","","👍 (3)"
"798485298874679309","andyr8842","2021-06-02T06:30:56.7380000+08:00","this is most excellent @LMtx  fantastic work, more please 😄","","👍 (1)"
"743347439972515894","mrjain.","2021-06-02T11:26:10.2400000+08:00","Well done @LMtx for useful information!","","👍 (1)"
"698244484302897323","lmtx","2021-06-08T14:47:01.2500000+08:00","I recorded a video about this concept: https://youtu.be/4OlnMmtFO2Q","","👍 (2)"
"698244484302897323","lmtx","2021-06-08T14:54:53.3030000+08:00","by the way - do you prefer a blog posts or video content?","",""
"743347439972515894","mrjain.","2021-06-08T15:06:40.0100000+08:00","I prefer both 😆","",""
"698244484302897323","lmtx","2021-06-08T15:09:45.1290000+08:00","personally I prefer video for a short introduction to some new topic and blog post to get deeper understanding of some advanced concepts","","💯 (2)"
"698244484302897323","lmtx","2021-06-12T12:39:25.6090000+08:00","Anyone is using AWS Timestream to store sensor readings?","",""
"743347439972515894","mrjain.","2021-06-12T18:12:24.9710000+08:00","I tried it for a POC and decided against it. You cannot delete data. We ended up using MongoDB Atlas.","",""
"743347439972515894","mrjain.","2021-06-12T18:13:15.0070000+08:00","Timestream still feels like its in beta mode","",""
"698244484302897323","lmtx","2021-06-12T23:29:59.0910000+08:00","does Mongo support time series data type out of the box or you had to do some custom development?","",""
"743347439972515894","mrjain.","2021-06-13T13:21:27.6040000+08:00","We did have todo some custom dev on our end but I believe in most cases it just works out of the box. The solution is not as elegant as I like. IIoT Device -> IoT Core -> IoT Rules Engine -> AWS Lambda (for our custom processing) -> MongoDB Atlas","",""
"817835202746253344","IIoT#4707","2021-06-13T13:21:27.9670000+08:00","GG @mrjain., you just advanced to level 2!","",""
"743347439972515894","mrjain.","2021-06-13T13:23:24.4180000+08:00","AWS DocumentDB would have been a top contender but it somehow has a bad reputation for not being 100% MongoDB compatible","",""
"698244484302897323","lmtx","2021-06-13T13:40:20.0690000+08:00","have you used greengrass?","",""
"698244484302897323","lmtx","2021-06-13T17:00:16.2420000+08:00","btw you could use the store retention configuration to remove data from timestream (https://docs.aws.amazon.com/timestream/latest/developerguide/API_RetentionProperties.html)","",""
"743347439972515894","mrjain.","2021-06-13T17:28:38.3660000+08:00","I have not looked at Greengrass as of now","",""
"743347439972515894","mrjain.","2021-06-13T17:29:31.8250000+08:00","thanks. Yes, this is possible. But, if you want to delete some data for a device that is no longer on the platform you have to wait for the retention period to kick in.","",""
"698244484302897323","lmtx","2021-06-13T17:49:30.9870000+08:00","using greengrass you could move some processing to the edge and (in some cases) remove the need for executing lambda in the cloud","",""
"698244484302897323","lmtx","2021-06-13T17:51:50.6150000+08:00","please be aware that currently there are two versions of greengrass v1 and v2; I recommend you use the v2 (provided that it has features you need)
https://docs.aws.amazon.com/greengrass/v2/developerguide/what-is-iot-greengrass.html","",""
"743347439972515894","mrjain.","2021-06-13T17:57:36.6690000+08:00","Thanks, I'll check it out v2.","","👍 (1)"
"519283075507814400","mariopoetazus","2021-06-15T16:46:46.3730000+08:00","or use aws iot sitewise edge? 🙂","",""
"519283075507814400","mariopoetazus","2021-06-15T17:49:17.1740000+08:00","in case you are using AWS IoT, we have slack channel: https://join.slack.com/t/awsiotusergroup/shared_invite/zt-niz2av2t-Vuz3zQowBm7ye3hcp_P5KA","",""
"743347439972515894","mrjain.","2021-06-15T19:05:34.0400000+08:00","Thanks, I'll check it out","",""
"194289793905983489","zackscriven","2021-06-16T14:50:29.2440000+08:00","AWS EC2 Mac Instances https://youtu.be/d0FulqrjHkk","","aws (3)"
"698244484302897323","lmtx","2021-06-17T18:30:21.8300000+08:00","What do you think about multi-account (ingest, application, data etc.) design of AWS IoT deployment? Please vote in my poll. Any comments are very welcome 🙂
https://twitter.com/lmtx1/status/1405468352714350592?s=20","",""
"798485298874679309","andyr8842","2021-06-23T05:29:10.7480000+08:00","what is the benefit to having multiple accounts? Can you not already divvy up a single account using their user management system IAM?","",""
"798485298874679309","andyr8842","2021-06-23T05:29:49.9640000+08:00","or are you thinking more along the lines of if someone gets the root password","",""
"519283075507814400","mariopoetazus","2021-06-23T05:34:04.2090000+08:00","security wise","","💯 (1)"
"519283075507814400","mariopoetazus","2021-06-23T05:34:12.4580000+08:00","if one device gets comprimessed","",""
"519283075507814400","mariopoetazus","2021-06-23T05:34:30.1610000+08:00","it could messs up all your iot data pipeline","",""
"519283075507814400","mariopoetazus","2021-06-23T05:35:04.1860000+08:00","in my case for example, i have 1 account per type of env","",""
"519283075507814400","mariopoetazus","2021-06-23T05:35:43.4220000+08:00","in one of my previous company (PaaS) every customer had is own account","",""
"798485298874679309","andyr8842","2021-06-23T05:45:50.7330000+08:00","what does somebody get by compromising your device?","",""
"798485298874679309","andyr8842","2021-06-23T05:46:10.2330000+08:00","is there an AWS token being stored there?","",""
"519283075507814400","mariopoetazus","2021-06-23T05:48:18.4850000+08:00","certificates","",""
"519283075507814400","mariopoetazus","2021-06-23T05:48:20.4710000+08:00","MQTT","",""
"519283075507814400","mariopoetazus","2021-06-23T05:48:27.1260000+08:00","ANDDD your code","",""
"519283075507814400","mariopoetazus","2021-06-23T05:49:03.3640000+08:00","so many things that can fail","",""
"519283075507814400","mariopoetazus","2021-06-23T05:49:07.0030000+08:00","S3 buckets?","",""
"519283075507814400","mariopoetazus","2021-06-23T05:49:19.8880000+08:00","🙂","",""
"519283075507814400","mariopoetazus","2021-06-23T05:50:00.3440000+08:00","for example, if you use Greengrass you can use AWS Secret Manager connector","",""
"519283075507814400","mariopoetazus","2021-06-23T05:50:23.0790000+08:00","which encrypts for example credentials","",""
"519283075507814400","mariopoetazus","2021-06-23T05:51:03.6760000+08:00","imagine your device gets compromised and you are not encrypting your credentials or putting to logs in plain text","",""
"519283075507814400","mariopoetazus","2021-06-23T05:51:18.4490000+08:00","(already saw that happening, looking at linksys)","",""
"519283075507814400","mariopoetazus","2021-06-23T05:52:02.5290000+08:00","and imagine that you use the same password for all devices in the same accounts","",""
"798485298874679309","andyr8842","2021-06-23T05:55:57.9220000+08:00","Can you specify different passwords for individual devices under a single account?","",""
"519283075507814400","mariopoetazus","2021-06-23T06:03:00.2150000+08:00","you can, but still you will have alot of entries in secret manager, which can be hard to maintain. Even if you use CloudFormation or Terraform. You will get overloaded","",""
"519283075507814400","mariopoetazus","2021-06-23T06:03:42.9390000+08:00","or you use OAuth with Google etc etc  for your devices and you put the auth responsibility elsewhere","",""
"519283075507814400","mariopoetazus","2021-06-23T06:04:09.6050000+08:00","but that is an exemple why some people go to multi account in aws","",""
"519283075507814400","mariopoetazus","2021-06-23T06:04:18.6800000+08:00","for example with Google Cloud","",""
"519283075507814400","mariopoetazus","2021-06-23T06:04:39.9530000+08:00","you dont have multiple accounts, you have projects. Which are under the same account","",""
"519283075507814400","mariopoetazus","2021-06-23T06:04:50.8830000+08:00","and its way easier to maintain","",""
"519283075507814400","mariopoetazus","2021-06-23T06:05:02.8210000+08:00","i dont know about azure","",""
"798485298874679309","andyr8842","2021-06-23T06:06:25.6310000+08:00","interesting cheers","",""
"519283075507814400","mariopoetazus","2021-06-29T17:29:25.5420000+08:00","https://www.youtube.com/watch?v=9tGbszPf_po my presentation about edge computing using aws iot for iiot is now on YouTube","",""
"851540984289951754","thewurstusername","2021-06-30T00:39:53.1290000+08:00","Was InfluxDB not a contender? Or were you looking for a managed service?","",""
"743347439972515894","mrjain.","2021-06-30T13:49:29.9320000+08:00","I was looking for a managed service","",""
"519283075507814400","mariopoetazus","2021-06-30T15:13:14.2500000+08:00","interesting, we do the same 😄","",""
"519283075507814400","mariopoetazus","2021-06-30T15:13:43.8460000+08:00","you use the aws lambda caching mechanism right?","",""
"519283075507814400","mariopoetazus","2021-06-30T15:14:34.1040000+08:00","by the way, do you leave all data in Atlas or you clean it after a while?","",""
"743347439972515894","mrjain.","2021-06-30T16:41:19.8700000+08:00","We have not looked at Lambda caching as of now. We leave all the data in Atlas.","",""
"519283075507814400","mariopoetazus","2021-06-30T16:41:36.0580000+08:00","not that, the auth with mongodb 🙂","",""
"519283075507814400","mariopoetazus","2021-06-30T16:41:53.1900000+08:00","alot of people i see using aws lambda with atlas, they dont cache connection","",""
"519283075507814400","mariopoetazus","2021-06-30T16:42:07.9350000+08:00","by the way, how do deal with lost messages?","",""
"519283075507814400","mariopoetazus","2021-06-30T16:42:15.4000000+08:00","e.g it reaches aws iot rule","",""
"519283075507814400","mariopoetazus","2021-06-30T16:42:21.3850000+08:00","if the aws lambda fails","",""
"519283075507814400","mariopoetazus","2021-06-30T16:42:28.2570000+08:00","you lose the message","",""
"519283075507814400","mariopoetazus","2021-06-30T16:42:39.9120000+08:00","do you send to SQS or Kinesis?","",""
"743347439972515894","mrjain.","2021-06-30T16:42:58.4030000+08:00","we are going to implement SQS for this","",""
"817835202746253344","IIoT#4707","2021-06-30T16:42:58.7440000+08:00","GG @mrjain., you just advanced to level 3!","",""
"743347439972515894","mrjain.","2021-06-30T16:43:05.9110000+08:00","but yet to do","",""
"519283075507814400","mariopoetazus","2021-06-30T16:43:25.4750000+08:00","nice we do SQS","",""
"519283075507814400","mariopoetazus","2021-06-30T16:43:35.0650000+08:00","we send to SQS messages that fail","",""
"519283075507814400","mariopoetazus","2021-06-30T16:43:39.7260000+08:00","and reprocess it","",""
"519283075507814400","mariopoetazus","2021-06-30T16:43:49.3130000+08:00","we putted aws cloudwatch monitoring","",""
"519283075507814400","mariopoetazus","2021-06-30T16:43:58.3850000+08:00","to know how many messages failed","",""
"743347439972515894","mrjain.","2021-06-30T16:44:39.8790000+08:00","oh man, that's exactly the setup we want to implement!","",""
"743347439972515894","mrjain.","2021-06-30T16:45:13.3820000+08:00","We have not because we have not really had an issue with Lambda....YET","",""
"519283075507814400","mariopoetazus","2021-06-30T16:45:54.4200000+08:00","well, you dont know till you monitor the messages losts 🙂","","👍 (1)"
"519283075507814400","mariopoetazus","2021-06-30T16:46:08.1620000+08:00","we have implemented that","",""
"519283075507814400","mariopoetazus","2021-06-30T16:46:13.0090000+08:00","like last year","",""
"519283075507814400","mariopoetazus","2021-06-30T16:47:06.5900000+08:00","some people are using kinesis","",""
"519283075507814400","mariopoetazus","2021-06-30T16:49:56.8700000+08:00","its 29 lines of code :p","",""
"519283075507814400","mariopoetazus","2021-06-30T16:51:37.0510000+08:00","you will need to build wrapper","",""
"519283075507814400","mariopoetazus","2021-06-30T16:51:44.7920000+08:00","because it will output 2 type of errors","",""
"519283075507814400","mariopoetazus","2021-06-30T16:52:00.5310000+08:00","and with different type of buffer output","",""
"743347439972515894","mrjain.","2021-06-30T16:53:22.1830000+08:00","hmm, thanks for the info","",""
"519283075507814400","mariopoetazus","2021-07-01T19:19:56.2170000+08:00","https://iot-sitewise.workshop.aws/en/ if anyone wanna learn about aws iot sitewise, here is a cool workshop","","👍 (3)"
"851540984289951754","thewurstusername","2021-07-02T11:34:36.9230000+08:00","Anyone using InfluxDB 2.0? About to start a greenfield app, I’ve used influx 1.8. Anything better? Going to display the data using Grafana.","",""
"711186774629679166","faithware101","2021-07-02T13:17:52.1010000+08:00","You can use thingsboard with Cassandra DB. You can manage multiple devices and you can use existing dashboard widgets or create new ones based on Angular.","","👍 (1)"
"305259056476454912","tom02686","2021-07-02T19:53:13.9660000+08:00","Yes, I use Influx 2.0 a bit, there is a bit of a learning curve with the new query language Flux","",""
"851540984289951754","thewurstusername","2021-07-02T20:56:10.2430000+08:00","Is the performance of the DB better than 1.8? I'm doing batched inserts every ~10s and read queries every ~15s or so.","",""
"305259056476454912","tom02686","2021-07-02T21:07:19.1850000+08:00","I haven't noticed any write / simple read performance difference with a few thousand signals. However doing more complex flux scripts can severely impact performance. A key point is understanding which flux functions get 'pushed down' to the storage layer and which are performed in memory.","",""
"817835202746253344","IIoT#4707","2021-07-02T21:07:19.4130000+08:00","GG @tom02686, you just advanced to level 1!","",""
"194289793905983489","zackscriven","2021-07-05T04:58:16.3100000+08:00","Hey Tom!","",""
"519283075507814400","mariopoetazus","2021-07-05T16:17:07.7430000+08:00","Hi, AWS IoT meetup is looking for speakers","",""
"519283075507814400","mariopoetazus","2021-07-05T16:17:23.7150000+08:00","if anyone wanna speak and showcase their work with aws iot","",""
"519283075507814400","mariopoetazus","2021-07-05T16:17:28.4060000+08:00","feel free to reach me","",""
"519283075507814400","mariopoetazus","2021-07-05T16:17:37.4120000+08:00","you will get AWS Credits 🙂","",""
"698244484302897323","lmtx","2021-07-07T00:50:56.6180000+08:00","short visualization of a secure connection setup in AWS IoT","https://cdn.discordapp.com/attachments/740336311671586968/862012753350754324/lmtx_aws_iot_connectivity.gif?ex=68df562f&is=68de04af&hm=4d9a6c7154fc956d7f019dc7c85ceafd66e0c63ae05012938e50dd2d69fc89b5&",""
"305259056476454912","tom02686","2021-07-07T01:08:07.5190000+08:00","Hey Zack!","",""
"698244484302897323","lmtx","2021-07-07T14:10:06.8220000+08:00","you can find some additional details in my article: https://www.thingrex.com/aws_iot_connectivity/","","🙏 (1)"
"194289793905983489","zackscriven","2021-07-09T06:08:54.6090000+08:00","@Hunkerdown","",""
"194289793905983489","zackscriven","2021-07-09T06:13:16.0530000+08:00","@treo","",""
"194289793905983489","zackscriven","2021-07-09T06:13:22.3770000+08:00","@trevor","",""
"801561312861618236","jon.forbord","2021-07-09T17:39:33.1350000+08:00","Does one HAVE to choose ONE cloud solution?","",""
"698244484302897323","lmtx","2021-07-09T17:53:26.8150000+08:00","there are many problems with multi cloud approach : you need to use very basic cloud services to remain compatible across provides so you can not leverage the full potential of the cloud; access and logs management is a pain in multi cloud setup; your developers and support need to know multiple clouds, there is no single view across all clouds so you need to switch interfaces or build a custom one","",""
"698244484302897323","lmtx","2021-07-09T17:54:31.9560000+08:00","pick vendor that meets your requirements and deploy your solution","",""
"698244484302897323","lmtx","2021-07-09T17:55:59.7970000+08:00","your biggest value is the bussiness logic which can be implemented on other cloud if you decide to migrate in the future","",""
"801561312861618236","jon.forbord","2021-07-09T18:19:49.6950000+08:00","Thanks! Pocketing this! Basically the benefits of having freedom to choose solution per use case, doesn't quite outweigh the disadvantages of disparate systems?","",""
"698244484302897323","lmtx","2021-07-09T19:18:04.7560000+08:00","you do not want to have different use cases in different clouds: every use case should have access to all data it needs, additionally one use case can leverage data generated by the other use case; moreover - the data governance is way easier using one cloud provider that multiple vendors","",""
"807682982109904925","ericschummer","2021-07-10T05:38:48.7920000+08:00","sorry for delay  ..   its running on AWS and is avialable on-demand with streams of data via API , or by way of colelction IOT data via MQTT, , Https, etc","",""
"807682982109904925","ericschummer","2021-07-10T05:40:07.0310000+08:00","true industry 5.0 stuff 🤣","",""
"698244484302897323","lmtx","2021-07-12T15:00:37.6280000+08:00","How to:

* use the #MQTT Client to test the #TLS secured connection between the #IoT Device and the #AWS IoT Core 
* enable the AWS IoT Core Logs 
* use the AWS CloudWatch Service to debug the connection issue

https://thingrex.com/iot_thing_conn/","",""
"698244484302897323","lmtx","2021-07-12T15:06:31.3250000+08:00","Feedback request:
* this post has too much/few technical details
* is (not) interesting for me
* does (not) help in my career development","",""
"519283075507814400","mariopoetazus","2021-07-12T21:59:49.7320000+08:00","https://pages.awscloud.com/AWS-Online-Tech-Talks_July-2021.html?webinar=2021_0702-IOT&trk=em_a134p000007BnibAAC&trkCampaign=GC-700-SPZ-July_2021_0702-IOT&sc_channel=em&sc_campaign=GLOBAL_OTT_WEBINAR_July-2021-DGA_20210712_7014z000001gIzd&sc_medium=em_393653&sc_outcome=Product_Adoption_Campaigns&sc_geo=NAMER&sc_country=mult&sc_content=Webinar&category=IOT","",""
"778288647521828874","joelmessina","2021-07-13T21:26:15.2880000+08:00","The PLCnext controller has been accepted by AWS and we are now apart of the APN (Amazon Partner Network)","https://cdn.discordapp.com/attachments/740336311671586968/864497954521481236/AWS_certified_APN.png?ex=68df2635&is=68ddd4b5&hm=7db6e087535a0ab95b789e4f86393fd9dc49c58423cba4eba455faf2a9ec50e6&","👍 (5),🔥 (2),ismile (1)"
"487658368492896257","benveenema","2021-07-13T21:51:26.6160000+08:00","Congratulations! What features does this enable?","",""
"778288647521828874","joelmessina","2021-07-13T21:55:32.9680000+08:00","@Ben Veenema  It was a make it official type of thing, you could always access the linux kernel and install greengrassV1 or V2 directly on our PLC. we have another application coming that allows for drag and drop citizen coding that can extract data from existing controllers,  normalize by some means of conversion, such as scaling, etc. and then connect to a cloud service, AWS, AZURE, to publish tag results.","","👍 (1)"
"628583377381097513","youbastardz5953","2021-07-19T03:44:53.8870000+08:00","Hey guys","",""
"628583377381097513","youbastardz5953","2021-07-19T03:45:14.5840000+08:00","Anyone know a good replacement to AWS Sitewise ?","",""
"628583377381097513","youbastardz5953","2021-07-19T03:45:45.2710000+08:00","I use AWS Sitewise and Greengrass, but sitewise is very expensive and your forced to pay for metrics you dont want","",""
"628583377381097513","youbastardz5953","2021-07-19T03:46:50.4680000+08:00","Currently I am accessing a historian (opc-ua server) through an gateway device  (greengrass)  and  sending data over to sitewise on the cloud","",""
"698244484302897323","lmtx","2021-07-19T03:47:53.8000000+08:00","you can access the opc-ua server without sitewise","",""
"628583377381097513","youbastardz5953","2021-07-19T03:48:19.9120000+08:00","what do I use instead? do i have to code my own program","",""
"628583377381097513","youbastardz5953","2021-07-19T03:48:27.9290000+08:00","or is there another service or 3rd party product","",""
"698244484302897323","lmtx","2021-07-19T03:49:04.1600000+08:00","you can use nodejs opc-ua connector","",""
"628583377381097513","youbastardz5953","2021-07-19T03:49:06.0970000+08:00","and then send data over to cloud, because sitewise has its own connector (sitewise connector to the cloud)","",""
"698244484302897323","lmtx","2021-07-19T03:49:20.2910000+08:00","running at the Greengrass device","",""
"698244484302897323","lmtx","2021-07-19T03:49:58.0720000+08:00","you can sent data from GG to Timestream or DynamoDB","",""
"628583377381097513","youbastardz5953","2021-07-19T03:51:07.1860000+08:00","is it hard to learn, implement for different data tags, and troubleshoot?","",""
"698244484302897323","lmtx","2021-07-19T03:51:33.9750000+08:00","it require some coding skills","",""
"628583377381097513","youbastardz5953","2021-07-19T03:51:39.5920000+08:00","i see, i'll look into this... i assume it uses a pre-built connector","",""
"698244484302897323","lmtx","2021-07-19T03:52:02.0790000+08:00","https://node-opcua.github.io/","",""
"628583377381097513","youbastardz5953","2021-07-19T03:53:25.5070000+08:00","do you know if it works well with other greengrass device features? like saving data locally in case of connection loss, so is it completely separate from other greengrass features","",""
"698244484302897323","lmtx","2021-07-19T03:53:59.6180000+08:00","do you use GG v1 or v2?","",""
"628583377381097513","youbastardz5953","2021-07-19T03:54:14.7040000+08:00","currently 1, heard its better","",""
"698244484302897323","lmtx","2021-07-19T03:54:58.3300000+08:00","v1 is better than v2? based on what factors ?","",""
"628583377381097513","youbastardz5953","2021-07-19T03:55:13.0200000+08:00","let me check my notes","",""
"698244484302897323","lmtx","2021-07-19T03:55:37.7790000+08:00","if you start some new project go with v2","",""
"628583377381097513","youbastardz5953","2021-07-19T03:55:50.7180000+08:00","""Discovery url doesn’t work so you will have to always hard wire the ip of greengrass""","",""
"628583377381097513","youbastardz5953","2021-07-19T03:56:15.7180000+08:00","so if it restarts and spins a new ip address","",""
"817835202746253344","IIoT#4707","2021-07-19T03:56:16.0030000+08:00","GG @Youbastardz, you just advanced to level 2!","",""
"628583377381097513","youbastardz5953","2021-07-19T03:57:01.5390000+08:00","or thats what i heard","",""
"698244484302897323","lmtx","2021-07-19T03:57:24.7360000+08:00","I'd suggest using GGv2 and create custom component to handle the opc-ua connection","",""
"698244484302897323","lmtx","2021-07-19T03:58:51.5590000+08:00","do some research before you start development","",""
"628583377381097513","youbastardz5953","2021-07-19T03:59:16.1890000+08:00","ok","",""
"628583377381097513","youbastardz5953","2021-07-19T03:59:42.2040000+08:00","do you know of any other 3rd party products that can replace sitewise besides node-opcua","",""
"698244484302897323","lmtx","2021-07-19T03:59:51.0030000+08:00","https://iot.awsworkshops.com/aws-greengrassv2/","",""
"628583377381097513","youbastardz5953","2021-07-19T04:00:51.3990000+08:00","ok","",""
"628583377381097513","youbastardz5953","2021-07-19T04:00:55.3580000+08:00","checking it","",""
"628583377381097513","youbastardz5953","2021-07-19T04:01:00.1980000+08:00","thanks for the help!","",""
"698244484302897323","lmtx","2021-07-19T04:20:18.9700000+08:00","I guess that nodejs opc-ua connector has commercial support if you need one","",""
"698244484302897323","lmtx","2021-07-19T04:20:33.2960000+08:00","let me know in case of any specific questions","",""
"628583377381097513","youbastardz5953","2021-07-19T04:42:31.0940000+08:00","alright, i am setting up a test run see how it works","",""
"519283075507814400","mariopoetazus","2021-07-19T19:59:55.2980000+08:00","@Youbastardz  https://www.youtube.com/watch?v=9tGbszPf_po we did something like you are looking for","","👍 (1)"
"519283075507814400","mariopoetazus","2021-07-19T20:00:37.9610000+08:00","GG 1 and 2 has buffer pool. The size of the buffer pool depends the size of your disk or ram and configured","",""
"519283075507814400","mariopoetazus","2021-07-19T20:00:53.2580000+08:00","we still save the data locally in mongodb","",""
"628583377381097513","youbastardz5953","2021-07-19T21:28:01.0770000+08:00","Thanks Mario, taking a look","",""
"260296842703536138","i.negativ","2021-07-19T21:48:41.2410000+08:00","thanks @Mario Pereira  for sharing!","",""
"860002848586072074","nathand9327","2021-07-21T06:48:50.5790000+08:00","https://www.linkedin.com/company/zadara 
A disruptor in the cloud space. Only pay for space you use and easily transfer to other cloud companies. A good addition to the stack that sits just below your cloud.","","👍 (1)"
"698244484302897323","lmtx","2021-07-30T16:38:47.4390000+08:00","Serverless IoT challenge.

Describe simple (yet functional) serverless IoT solution using the AWS Cloud.

I will shortly share my proposition.","https://cdn.discordapp.com/attachments/740336311671586968/870586208445669426/iot_challenge_2.png?ex=68dee2d6&is=68dd9156&hm=0999c1f9d5ed7cfed70ecf5bbf19092b3768fd90832ed8b103a8494ea1aab562&","aws (1)"
"698244484302897323","lmtx","2021-07-30T17:18:33.6760000+08:00","Started a thread.","",""
"820097580665929808","pvmagacho","2021-08-10T09:39:27.2130000+08:00","If it’s decided that most (or all) of a manufacturer data is to be held in the cloud I wonder if once decided on a cloud provider we are bound forever or is it possible to migrate the data between them. Or can we mix and match services with data from one of the other? Any thoughts? Thank you","","😍 (1)"
"698244484302897323","lmtx","2021-08-10T13:14:45.3060000+08:00","Short answer:

You own your data, no cloud provider should/can stop you from migrating your data somewhere else. I strongly advice against multi-cloud approach - it crates more problems than it solves.

Long answer: 

When you pick a cloud provider please remember that cloud is not only used to store data and do analytics in the cloud; different cloud providers offer different services to process data at the edge (on the factory floor level). That edge capabilities are even more important that cloud storage (that is my opinion based on my commercial experience).
If you decide that you need to change your cloud provider you need to migrate not only data but also the processing logic, analytics and remote management solution. Those kind of migrations are possible but difficult and time-consuming (expensive).

I advice against the multi-cloud approach for following reasons: it is very hard to manage access credentials in a unified way when you use multiple clouds; cloud services from different vendors look similar but are very different if you go into details - you will not be able to swap a service from one provider with service from the other providers (the only exception are the very basic services but if you use only those you loose lots of cloud potential).","","👏 (2),💯 (1),4point0 (1)"
"766684226455207996","bright_hummingbird_31342","2021-08-10T13:41:24.3690000+08:00","There exist ""multi-cloud"" technologies that enable one to architect their applications in such a way that promotes flexibility (e.g., on-prem, cloud, hybrid, edge, cost, performance, data governance) and avoids vendor lock among solution providers.  It fits in with general trend of commoditizing infrastructure.  Much of this driven by cloud orchestration and containerization technology.

Examples:  IBM Red Hat OpenShift, VMware Cloud Foundation, Cloud Foundry

This space has a really heated up.  People are doing mind blowing things with Kubernetes.

I think a critical piece is having a strategy on how data is modeled.  For the most part, anyone can bulk import or export data.  But, to make said data ready for use and do so at scale is another story.

@LMtx made fantastic points about how challenging multi-cloud is.  It requires standing up and maintaining an entire architecture on top of and across the multiple cloud architectures.  In many cases, the additional engineering resources multi-cloud requires can exceed the benefits it provides.  That is, committing to using a cloud's native technology can outweigh the risks.  It can be more performant, cost effective, and productive.  For some orgs, the risk is too high.  For others, they accept the risk of committing, but architect enough flexibility to migrate as a part of a long-term business continuity plan should something go awry.  It's something that is painful and disruptive, but doable.","","💯 (5)"
"698244484302897323","lmtx","2021-08-10T20:22:17.2630000+08:00","A short introduction to the IoT @ AWS solid foundations training I am preparing.

Would you be interested in taking this course? Are there any topics I should add to this foundations training?

Any feedback is very welcome!

https://youtu.be/FPnaf5AdsF0","","👌 (3)"
"194289793905983489","zackscriven","2021-08-13T13:33:12.1340000+08:00","Would you mind sharing this in the #📺-youtube-links channel? We don't allow unsolicited selling in the Discord, but feel free to advertise your youtube channel and course in the aforementioned channel.","","👍 (1)"
"194289793905983489","zackscriven","2021-08-13T13:33:29.8320000+08:00","Thanks!","",""
"698244484302897323","lmtx","2021-09-07T20:06:48.1670000+08:00","Anyone interested to talk about #IoT at #AWS? 
https://www.clubhouse.com/room/xlyOqak0","",""
"704690324815216641","mirol.9840","2021-09-07T20:11:12.0350000+08:00","I feel like it makes a space for a question like - ""who owns the data?"" - I would not deny that ""we"" are not the owner/accountable? Any thoughts?","",""
"519283075507814400","mariopoetazus","2021-09-08T17:57:40.6370000+08:00","sorry just saw this now 😦","",""
"698244484302897323","lmtx","2021-09-08T22:22:50.6890000+08:00","no problem, we can try next time ;)","",""
"194289793905983489","zackscriven","2021-09-09T01:45:03.4420000+08:00","!warn @LMtx  for sharing unsolicited links (Again) outside of the links area.","",""
"817835202746253344","IIoT#4707","2021-09-09T01:45:03.8770000+08:00","","",""
"830193224504705035","marc.jaeckle","2021-09-09T15:04:02.4830000+08:00","As others already said, I would try to avoid using multiple cloud providers as it adds a lot of complexity and cost. Still you should carefully think about which managed services you use. Using managed services can make you faster (from an implementation perspective) and reduces your operational effort. Having said that, I would try to focus on managed services that are based on OpenSource products or at least provide APIs that are compatible with OpenSource products. This allows you to operate them yourself if the managed service gets too expensive (they tend to be cheap at a smaller scale but can get very pricey) and it reduces the effort to switch to another cloud provider if you have to (for whatever reason and it could be a silly reason like your new CIO decides to partner with someone else just because). At the same time I wouldn't rule out using cloud provider specific (proprietary) solutions if they have a large benefit for you (e.g. using Azure IoT).","",""
"836165501989945345","billliu4646","2021-09-09T17:30:36.2850000+08:00","To be cloud agnostic, stick with Docker and K8s, which is supported by every cloud provider.","",""
"830193224504705035","marc.jaeckle","2021-09-09T21:39:02.9670000+08:00","I certainly wouldn't run everything in Kubernetes, especially when it comes to stateful services and analytics workloads. It saves a lot of time and effort to use managed solutions like a managed Kafka or managed Flink etc. or even a simple Postgres via AWS RDS or Azure Database for PosgreSQL. Also you can't just switch out your Kubernetes distribution without any effort (e.g. replace EKS with AKS). Although you can reduce the effort considerably if you use something like Rancher or D2iQ DKP (D2iQ Kommander is great) as Kubernetes distribution and for multi-cluster management. Also the cloud providers have been recently improving their hybrid cloud support (e.g. Azure Arc, Google Anthos or Amazon EKS Anywhere) which can also help to stay somewhat independent even though you would keep a certain dependency on the respective Kubernetes Control Plane.","",""
"519283075507814400","mariopoetazus","2021-09-26T16:23:23.3090000+08:00","https://www.youtube.com/watch?v=ZW39RLvH9zM rackspace built this using aws iot sitewise","",""
"519283075507814400","mariopoetazus","2021-09-26T16:23:27.9090000+08:00","Pretty  cool","",""
"846417580804669450","damaniaaditya","2021-09-26T23:22:57.1640000+08:00","@Mario Pereira This is good logistics & warehousing applications!","",""
"818594389830926369","durgakolli2717","2021-09-27T22:16:29.7300000+08:00","Wow...This was our academic project minus dashboard stuff and also to hack the system like a MIM attack! The simulator software we used is Factory IO. check out the course description incase if you are interested in hacking (Just an intro course.!) http://rbeyah.ece.gatech.edu/classes/spring2021/cs6263/","","ishocked (1)"
"817835202746253344","IIoT#4707","2021-09-27T22:16:30.0450000+08:00","GG @Durga Kolli, you just advanced to level 4!","",""
"870130040657035276","simith3321","2021-09-29T17:46:34.0460000+08:00","Thanks for posting @Mario Pereira 🙂","",""
"820097580665929808","pvmagacho","2021-09-30T08:05:29.8710000+08:00","hi @Michael Brown, first welcome back to the Discord. Second, I was checking AWS SiteWise but found one limitation. There is no 64 bits Integer (Long). Any thing we can do to work around it or is it something that could be improved 😀 ?","",""
"343075694903033857","michael.brown","2021-09-30T09:57:43.4160000+08:00","Hrm.... Let me dig into that.... Because I know they (sitewise team) are going to ask.. What measurements/data points require the long ints in your use case? (having the details helps)  are you passing long ints already and getting an unexpected behavior?","",""
"794020366536146977","mparris","2021-09-30T11:34:58.1090000+08:00","I'm voting Unix Time!","",""
"820097580665929808","pvmagacho","2021-09-30T11:36:13.3100000+08:00","I am passing a long timestamp. And it gets converted to int","",""
"820097580665929808","pvmagacho","2021-09-30T11:36:45.7820000+08:00","A long value of 1632945492741 that gets converted to 857920261","",""
"820097580665929808","pvmagacho","2021-09-30T11:37:47.1550000+08:00","However, this was a just a test. For float values the precision is 64 bits. Why not for int as well?","",""
"343075694903033857","michael.brown","2021-09-30T12:06:36.2870000+08:00","Ding ding ding ding.... We have a winner!","",""
"343075694903033857","michael.brown","2021-09-30T12:08:31.8240000+08:00","I was just screwing around with timestamps earlier this month... Let me ask around...","","👍🏼 (1)"
"846417580804669450","damaniaaditya","2021-10-01T00:26:09.1870000+08:00","why not send it as a datetime?","",""
"867075936054149191","rickbullotta","2021-10-11T23:19:16.3500000+08:00","Doesn't SiteWise have a TimeInNanos data type?","",""
"725011039980355687","jimmybarnyard","2021-10-12T08:13:23.5020000+08:00","Looks like the sim is using Factory I/O from Realgames.  We've used it for training.  A neat tool.","",""
"519283075507814400","mariopoetazus","2021-10-20T14:21:52.6670000+08:00","https://play.vidyard.com/qLVuH9QEdWbnZi1qonZZcc the recording of AWS Industrial and Manufacturing event. Technical Leadership talk (Maybe for for Engineering Managers, CTOs, Solutions Architect, IT Managers). the HEINEKEN example starts at 58min, a cool example.","",""
"519283075507814400","mariopoetazus","2021-10-20T14:24:21.1950000+08:00","https://play.vidyard.com/5tuQgGghVCspEGWUed9inR and this one is for Manufacturing Business people that want to know about more about it.","",""
"745009912160976977","marioishikawa","2021-11-10T04:52:15.6800000+08:00","it does not occur to me also but it is a common standard now on Databases so to have the same option underlying the database on Sitewise seems to make sense","",""
"889950316462735400","cyberwrights","2021-11-11T07:17:19.7480000+08:00","I'm doing some contract work for a startup and have an applied question about containerization. I held the MCSE years ago on Windows NT4.0, so the architecture has changed  a bit with the advent of cloud and virtualization. Here is the scenario: you have a product-based dashboard service where lots of small companies are uploading .csv files or streaming thin feeds from their source systems and/or edge devices so they can view their own data through the dashboard (template) you've built for them.  How do you segregate the database and web server instance to prevent one customer from bringing the others down, or having security concerns about their environment? Assume this is being done is Azure or AWS. I tried to find an Azure architect but all the MSFT people (both sales & architects) I knew only 2 years ago have been lift-n-shifted and I can't get any help on this. The root question is ""Is this a common use case for containers, and if so, how much of the architecture would you containerize?""","",""
"867075936054149191","rickbullotta","2021-11-11T21:58:05.5230000+08:00","I would just read up on multi-tenant architectures.

https://docs.microsoft.com/en-us/azure/architecture/example-scenario/multi-saas/multitenant-saas

Also, the startup should apply for the various Microsoft startup programs and resources.  If accepted into something like Microsoft For Startups, they'll have access to architects and other technical resources.","",""
"889950316462735400","cyberwrights","2021-11-11T22:35:19.4180000+08:00","Wow, thanks a million @RickBullotta ! That's more good news than I expected, and way more than my local rep offered. Much appreciated!","",""
"867075936054149191","rickbullotta","2021-11-11T22:36:22.9720000+08:00","It's a fairly selective program, but there are other types of resources for startups as well.  But in general, there are a lot of good architectural patterns for this from Microsoft, Amazon, and others.","","👍 (1)"
"194289793905983489","zackscriven","2021-11-12T01:17:11.4230000+08:00","Pinned a message.","",""
"194289793905983489","zackscriven","2021-11-12T01:17:36.1120000+08:00","Thanks for your input Rick!","",""
"519283075507814400","mariopoetazus","2021-11-16T20:25:16.1240000+08:00","i have been playing around with AWS IoT SiteWise, i wrote this blogpost about it, https://medium.com/@mariothedatanerd/data-the-pillar-for-industrial-4-0-revolution-35b5ac4f8f11, feel free to share, the blog post replaced the older one that i wrote about AWS Greengrass with Node.js OPCUA (Does not make sense to keep it). Feel free to share. Note that this post is not associated to AWS or Vopak 🙂 . The medium will be used to share my pet project /home projects or PoCs done in my free time.","","👏 (1)"
"740365995419631736","omarazizahmed","2021-11-17T00:34:56.3480000+08:00","Nice article @Mario Pereira . In your article you mention contexualization of data. HighByte is a partner of AWS and this is our focus. I think it would be good to catch up sometime.","",""
"743545122201010236","scottf4208","2021-11-18T03:38:00.7640000+08:00","Anyone headed to AWS re:Invent this year?! Would love to connect in person with anyone and everyone who's going! It's been a long 18 months of Zoom calls, and I'm looking forward to getting back out there in the wild for the first time since things locked down. Pop into our booth #1525 on the floor of the Venetian or meet with us in our suite away from the hustle and bustle to talk with our IoT Practice lead Carlos Lemus about your plans for AWS.","",""
"766684226455207996","bright_hummingbird_31342","2021-11-18T03:41:01.1860000+08:00","For those that already have something like Ignition and Canary Labs Historian, how does AWS SiteWise play into your overall strategy?","",""
"519283075507814400","mariopoetazus","2021-11-18T15:40:40.4000000+08:00","https://aws.amazon.com/pt/blogs/architecture/ingesting-pi-historian-data-to-aws-cloud-using-aws-iot-greengrass-and-pi-web-services/","",""
"519283075507814400","mariopoetazus","2021-11-18T15:53:05.2080000+08:00","it really depends of the scale you are working and what is your use case for ignition 🙂","",""
"519283075507814400","mariopoetazus","2021-12-01T18:09:43.2430000+08:00","https://aws.amazon.com/pt/about-aws/whats-new/2021/11/aws-iot-twinmaker-build-digital-twins/
https://aws.amazon.com/pt/about-aws/whats-new/2021/11/aws-iot-fleetwise-transferring-vehicle-data-cloud/","",""
"519283075507814400","mariopoetazus","2021-12-01T18:56:52.5840000+08:00","https://github.com/aws-samples/aws-iot-twinmaker-samples","",""
"869976961932480614","jouniaro","2021-12-03T17:56:07.0120000+08:00","https://www.prosysopc.com/blog/aws-iot-mqtt-demo/","",""
"869976961932480614","jouniaro","2021-12-03T17:56:20.2460000+08:00","https://www.prosysopc.com/blog/azure-mqtt-demo/","",""
"519666539436310529","aristotelestn","2021-12-04T05:00:47.7300000+08:00","Hey guys, are you typically migrating or developing your industrial applications based in microservices in the cloud using which platform: SAP BTB, AZURE OR AWS?","",""
"519666539436310529","aristotelestn","2021-12-04T05:01:23.4710000+08:00","SAP BTP*","",""
"867075936054149191","rickbullotta","2021-12-04T06:33:34.6120000+08:00","FYI, SAP BTP can be hosted on Azure or AWS also (as well as GCP and Alibaba).  

95+% of industrial applications are still on-prem, FYI.","","👍 (1)"
"745009912160976977","marioishikawa","2021-12-06T18:04:19.0200000+08:00","The ones on the cloud, are usually mostly in AWS 1st and Azure 2nd. In Brazil I've seen a lot using co-location in smaller data-centers but I don't see any advantage on that.","",""
"745009912160976977","marioishikawa","2021-12-14T19:22:21.7300000+08:00","Any interesting AWS new product announced in this re-invent? I saw the scheduling and it seems to be about case presentations and I didn't notice any major new product aside of the digital twin.","",""
"745009912160976977","marioishikawa","2021-12-14T19:25:55.7350000+08:00","But I also saw some interesting improvements like this https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-lookout-vision-visual-inspection-product-defects-edge/","",""
"745009912160976977","marioishikawa","2021-12-16T00:10:57.8650000+08:00","AWS West https://news.ycombinator.com/item?id=29567170 https://status.aws.amazon.com/","",""
"867075936054149191","rickbullotta","2021-12-16T00:41:53.9740000+08:00","Short term outage.","",""
"867075936054149191","rickbullotta","2021-12-16T00:42:29.0930000+08:00","Comment of the day:

""Is AWS having issues in west now?

I know you're supposed to replicate what happens in one region to the other, but I didn't think that rule also applied to outages""","","😄 (5),😆 (1)"
"151431281706663936","matthewjd24","2021-12-24T12:25:05.7340000+08:00","Is cloud a better solution for storing all of our business's data as opposed to locally?","",""
"690187418376208506","dzimmerman","2021-12-24T22:42:46.9020000+08:00","With an unlimited budget for data fee's maybe","",""
"925047453915426837","tkallmeyer9765","2021-12-28T02:14:28.5040000+08:00","m","",""
"867075936054149191","rickbullotta","2021-12-28T02:31:37.3460000+08:00","...and no concerns about availability or latency.","",""
"151431281706663936","matthewjd24","2021-12-28T02:40:43.1500000+08:00","so it seems pretty clear that having our data on-premises would be better in every way?","",""
"867075936054149191","rickbullotta","2021-12-28T02:43:37.8770000+08:00","Not necessarily - if you want a consolidated view across multiple facilities, want to share it with supply network partners (customers, suppliers, etc), want to leverage cloud compute for machine learning or advanced analytics, and want a reliable off-site long term archive for compliance purposes, the cloud is good fit.  As I often like to say, the answer is often ""AND"" not ""OR"".  A lot of companies keep ""hot"" and ""warm"" data onsite to support real time decision making and operations, and ""warm"" and ""cold"" data in the cloud.  You can move that needle to either extreme as needed, with tradeoffs of course - cost, reliability, capability, performance, and so on.","",""
"151431281706663936","matthewjd24","2021-12-28T02:48:21.1640000+08:00","Thanks. When you say hot, warm, and cold, I assume that's referring to how 'fresh' the data is. I assume we could mirror our onsite data to the cloud without much difficulty. We definitely want to leverage machine learning and advanced analytics in the future.","",""
"794020366536146977","mparris","2021-12-28T08:58:25.9630000+08:00","Hot, warm, cold typical is more strongly associated with how fast you can get at the data.

Tape storage = cold
RAM =volcanic hot 😊","",""
"867075936054149191","rickbullotta","2021-12-28T21:25:02.2140000+08:00","...which is also usually highly correlated to how ""fresh"" the data is...","",""
"836083954091950080","billbither4379","2021-12-31T06:19:53.4790000+08:00","Back in 2004 when I was founding my previous software company we decided to use salesforce.com for our CRM for a customer facing help desk. We didn't have an IT team to setup and manage servers for databases, and web servers, and I knew that our small dev team had better things to manage. Back then salesforce went down - a lot as they scaled. I ended up building a system that would synchronize our customer facing help desk tickets to an on-prem database to mitigate this issue so customers wouldn't know if there was downtime. Fast forward a few years and we found ourselves spending more time maintaining that system vs the limited amount of downtime that occurred. AWS's SLA is 99.95%, which is 21 minutes of downtime per month. As long as you build buffering into your real-time data system, you shouldn't have a problem with storing data in the cloud. And you avoid being woken up at 2am to fix a database issue, worry about scaling your servers, etc, etc. Yes, I'm biased as my company's product is cloud based. But even the largest of manufacturers (GE for example) are storing data in the cloud.","","👍🏼 (1)"
"867075936054149191","rickbullotta","2021-12-31T07:42:54.7370000+08:00","…but it’s often the latency issues of some cloud stores that limit their utility for near real time operations, and it’s often not the “cloud” that goes down.  It’s sometimes the network to the outside world.  I’m a fan of hybrid architectures and cloud plays a huge role. But I do think workloads should be designed as portable as possible in some cases so they can be moved from edge to cloud.  I really like the way Losant implemented that.","",""
"783917475128410112","geoffnunan","2021-12-31T09:48:16.8320000+08:00","Why not just be ""Cloud Agnostic"", run in any of the clouds, or run in your own on-premise cloud.","","👍🏼 (2)"
"817835202746253344","IIoT#4707","2021-12-31T09:48:17.0970000+08:00","GG @GeoffNunan, you just advanced to level 5!","",""
"867075936054149191","rickbullotta","2021-12-31T09:49:21.0810000+08:00","Including a blend of those options!  That’s the ideal setup.","",""
"766684226455207996","bright_hummingbird_31342","2022-01-04T01:49:24.4620000+08:00","This is certainly ideal, but there are tradeoffs.  Sometimes the effort required to go multi-cloud exceeds the benefits and simplicity of adopting a cloud natively.  Avoiding vendor lock and promoting flexibility are great, but it's not a free lunch.  There are many scenarios where it can be less economical, performant, or productive -- even with the potential risks and associated re-engineering efforts.  Generally, the economics of generic compute are going to be inferior to that of specific platform services.  At scale, cloud providers have to assume a greater consumption on the former over the latter.

Ultimately, the biggest determinant is scale and complexity.  It's too easy to take an on-prem mindset and let ""perfect"" get in the way of ""better"".  Just because one owns the hardware does not mean what they do with it is free.  There is always a cost.  There is too much emphasis on analyzing payables than total cost of ownership.  Those that succeed with the cloud are pragmatic about it.  ""Lift and shift"" is a shortcut to disappointment.  It wasn't that long ago that people were irrational about even considering the cloud as a theoretical exercise.  If there were no hard and fast rules, there wouldn't be a huge market for people to architect what's optimal.

Related discussion:
https://discord.com/channels/738470295056416930/740336311671586968/874527837363785758","",""
"783917475128410112","geoffnunan","2022-01-04T07:22:38.0940000+08:00","@js I would agree that the biggest determinant is scale and complexity IF you are comparing cloud to raw compute, but if you are comparing running in kubernetes on AWS, to running in kubernetes on GCS to running in kubernetes in your own cluster on your own VMs, I don't see that much difference.","","👍 (2)"
"914993398526656542","mikebartlett_nh","2022-01-04T07:55:31.3110000+08:00","Agree @GeoffNunan, also better to be containerized if it is a GxP application when IT ""encourages"" that it be cloud-based.  Treat cloud service providers like a commodity business.","","👍 (1)"
"745009912160976977","marioishikawa","2022-01-19T00:19:15.2140000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/933032802323152956/1642388819958.png?ex=68df4ec2&is=68ddfd42&hm=bc6fa9c5593d5c4ca330b4fe662852d021a184b7e29e321605d7966b3714246a&","😁 (1),👍 (1)"
"867075936054149191","rickbullotta","2022-01-19T01:50:32.1070000+08:00","Interesting.  I think TwinThread would only need two or three icons though.  The difference between DIY and SAAS 😉","",""
"745009912160976977","marioishikawa","2022-01-19T01:52:55.4730000+08:00","interesting, I didn't know it. Are you an investor there?","",""
"867075936054149191","rickbullotta","2022-01-19T01:54:07.8030000+08:00","Yes, investor + advisor.  Obviously there are other SaaS offerings in the industrial analytics space that could also provide similar simplification, but it does point out the complexity of DIY.","","👍 (1)"
"914993398526656542","mikebartlett_nh","2022-01-19T04:20:48.4960000+08:00","Quartic would only need a couple of icons too, plus I don't see inherent batch context (S88) representation anywhere, which I see as a big drawback of the big 3.","","👍🏼 (1)"
"867075936054149191","rickbullotta","2022-01-19T04:31:59.6760000+08:00","The big 3 offer 87 different sizes and shapes of plain white legos.  Everything else you gotta do yourself.","","💯 (2),👍 (1)"
"914993398526656542","mikebartlett_nh","2022-01-19T05:37:42.8380000+08:00","Like trying to build the Death Star without instructions but lots of training on how big Legos fit together with small ones...","",""
"812295088348200960","patanj2","2022-01-25T08:21:43.3630000+08:00","Not trivial to design or manage.  Can make sense if you have a talented cloud platform team though.","","👍🏼 (1)"
"897154180001726494","koios6274","2022-01-28T05:06:54.2530000+08:00","Let's say you have an Ignition server with a lot of data and it's organized very well.  Let's say you use the Azure Injector to push information up to the cloud, and then you run analytics etc.  My question is - How do you get information FROM Azure IoT Hub back into Ignition?  You can't browse or subscribe to IoT Hub as a broker (at least I don't think so)","",""
"898217314741280828","hobbes1069","2022-01-28T05:09:06.4810000+08:00","I know Highbyte has bidirectional access to Azure IoT. They also have something called ""Azure Input"" on their future release plans.","",""
"867075936054149191","rickbullotta","2022-01-28T10:55:14.7470000+08:00","Why? You’ll get slaughtered with azure  iot charges.  Just send the data directly to where you want it to end up.","",""
"867075936054149191","rickbullotta","2022-01-28T10:57:06.7500000+08:00","You sort of can subscribe to azure iot like you would a broker - use the device SDK to create a “virtual device” that can receive data, events, and method calls from azure iot","",""
"889950316462735400","cyberwrights","2022-01-28T20:41:18.5410000+08:00","Rick, this is an important consideration for most of us in the learning phase as Walker has identified this as a primary differentiator between Azure & AWS, stating that Azure makes it more difficult to get data back down to the edge. John from HB recently mentioned MSFT having improved that, but didn't go into specifics. Is custom code with an SDK the best practice approach to that at this point? Or could you elaborate on ""Just send the data directly to where you want it to end up"" a bit?","",""
"876880919988957205","ryankershaw","2022-01-28T22:50:18.4710000+08:00","We (Litmus) run into this case with different platforms, both the onsite and the cloud ones.  Being able to move data back and forth comes in handy for ML/AI applications where you can close the loop by using the AI to rewrite setpoints on process equipment.  To Rick's point though, the more you move back and forth, the more you're going to end up paying no matter the cloud provider. So, having all of the analytics being done in the cloud isn't a great idea (unless you're not a fan of positive cash flows), but that's not to say bidirectional comms doesn't have its advantages.  However, if you can unload most of your analytics to the edge, you could keep your data costs down without sacrificing capability","",""
"897154180001726494","koios6274","2022-01-29T00:03:22.4590000+08:00","Azure IoT Hub is where we want the data to end up. I'm not worried on costs right now, I'm worried on the technology.  I think future updates will allow IoT Hub to be more of a full blown Broker / support 5.1 so it could be an endpoint, but for now I'm just trying to understand use cases.  We talk about the full circle picture. Data from source > edge device > push to broker > inject to cloud > do ""cool stuff"" ML/AI/PM etc etc etc, but I don't see the final connection.  Walker talks on having ML / AI actualy push things back down to the edge. Perhaps that's easier to do with other platforms, but my question is specific to Microsoft & their cloud offerings","",""
"897154180001726494","koios6274","2022-01-29T00:04:02.2490000+08:00","Getting the data there is relatively easy.  Doing ""stuff"" with the data (I'm being intentionally generic / ambiguous / open) is relatively easy. But the final connection of getting info back down to the edge ; I'm missing something","",""
"897154180001726494","koios6274","2022-01-29T00:05:19.4800000+08:00","Walkers Holy Grail last steps - stakeholder execute (or not execute) recommended operational adjustments","",""
"867075936054149191","rickbullotta","2022-01-29T00:05:33.3220000+08:00","That’s easy too.  You can send data, events and invoke methods from the cloud to the edge.  As mentioned above take a look at the Device SDKs for azure iot.","",""
"867075936054149191","rickbullotta","2022-01-29T00:06:34.2500000+08:00","My cautionary tale is that if you’re focused on analytics, it might be easier (and much cheaper) to write the data directly to Azure Data Lake/Blob Storage.","",""
"867075936054149191","rickbullotta","2022-01-29T00:07:24.8720000+08:00","You could still use azure iot (or plain azure event hub) to send stuff from cloud to edge on an event driven basis.","",""
"914993398526656542","mikebartlett_nh","2022-02-02T22:49:11.8390000+08:00","To @Ryan Kershaw's point, model training and curation could/should be in the cloud, but  closed-loop execute (or not execute) would ideally be running at the edge.  I'm not sure how that works in Azure or AWS, but our (Quartic.ai) platform is purpose-built for that.","",""
"817835202746253344","IIoT#4707","2022-02-02T22:49:12.0720000+08:00","GG @MikeBartlett, you just advanced to level 4!","",""
"898217314741280828","hobbes1069","2022-02-02T23:30:58.7870000+08:00","What's the TL;DR version of the difference between Azure Time Series Insights and Stream Analytics?","",""
"867075936054149191","rickbullotta","2022-02-02T23:37:03.6790000+08:00","TSI is a time series database vs in-band stream processing.  Stream Analytics does not archive data for long periods nor is it a foundation for ML.  TSI is historical and near-real-time, stream analytics is near-real-time and real-time.","","👍 (2)"
"260594842093092864","y_u_no_python","2022-02-03T08:30:57.5690000+08:00","https://learn.acloud.guru/search?specialCategories%5B0%5D=FREE

FYI for anyone in the discord who is interested.
@Mastermind @Mentorship 
@Everyone","https://cdn.discordapp.com/attachments/740336311671586968/938592363285209118/1643839751415.png?ex=68df1941&is=68ddc7c1&hm=b5425431d951bbd87d4dc44e39df47dd49a0599da708f23e22f28fb7a4fadef5&","😲 (1)"
"745796393855352953","thedavidschultz","2022-02-03T18:52:23.0880000+08:00","Not at all @Y_U_NO_Python?   Tag @DavidSchultz as much as you want 😂","","👍 (2)"
"260594842093092864","y_u_no_python","2022-02-04T10:48:58.7960000+08:00","Oh, i thought this was directed at me….. (it was right after i posted an “at” mentorship and mastermind in the general channel) @DavidSchultz 

https://discord.com/channels/738470295056416930/738470295056416934/931512144757948476","",""
"745796393855352953","thedavidschultz","2022-02-04T17:37:38.2090000+08:00","You must have missed the person that came in and posted the same message in pert near every channel.","",""
"519666539436310529","aristotelestn","2022-02-04T21:10:54.8390000+08:00","Hello Guys, Does anyone here use Dremio to organize the Operational Data Lake? What do you think about him? Do you have another tool that you recommend to organize the Operational Data Lake for industrial data?","",""
"817835202746253344","IIoT#4707","2022-02-04T21:10:55.1620000+08:00","GG @AristótelesTN, you just advanced to level 3!","",""
"498555567078506500","jeremylorino2375","2022-02-13T08:30:16.8130000+08:00","Never used Dremio. Last time I built out a pipeline I used GCP.

Cloud Storage for raw data. DataFlow for ETL. BigQuery for analysis.

Reference architecture here
https://web.archive.org/web/20200607085041/https:/cloud.google.com/now-ims","",""
"381284588724420628","chill33","2022-03-05T20:44:38.9450000+08:00","Hi, we are currently exploring which Operational / Transactional database we should use to store our IoT telemetry data (and other document based datasets).

The goal is then to expose this data via APIs  for UI / other applications to build over it.  We will be using CDC / change feeds to perform some data processing tasks (using Azure Functions or AKS microservices).

We are in Azure, our current candidates are Azure CosmosDB and MongoDB Atlas since they are managed database.   Are there any other databases (timeseries maybe?) that we should be exploring for our use case in your opinion?  Thank you!","",""
"801561312861618236","jon.forbord","2022-03-06T02:39:23.5760000+08:00","Did you take a look at Azure Timeseries Insights yet?","",""
"801561312861618236","jon.forbord","2022-03-06T02:41:34.6830000+08:00","Sorry, forget it, seems you want to mix timeseries with other data, so timeseries insights is not going to cut it for you.","",""
"867075936054149191","rickbullotta","2022-03-06T05:47:44.0130000+08:00","TBH, it won't cut it for most people.  Stay clear of Time Series Insights.  Use ADX instead.","",""
"801561312861618236","jon.forbord","2022-03-06T05:52:23.2000000+08:00","Yes, agreed 💯, it maaaaaaay be useful for some limited use cases for IoT. Tried it, not impressed. Timeseries insights is not a very good product, fairly “cheap”, but you get what you pay for.","","👍🏼 (1)"
"894527802316046366","nickn5549","2022-03-06T09:34:30.5090000+08:00","Testing now InfluxDB vs PostgreSQL for time-series. So far, InfluxDB has the advantage of using less space, but speed-wise is slower than PostgreSQL (even MySQL) when you try to search for specific time ranges. Also, InfluxDB works better on SSD than spinning disk...maybe doesn't use cache efficiently?!?","",""
"867075936054149191","rickbullotta","2022-03-06T22:28:39.9890000+08:00","If I recall from some testing I did a while back, this inverts as you accumulate more data and the PostgreSQL indices get huge.","","👍 (1)"
"894527802316046366","nickn5549","2022-03-07T07:04:31.1480000+08:00","I'll continue in parallel with both...see how it goes during the PoC","","👍🏼 (1)"
"882642237522071642","jatinder7065","2022-03-07T12:10:16.7750000+08:00","Some issue found using with Teltonika gateway when I configured with aws cloud but it's working fine with hivemq cloud. I am check it all mqtt broker configure file and all above but still facing some problem. Have  Any ideas about it?","",""
"867075936054149191","rickbullotta","2022-03-07T20:44:33.0760000+08:00","One thing that you might find awkward/difficult with InfluxDB is querying ""most recent values"" - while the Flux language includes a ""last"" expression, you need to supply a time range.  Hopefully that's something that will get addressed in a future release.","",""
"381284588724420628","chill33","2022-03-07T21:08:42.7810000+08:00","Yes I took a quick, and it seamed more useful as an “data exploration tool” than a full fledge operational database.","","👍 (1)"
"381284588724420628","chill33","2022-03-07T21:09:49.2560000+08:00","Mongo 5.0 now has TimeSeries collections.  Anyone tried/explored it ?","",""
"867075936054149191","rickbullotta","2022-03-07T21:31:01.2800000+08:00","Saw that a few months back. After looking at the ugly and complex queries needed I didn't look at it any further.","",""
"830193224504705035","marc.jaeckle","2022-03-08T00:09:59.4230000+08:00","With a large amount of data you should always use local SSD storage or things get quite slow. We recently compared a few databases for analytics use cases in IoT projects: https://github.com/MaibornWolff/database-performance-comparison/ 
The tests assume that you forward all of your data to Kafka and persist it from there in batches to a database. Besides the insert performance we also looked at a few typical types of queries. Originally we wanted to see how the newer ""scalable"" SQL databases CockroachDB and YugabyteDB can be used not just for typical transactional workloads but also for analytics workloads in IoT projects and then we kept adding DBs. In summary: if you want to use an OpenSource solution, then use OpenSearch (Elastic). If a commercial product is fine too, then you can also use the official Elastic offering or InfluxDB. As managed service, TimescaleDB might also be an option. CockroachDB and the SQL interface of YugabyteDB disappointed. Interestingly we didn't even see a difference between 3 node and 5 node clusters in terms of scalability which is quite disappointing for both CockroackDB and YugabyteDB. Maybe both should put some more investment into the product instead of marketing 🙂 But then again, things might look different in other scenarios.","","👍 (2)"
"830193224504705035","marc.jaeckle","2022-03-08T00:25:07.1220000+08:00","See https://discord.com/channels/738470295056416930/740336311671586968/950425089676050453 regarding some performance tests for IoT telemetry data with different databases. In the end, I would (still) use two different types of databases for transactional data and timeseries data. On Azure, Azure Database for PostgreSQL is a good option. If you want to use managed services of the timeseries DBs on Azure through the Azure Marketplace, there can be some limitations that you should be aware of. For example Elastic Cloud requires you to let them connect to your / an AD which can be a problem but they offer Private Link support. InfluxDB on the other hand lets you manage users independently but does not offer support for Private Link so you would have to use it through a Public IP. Unluckily Azure Database for PostgreSQL does not offer a scalable version of TimescaleDB and CosmosDB can get quite expensive. In any case I would use a timeseries database that you could operate yourself if you have to. Depending on your use case, managed services can get quite expensive at a larger scale. But talk to the vendors about pricing before you switch to a self hosted solution. ""Enterprise sales"" is the magic word (and the rebates that can come with it) 🙂","","👍 (1)"
"740365995419631736","omarazizahmed","2022-03-08T01:02:14.5690000+08:00","Someone on here mentioned Cockroach DB. Anyone used that?","",""
"830193224504705035","marc.jaeckle","2022-03-08T01:21:12.2830000+08:00","We used it only in our performance tests (see above) and I wouldn't use it in projects for one main reason: YugabyteDB. More specifically:
* In contrary to YugabyteDB it is not OpenSource (meaning not under a real OpenSource license). 
* YugabyteDB showed better performance for timeseries data. Also YugabyteDB offers a YCQL interface which can be used for more analytics-like use cases. 
* We didn’t really see much of the promised scalability for CockroachDB. We only compared 3- and 5-node clusters though.
In summary, this makes YugabyteDB a better choice in many cases, especially if you just want a HA Postgres compatible database.","",""
"740365995419631736","omarazizahmed","2022-03-08T01:22:23.0700000+08:00","Nice. What are biggest use cases you are seeing with your customers these days? What is the type of data and where is it going and what are they trying to do with it?","",""
"830193224504705035","marc.jaeckle","2022-03-08T01:29:40.4810000+08:00","Do you mean what people do with IIoT data or do you mean trends regarding databases? The question about the trends regarding databases would be easier to answer 🙂","",""
"740365995419631736","omarazizahmed","2022-03-08T01:29:56.9460000+08:00","Sure, databases 🙂 I'm just here to learn","",""
"830193224504705035","marc.jaeckle","2022-03-08T16:04:38.8660000+08:00","Regarding operational / transactional databases, it seems like Postgres and Postgres-compatible DBs have taken over the world. I'd say of all our implementation projects at all our customers across all verticals about 90% use Postgres these days as operational / transactional DB. Most use the managed Postgres services that the hyperscalers provide. For object storage the projects also mostly use the managed offerings the hyperscalers provide. Just some use min.io for S3 compatible storage on other platforms than AWS. Regarding document and timeseries databases the picture is a bit more diverse. For timeseries / IoT data, often Elastic / Opensearch or InfluxDB are used. TimescaleDB is not that popular because the Azure managed service does not support horizontal scalability and I haven't seen anyone using TimescaleCloud. I also think TimescaleCloud only supports VPC peering on AWS but on GCP or Azure you have to use it through public IPs (I might be wrong though). Also TimescaleDB OpenSource cannot be set up easily in a scalable way. A few projects also use MongoDB Atlas for IoT data but I don't really know how well that works when you want to do analytics on top of it. If anyone uses MongoDB, it seems like they all use MongoDB Atlas which seems to be pretty good. On Azure some start with CosmosDB but it seems like they tend to migrate away from it due to costs. On AWS the usage of DocumentDB and DynamoDB are common. For caching, I'd say Managed Redis services from the hyperscalers are most commonly used. For analytics Cassandra-compatible DBs also still play a role. And I probably forgot to mention a few other databases 🙂","","👍 (2)"
"830193224504705035","marc.jaeckle","2022-03-08T17:32:41.3350000+08:00","Speaking of OpenSearch, my colleague Sebastian is currently working with the company Opster on an OpenSearch Kubernetes Operator which was still missing: https://github.com/Opster/opensearch-k8s-operator","",""
"894527802316046366","nickn5549","2022-03-08T18:52:39.5690000+08:00","Had the same reaction about their queries....","",""
"894527802316046366","nickn5549","2022-03-08T18:55:42.5150000+08:00","Flux is a piece of @#&Q ....pretty new to me....I SQLed for XX years and now FLUX...","",""
"381284588724420628","chill33","2022-03-26T08:59:30.5130000+08:00","We are in discussion with Google Presales team regarding IoT telemetry database in GCP.   They are pushing hard for us to use BigQuery for this!  I was very surprised, but it looks like they are expanding BigQuery to be more than a Data Warehouse for complex queries / analytics.  They actually have the functionnality of ingesting JSON documents in preview right now.  We will try / PoC it, but I am very skeptical about building frond ends that allows ends customers of our products to query BigQuery via APIs.  My impression is that it will be hard to control costs properly.

Anyone has experience storing IoT telemetry data in BigQuery to be displayed in a UI afterward (Time series graphs, aggregations..)?","",""
"817835202746253344","IIoT#4707","2022-03-26T08:59:30.9180000+08:00","GG @Chill33, you just advanced to level 1!","",""
"830193224504705035","marc.jaeckle","2022-03-30T03:33:46.0790000+08:00","In the end, BigQuery will still be based on a distributed file system with columnar storage and a distributed SQL engine on top of it. Even if they extend the query API to better support timeseries data and even add some internal optimizations, it will probably still not be the ideal solution for timeseries data. And of course presales is trying to sell BigQuery for telemetry data as well as Google does not offer their own timeseries database (at least I’m not aware of one).","",""
"857684726647488568","torije","2022-03-31T18:16:13.2840000+08:00","Me and my team has been using BigQuery as a component in a tool that processes, stores and visualizes time series data. We've been running on this stack for a few years now and I'd say your initial concern about controlling cost is justified. Even for internal use-cases, understanding the cost of queries can be challenging and exposing it directly for end users doesn't sound like something I'd want to do at least. For our specific requirements, BigQuery was always just a component in a tiered storage architecture. For what we need it for it performs well and I don't have anything against the product itself. Just proceed with caution wrt price...  Also worth checking out the quotas and limits for it: https://cloud.google.com/bigquery/quotas","","👍 (1)"
"381284588724420628","chill33","2022-04-02T09:31:51.0980000+08:00","Thank you for your insights","",""
"279393337042272258","pt.ox","2022-04-21T06:53:50.3880000+08:00","Unorthodox request, but does anyone on here have the phone number of someone I can contact at AWS?

We don't use AWS but have had a monthly $0.06 charge to an account that I can't log into, and these people won't let me submit a support request without logging in. It's super frustrating","","😩 (1)"
"441200515645177857","m4rek_g","2022-05-03T12:03:08.5930000+08:00","I see some people use Azure, do you use Azure Data Explorer in your applications? I see MS promotes this solution for timeseries and it seems to be better suited than CosmosDB... Any thoughts, experience?","",""
"743810005714600017","dep05d","2022-05-04T03:42:58.1130000+08:00","We have been using it for about a year.  Overall our experience has been quite positive.  Performance has been great.  Using partitioning and extent policies has allowed it to scale for us so far (14,000 spB ""devices"", ~14 mil spB DDATA messages a day, ~40 mil metrics per day).  We currently achieve around 15-20x compression on sparkplug json messages. Kusto is a nice language, and the Kusto Explorer app makes writing queries pretty easy with their auto-complete functionality. But it's still a new query language to learn.  You can use SQL too but it's very limited compared to Kusto.

Update policies and materialized views allow continuous transformation/summarization of ingested data.  For example, an update policy can expand sparkplug metric arrays into a new table with one row per metric, and a materialized view could create binned history of float values, or a last-known-value-per-metric table, that all update automatically.  If you want processed data out of the system, besides having polling queries of data or using a data pipeline tool, you will need to continuous export to ADLS, and then trigger an activity from there.  Also, Azure always wants to steer you towards Azure, so connectivity is slightly more challenging to the outside world.  Some tools like Grafana and Seeq natively support it, else you will be using REST API's or not-quite-as-good-as-kusto SQL connectors.

We wrote custom ingestion scripts in python rather than using Event Hubs, to save a little money and allow us to better adjust payloads before ingestion (decode sparkplug protobuf).  There are two types of ingestion: streaming and batch.  Streaming is near real-time (edge publish to cloud queryable is about 1-3 seconds based on our python microbatch insert size), batching ingestion is at a minimum 30 seconds delayed. There are design considerations/limitations with update policies and continuous export with regards to streaming ingestion as well.  Hope this helps!","",""
"441200515645177857","m4rek_g","2022-05-04T14:03:33.1740000+08:00","@dep05d thanks for your input! It looks liket your experience is similiar to mine - as long as we don't want to go ""Cloud Agnostic"", ADX seems to be fine idea. What I still haven't figured out is cold path: in theory, ADX allows to keep data for long (like 10 years) but reference architectures suggest to use ADX to only work on data, not to store them. 
Also, AFAIK, the same functionality (ingress, egress, data analytics, storage) might be done with Databricks - unfortunately, I have no experience with this service.","",""
"867075936054149191","rickbullotta","2022-05-04T21:22:56.4310000+08:00","It's also worth noting that the Azure IoT Central product switched from Time Series Insights to ADX.  For long term storage you would use Azure Data Lake Storage - very cheap and affordable.  You can also configure policies for warm vs cold storage as well as retention period.  And of course, export frequency to ADLS.

From a visualization point of view, PowerApps/PowerBI is also an option.","","👍 (1)"
"441200515645177857","m4rek_g","2022-05-04T21:26:44.0680000+08:00","@RickBullotta I heard that ADX is used by TSI, I didn't know about IoT Central, thanks! Anyway, ADX is fairly popular in Azure family, since MS tends to use it in any service that uses telemetry data.

I'm curious if AWS has similiar offering?","",""
"867075936054149191","rickbullotta","2022-05-04T21:26:58.6110000+08:00","Correct.  It's down at the bottom of the stack.","",""
"867075936054149191","rickbullotta","2022-05-04T21:28:43.2210000+08:00","On the AWS side, it's Timestream and OpenSearch AFAIK.","",""
"867075936054149191","rickbullotta","2022-05-04T21:29:36.6170000+08:00","For platform independent options, you could also look at InfluxDB, Clarify, Canary and others.","",""
"403511800068440074","rafaamaral","2022-05-04T21:50:56.6900000+08:00","Postgres Timescale works well as well. And grafana released their version now. Haven't tested it yet myself.","",""
"441200515645177857","m4rek_g","2022-05-04T21:57:41.2960000+08:00","@Raf Amaral I've heard about TimescaleDB but I'm not convinced to the idea of storing telemetry in RDBMS. Certainly, there is a lot of different db solutions for time-series data.
@RickBullotta I agree on vendor lock, so ADX is fine, since (at least - for now) Azure is my _main_ cloud provider 🙂","",""
"817835202746253344","IIoT#4707","2022-05-04T21:57:41.5950000+08:00","GG @Marek.G, you just advanced to level 2!","",""
"403511800068440074","rafaamaral","2022-05-04T21:59:46.7730000+08:00","I would agree with you. Funny thing is lots of historians from big companies do store in MSSQL. 

What Timescale does is partition data on a time column. They do tones of benchmarking with some results public. Well. It's an option. 
I would still go for managed services. I don't like to maintain servers anymore.","",""
"867075936054149191","rickbullotta","2022-05-04T22:01:29.6590000+08:00","Timescale offers a managed service also. Sort of.","",""
"403511800068440074","rafaamaral","2022-05-04T22:02:01.7680000+08:00","Sadly not in RDS.","",""
"441200515645177857","m4rek_g","2022-05-04T22:12:12.7220000+08:00","There is also an offering in Azure. Honestly, I'm a little bit puzzled about how to properly design data storage for telemetry. Right now, I would use Databricks.
@Raf Amaral I remember good old times when I tried to access data in WinCC 7... At that time, any major SCADA available in Europe was built on top of SQL Server.","",""
"403511800068440074","rafaamaral","2022-05-04T22:16:09.4060000+08:00","Exactly. And it wouldn't scale. I saw clients with MSSQL express!!
Telemetry Data storage is never easy. But there are fit for purpose out there. I would take mostly a cost approach since most should do the basic requeriment. I said should***.
Basic for me is able to store fast, downsize, deadband, interpolate,  query, etc. But cost could go out of control since data volume can be huge. I've seen some osi licenses and it was shocking.","",""
"867075936054149191","rickbullotta","2022-05-04T22:39:32.7600000+08:00","Time Series Insights used to be 5-25X the cost of OSISoft at um high ingest rates.","",""
"867075936054149191","rickbullotta","2022-05-04T22:41:08.1250000+08:00","Some were built on SQL Server but did not use the database for time series storage.  Wonderware InSQL for example.","",""
"857684726647488568","torije","2022-05-04T23:26:22.8370000+08:00","There are some advantages to using Timescale in terms of how you can store and query meta-data. My main objection is their HA deployment story which does require a fair amount of setup if you're operating it yourself. I've personally been super impressed with what the Timescale team has been doing, but like most cases there really isn't a one-size-fits-all solution. Which one is right for you really comes down to what requirements you have in terms of ingestion/query speeds, storage compression, operating complexity etc.","",""
"743810005714600017","dep05d","2022-05-05T07:22:16.0780000+08:00","We generally like to avoid vendor lock, but had a lot of political constraints.  As an Azure-only cloud org, there was little oversight or pushback when trying any Azure data service, but external vendors require an IT intake process that includes getting past ""enterprise"" groups that would insist we push telemetry into Snowflake and report time series with Tableau.  Where possible, we expose our asset model and metric history primarily in the form of an API to help insulate consuming clients from potential storage layer changes in the future.  Coming from an Oracle background, our team was also admittedly intrigued to try something different than another RDBMS, with potentially lower administrative overheard.","",""
"743810005714600017","dep05d","2022-05-05T07:31:46.8620000+08:00","Some interesting notes and comparisons between Timescale and ADX (note the author appears to be a 3rd Party Microsoft Certified Consultant).  I think the conclusion is pretty spot-on  https://option40.com/blog/querying-time-series-data","",""
"441200515645177857","m4rek_g","2022-05-05T13:13:19.7890000+08:00","@dep05d I like this kind of totally useless comparisions with note at the very end ""The purpose of these blog posts is not to compare ADX vs Timescale ..."" blah, blah, blah. First of all, there is not a single word about ADX setup: what SKU was used, what was the scaling setup etc. The same set of questions should be asked for Timescale. Like this, it's just a set of arbitrary numbers shown to prove author's idea about ADX superiority over Timescale. Not engineer way at all. 😉 (but I still _belive_ that ADX has better performance)","",""
"857684726647488568","torije","2022-05-05T14:57:51.2430000+08:00","There are some details on the setup in Part 1 & 2: https://option40.com/blog/ingesting-time-series-data","","👍 (1)"
"857684726647488568","torije","2022-05-05T15:09:24.8160000+08:00","Will for sure do some reading on ADX, looks like a really interesting product. Thanks for sharing @dep05d","",""
"812295088348200960","patanj2","2022-05-06T07:49:19.0240000+08:00","That is absolutely insane. Seems their pricing model is not targeted for high volume industrial data.  I had a similar finding when trying g to price out AWS TimeStream.  I even said to the AWS contacts “I have to be making a mistake with your cost calculator”, but no one ever from AWS ever spoke up and corrected me.","","😱 (1)"
"769436583753416706","jman444","2022-05-07T03:03:38.2660000+08:00","i was quite impressed by how fast you're calculating min,max,avg on Clarify.. do you pre-aggregate the data at 5m,60m? usually, TimescaleDB is pretty slow at scanning tens of million of rows..","",""
"857684726647488568","torije","2022-05-07T03:08:35.0680000+08:00","Thanks! We currently don’t pre-aggregate, but we have done extensive optimization on our Timescale deployment (we run it ourselves). It’s also just a layer in our timeseries storage, we have multiple layers where data can be stored.","",""
"769436583753416706","jman444","2022-05-07T03:09:19.8990000+08:00","do you use multiple nodes?","",""
"857684726647488568","torije","2022-05-07T03:11:39.9120000+08:00","Yes","",""
"857684726647488568","torije","2022-05-07T03:13:37.9980000+08:00","Are you using Timescale?","",""
"769436583753416706","jman444","2022-05-07T03:14:49.9530000+08:00","yes, we do use it to store a subset of our data","",""
"769436583753416706","jman444","2022-05-07T03:15:29.6720000+08:00","but we're mostly pre-processing everything in Kafka and push in bulk to TimescaleDB","",""
"769436583753416706","jman444","2022-05-07T03:16:14.3030000+08:00","and on top of Timescale, we have Hasura to expose the data as a GraphQL API","",""
"867075936054149191","rickbullotta","2022-05-07T03:18:32.8910000+08:00","Doesn't that introduce latency (push in bulk) that would make it impractical to use this data store for near real time analysis and visibility?","",""
"769436583753416706","jman444","2022-05-07T03:19:36.5970000+08:00","hmm, the latency isn't that bad, maybe less than a few hundred ms (I didn't measured it exactly though)","","👍🏼 (1)"
"867075936054149191","rickbullotta","2022-05-07T03:20:01.2080000+08:00","So small batches!  Like good whiskey.","",""
"867075936054149191","rickbullotta","2022-05-07T03:20:55.5580000+08:00","Probably worth running a test just to know.","","👍 (1)"
"769436583753416706","jman444","2022-05-07T03:21:13.5610000+08:00","*at each cycle, we're pushing maximum 1k rows, if there are less than 1k we're pushing what we have","",""
"769436583753416706","jman444","2022-05-07T03:22:26.1690000+08:00","the batching is mostly used when we re-process the data because the ""mapping configuration/analytics rules"" have been changed","","👍🏼 (1)"
"867075936054149191","rickbullotta","2022-05-07T03:24:10.8260000+08:00","That's a good approach.  Flush ""no later than...""","",""
"769436583753416706","jman444","2022-05-07T03:25:44.9100000+08:00","regarding Kafka, the thing we're struggling with is how to re-process the real-time reports when the rules that created them are updated","",""
"769436583753416706","jman444","2022-05-07T03:27:58.0970000+08:00","for example:
- we have an ""activity"" called ignition_on, which has start & stop triggers
- every time one of the trigger is fired, we create a new activity or close the last activity
- then we do some calculations for each activity (distance, duration, fuel consumption, etc)","",""
"867075936054149191","rickbullotta","2022-05-07T03:28:51.0750000+08:00","Does Timescale allow updates or only writes/deletes?","",""
"769436583753416706","jman444","2022-05-07T03:29:42.6680000+08:00","it allows everything, timescale is just a PostgreSQL extension which partition the data in sub-tables under the hood","",""
"867075936054149191","rickbullotta","2022-05-07T03:29:49.5930000+08:00","Yup.  Just looked.","",""
"769436583753416706","jman444","2022-05-07T03:30:10.2200000+08:00","*this is the core functionality, they have a low of other functionalities pretty useful too","",""
"867075936054149191","rickbullotta","2022-05-07T03:30:13.8610000+08:00","What do the calculations look like?  Could they be done in an SP?","",""
"867075936054149191","rickbullotta","2022-05-07T03:30:36.5640000+08:00","Or have you already lost the needed data granularity by then?","",""
"769436583753416706","jman444","2022-05-07T03:32:01.3440000+08:00","hmm, it's pretty hard to do the calculations in stored procedures (SP).. the ingestion rate will drop and in some use-case it's pretty hard to implement the triggers using SPs","",""
"867075936054149191","rickbullotta","2022-05-07T03:32:55.1580000+08:00","Yup.  Such are the joys of in-line/stream processing.  Hard to get ""do-overs"". 😉","","👍 (1)"
"898217314741280828","hobbes1069","2022-05-07T03:35:49.4240000+08:00","That's one of my beefs with Tulip. They don't store the raw machine data (I know it would be a lot of data) so once a machine ""state"" is calculated and written. That's it. We've evolved quite a bit over time but there's no opportunity to go back and reevaluate the old data.","",""
"867075936054149191","rickbullotta","2022-05-07T03:36:31.0640000+08:00","Definitely let Erik know - I think a time series/raw data store should be a foundational piece of Tulip.","",""
"867075936054149191","rickbullotta","2022-05-07T03:37:02.7200000+08:00","Similar I've encouraged them to make access to data in external time series DBs/historians a core capability as well.","","👍 (1)"
"898217314741280828","hobbes1069","2022-05-07T03:37:30.0210000+08:00","We like Tulip, but it's not the answer for everything. We're already working on splitting off our data stream to an Azure data lake as well as part of our longer term strategy.","",""
"867075936054149191","rickbullotta","2022-05-07T03:38:19.9780000+08:00","Have you considered dumping the raw data in chunks to blob storage of some kind?  You could still maintain your ingress rates but still have the raw data available if you needed it.","",""
"769436583753416706","jman444","2022-05-07T03:39:20.6880000+08:00","I'm thinking for a solution for the past two weeks, up until now there are the solutions:
1. have a paralel Kafka workflow that will do the re-processing jobs
 - the output of this workflow will override the data from the main workflow
 - for the entities which does not have unique identifiers (eg. ""activities"") we will have a job that will delete the entities from the Kafka compacted topic and then will insert the new entries
2. another option would be to create a separate Kafka workflow, push the data to a separate Timescale table and then replace the old table with the new one","",""
"867075936054149191","rickbullotta","2022-05-07T03:39:52.8810000+08:00","So you are retaining the raw data in Timescale as well?","",""
"769436583753416706","jman444","2022-05-07T03:40:05.1390000+08:00","yes, we already store the raw data permanently in Kafka also we push it to MongoDB","","👍🏼 (1)"
"898217314741280828","hobbes1069","2022-05-07T03:41:03.9610000+08:00","Cool. My only exposure to MongoDB is I maintain the Unifi Controller package for Fedora/RHEL/CentOS/Rocky etc. for Ubiquiti hardware.","",""
"769436583753416706","jman444","2022-05-07T03:41:09.7830000+08:00","no, the raw data is not pushed to Timescale because the ""end user"" doesn't need it, we push the records (which is the normalized data which has been extracted from the raw data)","",""
"403511800068440074","rafaamaral","2022-05-07T03:43:03.0170000+08:00","I could be way off but something tells me that zeeby could help you. Check camunda zeeby. I can manage states for your ""activities"" at scale. But maybe not. I just don't know enough of your use case to know for sure.","","👍 (1)"
"403511800068440074","rafaamaral","2022-05-07T03:43:21.4090000+08:00","Zeebe*","",""
"769436583753416706","jman444","2022-05-07T03:43:38.2720000+08:00","the cool think about Kafka is that you process the packages in-order (this is useful for computing the current state) and also that you can consume the same data multiple times (for example push to multiple databases based on what you want to accomplish, sometimes you need a noSQL dB, sometimes you might need SQL or a specialised timeseries database)","",""
"867075936054149191","rickbullotta","2022-05-07T04:05:37.0950000+08:00","I'm just roaring out loud at the mere existence of something called ""camunda zeeby"".  Are we completely out of names and words?","","😅 (1)"
"769436583753416706","jman444","2022-05-07T04:08:36.5560000+08:00","hmm, I'm not sure I understand why it might be useful to drop the raw data in a blob storage..","",""
"817835202746253344","IIoT#4707","2022-05-07T04:08:37.2860000+08:00","GG @jman444, you just advanced to level 5!","",""
"867075936054149191","rickbullotta","2022-05-07T04:09:49.8090000+08:00","If you're not storing it anywhere, blob storage = fast ingress but you'll have it if you need to ""replay"" it to do recalculations.","","👍 (1)"
"769436583753416706","jman444","2022-05-07T04:12:00.8460000+08:00","yup, for now we're storing it permanently in Kafka so we can re-play the data pretty fast","",""
"857684726647488568","torije","2022-05-07T04:15:26.9430000+08:00","We actually found BigQuery to be comparable in cost to blob storage for data you’re not querying. Then when you need it, it’s easier to work with than having the data as blobs. For AWS there is S3 select, which I think kinda solves the same cases. (https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html)","","👍🏼 (2)"
"817835202746253344","IIoT#4707","2022-05-07T04:15:27.6990000+08:00","GG @Tor-Inge, you just advanced to level 4!","",""
"769436583753416706","jman444","2022-05-07T04:20:01.3800000+08:00","I'm wondering, what is the throughout we could get from S3? imagine re-playing a few hundred GB of data on 500kB/s, about 7 days for 300gb - :)","",""
"857684726647488568","torije","2022-05-07T04:22:25.9300000+08:00","Hehe, good question. Can’t speak to AWS as I haven’t used it for quite some time, but we’ve been happy with the performance from BigQuery.","","👍 (1)"
"403511800068440074","rafaamaral","2022-05-07T04:25:44.2890000+08:00","All I know is that I feel I got lucky with mine and may not start a new Company due to lack of names /domains. It may create a stall in innovation.","","😂 (2)"
"867075936054149191","rickbullotta","2022-05-07T04:30:15.3430000+08:00","500KB/s is no problem.  50MB/s is pretty normal.  You can use EFS for crazy fast speeds if you really need it.","",""
"769436583753416706","jman444","2022-05-07T04:32:21.6130000+08:00","right now we're using  dedicated enterprise NVME SSD's and we're pretty happy 😅","","👍🏼 (1)"
"867075936054149191","rickbullotta","2022-05-07T04:44:24.9710000+08:00","How are you handling disaster recovery and cross region redundancy?","",""
"769436583753416706","jman444","2022-05-07T12:34:12.6870000+08:00","- we don't have cross region redundancy yet, the plan is to firstly have all the data in Kafka (configurations, unit information, field mappings, etc) then we will have two Kafka clusters which will be sync'ed between them","",""
"769436583753416706","jman444","2022-05-07T12:38:03.4820000+08:00","- for now, we have redundancy across one region, we're using Kubernetes and Kafka is deployed using Strimzi operator on 3 nodes, Timescale is deployed using Crunchy operator on 3 nodes (1 node for the master DB, 1 node for secondary DB and the third node for backups and WAL archiving, the secondary is keep in sync by applying all the master WAL changes)","",""
"769436583753416706","jman444","2022-05-07T12:38:46.4260000+08:00","- also, we do have snapshot support at disk level (we're using Longhorn for having distributed storage across our nodes)","",""
"245298428882452480","larsu2776","2022-05-10T15:09:27.9830000+08:00","Do anyone have any experience with AWS IoT core and pushing messages batch messages into PostgreSQL? Right now the only solutions I can find is using RDS PostgreSQL, and that means I will be unable to use Timescale and eventually Grafana. Is there any good solutions out there. My other issue is the the bulk message. It is in JSON format, with S7 data and 40 tags sent in a JSON array. It seems that some of the message is lost when trying to store it in AWS S3, and querying it in Postgres gives an error. I appreciate any and all input. The other possibility is to use Timestream and DynamoDB, but how can this data be visualized in Grafana?","",""
"857684726647488568","torije","2022-05-10T15:22:26.3880000+08:00","Unfortunately RDS still doesn't support Timescale, I'm also unsure if they can add it due to the licensing. There is a managed Timescale available on AWS here (https://www.timescale.com/products) or you can spin up an EC2 instance and run it yourself.  I haven't used AWS IoT Core, but I'd bet there is some way to process the data before inserting it. Perhaps using Lambdas (if not too expensive for your case). Storing smaller files into S3 isn't really a good idea, it can quickly become expensive to pull them out again and processing many small files is an absolute pain. Last time I did the calculation on Timestream for a case, it ended up being crazy expensive, but pricing might have changed since then. (Happy to see more Norwegians in here btw 😄 )","",""
"245298428882452480","larsu2776","2022-05-10T15:28:24.3620000+08:00","Awesome thanks, yeah I figured as much. And been looking at using S3 with tmp storage possibilities and lambda functions to process the data into a more readable CSV file for postgres. I know Postgres is able to handle JSON just fine, but the main issue right now is the fact that I want the data in postgres to automatically update as a new message is processed in IoT Core, and Importing data into postgres as JSON is not something I'm experienced enough to figure out myself. I guess the solution is running something like timescale with grafana?","",""
"245298428882452480","larsu2776","2022-05-10T15:29:03.4260000+08:00","BTW great to see more and more norwegians out there working on digital transformation! 😄","",""
"857684726647488568","torije","2022-05-10T15:32:41.2070000+08:00","Pretty sure something like this would solve it. I don't know how much experience with Lambda you have, but basically it's a solution that lets you run a bit of code when some event happens. Perfect for this kind of ""when new data arrives, process it and store it somewhere"". You can set it up so that it takes each message, processes the batch data and inserts it right into Timescale (or whatever DB you want to use). Then you'll have data streaming right into your database, being immediately available for visualizing in Grafana.","https://cdn.discordapp.com/attachments/740336311671586968/973487728555622430/aws.png?ex=68df7c19&is=68de2a99&hm=ac74e30feeae04d7d7e78439a96049a7bd61d99508048d85b8e993edf7b20e81&",""
"245298428882452480","larsu2776","2022-05-10T15:38:57.3880000+08:00","Yeah, that was how I wish I could do it, my experience with lambda is close to none, which makes it abit more problematic. I'm experienced with python, so it should be possible. I will try to follow this guide: https://docs.timescale.com/timescaledb/latest/tutorials/aws-lambda/

Thanks for the input, it helps a lot being able to spar my ideas with someone!","",""
"857684726647488568","torije","2022-05-10T15:41:15.3760000+08:00","It's a bit of reading to get started, but once you grasp the basics, Lambda is really easy to work with. Just give me a ping if you need any help with it, I've spent a fair amount of time making processing pipelines with Lambda in the past 😅  Good luck!","",""
"245298428882452480","larsu2776","2022-05-10T15:41:41.4100000+08:00","Thanks, appreaciate it! 😄","",""
"817835202746253344","IIoT#4707","2022-05-10T15:41:41.8360000+08:00","GG @LarsU, you just advanced to level 2!","",""
"403511800068440074","rafaamaral","2022-05-10T17:24:24.3120000+08:00","Make sure when you start, you start with something like serverless, cdk, Sam. Any infrastructure as a code.","",""
"867075936054149191","rickbullotta","2022-05-10T20:51:43.9820000+08:00","Another option would be to use InfluxDB cloud + Grafana.  InfluxDB's line protocol is a very simple textual batch ingress format.","",""
"745009912160976977","marioishikawa","2022-05-13T00:19:58.3880000+08:00","it now also allow inserts on compressed partitions (but not updates and deletes).","",""
"745009912160976977","marioishikawa","2022-05-13T00:22:01.9850000+08:00","I don't think they will ever license it unless they pay a huge Enterprise contract or buy Timescale company altogether. That will probably happen, like when Microsoft bought Citus","","👍 (1)"
"745009912160976977","marioishikawa","2022-05-13T00:23:16.6050000+08:00","I agree, and for old partitions that are not updated it is impressive how cheap it is. It is half the cost of Google Cloud Storage which is already cheaper than S3.","","👍 (1)"
"769436583753416706","jman444","2022-05-13T13:43:16.5960000+08:00","the best solution I'm thinking at is to push all the messages to AWS MSK (Kafka), then have a consumer (custom code or Kafka Connect Sink)  that will push the data to SQL DB, if you need help I can share some code to do this","",""
"745009912160976977","marioishikawa","2022-05-17T05:30:40.4750000+08:00","Depending on your use case you can also consider Google BigQuery. It supports inserts, but also batch upload using JSON or CSV. Regarding Postgres, you don't need Timescale to use Grafana, or you can also batch insert from AWS IoT Core directly to Postgres without Timescale too. Depending of the model you might not need TS. In general, to get a stream and insert as a batch you will need to create something such as a Python script to store the batch and then insert. The ideal is to actually insert as you receive so you can acknowledge the message was handled in case you have a pipeline.","",""
"245298428882452480","larsu2776","2022-05-18T00:17:54.3530000+08:00","I was able to run it through VPC and lambda function running it into an EC2 instance with Timescale DB.","",""
"745009912160976977","marioishikawa","2022-05-18T00:19:42.0540000+08:00","Good!","",""
"403511800068440074","rafaamaral","2022-05-18T09:48:18.0670000+08:00","This is the way","",""
"783917475128410112","geoffnunan","2022-05-20T08:49:54.6270000+08:00","Serverless has it's place for small, contained, asynchronous functions, but after seeing a lot of people struggle when their systems become more complex, I was interested to find the list of Serverless anti-patterns in the AWS documentation https://aws.amazon.com/blogs/architecture/mistakes-to-avoid-when-implementing-serverless-architecture-with-lambda/","",""
"403511800068440074","rafaamaral","2022-05-20T09:02:02.5660000+08:00","Great Article, thanks for sharing","",""
"976157728714129448","ravisubra","2022-06-01T00:47:39.7510000+08:00","We completely believe in avoiding vendor lock ins while ensuring that data is available for the Azure cloud in a secure, scalable and reliable manner. At the same time, we believe that through extensions, one should be allowed to take their data to other services that would allow you to integrate that with other applications of your choice. Here is some information on why one needs to under pin their Azure environment with a fully featured MQTT broker: https://www.hivemq.com/solutions/the-best-mqtt-broker-for-azure/","","👍🏼 (1)"
"798238402768142337","thavo007","2022-06-14T07:29:46.6960000+08:00","On the Azure side, we have also many architectures by Microsoft. But I like this non Microsoft one dedicated to IIoT, from Toon Vanhoutte, and I use it regularly : It gives an overview of what the Azure Industrial IoT could do.","https://cdn.discordapp.com/attachments/740336311671586968/986049775839363092/unknown.png?ex=68df0aea&is=68ddb96a&hm=aa003459b8fe6382aa63c0e38d0dda72b805401ee874f21469e55b5292d5665a&",""
"343075694903033857","michael.brown","2022-07-07T20:30:57.3530000+08:00","Just getting caught up on my news feeds - this caught my eye - AWS Greengrass now includes EMQX as its edge mqtt broker:
https://aws.amazon.com/about-aws/whats-new/2022/07/aws-iot-greengrass-mqtt-v5/","","👀 (1),emq (1),👍🏼 (2)"
"745009912160976977","marioishikawa","2022-07-08T03:20:35.3070000+08:00","More on low-code on Power Platform, now for Business websites https://powerpages.microsoft.com/en-us/","",""
"403511800068440074","rafaamaral","2022-07-08T03:51:07.9300000+08:00","Nice. I'm researching tools to build a partner relationship management portal. Havent found anything out of the box that I like yet so I'm looking at low code options. Will try this Microsoft option now. 
Anyone had to setup build a PRM?","",""
"894527802316046366","nickn5549","2022-07-08T13:29:38.4570000+08:00","I use PHPRunner https://xlinesoft.com/phprunner/ as a low code framework for almost everything. You can put together a solution pretty quickly if you have a spec in mind. If you need any help DM me.","",""
"783917475128410112","geoffnunan","2022-07-08T13:48:28.5490000+08:00","Would have thought you'd be going with Salesforce given the corporate direction","",""
"817835202746253344","IIoT#4707","2022-07-08T13:48:28.9030000+08:00","GG @GeoffNunan, you just advanced to level 7!","",""
"891563487241842699","jbonhage155","2022-07-27T13:36:08.2620000+08:00","https://youtu.be/BE77h7dmoQU","",""
"891563487241842699","jbonhage155","2022-07-27T13:37:17.1710000+08:00","This is a good watch. Is this the way things will go for manufacturing?","",""
"830193224504705035","marc.jaeckle","2022-07-27T15:32:26.3600000+08:00","We are already building Kubernetes based hybrid cloud platforms for our customers (with Kubernetes from the cloud to clusters in the plant to edge devices in the control cabinets). Some PLC vendors even already run Kubernetes on their PLCs like WAGO. Unluckily I only have a source link to a talk in German from the Building IoT conference: https://www.buildingiot.de/veranstaltung-13960-0-it-und-ot-verbinden--kubernetes-am-edge.html","",""
"794542235676180500","akoscs","2022-07-27T19:55:30.9240000+08:00","I am skeptical about real-time guarantees! It can be done, yes. Ist it fast, yes! Does it guarantee deterministic cyles times with low jitter? Here I am skeptical","",""
"830193224504705035","marc.jaeckle","2022-07-27T23:12:33.1840000+08:00","Actually in general Kubernetes makes it easier to guarantee certain resources because you can easily set CPU and memory limits. You just can't do overprovisioning of resources anymore then. Although I assume that they don't run the Codesys runtime via Kubernetes (k0s specifically). Still they probably had to pin k0s to a single core but I don't know how they handle the pods that k0s starts. Although I don't know what exactly WAGO does with k0s on the PLC. They probably use it to run non-realtime software with it like Node-RED and let you easily install additional software through some form of ""app store"" and deploy your own custom containers. Which is still a BIG advantage because then you don't need extra edge / gateway IPCs for this.","",""
"794542235676180500","akoscs","2022-07-27T23:20:13.7290000+08:00","Kubernetes and docker (and alike) try to reserve resources, but automation (PLCs, CNCs, Robot Controllers) are about guaranties on determinism with extremly small jitter. Docker and Kubernetes are far from being able to do this. Furthermor etheir networking concept is not well suited for real-time networks such as Profinet EtherCat, CanOpen is nearly impossible. You can add the preempt patch to bot the host system and the container but that still does not offer any guarantees when ising docker as there is another scheduler at play there. Pinning to a single core still does not offer guarantees. It might run, but it might just fail when you do not expect it. For non-real time applications it is OK","",""
"830193224504705035","marc.jaeckle","2022-07-27T23:24:16.9890000+08:00","That's why I'm assuming that they run Codesys separately and somehow managed to reserve cores and memory for it. Opto22 for example also lets you run your own docker containers on the PLC. Except that they just use the plain docker runtime.","","👍 (1)"
"867075936054149191","rickbullotta","2022-07-28T01:34:51.7190000+08:00","Have you seen: https://www.softwaredefinedautomation.io","",""
"830193224504705035","marc.jaeckle","2022-07-28T01:52:15.3560000+08:00","Yes, I even had a video conference with them a couple of weeks ago. It's pretty cool what they are building. Especially bringing continuous integration combined with splitting up the single project files into comparable parts in a git repo is pretty cool and brings modern software development practises to PLC development. The question is, if it is not too advanced for many in the industry. They will probably have to do a lot of explaining why these things make sense. This actually reminds me that a colleague of mine wanted to do an evaluation and give some feedback but I totally forgot to ask her about it 🙂","","💯 (1),👍 (1)"
"830193224504705035","marc.jaeckle","2022-07-28T01:57:28.1070000+08:00","The PLC IDE as a Service is also nice, especially as it makes sure that you always open the right IDE version for your project file 🙂 (I've never done PLC programming myself but this seems to be a common problem).","",""
"794542235676180500","akoscs","2022-07-28T03:08:53.5330000+08:00","Would be interesting to see their networking solution. On prem is just difficult, but cloud based 10ms guarenteed, always? I doubt that!","","💯 (1)"
"820097580665929808","pvmagacho","2022-07-28T08:47:28.9210000+08:00","I think trying to build a layer on top of existing PLCs vendors software is always complicated.
The other solution is not to use PLC or using something like PLCNext and try to follow open standards like OPAS https://www.opengroup.org/forum/open-process-automation-forum. My main objection against OPAS is that they want to use OPC-UA for **everything**. And they called it data bus, which OPC-UA (at the moment) doesn't have any real product to show for.","",""
"891563487241842699","jbonhage155","2022-07-29T05:57:49.7400000+08:00","Good article the Software Device Automation folks wrote:
https://www.linkedin.com/pulse/unchain-shopfloor-software-defined-automation-dr-dennis-kuesters/?trackingId=bVKHlnuBAAoDti5KUgysGA%3D%3D","",""
"891563487241842699","jbonhage155","2022-07-29T06:03:58.9660000+08:00","as long as you have a local store and forward capabilities on premise than anything possible in the cloud?!?! ha ha.","",""
"867075936054149191","rickbullotta","2022-07-29T07:14:53.9310000+08:00","What are you unfiltered/initial thoughts?","",""
"894527802316046366","nickn5549","2022-07-30T13:14:59.4940000+08:00","I dunno...too much cloud this and that...at this stage I digest better the UNS version of moving forward.","",""
"891563487241842699","jbonhage155","2022-07-30T13:24:30.3240000+08:00","Very impressed, they are 100% spot on. 

Just the idea of manufacturing trying to attract talent using outdated software/ programming languages. Why work as automation/industrial engineer when you work with the latest tech/software in another industry ?

Manufacturing is in much need a shock to the system and the ideas in the article is a solid start. Side rant: Also I’ve worked for 3 major manufacturing companies and executive level is always an IT person but never OT? OT group is a side thought off the plants and never properly represented at a corporate level. Totally insane for a manufacturing company. But shows the misdirected priorities of large manufacturing companies. 

Overall driving a tightly coupled plant floor to cloud link should be top priority. This can then start driving more talent into manufacturing and make it “cool”.. don’t see too many TV shows about manufacturing— certainly a lot more dumbass programming out there…..

We need to add #PLCTwin thread to this discord.","","💯 (1)"
"894527802316046366","nickn5549","2022-07-30T16:08:45.0690000+08:00","Why have to be cloud and not on-premises? That push is artificial and exaggerated...just for some to make money from XaaS. X -anything that you can think of...","","👍 (1)"
"830193224504705035","marc.jaeckle","2022-07-30T19:14:44.0130000+08:00","I think that you will still need some core functionality on the PLCs but it should be possible to move certain functionality to the cloud using a PLC Twin as in the sda solution (we probably shouldn't get into the discussion if a machine twin would make more sense). Btw in case of the sda solution, you also still need some edge device on prem on which part of their software runs and connects to the actual PLCs.","",""
"830193224504705035","marc.jaeckle","2022-07-30T19:16:29.9050000+08:00","In general I agree with the challenges they describe in their blog post and I love the McKinsey quote on the ""pilot purgatory"".","",""
"894527802316046366","nickn5549","2022-07-30T19:16:42.4050000+08:00","I see a mixed solution prem and cloud, but don't get the 100% cloud push...especially when internet connections are not even that good when you want to get near real-time stuff not delays and frustration","",""
"894527802316046366","nickn5549","2022-07-30T19:17:52.5700000+08:00","We've had MES on AWS and ended up bringing it back on-prem....internet in Australia is still patchy when you expect it to be snappy...","",""
"830193224504705035","marc.jaeckle","2022-07-30T19:25:00.5250000+08:00","Agreed, a 100% cloud approach won't work. Even at companies with good network connections, you still have quite a bit of latency and of course you won't get any realtime behaviour in the cloud even without considering the latency, although not everyone needs the realtime characteristics. It's also not completely uncommon that you have connection downtimes to the cloud, e.g. if some excavator hits a cable or if enterprise IT messes up networking. On top of it, almost no one wants to put the production critical automation part into the cloud and let that connect directly to production machines.","",""
"891563487241842699","jbonhage155","2022-08-03T04:13:13.0700000+08:00","Yeah it's strange but our company is definetly in the cloud push. I don't understand it, the c-suite must really like the cloud buzzword. We are currently testing a containizered MES on-perm and I'm hoping it will stay there, LOL","",""
"817835202746253344","IIoT#4707","2022-08-03T04:13:13.3300000+08:00","GG @Joe Bonhage, you just advanced to level 7!","",""
"891563487241842699","jbonhage155","2022-08-03T04:14:15.8100000+08:00","so maybe an MES can live it a cloud? (Just not a SCADA?) Dunno, but I'm about to find out.","",""
"891563487241842699","jbonhage155","2022-08-03T04:26:28.0690000+08:00","Maybe cloud and containerization are being mixed up? (being containerization could be good and cloud bad?) 
Adding some sort of DevOps pipeline to IIoT world might be good... I'm only guessing here but things might be going that direction?","",""
"894527802316046366","nickn5549","2022-08-03T12:01:41.4640000+08:00","Our IT is still against it...so I'm not pushing","",""
"867075936054149191","rickbullotta","2022-08-03T18:35:59.2720000+08:00","They’re actually becoming symmetric so that workloads can be moved anywhere up and down the network from cloud(s) to edge(s).","","👍 (1)"
"795178288330440704","youri.regnaud","2022-08-04T01:37:31.9290000+08:00","DevOps or DevSecOps I should not be an option, but a fondation of any IIoT architecture. By DevOps I mean version control, configuration as code, infrastructure as code, full monitoring… from edge to cloud.    Maybe IndusDevSecOps can be a new « buzz world » 🙂","","👍 (1)"
"830193224504705035","marc.jaeckle","2022-08-04T17:46:58.2760000+08:00","Absolutely, both SCADA and MES systems can live in the cloud. You just can't move the real-time automation part (especially when it's safety critical) to the cloud.","","💯 (1)"
"867075936054149191","rickbullotta","2022-08-04T22:04:29.4480000+08:00","I personally would never place a primary HMI in the cloud.  Never.  Ever.  I consider that part of the ""real-time automation"" and ""safety critical"" systems. WDYT?","",""
"745796393855352953","thedavidschultz","2022-08-04T23:37:15.1900000+08:00","I am good with primary HMI in cloud so long as there is a local HMI that will support operations on prem. Ignition 8.1.8+ supports failover to local project. 4IR goes about this with a 0-chassis EPIC running Ignition locally supporting the main instance in Azure of AWS running Ignition and Sepasoft.","",""
"867075936054149191","rickbullotta","2022-08-04T23:45:18.7850000+08:00","I don't see the benefit, TBH","",""
"867075936054149191","rickbullotta","2022-08-04T23:45:30.6230000+08:00","All risk, no reward. 😉","",""
"745796393855352953","thedavidschultz","2022-08-04T23:46:04.7970000+08:00","Limits the amount of on-premise hardware. And it's cloud 😀","",""
"830193224504705035","marc.jaeckle","2022-08-05T03:02:41.9150000+08:00","In most cases I probably also would not put it into the cloud, especially when it comes to safety critical stuff. If you think about the tablet of a KUKA robot, you even have to keep pushing buttons underneath the tablet so not everything stops while you make changes to the arm movements. In general it's nice to have the absolute production critical stuff on prem that you need to keep things running (or at least be able to start it on prem as well) but since you are depending more and more on things that are in the cloud this becomes more and more difficult. I guess I should also be specific regarding SCADA systems / functionality: In many cases it's also not really an option to put a SCADA system that comes with a machine into the cloud unless it's been built for that because those often use protocols that don't allow to put it in the cloud (and OPC UA C/S is the best case, more likely some obscure TCP socket based self-defined protocol no one has ever heard of).","",""
"794020366536146977","mparris","2022-08-07T02:12:08.7780000+08:00","My criteria:  Will the plant care if this function disconnects?  If not, cloud can be an option.

The plant depends on many functions that, technically, are not required for the process to run. That still doesn't mean that it's not important.

I think read-only HMIs available outside the plant are useful... Although at that level, the information would typically be aggregated into different views","",""
"867075936054149191","rickbullotta","2022-08-07T02:17:26.9440000+08:00","As always, “AND” not “OR”","",""
"794020366536146977","mparris","2022-08-07T02:20:33.4120000+08:00","Graceful degradation is the key. Working with an efficient techstack 95% of the time, with a crippled but still functional fail-over seems to be the right strategy","",""
"867075936054149191","rickbullotta","2022-08-07T02:26:33.3190000+08:00","5% in degraded mode seems high to me.","",""
"867075936054149191","rickbullotta","2022-08-07T02:28:00.9400000+08:00","I would think 0.5%.  That’s more than a full day in a 3 shift operation.","",""
"894527802316046366","nickn5549","2022-08-07T10:54:08.8870000+08:00","How much do you pay for 'Cloud' per month for a Site? All my calculations give me a starting point of 1.5K USD/ month for an SMB","",""
"917925131261718558","jpmoniz","2022-08-09T07:27:00.0030000+08:00","This is why we are deploying hybrid with prod on edge and DEV and QA in cloud.  Just getting everyone talking about architecture now but should be interesting in a few months.","",""
"519666539436310529","aristotelestn","2022-08-17T22:16:15.5740000+08:00","Which MQTT in Cloud do you guys recommend from the point of view of cost, performance and ease of scalability? In MQTT on Edge I'm using HiveMQ (Free). The cloud I use is Azure, I have already analyzed the Azure IoT Hub but when I scale it is very expensive.

Would AWS IoT Core be significantly cheaper than IoT Hub or would it be the same cost when I scale?","https://cdn.discordapp.com/attachments/740336311671586968/1009465689670688909/DMZ_Example.png?ex=68df31ef&is=68dde06f&hm=621d093923a6563ad3554ca51edf3f54ab02de371eef18a060cf6178330db6bd&",""
"685857538096234546","plcmercenary","2022-08-17T22:42:20.3670000+08:00","@AristótelesTN  Where are you trying to get your data? It is only recently that I attempted to use IoT Hub in Azure and it was a difficult integration (spoken shit sammich lunch at a royal f**k show). That is likely due to my own ignorance and lack of experience with the product. I have run mosquitto brokers and clustered verneMQ free license brokers on amazon compute instances for years at a time with 0 problems. And I have used either a py script or lately telegraf running on those EC2 compute VM's to shove message data into an amazon RDS, Dynamo, or InfluxDB (again running on an EC2 machine on the same vps), and even from a cloud broker to a local Timescale DB using Nodered and Prometheus.","",""
"817835202746253344","IIoT#4707","2022-08-17T22:42:20.6680000+08:00","GG @plcmercenary, you just advanced to level 3!","",""
"867075936054149191","rickbullotta","2022-08-18T00:37:42.2510000+08:00","@plcmercenary and @AristótelesTN - pro tip: don't use IoT Hub, use IoT Central.  Sometimes it's actually even better pricing, and you get a LOT more functionality, in a much easier to use way.  And now there are lots of APIs and hooks so you can do anything you could do with IoT Hub, just a whole lot easier.","",""
"830193224504705035","marc.jaeckle","2022-08-18T01:04:52.3000000+08:00","@AristótelesTN Also, IoT Central makes scaling much easier. You just need to be fine with using shared infrastructure. Just make sure that you don't treat it as a complete IoT solution. It only stores telemetry data for 30 days and has other limitations so you will have to forward data for example to EventHubs and process/store it from there. Forwarding to EventHubs is one of the features of IoT Central, if I remember it correctly. If you just want an MQTT broker and want to use a managed service, HiveMQ Cloud might be an option. Depending on your requirements the free tier might even be an option (but it's also shared infrastructure). As the HiveMQ Community Edition does not support bridging to another broker, you will also need a service that forwards messages between the two brokers. Maybe @Jermuk has an OpenSource one laying around.","",""
"867075936054149191","rickbullotta","2022-08-18T01:05:59.5880000+08:00","They've added a bunch of new stuff to CDE (continuous data export) to make it even easier to archive your history data in an easy to access way.","","👍 (1)"
"277515221885779970","jermuk","2022-08-18T01:26:07.9650000+08:00","Interesting graphic 😄 hope you did find that on learn.umh.app and not somewhere else 😄","",""
"277515221885779970","jermuk","2022-08-18T01:26:23.9990000+08:00","https://github.com/united-manufacturing-hub/united-manufacturing-hub/tree/main/golang/cmd/mqtt-bridge","","👍 (1)"
"519666539436310529","aristotelestn","2022-08-18T02:15:18.9230000+08:00","Yes! I took this image from your article to illustrate my question 😁 . It was reading the article that I remembered to consult colleagues here on discord.","",""
"519666539436310529","aristotelestn","2022-08-18T02:16:47.9120000+08:00","Thanks for the tip, I'll use the calculator to see the difference in values. I'm currently considering uploading the highbyte information to the event hub directly.","","👍🏼 (1)"
"519666539436310529","aristotelestn","2022-08-18T02:39:18.0120000+08:00","From the edge, I am building a UNS structure with support from Mario Ishikawa and also building a local big data using timescale and custom cassandra with a local partner, which will store my data at the edge (contextualized from UNS and IIoT/Process raw data) and then I replicate this data for my data lake and I govern both big data at the edge and data in the cloud using Azure Purview.","",""
"519666539436310529","aristotelestn","2022-08-18T02:49:10.3600000+08:00","Good informations, I will check. If @Jermuk could help with this informations which bridge or other opensource solution, so i can use between HiveMQ Community with Cloud MQTT Broker.","",""
"685857538096234546","plcmercenary","2022-08-18T09:42:39.4650000+08:00","@RickBullotta  Interesting.. IoT central was not ever mentioned as an option on that project and its for M$. Microsoft and UW Vancouver students are the stakeholders. I was asked to build code or construct a way to get to IoT hub. so i did. Actually they are showing this project off on the Redmond Campus this month and doing some promo videos for ""airband"" and the ""nomad trailer""","","👍🏼 (1)"
"277515221885779970","jermuk","2022-08-18T15:05:45.7990000+08:00","I posted the source code to our self-written mqtt bridge. It is also available as a docker container. https://docs.umh.app/docs/developers/united-manufacturing-hub/mqtt-bridge/ (the documentation)

It is an older piece of software, however, we found that it was more reliable than other open source mqtt bridges.","",""
"685857538096234546","plcmercenary","2022-08-19T00:48:18.5640000+08:00","What is the the benefit of hive or emq or any other managed broker VS running a broker on a VM in the main company VPS? Scaleability? throughput? what is the value driver?","",""
"867075936054149191","rickbullotta","2022-08-19T06:07:21.7130000+08:00","You don’t need to take phone calls at 3am Saturday night.","","👍 (1)"
"830193224504705035","marc.jaeckle","2022-08-19T15:11:52.0970000+08:00","You probably still do because if something goes wrong, the first thing people blame is the broker / connectivity 🙂 I can almost hear it: ""There is a problem with HiveMQ Cloud. We don't get any messages. We have to call Marc who's in charge of connectivity"". Of course in the end it turns out it was something completely different like Paho thinking it's still connected but the services are not getting messages anymore.","","😂 (1)"
"958012184263274606","cproch","2022-08-19T21:13:58.1640000+08:00","I am interested if someone actually using the Google IoT Core. The outcry seems to be big, but from the discussion it seems that many people rely on other solutions (e.g. AWS). 

What is your experience with this?","",""
"867075936054149191","rickbullotta","2022-08-19T23:55:54.1830000+08:00","I spoke with someone involved - not a lot of usage.  One large user with a couple hundred thousand low value devices connected.","",""
"830193224504705035","marc.jaeckle","2022-08-21T16:39:50.9940000+08:00","I think the outcry is this big because it shakes the trust into cloud provider specific / proprietary solutions. Also, as some companies did not implement remote software update solutions and failed to implement a platform based approach for device software (i.e. the good old hardware abstraction layer) that lets them easily update existing devices, this has a larger impact compared to when a backend-only offering is being retired. Also Google did a really bad job at communicating it and didn't give customers any officially supported way forward (e.g. through a partner that offers compatible APIs).","",""
"894527802316046366","nickn5549","2022-08-22T15:45:52.8190000+08:00","in the last few weeks, I got hundreds of attempts to hack by WordPress blog from Microsoft registered IP addresses - more precisely Azure Cloud...reported the issue to Microsoft see if they come up with a satisfactory answer...How many scripting 'kids' are using the cloud for no good?","",""
"876880919988957205","ryankershaw","2022-08-22T21:08:23.5100000+08:00","This is something that needs to be taken into account with any application where a company is handing off control, and we are seeing many of these new models come up in I4.0.  Cloud as you mentioned, but also other XaaS services, gig-type employees, and other ones where services are replacing historically capital projects.  There's definitely an advantage in using these types of services, for instance the ability to limit capital spending and the access to specialization, but there are significant risks, and a loss of control on how and when a product/service is sunsetted is way up there.","",""
"830193224504705035","marc.jaeckle","2022-08-22T22:11:01.4110000+08:00","A good way to reduce the dependency on a vendor / cloud provider is to use managed solutions that are based on open standards (e.g. HiveMQ Cloud) or managed solutions that are based on OpenSource products (e.g. AWS RDS for PostgreSQL) or offer OpenSource quasi-standard APIs (e.g. Azure EventHubs offers Kafka API). The problem is that for many parts of an (I)IoT platform there are no usable solutions based on open standards (e.g. never met anyone using LWM2M over MQTT for device management) and no complete OpenSource solutions*, even less so managed solutions based on open standards / OpenSource solutions only. Of course you can build your own solutions on top of OpenSource tools but these OpenSource tools are no integrated, complete end-2-end solutions.

* @Jermuk might disagree 🙂","","👍 (1),😆 (1)"
"867075936054149191","rickbullotta","2022-08-22T22:50:49.4470000+08:00","False equivalence, Marc.  An MQTT broker is not functionally comparable to most vendors' IoT clouds, which include device management, software updates, edge management, data storage, and other features.","",""
"830193224504705035","marc.jaeckle","2022-08-22T22:53:18.8530000+08:00","That’s exactly what I tried to say with the second half of the post. There are currently no open standards based solutions or OpenSource based solutions that provide an end-to-end IoT/IIoT platform. There are only single building blocks that you can use to build something yourself.","","💯 (1)"
"1014766146936897548","mattcurnow","2022-09-07T18:38:30.6730000+08:00","I have a question regarding Google vs Ignition….i see in Google you can use MQTT, load a device into ioT Core, use Pub Sub and Big Query….and was wondering whether this was suffice to use as a UNS, building all tags and context etc","",""
"867075936054149191","rickbullotta","2022-09-07T20:36:58.6910000+08:00","https://thestack.technology/google-cloud-iot-core-retired-killed-by-google/","",""
"1014766146936897548","mattcurnow","2022-09-10T12:20:53.8430000+08:00","Wasn’t aware Rick / thanks for the info","","👍🏼 (1)"
"691362618681589860","keerthana7778","2022-09-14T12:24:46.2030000+08:00","anyone worked with this?
https://www.dcvelocity.com/articles/51182-uptake-partners-with-inductive-automation-with-new-cross-platform-capabilities","",""
"801567220764639273","bryanymack","2022-11-07T19:22:53.5600000+08:00","Has anyone any experience pulling data from an AWS Kinesis stream and forwarding the data to a mqtt broker? Kafka connect has been put on the table but I am in unfamiliar territory. Any help much appreciated 👍","",""
"867075936054149191","rickbullotta","2022-11-07T21:41:20.5240000+08:00","""Uptake"".   LOL.","",""
"691362618681589860","keerthana7778","2022-11-12T00:27:22.0360000+08:00","please explain the LOL 😂","",""
"867075936054149191","rickbullotta","2022-11-12T01:04:42.3910000+08:00","Industrial software from the team that gave us Groupon...","",""
"898217314741280828","hobbes1069","2022-11-12T02:14:33.0230000+08:00","I bought a Groupon for a massage for a gift like 5 years ago. I still see it in every email they send me... Not leveraging ML very well are they?","","🤣 (1)"
"812295088348200960","patanj2","2022-11-15T07:31:48.3530000+08:00","Typically it would be the other way around,  mqtt to kinesis either for buffering for writing data to a data lake or for doing stream analytics.","",""
"691362618681589860","keerthana7778","2022-11-16T12:38:40.3740000+08:00","I’m Actually interested in this question too","",""
"908341993820811295","chris.demers","2022-12-08T06:20:36.7760000+08:00","One of the things that comes up often both in some of Walkers videos and in discussions I’ve had internally is that simply sending our data to the cloud for storage will be “too expensive”.  Does anybody have any first hand account of this? Because if I ask our enterprise/cloud team they tell me that moving about 500GB of data a week to the cloud or 27TB a year  only ran them about $4000 for the year. They clarified that at any given moment they had 3TB stored due to retention policies. Which seems like (A) far less than the amount of data a smaller site would generate in historian data and (B) far cheaper than any historian offering.

The skeptic in me though makes me wonder whether number is the full picture","",""
"867075936054149191","rickbullotta","2022-12-08T07:10:08.2380000+08:00","That totally depends on *how* you ingest it and *where* you store it.  Ingesting it directly into blob stores is indeed quite cheap.  Ingesting it via IoT clouds into time series data stores, the numbers add up.","",""
"908341993820811295","chris.demers","2022-12-08T07:13:21.7840000+08:00","Ok good that’s exactly the answer I’m looking for - because this is the proposal basically to lay down Azure IoT Edge virtual machines, which could run either native Microsoft tools or Ignition as a container. And that’s how we would connect to field devices. But I can’t seem to get enough information to be able to ballpark a figure for this cost - and it’s probably intentional.","",""
"817835202746253344","IIoT#4707","2022-12-08T07:13:22.3150000+08:00","GG @chris.demers, you just advanced to level 4!","",""
"867075936054149191","rickbullotta","2022-12-08T07:57:40.5460000+08:00","If you're committed to the Azure IoT stack, take a look at IoT Central pricing - it can save a lot of money for some people.","",""
"867075936054149191","rickbullotta","2022-12-08T07:58:18.8120000+08:00","Azure IoT Central itself is apparently going to morph into something else over time, but I'm sure there will be a clear and easy migration path.","",""
"338464168229339144","itami0432","2022-12-09T01:04:56.9920000+08:00","any idea on how to get free AWS credits for some educational purposes","",""
"338464168229339144","itami0432","2022-12-09T01:04:59.9570000+08:00","i have a school email","",""
"877250462737387570","jere1128","2022-12-09T18:44:35.3830000+08:00","Try this..
https://pages.awscloud.com/GLOBAL_NCA_LN_poc-program-2022.html?trk=ea7da5bb-5b3a-4d90-9416-29eb67ad2d08&sc_channel=em","",""
"571815818308878347","binyameen_980","2022-12-11T17:53:45.6810000+08:00","Have you heard about Anacode (https://www.anacode.io/) ? I heard about it in a podcast. Apparently they performs 1:3 lossless compression which is same AWS preforms to optimize its storage. CEO claimed that AWS makes around 2B profit annually just by compressing the data.","",""
"571815818308878347","binyameen_980","2022-12-11T17:54:19.0370000+08:00","@chris.demers","",""
"867075936054149191","rickbullotta","2022-12-11T21:40:06.2270000+08:00","That generally won't help with ingesting data into cloud IoT platforms in most of our typical use cases (though it can if you're just sending opaque payloads).  And storage itself is very cheap.  Also, many protocols already support zipping and other compression as an option.  For the example Anacode gives, log files, it makes sense - though I suspect almost any mainstream compression algo would perform well.  Also, compression isn't free - it requires CPU.  On constrained devices,  that could be a challenge/tradeoff.","","💯 (1)"
"898217314741280828","hobbes1069","2022-12-12T21:23:53.2900000+08:00","Not really new anyway. Most linux distros now do on the fly compression if using BTRFS (and maybe a few others). Fedora defaults to zstd:1 for SSDs and zstd:3 for spinning disks. There's probably a slight decrease in performance of SSDs but compression helps reduce the overall writes and improves drive life. For spinning disks it actually speeds up a system with decent CPU because I/O is so constrained.","","👍🏼 (1)"
"794542235676180500","akoscs","2022-12-13T04:56:53.1450000+08:00","You are better of taking IoT Hub pricing. IoT central is built on IoT hub. The table does not include storage cost, just traffic.","https://cdn.discordapp.com/attachments/740336311671586968/1051965891434258472/image0.jpg?ex=68dee715&is=68dd9595&hm=40f742b90a6beedcd8b84d474791c91c44e891c6c7f97c84bc2982806aa60c0a&","👍 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:02:44.5920000+08:00","Respectfully disagree.  For many people it will be more cost effective overall.  And it does (if I recall correctly) include some period of historical data storage.  With CDE (continuous data export) you can easily use blob storage to have ultra cheap long term data retention in any analytics-friendly format.","",""
"794542235676180500","akoscs","2022-12-13T05:06:17.8750000+08:00","Here is the IoT central pricing","https://cdn.discordapp.com/attachments/740336311671586968/1051968260008054864/image0.jpg?ex=68dee949&is=68dd97c9&hm=3fd6640fedc96a98c229d1ca838c1566910d5c0b0ea02bca51748a47fed95767&",""
"867075936054149191","rickbullotta","2022-12-13T05:11:22.0190000+08:00","Yup.  Well aware of it.  IoT Central unburdens developers from a lot of the crap that they'll need to write code for, manage manually or with code, or pay for other Azure services to do.  IoT Central has come a long way in the last 24 months.  I think you need to look at the total cost of implementing and operating the solution, and in many cases, particularly for fleets of devices, IoT Central has a big advantage.  For IIoT (e.g. bringing factory data to the cloud), IoT Hub adds very little value IMO.  I would just write the data from the edge to the endpoint (storage, messaging, whatever) that you need in that case.  Software developers are expensive! 😉","","👍 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:13:31.2350000+08:00","I will add that at some point there will almost certainly be a ""grand convergence"" of IoT Hub/DPS, Azure Digital Twins, Azure IoT Central, and some other capabilities and tooling, so these are all just steps along the way.

My new Keurig coffee machine connects through IoT Central, for what that's worth! ☕ 

What are your primary use cases for IoT Hub/etc?","","👍 (1)"
"794542235676180500","akoscs","2022-12-13T05:14:54.5790000+08:00","IoT Hub per message price is way cheaper then IoT Central. I was not aware tou are talking about overal dev cost, the question was refering to traffic cost to be frank… when taking overal dev cost…i have to admit, IoT central was so limited that I immediatly skipped it.","","💯 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:17:48.7490000+08:00","Ah - for sure.   Raw Azure costs, much lower.  Total cost to operate/implement, that's a use case specific consideration.  

Two years ago there's no way I would have recommended or used IoT Central.  I was hopelessly lacking in APIs and extensibility, and was more of a ""demo"" platform than a production grade platform.  That has changed considerably.","",""
"867075936054149191","rickbullotta","2022-12-13T05:20:44.9460000+08:00","https://learn.microsoft.com/en-us/rest/api/iotcentral/","",""
"867075936054149191","rickbullotta","2022-12-13T05:20:53.6990000+08:00","Also here's the historical data query:

https://learn.microsoft.com/en-us/azure/iot-central/core/howto-query-with-rest-api","",""
"867075936054149191","rickbullotta","2022-12-13T05:21:23.9730000+08:00","There are APIs also to autoconfigure IoT Central if you have object models and device info from some other system(s).","",""
"794542235676180500","akoscs","2022-12-13T05:21:34.2630000+08:00","The grand convergence cannot come soon enough. You cannot even access the underlying IoT Hub in IoT central (hints to this are ongoing since the begining). I did a comparison for a client for different IoT related stuff and IoT Hub is in my opinion the best option (obviously not tageted as SaaS, like many others, somw of which you mention sometimes). I admit I am an Azure fanboy also. I used it to aggragate factory data and energy consumption data. But I wrote the containers running on the edge, again not a SaaS type offering and that is why I like it for my usecases.","","👍🏼 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:22:10.5630000+08:00","I really wish IoT Central had used Azure Digital Twins, but unfortunately they were under simultaneous (and parallel) development - a problem that both Microsoft and AWS seem unable to address.","",""
"867075936054149191","rickbullotta","2022-12-13T05:23:38.2390000+08:00","With the IoT Central APIs and various declarative routing hooks now, you don't need to get to the underlying IoT Hub at all.  It also allows some voodoo (if I recall correctly) where you might even have geodistributed IoT hubs transparent to the user/developer.","",""
"794542235676180500","akoscs","2022-12-13T05:25:29.4110000+08:00","I whish I had project where I need geo-replication :))","","😂 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:25:43.8290000+08:00","Also, I just checked and the built-in data retention period is still 30 days for historical/time series data.  At one point, that used to be in Time Series Insights, but now it's in Azure Data Explorer/Kusto.","",""
"794542235676180500","akoscs","2022-12-13T05:28:32.8850000+08:00","Also, you should get a real coffe machine…","","🤣 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:31:53.9990000+08:00","I had a DeLonghi and a Moccamaster and got rid of them for this Keurig.  It makes a great cup of coffee!  So much better than the basic Keurigs.  Decent frother too.  Here's the one I got:

https://www.keurig.com/Home-Coffee-Makers/K-Cafe%E2%84%A2-SMART-Single-Serve-Coffee-Maker/p/K-Cafe-SMART-Coffee-Latte-Cappuccino-Maker#Black_color?&&utm_source=google&utm_medium=cpc-ecomm&utm_campaign=Search_Brand_BrandSupport_GeneralMarket_K-Caf%C3%A9&utm_term=keurig%20k%20caf%C3%A9%20smart&gclid=Cj0KCQiAmaibBhCAARIsAKUlaKT1HfBZADW_0UqRmmbl1CFMBgwkW2NmFelz6OBFy0mGzKqFcaZzSkUaAmSpEALw_wcB&gclsrc=aw.ds?&&utm_source=google&utm_medium=cpc-ecomm&utm_campaign=Search_Brand_BrandSupport_GeneralMarket_K-Caf%C3%A9&utm_term=keurig%20k%20caf%C3%A9%20smart&gclid=Cj0KCQiAmaibBhCAARIsAKUlaKT1HfBZADW_0UqRmmbl1CFMBgwkW2NmFelz6OBFy0mGzKqFcaZzSkUaAmSpEALw_wcB&gclsrc=aw.ds","",""
"794542235676180500","akoscs","2022-12-13T05:34:01.5370000+08:00","I figured it is something like this. The only other discord server I am participating in is about reverse engineering jura coffe machine comms. 🙂","",""
"867075936054149191","rickbullotta","2022-12-13T05:35:13.3690000+08:00","Oh, now you're gonna make me obsessed about capturing the Keurig API....","",""
"794542235676180500","akoscs","2022-12-13T05:35:31.6720000+08:00","Start the discord server!","","💥 (1),☕ (1),🔌 (1)"
"867075936054149191","rickbullotta","2022-12-13T05:37:37.7820000+08:00","Here's a video with some folks I know describing how they utilized IoT Central for the Keurig system:

https://techcommunity.microsoft.com/t5/internet-of-things-blog/keurig-s-connected-smart-coffee-brewers-enabled-by-azure-iot/ba-p/2952499","",""
"794542235676180500","akoscs","2022-12-13T06:44:43.5830000+08:00","I did not expect to be able to take azure devops releases and make an OTA firmware update on the device. That is nice!","",""
"571815818308878347","binyameen_980","2022-12-14T02:58:06.9540000+08:00","Ah Got it. Thanks","",""
"794020366536146977","mparris","2022-12-16T09:40:51.6500000+08:00","Just as the market needs a product like Kepware as a Device Gateway (swiss army knife of device protocols), while the market awaits the ""great convergence"" of pub/sub protocols 🙄, architectures should deploy Cloud Gateways (Swiss army knife of cloud information modeling).

What say you?","","👍 (1)"
"867075936054149191","rickbullotta","2022-12-16T22:52:52.3580000+08:00","I personally wouldn't use an IoT cloud stack for factory use cases.  Completely different scenarios IMO.  Something like Azure Digital Twins would be better.","",""
"798238402768142337","thavo007","2022-12-27T04:06:40.9830000+08:00","IoT Central is great, cheap and easy to use... There's PLEINTY of advantages (I got the chance to provide the first training for Microsoft few years back), But their 's a but :

1) you need to model your device as Azure Digital Twin to enable Plug and Play : its a good thing, however it's not easy to model your device(s) as few JSON files (unless you use an already made DTDL JSON device : Advantech,...) . 

2) Also if you want to perform Azure Direct Methods from IoT Central (that is Command & Control) , it's not really user friendly for a true end user(*) 

3) the reports are really limited 

(*) Note : remember we are in a factory domain, some people hate IT and any micro non user friendly GUI will be an excuse for not using the solution...","",""
"867075936054149191","rickbullotta","2022-12-27T04:14:05.6340000+08:00","Realize that these will all converge in the next year or so as Azure IoT Hub/Azure IoT Central/Azure Digital Twins become a more unified platform.  Also, with IoT Central you can of course author your DTDL without writing any JSON.  I would also add that I do not consider IoT Central the appropriate platform to build an end user interface.  It's helpful for diagnostics and basic monitoring, but I would use some other environment for building the UX on top of IoT Central or ADT.  You could even consider using PowerApps in some cases.","","👍 (1)"
"891563487241842699","jbonhage155","2023-01-27T15:20:37.8560000+08:00","Anyone use AWS route 53 latency monitor? We are standing up a cloud based MES and was thinking of using it for monitoring networking performance on API/endpoints (ERP/middleware, Ignition, printing, etc...)

https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/monitoring-health-check-latency.html","",""
"891563487241842699","jbonhage155","2023-02-01T14:23:03.4260000+08:00","Anyone hosting their MES/web app in AWS/Azure? I'm curious to how you handle connections on front and backend of the load balancers?
We found having too short of an idle connection timeout causes the client/server to go into retransmission (via wireshark) which causes slowdown to the users.
https://docs.aws.amazon.com/elasticloadbalancing/latest/application/application-load-balancers.html#connection-idle-timeout","",""
"898217314741280828","hobbes1069","2023-02-02T01:42:42.9640000+08:00","Not sure of their architecture, but Tulip seems to have this figured out. Performance is pretty good and stable.","",""
"898217314741280828","hobbes1069","2023-02-02T01:42:52.1850000+08:00","They use AWS","",""
"891563487241842699","jbonhage155","2023-02-02T04:37:30.3800000+08:00","Yeah they are not going to tell me 🤣","",""
"891563487241842699","jbonhage155","2023-02-02T04:38:37.7460000+08:00","For Tulip, you don’t see any of the web host / AWS part right? They make it work and give you the URL?","",""
"891563487241842699","jbonhage155","2023-02-02T04:39:38.5130000+08:00","Mine is the DYI MES, kinda","",""
"891563487241842699","jbonhage155","2023-02-02T04:42:54.2790000+08:00","If you ever do have slowness on a client, open up wireshark and filter traffic between client/server, you will see TCP retransmission flags if it’s a port negotiation issue","",""
"898217314741280828","hobbes1069","2023-02-02T05:11:18.4040000+08:00","Exactly. They setup a cloud instance on your behalf.","",""
"898217314741280828","hobbes1069","2023-02-12T09:27:53.2120000+08:00","I've got a lot to learn about ""The Cloud"" but pretty much all modern Linux distros support disk level compression via zstd which is optimized for low CPU overhead. The default compression level on Fedora is 1 for SSDs because they're already fast, but compressing means less writes, and 3 for spinning disks (the level goes up to 9 I believe). Interestingly the decompress speed is the same regardless of compression level.","",""
"898217314741280828","hobbes1069","2023-02-12T09:29:00.7690000+08:00","I would be surprised if tech like this already isn't in widespread use in ""The Cloud"".","",""
"867075936054149191","rickbullotta","2023-02-12T10:39:55.9760000+08:00","Unfortunately they typically need the data in a JSON format.","",""
"898217314741280828","hobbes1069","2023-02-12T20:07:05.9460000+08:00","Which should be highly compressible. The file system based compression is effectively transparent to the operating system.","","💯 (1)"
"794542235676180500","akoscs","2023-03-19T05:07:23.6290000+08:00","I am looking to get info from an MQTT capable client onto dashboard, completly by SaaS tools. My first choice was Grafana as dashboard (as Grafana Cloud is SaaS). InfluxDB (as InfluxDB Cloud is SaaS) was my next element in the stack. I knew I needed a broker, HiveMQ has a cloud broker as SaaS. So far so good, but I forgot (well I just never knew I guess), that Telegraf is not included in the InfluxDB cloud offering, so I cannot connect the MQTT broker to InfluxDB. At least this is my understanding. Did I understand correctly, that Telegraf is not part of InfluxDB Cloud?

I can go down the Azure route with IoT Hub -> use it as an MQTT Broker -> Azure Stream Analytics -> SQL -> Grafana/PowerBi, but I want to explore alternatives to be able to use InfluxDB. Does anyone know how to get MQTT data into Influx without self hosting anything?","",""
"1031940518730543106","thunt.career","2023-03-20T00:34:45.8410000+08:00","Does this fit the bill? https://www.hivemq.com/blog/mqtt-influxdb-native-integration-hivemq-broker-aws-cloud/","",""
"794542235676180500","akoscs","2023-03-20T03:19:52.1500000+08:00","This would be exactly what I need, however...I cannot actually find anything about this. Influx Documentation on this returns 404 https://docs.influxdata.com/influxdb/cloud/write-data/no-code/native-subscriptions/","",""
"1031940518730543106","thunt.career","2023-03-20T03:34:49.3710000+08:00","I just created a test instance and I'm not seeing it either.","",""
"817835202746253344","IIoT#4707","2023-03-20T03:34:49.6630000+08:00","GG @Travis Hunt, you just advanced to level 5!","",""
"1031940518730543106","thunt.career","2023-03-20T03:45:29.1410000+08:00","@akos joined the InfluxDB slack and found this.","",""
"1031940518730543106","thunt.career","2023-03-20T03:45:36.2340000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/1087099575678013560/Screenshot_20230319_144501_Slack.jpg?ex=68df7f20&is=68de2da0&hm=75e20eba3f78ed0db1614cfbceb2c2936a93d4d3abc1bb27506c2ab664b1ffe5&",""
"1031940518730543106","thunt.career","2023-03-20T03:48:24.1840000+08:00","Weird that it basically went silent after Oct 2022 with no public announcement they were putting it on hold.","",""
"794542235676180500","akoscs","2023-03-20T03:52:38.8790000+08:00","😦","",""
"794542235676180500","akoscs","2023-03-20T03:53:38.2190000+08:00","Guess there is no way around self hosting telegraf....","",""
"1031940518730543106","thunt.career","2023-03-20T04:05:14.4710000+08:00","Looks like you might be able to do it with EMQX Cloud","",""
"794542235676180500","akoscs","2023-03-20T04:11:41.2600000+08:00","Did not know this, yes it seems you can! Thanks a lot! The only small caveat is the price, you need the  dedicated professional package, about  250 USD per month!","",""
"867075936054149191","rickbullotta","2023-03-20T19:54:38.9120000+08:00","You can likely run it on a free sized instance though.","",""
"794542235676180500","akoscs","2023-03-20T20:14:00.5690000+08:00","Free instance? Where?","",""
"867075936054149191","rickbullotta","2023-03-20T22:30:33.9040000+08:00","T2 or T3 micro instances on AWS.","",""
"867075936054149191","rickbullotta","2023-03-20T22:30:48.8930000+08:00","https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all","",""
"794542235676180500","akoscs","2023-03-21T02:01:00.4530000+08:00","Enjoy these offers for 12-months following your initial sign-up date to AWS  😐","",""
"817835202746253344","IIoT#4707","2023-03-21T02:01:00.6860000+08:00","GG @akos, you just advanced to level 14!","",""
"794542235676180500","akoscs","2023-03-21T02:02:17.7770000+08:00","There is no always free VM, or container","",""
"867075936054149191","rickbullotta","2023-03-21T08:02:06.2060000+08:00","Sure there is. 750 free hours a month of T2 or T3 micro?  744 hours in the longest month. I think you’re good.","",""
"867075936054149191","rickbullotta","2023-03-21T08:04:19.6160000+08:00","Cmon man. I know you know how to create Gmail accounts! Telegraf.2023, Telegraf.2024…","",""
"794542235676180500","akoscs","2023-03-21T08:33:25.9410000+08:00","Can I? Yes! Will I do this every year for the next 20 years? Nope! An it is not just a choice, I might get hit by a bus. I know that the rest os the solution will not survive 20 years, but still.","","😂 (1)"
"867035383509024778","mattmigchelbrink","2023-03-21T21:56:21.6820000+08:00","use the + sign trick and you can use the same gmail for multiple accounts; myemail+2022prod@gmail , myemail+2022dev@gmail","","👍🏼 (2)"
"603301251177775104","asthomas","2023-03-22T03:46:47.8340000+08:00","You might want to look at https://skkynet.com/microsoft/.  It's pay-as-you-go through your Azure subscription with built-in MQTT broker, InfluxDB and Grafana.  You just configure it and then send your data.","",""
"972180596166115328","luismiguelbp","2023-03-24T05:30:11.7640000+08:00","Hey, Oracle Cloud have Free Tier, and you can create 2 free VM instances, it's a good option.","","👍 (2)"
"794542235676180500","akoscs","2023-03-27T03:41:52.1090000+08:00","Thanks fo rthe tip. Never even crossed my mind to check oracle. It is always Azure, AWS, GCP, Hetzner and Linode for me.","",""
"111895373613666304","archstreet","2023-04-19T17:34:23.3950000+08:00","Hi, anyone that have experience in using the Azure Blob Storage protocol in HighByte? When creating a connection for Azure Blob Storage in HB how should the connection string be formatted? What I have to work with is the ""Blob Storage SAS Url"".","","👋 (1)"
"867075936054149191","rickbullotta","2023-04-19T19:48:24.8890000+08:00","Their support is usually excellent. I’d reach out to them directly.","",""
"111895373613666304","archstreet","2023-04-20T21:39:02.8490000+08:00","Will do, thanks!","",""
"808324876980322355","carson3949","2023-05-15T18:03:46.6520000+08:00","Hi All, just a quick question here.

I had Siemens PLC and IPC (act as HMI) on shopfloor. I wanted to pass PLC information/data to Cloud via MQTT. I planning to use Kepware Siemens and IoT Gateway (MQTT) to perform this. 

However, when there is disconnection happen i would like to push back or transfer all the data back to Cloud. What should i do on it? and also if I would like to do control from Cloud (is that possible) Any solutions can perform this ?","",""
"817835202746253344","IIoT#4707","2023-05-15T18:03:46.9790000+08:00","GG @carson3949, you just advanced to level 1!","",""
"745796393855352953","thedavidschultz","2023-05-15T22:22:52.6470000+08:00","Which Siemens PLC? The S7-1200/1500 have native MQTT support.","",""
"794542235676180500","akoscs","2023-05-16T19:01:24.8600000+08:00","Native...well first party...you need to download their library, it is not quite native, but also not third party.","",""
"833941249362493450","sammysevens777","2023-05-17T13:47:50.2430000+08:00","By disconnection you mean the MQTT broker disconnects? Or fails?","",""
"833941249362493450","sammysevens777","2023-05-17T13:48:24.0540000+08:00","Cause you can probably have a redundant broker in that case?","",""
"1073312001788477471","sparkylarks","2023-05-17T23:02:08.5640000+08:00","I'm trying to understand your architecture. If I'm correct, it might look something like this:

Siemens IPC-HMI -> (Profinet) -> Siemens PLC -> (TCP/IP) -> Kepware (running Siemens Suite Drivers) -> (OPCUA) -> Siemens IOT2050 -> (MQTT) -> Cloud

The destination of the data in the cloud is crucial to know. Is the cloud node subscribing to the Siemens IOT device, or is the Siemens IOT device publishing to an MQTT Broker in the cloud?

When you mention ""when there is disconnection, I would like to push back or transfer all the data back to Cloud,"" are you worried about losing data if you lose a connection? Is it just the connection to the cloud that concerns you or something more?

To prevent data loss, you can:

    Provide Redundant Paths:
    a. Use redundant Kepware servers. This is fairly straightforward.
    b. Create redundant Siemens IOT gateways. While I'm not certain if this is feasible, Siemens likely has a solution.

The above points help reduce the risk of an in-plant outage but don't address the potential loss of the connection to the cloud. Hence, you need to allow for buffering or Store-and-Forward.

    Store and Forward:
    a. IOT devices have integrated buffering, which can help prevent data loss. If you're concerned about data loss due to a connection drop to the cloud, perform the buffering here.
    b. Kepware also has a Store-and-Forward buffer.
    c. Some buffering can be done in the PLC, but it usually can only store a small amount of data. This can be very useful if you're worried about the plant network.

Hopefully that helps","",""
"808324876980322355","carson3949","2023-05-23T18:19:28.7680000+08:00","Hi David, i'm not sure what PLC they are using, waiting end user to feedback me the model.","",""
"808324876980322355","carson3949","2023-05-23T18:20:34.6620000+08:00","The connection in between IoT Gateway to Cloud.","",""
"808324876980322355","carson3949","2023-05-23T18:22:41.5160000+08:00","The architecture is correct. Btw, could i use Kepware IoT Gateway instead of using Simenes IOT2050? and the IoT Gateway should published and subscibe the MQTT Broker in the cloud (normally can it work like that) ?","",""
"568913935147728896","zeratall","2023-06-02T06:14:31.8510000+08:00","Has anyone used timestream AWS TSDB, curious on peoples opinion on it, considering using it to allow race teams to upload data which will eventually be consumed by a web app.","",""
"867075936054149191","rickbullotta","2023-06-02T18:43:43.4440000+08:00","Haven’t used it, but price it out completely first - the cost might shock you.","",""
"568913935147728896","zeratall","2023-06-02T21:12:02.3360000+08:00","Yeah the in memory is a tad bit expensive","",""
"568913935147728896","zeratall","2023-06-02T22:30:53.6850000+08:00","Am I missing something 1Gb worth of writes is only 50 cents, that doesn’t seem to bad.","",""
"568913935147728896","zeratall","2023-06-02T22:30:58.1500000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/1114199485162213469/IMG_7309.png?ex=68df3562&is=68dde3e2&hm=5150da6359e2eae27a07a1808a2842cbefa2f92dac68fe16b88327141152292c&",""
"867075936054149191","rickbullotta","2023-06-02T22:53:03.8320000+08:00","Sorry - wrong cloud.  My bad. 😉","",""
"568913935147728896","zeratall","2023-06-02T22:53:34.5490000+08:00","Hahah no all good, I appreciate the on-site you have the last thing I want to do is get hit with a fat aws bill lol","",""
"568913935147728896","zeratall","2023-06-02T22:54:45.4840000+08:00","That being said I’m leaning towards Timeshare just because I like the server less aspect of it, and I can charge back the customer on their usage. Plus my projects are my only little bootstrap effort and I can’t afford a unlimited tag license for something like canary lol. That being said I have about 10,000 users so scale cost def is a concern for me lol","",""
"867075936054149191","rickbullotta","2023-06-02T22:59:39.5520000+08:00","I did a spreadsheet a couple years ago comparing Azure TSI, AWS Timestream, and OSISoft Pi.  The thing that will drive costs in Timestream is queries.  If they'll have ""live monitors"" up all the time that could really hurt.","",""
"568913935147728896","zeratall","2023-06-02T23:04:41.6100000+08:00","Interesting I’ll have to do some prototyping and see where I can optimize. The idea is to save data which can then be analyzed later. So not really something that would be continuously queried like a dashboard, but selected when a engineer wants to analyze a specific lap/session .","",""
"834581734455640064","rafaelrrf","2023-06-15T07:24:45.9370000+08:00","It seems to work fine, however the communication diagnostics is not simple,  I already needed to restart the PLC in order to restablish communication (had to stop the process also, because the process was running. Siemens does not support these libraries it’s up to you use it.","",""
"756247672637358181","sherylmccrary","2023-07-06T02:19:30.5880000+08:00","Thanks Rafael.","",""
"766684226455207996","bright_hummingbird_31342","2023-07-07T03:47:02.5320000+08:00","Have you looked into the cloud/managed versions of TimescaleDB or InfluxDB?","",""
"898217314741280828","hobbes1069","2023-07-08T02:50:00.8500000+08:00","Interesting thing I found out from @Jermuk. If you use Azure's flexible server you get a crippled version of Timescale because of the licensing. You're better off going open source on a VM yourself or using Timescle's managed service.","","👍 (2)"
"277515221885779970","jermuk","2023-07-08T03:01:09.1340000+08:00","open source is not entirely correct (but only if you are really picky), because the missing features are under a special license, which is basically apache2.0 just with a ""f*ck you Azure / AWS / Google"" clause. this approahc is the same for redis, mongodb, etc., so that Azure etc cannot monetize on the work of timescale, mongodb, etc.","",""
"277515221885779970","jermuk","2023-07-08T03:01:37.6570000+08:00","the license is therefore not considered open-source","",""
"277515221885779970","jermuk","2023-07-08T03:01:52.9350000+08:00","however, you can use it however you want basically","",""
"277515221885779970","jermuk","2023-07-08T03:04:51.6740000+08:00","if you want to support timescaledb, you should go for the official managed version","",""
"277515221885779970","jermuk","2023-07-08T03:05:12.1030000+08:00","can give more background information if anyone is interested 🙂","",""
"339656700745351180","douglawrie","2023-07-10T17:00:04.3440000+08:00","Does there exist a standard pattern for setting up an MQTT VM in azure that accepts connections from public IPs? We’re talking specific IPs here as in connecting two organisations. I am hearing people talk about Azure Application Gateway on the public side but a lot of the docs online are talking about HTTP specifically","",""
"794542235676180500","akoscs","2023-07-10T18:20:04.6160000+08:00","You can set up a VM and use it as an MQTT borker in a second step ( I am not sure if there is a pre-made MQTT VM but there might be). App Gateway is a load balancer, I do not think that is what you need (it might have the options you need, but that is not its main role). Have you looked into Azure Virtual Network?  You can make  a closed network and make the VM(s) connect to (only) that closed network, then you can add your local netwrok to that closed network, see here https://learn.microsoft.com/en-us/microsoft-365/enterprise/connect-an-on-premises-network-to-a-microsoft-azure-virtual-network?view=o365-worldwide

If you want your VM to accept anything from any public IP you can create a global IP (i think that is the name, of reserved or fixed IP or static IP not sure about the exact name) when you create the VM and then the VM will be fully exposed to the public internet and accessible using that IP. Make sure to configure the broker also (e.g. moquitto needs a config line to accept form any IP)","",""
"698244484302897323","lmtx","2023-07-10T20:37:46.3480000+08:00","I look for friendly book reviewers!

I decided to write a book about the Internet of Things at AWS Cloud.

That will be a hands-on technical book for architects/developers interested in starting their IoT journey using AWS Cloud. Once ready, I will self-publish it on Amazon.

I look for 5 to 10 friendly reviewers who will share their feedback as I progress with my work. In return, they will get the final ebook for free.

Please comment/DM me if you are interested.","https://cdn.discordapp.com/attachments/740336311671586968/1127941737097212017/intro_to_iot_at_aws.pdf?ex=68df1ada&is=68ddc95a&hm=e51054dc2015a3c955644bbaad5ffdf35c9de67eae17dc1f5accb3f9473a93d5&","💯 (1)"
"698244484302897323","lmtx","2023-07-19T15:34:25.1600000+08:00","What must you know about the implementation of MQTT protocol at AWS Cloud?

MQTT is an OASIS standard messaging protocol for the Internet of Things (IoT). It is of the most popular protocols in the Internet of Things domain. AWS supports MQTT, which is the default communication method between devices and AWS IoT Core service. But there are some significant differences between the implementation of the MQTT protocol at AWS and the OASIS specification.

QoS (Quality of Service) levels define the assurance for message delivery. According to the specification, the QoS 0 determines at most once delivery. AWS documentation states that IoT Core will deliver messages sent using QoS 0 zero or more times. In other words, devices or applications might receive duplicated messages when using QoS 0. Developers need to implement proper handling of replications to avoid unexpected issues.

QoS 2 guarantees precisely once message delivery (no missing data, no duplicates). AWS does not support this functionality.

AWS limits the size of the MQTT message payload to 128 KB. IoT Core will reject messages bigger than that quota.

AWS charges MQTT messages for every 5 KB. MQTT message of 7 KB cost equals two messages.

MQTT specification and AWS IoT Policies use different wildcard characters. AWS IoT Policy defines allowed actions for devices and applications communicating over MQTT. Wildcard characters help to specify flexible MQTT topic filters for subscribers. Wildcards from the MQTT specification will not work as expected in AWS IoT Policy. That could lead to misconfiguration issues of the IoT system, impact its operations, and produce a security vulnerability.

Please carefully read the AWS documentation before applying your MQTT knowledge during the design and implementation of IoT solutions using AWS Cloud.

Let me know in case of any questions!","https://cdn.discordapp.com/attachments/740336311671586968/1131126886622306305/mqtt_at_aws.png?ex=68df7c81&is=68de2b01&hm=64642a54756b379dba239fd33d230ceef11da4b137d25f0dcb76c5b5896620b8&","👍🏼 (1)"
"1023339351834370089","rehenley","2023-07-29T20:19:42.9150000+08:00","ISO `- **Azure Infrastructure architect **- **Consulting basis.* Azure Architect needed for integration team.  Help setting up the initial Azure enterprise architecture.  Assist with the inbound and outbound connections to facilities, other cloud platforms, intra cloud virtual network interactions, create the general network structures within azure, and assist with access permissions using Azure AD.  Project is expected to last 3 years and roll out in phases, this will be phase I - infrastructure.  Phase II will include setting up DNS on the private 10. enterprise network, hosting the company website, Advanced analytics (AI /ML - using embedded NLP agents with specialized knowledge bases in HMI / UI interfaces for all stakeholders - Microsoft Fabic, Co-Pilot, OpenAI, Cody AI), .  Initial funding from a Microsoft Start-up grant. Someone interested in learning new things and being part of a team that will push the boundaries in the distilling industry.    We will be implementing a UNS with highly converged IT/OT infrastructure - All IT assets will exist in cloud platforms and the enterprise will be built in Azure.  Consulting basis - for hourly rate to start.   Project will last multiple years, but the amount of work in the various phases will change considerably.    Could morph into a full-time position after the first rollout.  If you have the skill set and want to be part of an exciting team; in an industry with nearly unlimited upside potential, reach out to me for more info.  Email is preferred means of contact - reh@acizone.com.","",""
"766684226455207996","bright_hummingbird_31342","2023-08-01T06:55:38.3700000+08:00","For those who have used AWS IoT SiteWise, what have been your impressions?","",""
"891563487241842699","jbonhage155","2023-08-01T13:19:46.2190000+08:00","I'm curious as well about it .. did they rename it SiteWise Edge?
Specifically around the ability to normalized/contexualize the data (is there a scripting component?)

I do like AWS manages / controls the SiteWise edge nodes","",""
"568913935147728896","zeratall","2023-08-03T09:16:04.2500000+08:00","I’ve used it in some initial prototyping both in the cloud and in Greengrass. I enjoyed using it to do some basic modeling, but imho the mapping is really clunky. I much prefer the UX that IH provides around modeling and mapping tags to data model/instance properties then sitewise.","",""
"766684226455207996","bright_hummingbird_31342","2023-08-03T11:05:45.0550000+08:00","Thanks for the input.  Overall, I've been underwhelmed by it, but I've been curious if anyone has had different experiences.  I'm curious what applications where it works well.

The console is definitely clunky.  It seems like everyone who successfully adopting is doing some sort of trickery with an alternative interface or a script.  It does seem rigid as a time series solution and the API does not seem to align well with user intent.  The approach to hierarchy is a bit odd with all the model/asset creation.","",""
"766684226455207996","bright_hummingbird_31342","2023-08-03T11:08:46.1260000+08:00","SiteWise Edge is just on the on-prem or edge component.  It can be used as a local ingest and time series database.  SiteWise is the cloud version.","",""
"958349073126129665","niravpatel16","2023-08-09T22:48:11.8240000+08:00","We use SiteWise in our Digital transformation stack. However, there are limitations that you must be aware of. 1. SiteWise has specific quotas and limitations that you must read to see if this will work for your use case. 2. SiteWise suits time series (OPC, MQTT, Modbus) and well-structured historians. But as a suggestion, don't try to ingest non-telemetry data via SiteWise, it doesn't perform well with some structured data for example, (Batch, Recipe, etc..) 3. SiteWise minimum requirement is 16 GB on Linux-hosted Edge. But this is not true, 32 GB is ideal, as we have seen spikes in memory up to 21 GB without any computing at the Edge. 4. The one feature of SiteWise I like is its modeling and asset hierarchy other than that the product still needs to be mature more. 5. All private components must be written in a choice of coding language. 5. Logging and troubleshooting can be very challenging on custom components. 6. There is no easy way to enable/disable the components when not needed.  For now, these are my observations.","",""
"766684226455207996","bright_hummingbird_31342","2023-08-09T22:49:54.8940000+08:00","Despite these limitations, why do you still use it in your stack?  Have you looked into alternative time series solutions?","",""
"958349073126129665","niravpatel16","2023-08-09T22:53:32.0440000+08:00","Good point. Even I don't know the answer. The decision is above and beyond my reach. But I have separated non-time-series data to dump directly to S3 via StreamManager/Greengrass v2. This has resolved our issues with structured data for the time being. But will SiteWise Edge scale well... I don't know.","",""
"958349073126129665","niravpatel16","2023-08-09T23:27:30.9080000+08:00","SiteWise Edge allows you to retrieve your model and assets at the Edge for any custom application or use case via API. When you lose connectivity with cloud SiteWise to S3 for data-lake, you can continue on your local dashboard or apps without getting affected if you like. SiteWise StreamMangaer is a transient hot-tier that can store data for up to 30 days (Dependent on hardware and tags) FIFO. If you like you can enable the data processing pack, which allows you to contextualize and compute data at the Edge at $400/month.","",""
"867075936054149191","rickbullotta","2023-08-10T00:22:24.0530000+08:00","I'm fairly sure that SiteWise Edge uses InfluxDB internally.","",""
"795178288330440704","youri.regnaud","2023-08-14T02:12:18.4230000+08:00","It's not always easy to understand the technologies behind AWS offerings","",""
"538476855892770836","leafert.","2023-08-17T05:19:08.2760000+08:00","Hi, has anyone of you have experience with Smartsheet? If so, how can I make use of the Smartsheet API and publish data back into Smartsheet. Currently I managed to get data from Smartsheet into an Azure SQL database. Now, I want to send data into Smartsheet from the SQL database. Any suggestions?","",""
"833941249362493450","sammysevens777","2023-08-17T13:56:30.4900000+08:00","So it looks like smartsheet is ""restful"" - write an azure function in python to get data from your db - and then post to smartsheet. 

So ""select....."" From your db, and then ""post"" to smartsheet","",""
"833941249362493450","sammysevens777","2023-08-17T13:56:44.3040000+08:00","Disclaimer - i have no experience with smartsheet 😆","",""
"698244484302897323","lmtx","2023-10-09T20:23:01.1850000+08:00","Managing AWS IoT infrastructure like a pro. Developers-focused training!

The Internet of Things infrastructure spans across local devices and cloud services, but that is not the only differentiator.

Some IoT assets are ""static"", do not change often, and are sparse.
We can design and deploy ""static"" infrastructure upfront using technologies like CDK (Cloud Development Kit).
""Dynamic"" assets represent items created on demand. Sometimes, we can not predict the total number of ""dynamic"" assets. To manage those objects, we use applications leveraging SDK (Software Development Kit).

I started working on developers-focused training to help you manage AWS IoT infrastructure. No AWS knowledge is required, but familiarity with Python is highly recommended.

Please let me know if you are interested in this training and what topics I should include in the scope.","https://cdn.discordapp.com/attachments/740336311671586968/1160915320299585636/aws_iot_greengrass.001.png?ex=68df1765&is=68ddc5e5&hm=6b9d2c8e3104218b86a9769b87ad255740d0228104ce3f9cdbd3f5d079ac546b&",""
"698244484302897323","lmtx","2023-10-18T19:35:04.7450000+08:00","I wrote a book about the Internet of Things using AWS Cloud:

https://a.co/d/4qDOA3r

This book provides an introduction to the Internet of Things domain, covering various aspects of connectivity and device management using AWS Cloud.

Key Features

* Technical foundations of the Internet of Things explained and reinforced with sample implementations.
* Uncovered the reasoning behind best practices tested in real-life commercial deployments.
* Hands-on exercises using an interactive IoT Lab environment.

I hope you will find it interesting. Let me know in case of any questions!","","📕 (1)"
"698244484302897323","lmtx","2023-10-25T18:05:48.8100000+08:00","Why Infrastructure as Code is crucial to effectively managing your assets?

Modern solutions utilize distributed infrastructure to deliver business value. Manual management of those assets is error-prone, time-consuming, and does not scale. Fortunately, we often leverage a virtual infrastructure offered by the cloud providers. One of the benefits of a cloud is that we can describe it using code. That approach is called Infrastructure as Code (IaC).

What benefits does IaC offer?

IaC enables using agile software development methodology to describe and manage infrastructure. As a result, we achieve the:

* Ease of reviewing the environment's configuration because it is defined using the source code. You don't need to log into the AWS Web Console and manually browse cloud resources.
* Quickly reproduce the working setup by invoking our code again. Moreover, we can experiment with various configurations by modifying the parameters of our invocations.
* Version the source code to track changes introduced to the environment. This is crucial for debugging and auditory purposes.","https://cdn.discordapp.com/attachments/740336311671586968/1166678997330034688/iac_post.png?ex=68def73c&is=68dda5bc&hm=21539571f4adea5beb63efea7c85a6bf0999530b908cc4ea3f0b4d277e35016c&",""
"698244484302897323","lmtx","2023-10-30T16:10:26.2910000+08:00","Working with cloud/virtual assets is way easier than with actual hardware and OT systems. That is my personal opinion, but I've got some reasons to back it up.

We can manage cloud/virtual resources like software. That abstract approach enables fast development cycles utilizing:

* Infrastructure as Code (IaC) capabilities
* automated deployment and testing
* unlimited number of development/test environments

Copy of the production environment needs minutes to deploy. We can experiment/break/destroy/recreate it as frequently as necessary, doing no harm to the business continuity. That is a pretty fantastic capability!

Some companies try to implement this approach in the hardware space, but handling physical assets is slower than with virtual objects by its very own nature.

That is why I do claim that working with cloud/virtual assets is easy.

The real question is how to make developing hardware and OT infrastructure as agile as software.

Any ideas?","",""
"898217314741280828","hobbes1069","2023-10-31T02:00:14.9710000+08:00","I think some of this is being addressed but I don't know if the tech is ""there"" yet. So in my case I know how to install linux on bare metal and make it do things. That's great, but it doesn't make me very scalable. I would soon become my own bottleneck. And that ignores the maintenance / daily operations side of things. 

What I need is a management console were I can ""see"" all my edge devices in one place. Know if there is an issue or not, what the issue is, deploy updates, etc. I don't want to care if the edge device is x86, ARM, or even Apple Mx.

Basically, I want for edge devices what everyone else already uses/expects from major networking equipment providers. I run Ubiquiti at home, and if I plug in a new access point, the Network Controller will find it and I can adopt it with one click.

I think Portainer k2d's may do some of this...","",""
"698244484302897323","lmtx","2023-10-31T02:08:39.5610000+08:00","Fleet management is challenging; operating a heterogamous fleet is even harder.","",""
"898217314741280828","hobbes1069","2023-10-31T06:40:02.1550000+08:00","Hard, but shouldn't be impossible these days,","",""
"698244484302897323","lmtx","2023-10-31T15:47:09.0680000+08:00","Agreed.","",""
"794542235676180500","akoscs","2023-10-31T19:19:55.1390000+08:00","What do you mean by ""see"" all your edge devices? Centralized logs/traces/health checks are fairly easy to implement and cetralize to a prometheus/grafana dashboard. I you mean to also control them....well that is very framework dependent.","",""
"898217314741280828","hobbes1069","2023-10-31T20:02:01.4010000+08:00","Yes, full deployment, management, everything. I envision a slim bare metal linux install with docker.","",""
"794542235676180500","akoscs","2023-10-31T20:14:13.9680000+08:00","My simplest idea to do this was to have a company wide kubernetes cluster, add everything as a node and taint the nodes with special HW (I/Os) directly connected to it. That way you get pods running where they should and alll of it is one large system. Sadly could not try it  out in practice at a large scale.","",""
"898217314741280828","hobbes1069","2023-10-31T20:25:38.8720000+08:00","UMH kind of does this and I want to try it out as well but no time this year...","",""
"766684226455207996","bright_hummingbird_31342","2023-11-10T14:30:04.8650000+08:00","SiteWise Edge is built on InfluxDB.  SiteWise is built on DynamoDB.","","👍🏼 (1)"
"698244484302897323","lmtx","2023-11-23T17:59:58.7820000+08:00","The nature of input data defines the backend storage of an IoT system.

When designing the Internet of Things solution, I recommend starting by defining the nature of input data and the way we want to consume (analyze) it. Once we understand those aspects, we can decide on the appropriate way to transfer and store obtained information.

I described the primary use cases in my today's article.

Let me know if you have any questions!

https://www.thingrex.com/type_of_data_defines_storage/","",""
"891563487241842699","jbonhage155","2023-11-28T04:15:58.2030000+08:00","anyone used VMWare Tanzu for on-prem containerization?","",""
"1073620930636550276","alejandrosimo","2023-12-18T22:55:59.3340000+08:00","Hi everyone! I'm looking into the integration of HiveMQ with Azure. A common route seems to be using the HiveMQ Kafka Extension and Azure Event Hubs. Anyone here has tried different integration methods or knows of alternatives?","",""
"766684226455207996","bright_hummingbird_31342","2023-12-19T01:06:30.2680000+08:00","There are a lot of options in addition to HiveMQ's extensions.  

It's more important to ask...
What kind of data do you want Azure to ingest?
How will the data be consumed?  What is the use case?  What service(s) in Azure will use it?","",""
"867075936054149191","rickbullotta","2023-12-19T01:10:21.0100000+08:00","Azure is a lot of things - can you be more specific?","",""
"1073620930636550276","alejandrosimo","2023-12-19T18:13:19.7710000+08:00","I'm ingesting manufacturing time series data. My main goal for now is data analysis and reporting, but I also want to explore options for learning purposes","",""
"1073620930636550276","alejandrosimo","2023-12-19T18:24:00.1190000+08:00","So I'm just looking for other options to get the data in Azure for doing data analysis and for learning purposes. I think one option could be to use NodeRED to publish messages to an Event Grid mqtt broker or to IoT Hub. HiveMQ would be on prem btw. Another would be to create an Azure function that subscribes to the necessary topics from HiveMQ and then publish again to Event Grid.","",""
"867075936054149191","rickbullotta","2023-12-19T20:34:44.3860000+08:00","What would keep that Azire function “active”?","",""
"1073620930636550276","alejandrosimo","2023-12-19T20:44:05.2320000+08:00","The Azure function would be triggered by new messages arriving in the subscribed HiveMQ topics. I assume that as long as messages are being published to these topics, theAzure function will be triggered and remain active. But I may be wrong, I have no experience with Azure Functions yet.","",""
"867075936054149191","rickbullotta","2023-12-19T20:52:43.5820000+08:00","Not sure that’s possible without someone writing a HiveMQ extension or unless there’s a stateful app listening on a subscription.  It should  be possible using Event Grid though.","",""
"1073620930636550276","alejandrosimo","2023-12-19T21:05:38.3500000+08:00","Thanks! I didn't know that with Event Grid you can directly subscribe to HiveMQ without some other service in between, I will take a look","",""
"817835202746253344","IIoT#4707","2023-12-19T21:05:38.6910000+08:00","GG @Alejandro, you just advanced to level 2!","",""
"867075936054149191","rickbullotta","2023-12-19T21:07:16.7150000+08:00","I don’t think you can do that actually - I think you’d need your site HiveMQ to publish to Event Grid’s optional MQTT broker","","👍 (1)"
"867075936054149191","rickbullotta","2023-12-19T21:07:56.7520000+08:00","https://learn.microsoft.com/en-us/azure/event-grid/mqtt-overview","",""
"873009180938743828","sim_sam3","2023-12-20T00:13:52.8380000+08:00","Also check out Azure IoT Ops - easy-ish integration from edge mqtt broker to event grid and other azure services: https://azure.microsoft.com/en-us/products/iot-operations","","👍 (1)"
"783917475128410112","geoffnunan","2024-01-05T12:02:44.7170000+08:00","We are working on it now. Would be great to compare notes","",""
"343452320216121345","hanno23","2024-01-10T14:30:20.6310000+08:00","I have implemented a couple of IIOT projects for remote pump station etc, but we now have a client in the food and beverage space that wants his Ignition SCADA in the cloud (AWS). Our S88 standard is pretty heavy, we are looking at 60k-100k tags. I was thinking of doing the following:
Siemens PLC <---OPCUA--->Ignition Edge<---MQTT SpB--->EMQX Broker (EC2)<---MQTT SpB--->Ignition Perspective  (EC2)

I am familiar with AWS and Terraform so it shouldn't be too difficult. I was just wondering:
1) Has anyone done this before? Any gotcha's I need to look out for? Things like tag count limitations, MQTT aspects that could mess with the standard SCADA control process.
2)I am thinking of running the broker and Ignition on one EC2 instance and the Historian DB on another EC2 instance. Once we are done with comissioning and happy with EC2 sizes, I'll apply EC2 Reserved instances to save money. This feel to me like the best solution in terms of cost. I know there are other costs like R53 that I need to take into considderation but am I missing anything major? Is there a better solution ito cost?","","👀 (2)"
"817835202746253344","IIoT#4707","2024-01-10T14:30:21.0180000+08:00","GG @Hanno, you just advanced to level 1!","",""
"890244048739270656","brianpribe","2024-01-12T23:17:44.7400000+08:00","I would be very careful with running your SCADA in the cloud. You must do what you can on maintaining connection or redundancy to prevent your SCADA control from going offline.","","💯 (4)"
"890244048739270656","brianpribe","2024-01-12T23:22:55.6270000+08:00","Ask specifically why the customer wants SCADA in the cloud. SCADA doesn't typically need the features that cloud services offer like scaling up to 100X. MES is typically the line where OT services move to the cloud and it's typically due to the business having multiple locations.","","💯 (1)"
"230441548653789184","r.pop","2024-01-13T08:10:14.4360000+08:00","Is it actually a SCADA? or are they using Ignition Perspective for Visualization in the cloud?","",""
"528668306690015284","vatsalshah","2024-01-14T10:15:20.3140000+08:00","This and we are underestimating security risk involved for running scada in the cloud. None of the scada systems are cloud native - that means they never isolated frontend and backend neither they authorize every call.  Securing that attack surface forever is not a small feat.","","💯 (2)"
"343452320216121345","hanno23","2024-01-15T20:43:34.2030000+08:00","Jip that is the point I made as well, the client is ""high"" on cloud and I explained to him that there is no advantage (in this case) to run the SCADA on site vs in the cloud.  The SCADA controls a critical process and adding an IOT layer to that does not make sense. I explained it to the client and was basically told that we should still do it and if it does not work out, move it back to site. So at this stage I am just trying to make sure that I implement it in the best way possible although I don't agree with the design.","",""
"867075936054149191","rickbullotta","2024-01-15T22:39:52.4250000+08:00","Make sure that you have no liability exposure as well.  It's a dangerous approach they're taking.  Or say ""no"".  You'd be doing them a favor.","",""
"890244048739270656","brianpribe","2024-01-15T22:46:30.7360000+08:00","I hope it’s not gonna be any worse than Jurassic Park’s SCADA. Give the movie a rewatch and you’ll see what I mean.","",""
"343452320216121345","hanno23","2024-01-16T00:57:42.4940000+08:00","Jip at this stage I am just making sure I spec the edge PC so that it can run the whole SCADA (If they plan on moving it back) and setup TLS/SSL in the MQTT layer. But I am going to make it clear to him that he is now introducing a new point of failure.","","🔥 (1),👍🏼 (1)"
"343452320216121345","hanno23","2024-01-16T00:58:50.1790000+08:00","😂  I will check it out.","","🔥 (1)"
"693309801589112862","_dyland","2024-01-16T03:07:59.7990000+08:00","https://jurassicsystems.com/","","😂 (1)"
"890244048739270656","brianpribe","2024-01-16T08:31:39.1600000+08:00","HOLY CRAP!!","","🤣 (2)"
"1129435706285101076","ted.garrison","2024-01-18T21:41:15.7580000+08:00","hah.. now next time I decide to rewatch that, I'm going to actually be paying more attention to their infrastructure architecture than the movie itself.. THANKS A LOT>","",""
"890244048739270656","brianpribe","2024-01-18T22:56:21.3730000+08:00","Hey I couldn't help myself and now you all must bare the consequence 😂","","😂 (2)"
"442331638727311370","giulianog_","2024-02-05T22:59:18.3590000+08:00","hey @everyone i am a cloud vendor and we have this software that is very similar to an ERP but we call it the MRP3. we have only been in the market for 7 months and want to see what other people think about the software so we can keep growing and make it better","",""
"442331638727311370","giulianog_","2024-02-05T22:59:31.9410000+08:00","here is the login to the demo if anyone is interested","",""
"442331638727311370","giulianog_","2024-02-05T23:02:34.3250000+08:00","https://demo.ajawmrp.com/","",""
"442331638727311370","giulianog_","2024-02-05T23:02:39.4770000+08:00","AdminDemo","",""
"867075936054149191","rickbullotta","2024-02-06T03:00:59.3280000+08:00","I would highly recommend not doing this - you just gave us an Admin account - and the first thing I was tempted to do was to change the password....","",""
"766684226455207996","bright_hummingbird_31342","2024-02-06T04:17:57.8130000+08:00","I thought it was some sort of bot.","",""
"442331638727311370","giulianog_","2024-02-06T05:57:17.9880000+08:00","I own the plat from so its fine i can just change it","",""
"442331638727311370","giulianog_","2024-02-06T05:59:04.4890000+08:00","but your right","",""
"817835202746253344","IIoT#4707","2024-02-06T05:59:04.7910000+08:00","GG @giulianog_, you just advanced to level 1!","",""
"442331638727311370","giulianog_","2024-02-06T05:59:22.7500000+08:00","@everyone DM me if you want access to the MRP3","",""
"867075936054149191","rickbullotta","2024-02-16T19:28:00.8330000+08:00","Oops.  https://www.theregister.com/AMP/2024/02/15/microsoft_retires_azure_iot_central/","","🤔 (1),👀 (1)"
"1073620930636550276","alejandrosimo","2024-02-17T00:27:10.7420000+08:00","What alternative withing Azure would you suggest to people that were using IoT Central?","",""
"867075936054149191","rickbullotta","2024-02-17T00:39:14.2290000+08:00","That's a tough one - I personally like Azure Digital Twins quite a bit, but there's no clear committment to its future either.  That could be easily addressed.  And I'm told that there's a replacement for IoT Central coming at some point.  Utterly shocked that they would announce Central's demise without also announcing any pending alternatives.","","👍 (1)"
"657361690379288596","du5tins","2024-02-21T00:43:23.9390000+08:00","This might be a little off topic but not sure where to ask this question or start a discussion on it. Is anyone in this community following the Broadcom take over of VMware? Losing ESXi free license last week feels like a huge loss. What is the next evolution of on-prem cloud for OT? XCP-NP or Proxmox?","",""
"1129435706285101076","ted.garrison","2024-02-21T00:57:56.7570000+08:00","we've been moving from VMWare to Nutanix over the last year or so.  Beyond that, I know nothing, as it's all IT doing it..","",""
"657361690379288596","du5tins","2024-02-21T00:59:59.1810000+08:00","We work on some larger DCS style systems with on-prem virtualization for the SCADA/HMI servers and historians. Emerson DeltaV, Rockwell, and others have been mainly recommending VMware for such deployments to date. If the cost structure of VMware changes a lot I can see these vendors changing things up a bit.","",""
"766684226455207996","bright_hummingbird_31342","2024-02-21T01:47:59.8260000+08:00","It's been a while since I've looked at the ESXi licensing stuff, but I don't remember it being significant relative to the resources required to stand up, say, a SCADA or DCS solution.  It seemed like Microsoft and Cisco was always the source of complications on how to optimally balance licensing, architecture, and requirements.  Will the VMware license changes, beyond not being free, have a significant impact?

Industrial vendors are slow and like stability.  Outside of industry, the market has been shook up in recent years.  Unlike a decade ago, there is a lot more than VMware now.  VMware is mature technology that will continue to be relevant for years, but it has a lot of competition.  Organizations too lazy to buy anything other than Microsoft have been migrating to Hyper-V for quite some time.  Also, the cloud services and containerization have diminished the role of hypervisors.  Ted also mentioned Nutanix AHV.

The tricky thing will be is if vendors are still deploying applications as ESXi images and only offering support as such.","",""
"568913935147728896","zeratall","2024-03-03T21:49:57.9910000+08:00","Anyone using InfluxDB Serverless MS? I'm using Azure which is V2. My architecture diagram is below:","https://cdn.discordapp.com/attachments/740336311671586968/1213845829664776212/image.png?ex=68df2bc5&is=68ddda45&hm=16e73c89d57cbb179a2cc60ba51d7ff77f175bca9f6ac6f4074e9d83f5e3fd49&",""
"568913935147728896","zeratall","2024-03-03T21:51:37.5760000+08:00","The problem I'm having is the InfluxDB writer is subscribed to my MQTT UNS, and writes data to InfluxDB when topics update (topics update at different rates because I'm reporting on exception only). The problem is it's a few thousand messages/second, because of this, the data that is published via mqtt is not instantly available in InfluxDB, the latency grow as the load grows.","",""
"568913935147728896","zeratall","2024-03-03T21:53:14.0380000+08:00","My KPI calculator service, essentially calculates some KPIs from the time series data and appends the KPIs to a SQL db to contexulize the data with some relational data. the KPI Calculator Service gets triggered by a message that gets sent from the Data Collector Client over MQTT, essentially The Data Collector client, notifies via sending an event to the MQTT Broker that the KPI Calculator is subscribed too.","",""
"568913935147728896","zeratall","2024-03-03T21:54:02.7440000+08:00","`The Problem` : The Data Collector Publishes to the KPI Calculator as soon as the threshold logic is met, when the KPI goes to calculator not all the data is written to influxDB yet.","",""
"568913935147728896","zeratall","2024-03-03T21:55:23.0440000+08:00","Right now I'm working around it because in my KPI Calculator I have a query with exponential backoff, essentially I query InfluxDB, and if the data hasn't written I wait exponentially until 10 tries or 5 minutes has past. To me this is a total work around, and ends up eating influxDB cost in terms of increased query account.","",""
"568913935147728896","zeratall","2024-03-03T21:56:52.3380000+08:00","Ideally I'd have some way to coordinate between the Writer Service and the KPI service. Because I'm writing topics as they in there's no real way to do this, I'm curious how others do this, or if influxDB has some sort of trigger I can create that essentially would provide feedback that the KPI is ready to be calculated.","",""
"867075936054149191","rickbullotta","2024-03-03T23:50:52.3800000+08:00","You really should be batching updates to Influx anyway.  Almost all cloud writes will have some level of latency before the data is queryable, particularly in an HA or redundant scenario.  I've also had lots of issues with Influx Cloud V2 - 503 errors on writes, timeouts on queries.  Not too happy with that.'","","💯 (1)"
"867075936054149191","rickbullotta","2024-03-03T23:52:36.8170000+08:00","If you're using a custom MQTT broker (what is it?) you might be able to do some of this processing in-band inside the broker.  Pros and cons for both.  And you might benefit from Kafka or something similar in the mix to deal with burstiness and to enable some stream processing.","",""
"568913935147728896","zeratall","2024-03-03T23:54:14.5870000+08:00","Yeah I'd argue not just cloud but any db is going to have some latency associated with it, thats a no brainer, the main question I was trying to see is if Influx had some type of way to notify on data write complete, so I didn't have to do that on my writer service, I don't want to much logic in the broker, just worried about to much logic bogging it down. I was hoping that influx had some type of serverside batching, but I guess I'll just come up with something in my InfluxDB Writer Service, to batch and then notify on write complete. Was trying to keep that service stateless but not seeing another path. Can't batch client side either because I want the current state from the broker for other services.","",""
"794542235676180500","akoscs","2024-03-05T02:06:59.1770000+08:00","For e few thousand writes per second you do not really need Influx, do you? Also, could you add redis or any in memory solutiuon (incl. also just a simple array kept in memory in your KPI calculator) to keep last n seconds in memory and calculate the KPI on that, or complete the in memory data for the last 10 min and get older data form influx, merge the two and calculate your KPI.","",""
"568913935147728896","zeratall","2024-03-05T02:09:15.8520000+08:00","I need persistence for the data yes, in terms of the second part, that's what Rick was suggesting Batching by keeping things in memory. KPI Calculator does not subscribe to data so I wouldn't do it there, could do it on the Writer, but again would like to keep it stateless.","",""
"794542235676180500","akoscs","2024-03-05T02:10:18.7650000+08:00","You need persisance, OK, but for that amount of data it does not have to be influx..","",""
"568913935147728896","zeratall","2024-03-05T02:10:47.8340000+08:00","GB of time series data, were talking an ingest of a few GB/s, over anywhere from 50-100k Msg/s","",""
"794542235676180500","akoscs","2024-03-05T02:12:21.3180000+08:00","Than I missunderstood, for some reasone I was under the impresson it was a few thousand datapoitns per second.","",""
"794542235676180500","akoscs","2024-03-05T02:16:03.9340000+08:00","Bathcing before inserting, yes. You can also use the in memory data for calculations.","",""
"568913935147728896","zeratall","2024-03-05T02:16:45.2670000+08:00","Yeah even at lower ingest rates, I think there still value in using a historian for time series data, mainly in the way the data is queried and some of the operations you have at hand. Especially when dealing with non-constant timestamps and different sample rates.","",""
"568913935147728896","zeratall","2024-03-05T02:17:26.3370000+08:00","Yeah 100%, I think that's viable, imho those two design patterns really come down to, do I want to pay VM prices for Memory Usage, or do I want to pay Influx prices on Query hits.","",""
"794542235676180500","akoscs","2024-03-05T02:18:34.1970000+08:00","Other then faster insert rates and very few queries which actually use time..I do not think there is any advantage to a time series DB\","",""
"794542235676180500","akoscs","2024-03-05T02:18:39.8890000+08:00","you can also look at clickhouse","",""
"794542235676180500","akoscs","2024-03-05T02:18:49.8350000+08:00","for realtime analytics","",""
"794542235676180500","akoscs","2024-03-05T02:19:00.6050000+08:00","https://clickhouse.com/use-cases/real-time-analytics","",""
"568913935147728896","zeratall","2024-03-05T02:20:42.4910000+08:00","I actually use a lot of time queries when were talking about data for a race car lol","",""
"568913935147728896","zeratall","2024-03-05T02:21:02.1810000+08:00","Interesting, the prices on that are really attractive compared to influxDB, especially the storage cost, it's basically nothing.","",""
"794542235676180500","akoscs","2024-03-05T02:21:34.1690000+08:00","Which are the ones that are only specific to a time series db","",""
"794542235676180500","akoscs","2024-03-05T02:21:34.7630000+08:00","?","",""
"568913935147728896","zeratall","2024-03-05T02:22:45.7700000+08:00","Very few uses cases are only achievable in TSDB vs a RDBMS, there is always a workaround to get things “working” but just because you “can”, doesn’t mean you “should”, a lot of uses are just made easier in TSDB than when working with a RDBMS","",""
"568913935147728896","zeratall","2024-03-05T02:27:13.7520000+08:00","For example, lets say I have 4 sensors, all 4 sensors may or may not have a value (report by exception) for a specific timestamp, all 4 sensors have different timestamps, and different sample rates. 

If I want to get data for the past 4 hours for these 4 sensors, I can query the time window, resample, and get a consistent timestamp for all 4 sensors in one flux query.","",""
"568913935147728896","zeratall","2024-03-05T02:51:58.7230000+08:00","Thank you for sending this my way, this actually seems like a pretty cool solution, actually have some ideas looking through their documentation","","👍 (1)"
"867075936054149191","rickbullotta","2024-03-05T03:26:05.8770000+08:00","One approach that is pretty common is to batch stuff for storage/ingress, but keep a ""warm cache"" in memory.  Query the historian for the data you need, then fill in the gaps from the warm cache.","",""
"568913935147728896","zeratall","2024-03-05T04:01:27.2940000+08:00","You know, thats a great idea and what I already have, just didn't think about it lol. I have a que for all the data that is popped off the broker, but waiting to be written to the DB, if a query comes back as an error, I could always just query the que, idk why I didn't think of that.","","✌🏼 (1)"
"607417455090073610","bigictyreject","2024-03-16T01:20:48.0280000+08:00","any thoughts on Rockwell’s new FT DataMosaix (dataops platform) compared to other solutions?","",""
"1129435706285101076","ted.garrison","2024-03-16T01:30:32.6700000+08:00","does it meet the MTR?","",""
"1129435706285101076","ted.garrison","2024-03-16T01:30:36.4490000+08:00","!MTR","",""
"817835202746253344","IIoT#4707","2024-03-16T01:30:36.8430000+08:00","These are the Minimum Technical Requirements for your IIoT Ecosystem:

1. Edge-Driven
2. Report by Exception
3. Lightweight
4. Open Architecture.","",""
"766684226455207996","bright_hummingbird_31342","2024-03-16T05:41:38.0750000+08:00","I believe it’s just Cognite Data Fusion white labeled.

It’s not a DataOps platform. Data must be ingested and persisted in the platform before anything can be done. It primarily models data for itself. It’s more like a digital twin or analysis solution. There are some options to pull data out, but that’s not its focus. Most data that goes into the platform will stay there.","",""
"254777321788145664","terrancesmith","2024-03-16T06:07:53.5350000+08:00","FTDM is a white labelled version of CDF. 100%  There are some differences.... Some ootb modelling, simplified permissions and RA(I work for them) complicated the licensing structure with tiers, but it should make some features more accessible to low scale operations. I haven't done a FTDM implementation yet, but I've done a CDF integration for an O&G company.

I did not expect to hear that it ""isn't a DataOps platform"" though. I don't understand that perspective.","",""
"766684226455207996","bright_hummingbird_31342","2024-03-16T06:20:26.6160000+08:00","I personally define DataOps as a methodology to enable interoperability for a broad set of external data consumers whether its apps, services, users,  etc. It’s not say that CDF or FTDM are bad solutions. I just don’t believe they’re designed to solve this problem. They solve a different problem.

If data must be persisted in a platform before it can transform data and the same platform is a first class consumer (for analysis, visualization, reporting, etc) of that transformed data, it’s not truly DataOps.

One can’t be objective about interoperability if they stand to benefit from consuming data before or instead of others.

These platforms are “net consumers” of data. They’re a spoke in the architecture. If they were a hub, there would be parity between the data ingressed and egressed. 

Additionally, while I don’t feel as strongly about this, some organizations have reservations about a SaaS platform being the core of their data infrastructure if they don’t have control of the underlying infrastructure. That is,  they require direct access to the underlying services and data within them without going through the SaaS layer.","","👍 (1)"
"254777321788145664","terrancesmith","2024-03-16T09:16:58.3640000+08:00","I know you aren't the type of guy to bash other solutions. Don't worry about getting accused of that.

Every voice matters in defining concepts as an industry. Your definition is narrower than others I've heard. I too agree it's a methodology and its focus is on making data broadly available and usable by all potential consumers. I don't understand the significance you place external data consumers only. If anything, CDF is a ""DataOps+ Platform"" in that respect, because of the few consuming applications that come with it. But that sounds awful and shouldn't be a thing.

The reason for persisting data in CDF before the transformations and data workflows kick in is to reduce computational load on the original source. Those systems may or may not have been designed for the transformational load so that pre load is the least impactful way to get the transformations done. The tables are always referred to as RAW and never last long after the transformations are complete and the data is prepared for consumers.

That concept of a DataOps platform required to be ""net zero"" is interesting. I had to dig around to make sure(IBM, Garnter, Forrester), but I haven't bumped into that anywhere else. As you pointed out, CDF doesn't really push data to others. They have to come and get it. Do you think a dataops platform has to push the data along? In that respect, CDF is definitely not that kind of dataops platform. But it does make the data plenty accessible to any consumer.

I agree that an organization's perspective on if data infra should involve a SaaS service or not doesn't decide if something is a dataops platform. It certainly does affect how willing some organizations are to use it. Don't even get me started on the branding confusion DataMosaix  Private Cloud edition is causing...","",""
"817835202746253344","IIoT#4707","2024-03-19T22:30:58.8250000+08:00","GG @Nirav Patel, you just advanced to level 3!","",""
"698244484302897323","lmtx","2024-03-26T20:04:29.2100000+08:00","Q: What are the main factors that affect the cost of cloud infrastructure utilized by the IoT solution? 🤔

A: The frequency of telemetry messages is one of the primary cost factors in IoT solutions. Implementing edge analytics is a cost-effective strategy that enables savings while providing real-time capabilities. 👍

I recommend pre-processing and aggregation at the edge to reduce expenses associated with frequent messages. 💰

To further optimize cloud-side costs, analyze and buffer data BEFORE storing it. That step is often overlooked but can provide significant savings in specific scenarios (for example, when storing data using AWS S3 Bucket). 💡
Would you be interested in discussing that topic further? 👈","","👍 (1)"
"867075936054149191","rickbullotta","2024-03-26T23:05:50.2610000+08:00","If you aggregate at the edge you lose a significant amount of fidelity and signal that is critical to training AI/machine learning models.","","👍 (2)"
"698244484302897323","lmtx","2024-03-27T04:15:21.8960000+08:00","That is only sometimes the case. When implemented correctly, you won’t lose data.","",""
"867075936054149191","rickbullotta","2024-03-27T04:52:43.1920000+08:00","Explain.  If you aggregate, you lose fidelity and granularity.","","💯 (2)"
"796223784650670110","dapomeranz","2024-03-27T05:07:58.8660000+08:00","@RickBullotta I'm merely playing devils advocate, but there has to be some options for lossless compression in this space, no?","",""
"898217314741280828","hobbes1069","2024-03-27T09:24:44.3580000+08:00","I think the fatal part of the assumption is that if you aggregate, you throw away the raw data, certainly if this is what you do then you are correct, but nothing requires that you do this. You can contextualize data and keep the raw data. The two are not mutually exclusive.","","💯 (3)"
"867075936054149191","rickbullotta","2024-03-27T20:20:18.9170000+08:00","Right.  But the original post suggested saving money by aggregating at the edge.  If you're saving money by aggregating you're not storing the raw data in the cloud to facilitate machine learning or other advanced analytics.  Have I ever mentioned AND not OR? 🙂","",""
"867075936054149191","rickbullotta","2024-03-27T20:20:54.7490000+08:00","Where?  Storage side? Edge? Ingest?","",""
"698244484302897323","lmtx","2024-03-27T21:26:54.2510000+08:00","You can aggregate the raw data and use batch upload as an example of a loss-less aggregation that reduces your costs.","","👍 (1)"
"867075936054149191","rickbullotta","2024-03-27T21:28:18.2380000+08:00","Still not following. Aggregation typically refers to bucketing min, max, average, etc. - not lossless.  Batching is not aggregation.","",""
"698244484302897323","lmtx","2024-03-27T21:53:29.2360000+08:00","You're right, @RickBullotta . Batching would be a bettern term to describe my point.","","👍🏼 (1)"
"867075936054149191","rickbullotta","2024-03-27T22:04:33.5620000+08:00","This is also why I want the MQTT committee to add a ""multi-publish"" message type - it would be the equivalent of ""batching"" and would be more efficient, lower latency, and so on.\","","👍 (3)"
"452843187719897088","scrapper7161","2024-03-29T06:57:42.5900000+08:00","We would definitely support that , makes total sense but I see that the protocol would have to have a terrible workaround especially the 4 bits length size ..... 🤔","",""
"867075936054149191","rickbullotta","2024-03-29T20:10:43.6630000+08:00","You mean 4 bits! What an awful decision that was.","",""
"452843187719897088","scrapper7161","2024-03-29T20:11:00.8660000+08:00","yes... already edited the answer... 😅","",""
"817835202746253344","IIoT#4707","2024-03-29T20:11:01.1060000+08:00","GG @Hugo Vaz, you just advanced to level 3!","",""
"452843187719897088","scrapper7161","2024-03-29T20:29:54.5740000+08:00","In essence, we’re hitting a bit of a wall with MQTT's fixed header, specifically the 4-bit limit for the message type. It’s a bit like trying to fit a square peg in a round hole when we talk about evolving needs, such as multi-publish features. So, here's a thought for MQTT 7.0 – why not play a bit of a trick with one of those ""Reserved"" slots in the 4-bit message type field? We could signal that there’s more to the message than meets the eye, leading the way to an extended message type space hiding in the variable header.

Picture this: We pick a reserved value, say 0 or 15, to flag that we're dealing with an MQTT 7.0 message with some new tricks up its sleeve. Older MQTT versions would just skip these messages, keeping things compatible. Then, for our MQTT 7.0 clients, they’d see this flag and think, ""Aha! Let's look further some bytes!"" And in that variable header, we’d have our extended message type, ready to cater to whatever future expansions we dream up, including multi-publish capability.

This multi-publish would let us send a bundle of messages in one go, each potentially for a different topic, all neatly packed into a single MQTT message. 

So, to wrap it up: MQTT 7.0  OASIS guys come read this!😅","",""
"698244484302897323","lmtx","2024-04-06T17:40:59.6800000+08:00","What if AWS decides to shut down the AWS IoT Core?

Devices communicate with the AWS IoT Core using MQTT Protocol and authenticate using X.509 Certificates - neither of those technologies is AWS specific.

If AWS decides to shut down the AWS IoT Core (which is rather unlikely), you will be able to migrate to any other MQTT Broker (hosted on-site or cloud offering). In my opinion, vendor lock-in is not severe, considering solely the communication with devices.

Naturally, the IoT platform leverages far more services than exclusively communication-related. Moving the entire IoT platform from AWS to another provider would be way more painful.

Would you move your entire IoT Platform to another provider or just the communication part?

1. I would move everything. 🧰
2. I would only move the connectivity and keep the rest in AWS. 📡

Please share your opinion! 💬","","🥇 (1),🥈 (2)"
"894527802316046366","nickn5549","2024-04-07T17:34:50.0950000+08:00","No AWS for me...my servers are just fine","",""
"698244484302897323","lmtx","2024-04-07T20:25:30.5960000+08:00","I can understand that 😉","",""
"230441548653789184","r.pop","2024-04-08T22:27:39.2360000+08:00","Would depend on the type of project. Are we talking Connected Vehicle? Connected Product? Or Connected Factory?","","💯 (1)"
"898217314741280828","hobbes1069","2024-04-09T21:10:36.6010000+08:00","So random thought for the day... While AWS seems to be a better overall cloud services provider than Azure, I have to say the concept behind Azure Container Instances (ACIs) is pretty cool.","",""
"867075936054149191","rickbullotta","2024-04-10T22:02:04.2500000+08:00","That's a super important point to consider.  Much harder to swap out edge software on 10,000,000 cars or 10,000 MRI machines than it is to swap out code on a handful of gateways to point somewhere else.","",""
"1214242167640424619","zack.scriven","2024-04-11T01:39:22.9180000+08:00","you are right. tesla is approaching a vehicle fleet of 10,000,000. good point.","",""
"1057737574287945899","xamp4248","2024-04-12T23:51:21.1860000+08:00","Are there any use cases other than Tesla? I heard that Nike, Airbus, and Coca-Cola have also succeeded in implementing Industry 4.0.","","👍 (1)"
"230441548653789184","r.pop","2024-04-18T22:59:08.2020000+08:00","Ford, Stellantis, GM, BMW, Volvo, Volkswagen, etc..","",""
"795725198980677734","diederik9434","2024-04-18T23:06:05.7300000+08:00","I liked what i saw at BMW, BASF is also trying","",""
"795725198980677734","diederik9434","2024-04-18T23:06:25.6710000+08:00","all big companies have something but i dont know any that are near perfect yet","",""
"230441548653789184","r.pop","2024-04-18T23:09:04.6570000+08:00","I would agree, I don't thing there are any ""perfect"" strategies of Industry 4.0","",""
"230441548653789184","r.pop","2024-04-18T23:09:08.3380000+08:00","Including Tesla","",""
"382941357699760129","walker.reynolds","2024-04-18T23:10:17.0440000+08:00","Correct — Tesla’s maturity score is 86/100.  It’s the highest in the dataset but not perfect.  🙏","",""
"230441548653789184","r.pop","2024-04-18T23:11:42.8630000+08:00","They just need to get better at using that data to manufacture 😂","",""
"867075936054149191","rickbullotta","2024-04-19T01:42:22.7760000+08:00","I was blessed to work alongside some very progressive manufacturing companies over the years - Dow Corning was years ahead of everyone in terms of i4.0 adoption as an example.","","👏 (1)"
"1057737574287945899","xamp4248","2024-04-22T00:53:39.3500000+08:00","If tesla got 86%, then who can chase it?.. By the way Musk agreed to your DTMA survey 😀😅.","",""
"1162450027508158556","bddownen","2024-04-25T22:18:26.9780000+08:00","@js and @TerranceSmith , thank you so much for discussing this topic, my company is starting on the journey in utilizing FTDM and would love to have a clearer picture in the pros and cons and also how it compares with other offerings.  @Js, can you elaborate on what you mean by ""persisted""...do you mean live and that is the location where many external apps would need to have access to?  Any additional insight would greatly be appreciated.","",""
"685604620810322017","mattventer.","2024-04-27T05:06:35.2230000+08:00","You need to consider how much you are using the IoT Core Rules engine and other AWS services. The level of integration with these can significantly impact the complexity and time required to migrate to another broker. If the alternative broker does not natively support the same features, building integrations could be challenging.","",""
"1214242167640424619","zack.scriven","2024-04-27T11:54:31.3900000+08:00","Tesla was scored by Walker when he was working on the model S MES at Giga Nevada back almost 10 years ago. Since then the internal contact at Tesla re-does  the scoring.","","👍 (1)"
"698244484302897323","lmtx","2024-04-27T18:06:41.3530000+08:00","That is correct. IoT Rules are a powerful tool and most IoT deployments utilize them.","",""
"740365995419631736","omarazizahmed","2024-04-29T22:52:11.2850000+08:00","and they were blessed to work with you brother.","",""
"795178288330440704","youri.regnaud","2024-05-03T13:43:36.3830000+08:00","A lot of discussion on social networks about GCP's offer to HM24. Objectively speaking, can GCP be used as a time series database, given that the Big Query and Big Table offerings are columnar databases? If we already have our data in InfluxDB, for example, what would be the value of ""pushing that data"" into GCP? Looker is still a limited tool for advanced visualization, as we sometimes need in Manufacturing. How can we exploit GCP's visualization tools? Should we wait for the merge of Data Studio and Looker? What real promise does the Google stack hold for AI? .... I'd be delighted to hear insights from the community.","",""
"867075936054149191","rickbullotta","2024-05-03T21:18:37.4610000+08:00","@Vatsal Shah knows the Google stack very well and can provide some insight","","👍 (1)"
"528668306690015284","vatsalshah","2024-05-03T21:52:34.6420000+08:00","You can try the whole portfolio here (just need a GCP account) : https://console.cloud.google.com/marketplace/product/litmus-public/intelligent-manufacturing-connect

can GCP be used as a time series database, given that the Big Query and Big Table offerings are columnar databases?
- Yes Manufacturing Data Engine takes care of data data / metadata layer and optimize it on the fly (on Google Pubsub) for Bigquery 
- Surprisingly cost-efficient at scale
- Pubsub is very performant and low cost

looker is still a limited tool for advanced visualization, as we sometimes need in Manufacturing. How can we exploit GCP's visualization tools?
- Looker is one of the best BI tools in my opinion. 
- Slicing and dicing at scale is very smooth. (Cross plants/sites queries)
- If you use Manufacturing Data Engine format, Looker is out-of-the-box for analytics. 

Should we wait for the merge of Data Studio and Looker?
- Already merged. Lots of customers are using this stack (above link will give you all):

1. Manufacturing Connect Edge (MCE) for Edge and industrial data collection 
2. Manufacturing Connect (MC) for global management 
3. Manufacturing Data Engine (MDE) for data management at scale. The UI of MDE is inside MC only. 
4. Bigquery for long term storage 
5. Looker for analytics + ML Analytics
6. AI 
6.1 Vision Processing is out of the box 
6.2 AI frozen models access on bigtable/bigquery you might have to request access to GCP team 
7. Cortex framework for SAP integrations (essentially MDE + Cortex go hand in hand)

What real promise does the Google stack hold for AI?
- in my opinion, few of the best SLM to LLM frozen models are available in Google AI portfolio. We are seeing uptick in some of the multimodel analysis / document ai usecases
- VertexAI is integrated well on MDE/Bigquery","","👍🏼 (2),🔥 (1)"
"795178288330440704","youri.regnaud","2024-05-04T00:03:13.9360000+08:00","Where is Litmus in GCP offer? MCE, MC?","",""
"528668306690015284","vatsalshah","2024-05-04T00:13:55.9060000+08:00","Yes MC (cloud) and MCE (edge) co-developed with GCP.","",""
"795178288330440704","youri.regnaud","2024-05-04T01:32:09.9880000+08:00","Codevelop? Litmus on « white label »? Litmus on Anthos?…","",""
"795178288330440704","youri.regnaud","2024-05-04T01:40:54.7490000+08:00","What is really MDE?","",""
"528668306690015284","vatsalshah","2024-05-04T01:54:52.4540000+08:00","Yes white label MC and MCE - codevelopment for anthos / Identity management / native GCP features like storage and container registry.","",""
"795178288330440704","youri.regnaud","2024-05-04T03:27:56.1930000+08:00","Thanks for your answers","","👍 (1)"
"528668306690015284","vatsalshah","2024-05-04T03:29:45.7940000+08:00","It is a transformation and data contextualization engine built on Google Dataflow (I might be wrong) , and big query. It takes data from Google pubsub and gets it to the destination in a clean, organized and contextualized format. 
All of the MDE can be configured from MC ui.","",""
"528668306690015284","vatsalshah","2024-05-04T03:29:51.3670000+08:00","I will send you docs link.","",""
"528668306690015284","vatsalshah","2024-05-04T03:30:08.2020000+08:00","All public and you might want to give it a try. COTS product","",""
"698244484302897323","lmtx","2024-05-13T22:04:10.5970000+08:00","","",""
"698244484302897323","lmtx","2024-05-13T22:04:14.8140000+08:00","What is the optimal team size to design and deliver a high-profile initiative?

I worked at several companies, leading teams of various sizes (from 1 to 15 developers, depending on the initiative). Based on my experience, what matters is the seniority of a development team, not the headcount.

Various team sizes enforce different strategies and introduce versatile risks.

Based on your experience, what is the optimal number of senior developers working on a global-scale SaaS IoT platform backend?","",""
"698244484302897323","lmtx","2024-05-14T18:06:16.6750000+08:00","CI/CD in IoT: the ""T"" (Thing) component 📡

Continuous integration and delivery (CI/CD) is a powerful approach to software development that enables teams to deliver high-quality software faster. However, implementing CI/CD in the IoT domain presents unique challenges due to the ""T"" (Thing) component.

The ""T"" in IoT refers to the physical devices interacting with the real world. These devices can be anything from sensors and actuators to smart appliances and vehicles. They are often resource-constrained and have different operating systems and architectures than traditional cloud and server-based systems.

This heterogeneity makes it difficult to automate the testing and deployment of IoT software. Traditional CI/CD tools and techniques are not well-suited for handling the unique challenges of IoT development.

One way to address these challenges is to use software abstractions to emulate devices. This enables developers to simulate the entire IoT infrastructure, including the devices, the network, and the cloud. This allows them to test their software in a controlled environment and identify potential issues early on.

Another way to address the challenges of CI/CD in IoT is to adopt a microservices architecture. This involves breaking down the IoT system into small, independent services that can be developed, tested, and deployed independently. This makes it easier to automate the CI/CD process and to scale the system as needed.

By addressing the challenges of CI/CD in IoT, organizations can improve the quality of their software, reduce time to market, and enable faster innovation. 🤖

👉 How do you implement the CI/CD paradigm for Internet of Things deployments? 💡","",""
"867075936054149191","rickbullotta","2024-05-14T19:13:09.6390000+08:00","Operational safety makes CI/CD impractical for much of OT.","",""
"698244484302897323","lmtx","2024-05-14T19:18:16.5560000+08:00","For that exact reason, I suggest software emulation instead of using the actual hardware within the pipeline.","",""
"867075936054149191","rickbullotta","2024-05-14T19:19:29.5140000+08:00","Not for deployment!","",""
"698244484302897323","lmtx","2024-05-14T19:22:04.6640000+08:00","Agreed. During the OT deployment, there is always a manual checkpoint.","",""
"890244048739270656","brianpribe","2024-05-15T01:00:41.4130000+08:00","I agree, but how should software providers and manufacturers implement CI/CD to keep production up and software up to date? Obviously during planned downtime, but what else?","",""
"867075936054149191","rickbullotta","2024-05-15T01:16:38.9720000+08:00","There’s a lot of synchronization need with major changes of course. I am skeptical about the need for CI/CD for PLC code. Source management sure.","",""
"890244048739270656","brianpribe","2024-05-15T01:52:37.3800000+08:00","PLC code really does not need CI/CD. I’m talking more CIV patches and non-critical software.","","👍🏼 (1),💯 (1)"
"867075936054149191","rickbullotta","2024-05-15T02:24:52.2520000+08:00","I guess the other question is, where would you place this on your list of priorities and issues that really need solving. It would probably be near the bottom of the list for me.","",""
"890244048739270656","brianpribe","2024-05-15T02:29:03.7900000+08:00","For machine builders and SI that provide ""cloud"" services (web dashboards, monitoring) I would say mid to bottom tier. For manufacturers, really it would only include CIV patches and that's bottom of the barrel stuff unless you're dealing with RTUs n stuff like that.","","👍🏼 (1),💯 (1)"
"867075936054149191","rickbullotta","2024-05-15T02:36:09.1860000+08:00","And even the patches need to be tested and carefully deployed","","💯 (1)"
"794542235676180500","akoscs","2024-05-15T04:56:27.5240000+08:00","I would strongly disagree with the first half. CI definetly yes much needed! CD...deliver..where....direclty to teh PLC? yeah...I would not do that. deliver eeevrywhere else (tesitn, validation, etc) definetly yes!

For sure you see value in comming the code to a repository and having all versions available in an organized manner and not names as X_final, X_final_done_installed_working_OK_but_not_for_clientY","",""
"890244048739270656","brianpribe","2024-05-15T06:31:09.4550000+08:00","Okay new acronym: CI/SD
Continuous improvement stable delivery","",""
"867075936054149191","rickbullotta","2024-05-15T20:52:23.4180000+08:00","How many times do you have multiple developers and lots of dependencies in PLC code...really.","",""
"794542235676180500","akoscs","2024-05-15T22:18:48.2450000+08:00","More and more often. Also version control serves you well even as a solo dev. Furthermore, if you create your own blocks, which you can manage centrally that boost your productivity a lot!","",""
"867075936054149191","rickbullotta","2024-05-15T22:21:30.8360000+08:00","Right. But version control is different than CI.","",""
"794542235676180500","akoscs","2024-05-15T22:26:16.5230000+08:00","Well…they are getting integrated (pun intended). Your version control system in most cases becomes your CI system…","",""
"794542235676180500","akoscs","2024-05-15T22:26:57.7380000+08:00","As in github/gitlab (not just git)","",""
"1073312001788477471","sparkylarks","2024-05-15T22:35:52.6170000+08:00","If you are working in Level 1&2, You need to mange how you change you PLC code and SCADA, and other configurations.
This could be as simple as creating a backup of the program file before any changes, making the change, Testing, and then making a backup after the change. and an Excel file to log what change was made.

Asset Centre is a great tool if you are using Rockwell. 
VersionDog and Octaplant are good too.

I don't think standard ITIL approaches are a good fit for PLC code. The concept of testing before deploying to production in particular is problematic. But the concept of , Plant the Change, asses the risk, have a rollback plan, make the change, test the change is a great process to start with.

And having a Test bed of a few PLC's common in a plant for Testing SCADA or other Integration to the PLC is very useful, to test from the PLC up and remove any issues there, but you will always need to retest once you deploy to production.

I don't know if CI/CD is appropriate, I don't know if the concept of testing after deployment, and especially making tweaks to the code is captures.
I certainly don't want Firmware versions being continuously updated without me knowing. I had a Rockwell L81( V16.4????) that Kepware would not communicate with. and of course the highest firmware we could use on the PLC was 16.4.

IT were really looking at a big change and retest , and when we came in on Monday we found the PLC had failed and been upgraded with a new L81 from stores with firmware V20.","","👍 (2)"
"1214320791139655760","lifelong_learner001","2024-05-17T05:36:23.4940000+08:00","I believe that CI/CD will be more relevant for managing data on edge devices than for PLCs. Collecting and analyzing data, these tasks are less critical than ensuring safety near machinery.

When it comes to managing code for PLCs, having a system like SCM is important, especially with multiple developers working on the same project. I faced this firsthand while working on a carton conveying line with a robot palletizer running day and night shifts. Tracking changes made during different shifts was really challenging, and we had to document every modification by each developer using comments named after each dev.

SCM also offers the advantage of easy rollback. If there's a problem with a PLC software update that affects or breakes production, reverting to a stable version is straightforward, ensuring smooth operations.

I know that SCM isn't popular for the PLC world due to the Ladder  language, but I think it's gone gain popularity when a stable open source SCM is available","",""
"890244048739270656","brianpribe","2024-05-17T06:12:58.1940000+08:00","Or when better platforms come out. PLCNext has a lot of this built-in tho version control requires a license","","👍 (1)"
"867075936054149191","rickbullotta","2024-05-17T20:27:53.1850000+08:00","Codesys now offers a Github integration.","","🔥 (2),👍 (1)"
"817835202746253344","IIoT#4707","2024-05-17T22:19:15.1220000+08:00","","",""
"1243271145390866623","safasaib_10899","2024-05-24T03:14:28.4920000+08:00","could anyone tell me the steps to implement the cloud in a company ?","",""
"212982116764483597","elorso.","2024-05-24T05:02:44.5980000+08:00","Hi All, in my company we are looking at our Cloud provider and was wondering if any benchmarking was shared here between azure, aws, google... . I found that azure struggles in the ot side. But find it hard to make the best decision on enterprise level","",""
"817835202746253344","IIoT#4707","2024-05-24T05:02:44.9910000+08:00","GG @elorso., you just advanced to level 3!","",""
"867075936054149191","rickbullotta","2024-05-24T05:25:22.2730000+08:00","Do not use ANY of your cloud providers in OT.  Use them in the cloud.  That's my POV.","",""
"890244048739270656","brianpribe","2024-05-30T00:06:52.1980000+08:00","Look at cloud-technology before thinking about deploying in the cloud. The cloud is really just someone else's virtual machines with their custom services.","",""
"1243271145390866623","safasaib_10899","2024-05-30T01:11:42.0530000+08:00","can u tell me how ?","",""
"1028835038378328164","sdeggans","2024-05-30T02:03:10.4620000+08:00","@safa saib That's going to require a discussion. Someone is going to need to know a lot more about your company and your goals before making any type of technology recommendation. You may not even need cloud services.","",""
"1073632885153730621","vaughnturner","2024-05-30T02:12:33.0310000+08:00","This is correct. @safa saib you need to perform a DTMA or some type of assessment first. This process includes: Define your digital strategy, a 3 sentence statement of why your company wants to be digital. Inventory the business, Inventory the intelligence, Define your Minimum Technical Requirements (MTR), Define your architecture, Identify a Proof of Concept, Connect the intelligence to the network, Create your Unified Namespace (UNS), Integrate intelligence to the UNS, Consume data, publish information, solve the first problem, then iterate. These are the high level steps to digitally transform your business.","","👍 (1)"
"1243271145390866623","safasaib_10899","2024-05-30T02:23:12.4360000+08:00","it's actualy for my master thesis about the transition to industry 4.0","",""
"817835202746253344","IIoT#4707","2024-05-30T02:23:12.7900000+08:00","GG @safa saib, you just advanced to level 3!","",""
"1073632885153730621","vaughnturner","2024-05-30T02:24:56.5240000+08:00","Excellent, you should talk to @Jeff Rankinen 🕺 he's a professor at Penn Tech, and a long time member of the community. He could give you some advice as well.","",""
"1243271145390866623","safasaib_10899","2024-05-30T02:26:31.4530000+08:00","how i integrate the intelligence","",""
"744671252605829181","jeff.rankinen","2024-05-30T02:33:39.2130000+08:00","Glad to provide some insight. I agree with @Vaughn Turner about developing a digital strategy first. Feel free to contact me through Discord or email - jrankin@pct.edu","",""
"1243271145390866623","safasaib_10899","2024-05-30T03:03:34.7310000+08:00","i just sent you the details","",""
"1243271145390866623","safasaib_10899","2024-05-30T06:52:11.5030000+08:00","how i connect the intelligence","",""
"867075936054149191","rickbullotta","2024-05-30T19:28:34.6420000+08:00","Perhaps you should start with the Mastermind classes offered here.","","💯 (1)"
"1243271145390866623","safasaib_10899","2024-06-01T23:04:02.6060000+08:00","Hello, I’m a student in industrial engineering, and this year I’m working on my master thesis about the transition to industry 4.0, i started my project with an internship in a company, i started to solve some problems with lean manufacturing like overproduction, waiting time, and defect, then i started to plan for industry 4.0 by defining the company strategy and evaluate the digital maturity of the company","",""
"867075936054149191","rickbullotta","2024-06-02T06:20:05.6110000+08:00","Check out Leela.ai - it’s like having an industrial engineer doing a time and motion study but via AI.","","🕺 (1),👍 (1),💯 (1)"
"744671252605829181","jeff.rankinen","2024-06-02T08:18:23.9010000+08:00","I just sent you an email. Reach out to @Zack Scriven  about the Mastermind class starting next week.","","💯 (1)"
"1214242167640424619","zack.scriven","2024-06-03T00:04:50.6550000+08:00","Thanks Jeff","",""
"825084676066246677","anibalvelarde","2024-06-21T11:53:33.7950000+08:00","**Curiosity Question:**
- has anyone here been using AWS Iot services (e.g., Greengrass, SiteWiseEdge, etc.)?

I was wondering if any one had tried using a Greengrass Docker Image on-prem (running on Docker on a Windows VM).  I was able to crate a Docker image based on AWS Dockerfile available at this [repo](https://github.com/aws-greengrass/aws-greengrass-docker/blob/main/Dockerfile).

The README.md mentions Mac OS or Linux as one of their pre-reqs, but I figured out a way to get the image to build on Windows Server 2022 - in case anyone is interested. I'm looking for anyone interested in trying on your side to see if you encounter any issues.  I'm able to connect to the the AWS cloud and configure my GG device, download components to it, etc.

LMK if you'd like to connect on this topic to discuss further.","",""
"795178288330440704","youri.regnaud","2024-07-06T13:54:46.1030000+08:00","What would you say are the main challenges in transferring data from a graph database (DGraph with ISA-95 schema) to BigQuery?","","👀 (1)"
"783917475128410112","geoffnunan","2024-07-06T15:17:38.8980000+08:00","BigQuery works best with wide tables, so data modelling is the first challenge, then deciding on the frequency of update. Example, daily load of data or streaming changes as they happen.
DataModelling challenge is similar to any data warehouse design. Define the stakeholders, requirements, granularity and latency needs, then design the transformation from ISA95 to bigquery","","👍 (1)"
"783917475128410112","geoffnunan","2024-07-06T15:18:56.6590000+08:00","We are working on a similar requirement to load Azure DataLake and Databricks at the moment","",""
"403511800068440074","rafaamaral","2024-07-09T13:06:01.7220000+08:00","We have that functionality but we use S3 as a transfer gateway. it does mean we flatten and denormalise the data but its easier to consume then. Let me know if you want some ideas.","",""
"684990296651726877","todd_abraham","2024-07-12T22:29:31.3830000+08:00","Reading through this article from NetApp talking about how their NetApp OnTap service is the way to deal with the OT/IT convergence challenge. Does anyone have experience with this service? Thoughts, comments?

https://www.netapp.com/blog/bridging-the-ot-it-divide-in-manufacturing/","",""
"795178288330440704","youri.regnaud","2024-07-20T03:45:42.1090000+08:00","For Hexagon Cloud EAM users, how do you push data into a data lake?","",""
"1214242167640424619","zack.scriven","2024-07-26T09:13:19.8460000+08:00","haven't heard of that platform. what methods does it support for ingest?","",""
"766684226455207996","bright_hummingbird_31342","2024-07-26T10:01:07.3660000+08:00","It's the ""new"" Infor EAM.
https://docs.hexagonppm.com/r/en-US/HxGN-EAM-Rest-Web-Services/1264213","","ithink (1)"
"1214242167640424619","zack.scriven","2024-07-26T10:49:36.4550000+08:00","Infor was a great name","",""
"795178288330440704","youri.regnaud","2024-07-26T13:56:04.1450000+08:00","https://hexagon.com/company/newsroom/press-releases/2021/hexagon-acquire-infors-eam-business","",""
"867075936054149191","rickbullotta","2024-07-26T21:46:46.7320000+08:00","I think Hexagon has done over 200 acquisitions...","",""
"756565963520081950","andersgustav","2024-07-27T01:20:33.6890000+08:00","Does anyone know how much of infoor “remains“ in hexagon?","",""
"766684226455207996","bright_hummingbird_31342","2024-07-27T01:59:21.7390000+08:00","It's more like Koch owns Infor and Koch owns a small percentage of Hexagon.  It's the same EAM solution, but probably with a slightly different go to market (Mfg ERP suite vs Quality+Engineering portfolio).","",""
"795178288330440704","youri.regnaud","2024-07-27T03:31:59.7010000+08:00","As far as I know, EAM Cloud has moved from the Infor Cloud to the Hexagon Cloud, and since the EAM acquisition, the roadmap includes a strong focus on integration (a complete REST API catalog and DataBridge Pro with Nifi).","","👍 (1)"
"360655177512124416","paobaowow","2024-07-27T05:59:36.7720000+08:00","I am not sure if it was mentioned in one of Walker's Youtube videos, but I remember Walker mention that edge computing is not advisable (that's why computing is done at the cloud). What are the certain factors that make edge computing not scalable?","","⁉️ (1)"
"817835202746253344","IIoT#4707","2024-07-27T05:59:37.0910000+08:00","GG @paobaowow, you just advanced to level 1!","",""
"1214242167640424619","zack.scriven","2024-08-07T07:53:54.8320000+08:00","idk. but the Infor MES guy on linkedin. i don't think he knows what he is talking about.","",""
"1214242167640424619","zack.scriven","2024-08-07T07:54:12.4190000+08:00","after that post the other day. Should you connect your PLC directly to MES and skip SCADA...","",""
"1214242167640424619","zack.scriven","2024-08-07T07:54:21.5850000+08:00","it's like tell me you have zero clue about IIoT without telling me.","","💯 (1)"
"867075936054149191","rickbullotta","2024-08-07T20:43:56.7030000+08:00","Depends on the use case.  In heavily manual processes (even with PLCs doing some material handling or monitoring) you might well do without SCADA.","","👍 (2)"
"1214242167640424619","zack.scriven","2024-08-08T01:08:52.3590000+08:00","But the notion of connecting “directly” edge to any application, and not to infrastructure, is the part that loses me.","",""
"568913935147728896","zeratall","2024-08-08T01:55:52.5240000+08:00","All architecture/infrastructure is composed of apps, your always just connecting devices to apps at the end of the day. But there is a difference in point to point connections to end consuming applications, vs connecting to an application that fits into an entire architecture that is integrated with other apps for example a Gateway (like Kepware)","",""
"1214242167640424619","zack.scriven","2024-08-08T02:34:33.9560000+08:00","Well said.","",""
"1214242167640424619","zack.scriven","2024-08-08T02:36:02.9580000+08:00","Within the context of the architecture you have software that’s primarily used to build applications, and software you primarily use to build infrastructure. When I say infrastructure/ applications that’s The distinction I’m referring to","","💯 (1)"
"743826569918939217","reliabilityrooster","2024-08-10T07:55:04.9180000+08:00","The bigger question is how much DataStream remains in Infor/HxGN EAM lol. I have heard HxGN is formally ending support for MP2. Like Rick said, they made a TON of acquisitions, as too has IFS. And the lead of Hexagon EAM is now leading IFS EAM business","",""
"817835202746253344","IIoT#4707","2024-08-20T17:57:07.6340000+08:00","","",""
"877337143742197810","karltbraun","2024-10-14T23:32:12.1070000+08:00","I could be wrong - but that doesn't sound right.  I think you need edge computing if you are doing ML - ML is usually done at the edge.  Even most AI-driven vision systems (cameras) have the ML function onboard the camera.","",""
"891563487241842699","jbonhage155","2024-10-18T02:14:26.5630000+08:00","suggestion for reporting -- I have a lot of activity data from our AWS load balancer stored in S3 buckets. Currently I can do ad-hoc queries against this data via a tool called Athena in AWS (parses the object store). I'd like to formalize this some more by running an ETL against the data and moving into relational data store in order for better analysis (trending, alerting, etc) Anyone familiar with AWS components to what the best tools would be to do so? (AWS Glue, Lamdba, QuickSight?)

I'm finding the data stored in load balancer logs give a lot of insights to a self managed MES, it records all traffic between client and server. Would allow us to run reports on an enterprise level to see how the system is performing --  http 400, 500 errors along with trends on long running API calls","",""
"795178288330440704","youri.regnaud","2024-10-20T23:45:03.5550000+08:00","I've done the homework on Manufacturing Data Engine and I'm much clearer on the functionality of this Google Cloud Platform solution. I have a question for people who are already using this configuration. Do you only use Looker/Looker Studio for time series analysis? Is a solution like Grafana still necessary when monitoring equipment, for example?","",""
"891563487241842699","jbonhage155","2024-10-25T09:29:05.9750000+08:00","this data engine gonna end up here?
https://killedbygoogle.com/","",""
"894527802316046366","nickn5549","2024-10-27T09:52:02.2360000+08:00","Damn, Google Cemetery is huge...","",""
"867075936054149191","rickbullotta","2024-10-27T20:44:21.3760000+08:00","Looker is at least as good as Grafana (which is grossly overrated IMO)","",""
"783917475128410112","geoffnunan","2024-10-28T15:57:48.3440000+08:00","That really depends on the use-case.","","💯 (1)"
"867075936054149191","rickbullotta","2024-10-28T20:56:33.9710000+08:00","Fair point.   Very true.","",""
"891563487241842699","jbonhage155","2024-10-29T01:47:14.1940000+08:00","Has anyone architected cloud systems, specifially how you determine storage type to use? We deployed an MES with MSSQL server running EC2 with 'defaults' -- in this case we use gp3 with IOPS of 3000. After running an MES for 2 years we are starting to see some significant performance issues. Optimizing SQL directly via indexes, optimized queries is best, I don't want to let the 'hardware' portion off the hook

The article below makes it seems like selecting gp3 with 3000 IOPs is like running a SQL server off a USB 1.1 attached drive with a cap of 12 MB/s.

https://ntorga.com/throughput-and-iops-how-much-is-enough","",""
"867075936054149191","rickbullotta","2024-10-29T02:11:14.0110000+08:00","Have you used the various monitoring tools in AWS to see what's up?","",""
"867075936054149191","rickbullotta","2024-10-29T02:17:38.1660000+08:00","Here's a good discussion of EBS options and the considerations.  Like most stuff in life: cheap, reliable, performant: pick any two.   Might be worth getting an AWS expert involved for a short gig to get you tuned and migrated.","","👍 (1)"
"891563487241842699","jbonhage155","2024-10-29T02:50:28.4980000+08:00","good idea, looks like there are tools for IOPS monitoring. Also they have 'burst credits' so need to check on that
[SQL Server with Amazon EBS](https://aws.amazon.com/blogs/storage/maximizing-microsoft-sql-server-performance-with-amazon-ebs/#:~:text=SQL%20Server%20and%20gp2&text=Gp2%20volumes%20deliver%20single-digit,well%20suited%20to%20SQL%20Server.)","",""
"867075936054149191","rickbullotta","2024-10-29T02:54:33.6590000+08:00","Go io1 and let that data fly!","","💯 (1)"
"403511800068440074","rafaamaral","2024-10-29T15:00:23.0340000+08:00","I wished you could use Aurora instead of MSSQL. I think what AWS did is a game changer that breaks a few paradigms on the SQL world.","",""
"867075936054149191","rickbullotta","2024-10-29T19:27:08.5180000+08:00","Except that would eliminate the possibility of running at the edge/on-prem.","",""
"891563487241842699","jbonhage155","2024-10-29T22:35:38.0360000+08:00","Yeah I've become a cloud hater now using it for 2 years.","",""
"891563487241842699","jbonhage155","2024-10-29T22:40:53.0210000+08:00","our MES is currently running AWS on kubernetes -- overkill. Finding out we are running our SQL server with speeds of USB 1.1. Want to go back to edge, nice hardware, still containerized but run every local. Having latency of <10ms between all software components.","",""
"891563487241842699","jbonhage155","2024-10-29T22:40:55.0470000+08:00","https://world.hey.com/dhh/we-have-left-the-cloud-251760fb","",""
"867075936054149191","rickbullotta","2024-10-30T00:06:55.5590000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/1300853384328511518/image0.jpg?ex=68df4bdf&is=68ddfa5f&hm=5212eea3e1bdf5751c7073b5ad263e3d2e048b069264774d1b7ca2cd6fb0cbf5&","💯 (5),😆 (1)"
"891563487241842699","jbonhage155","2024-10-30T00:36:02.9210000+08:00","Not anymore, it's gonna be my computer... haha.

DHH ""We’ve sort of all turned into pink elephants tied with a tiny rope of learned helplessness when it comes to deployment… The problem is that the entire industry has cultivated a fear of touching a server.”""

https://youtu.be/-cEn_83zRFw?t=1297","https://cdn.discordapp.com/attachments/740336311671586968/1300860713681686598/image.png?ex=68df52b2&is=68de0132&hm=63825e7939e29db4eed114eb253ee3c62d02f3e8c4225ea77d2583a90d46e272&","👍🏼 (1)"
"867075936054149191","rickbullotta","2024-10-30T01:08:52.9850000+08:00","""they've turned the insecurity of developers into a mass market opportunity...""","","💯 (1)"
"891563487241842699","jbonhage155","2024-10-30T02:53:47.5410000+08:00","love the guy. I might start learning Ruby on Rails just because I like his vision.","",""
"891563487241842699","jbonhage155","2024-10-30T02:56:07.5350000+08:00","another rant by DHH, similar to the pink elephant link:
https://youtu.be/a30vFpSaoZg?t=104","",""
"403511800068440074","rafaamaral","2024-10-30T03:56:24.4170000+08:00","I wonder if it's because you are running on the cloud and not in the cloud? After years of managing local servers, mssql, I became allergic to server. Spending that much time on patching, maintenance. If you manage to go native and use the toolset (here there are drawbacks around being locked to one of the two vendors) but you find yourself not spending time things other than your application and your business logic. But I guess everyone has different points of view.","","👍 (2)"
"891563487241842699","jbonhage155","2024-10-31T09:24:20.5180000+08:00","Yeah the simplicity of it does sounds nice. 

Also with a large company I’m finding all cloud activity is much more scrutinized, with governance and global security review. To do a simple ETL on S3 data requires an act of congress. 

When on-prem and not exposed to the outside, it’s way easier to develop and innovate.","",""
"403511800068440074","rafaamaral","2024-11-02T08:45:02.9570000+08:00","Yeah. The IT/OT paradox. One can be too much red tape and the other can be too much cowboy. Finding the sweet spot is a challenge.","","👍 (1)"
"894527802316046366","nickn5549","2024-11-02T10:27:57.3930000+08:00","I stay on-prem, otherwise, I get lost in  bureaucracy","","💯 (3)"
"343075694903033857","michael.brown","2024-12-03T03:04:52.1780000+08:00","Hey Joe, a bit late to the thread. If you've not already remediated - I'd be happy to walk you throught the options on how to manage performance on EBS/EC2","",""
"891563487241842699","jbonhage155","2024-12-03T08:14:04.3980000+08:00","Thanks! I'll ping you","",""
"898217314741280828","hobbes1069","2024-12-09T20:56:18.8280000+08:00","Sound like a great podcast idea!","",""
"905729927968612382","fishburger3430","2024-12-17T04:39:12.9820000+08:00","Hi @Joe Bonhage 
I have worked across large government and mining companies and spent a lot of time educating and overcome the objections/perceived risks with  leveraging hyperscalers like aws, azure and gcp for IT/OT.

Cloud can and will accelerate your speed of delivery for IT/Analytics, however, if your company or IT/OT team is new to cloud there are key risks which need to be addressed up front to overcome these objections - access management and public exposure (api/data), credential leakage and data protection.

Feel free to DM I have more than happy to share my experience and provided insights/help to overcome these challenges.","","👍 (1)"
"343452320216121345","hanno23","2025-01-13T17:04:20.6100000+08:00","Hi all, has anyone looked into leveraging someting like s3 + Athena as a historian for Ignition?","","💯 (1)"
"812295088348200960","patanj2","2025-01-13T20:13:43.6240000+08:00","In general,  it is inexpensive for storage,  but is not a good choice for storing time series data if tou value query performance.   You can do some optimizations such as partitioning and compaction, but query performance is going to be an order of magnitude slower than even a database.  The result  is that end users will have a poor experience.","","👍 (1)"
"766684226455207996","bright_hummingbird_31342","2025-01-14T12:46:18.9280000+08:00","It depends on what you consider historian. If ""historian"" means specific time series analysis and visualization to effectively observe a production process in near real time, probably not. This audience would probably prefer the native tag historian or one of the partner offerings. If historian means something more general, perhaps. It depends on how technically ambitious a team is, the access patterns, and where the Ignition gateway resides.

John is spot on about it being cost efficient for storage and somewhat suboptimal for what many are accustomed to with historians. I'll also add that it's cost efficient for ingress and storage, but can be inefficient for egress and crude queries. Utilizing object storage for structured data tends to work well if the data is used internally (e.g., VPC, region). Outbound access and transfer are considerably less efficient. Both cost and query performance are heavily influenced by the object format, object size, and partitioning. If there are a bunch of small files with a row-oriented format and high cardinality, it will take more compute to query. This is why S3 is commonly paired with Kinesis, MSK, EMR/Spark, and Glue.

S3 is pretty popular with HighByte users. They'll extract data from Ignition or other OT data sources and model as necessary. If they have incumbent integrations to S3, they'll use something like Kinesis. Most elect to ""shift left"" by processing on the edge and publish directly to S3. The pipelines are configured to optimize the ingest, storage and query performance. Downstream, this is used to support more analytics and data science access patterns. So, not quite historian-style production monitoring, but more varied consumption and often blended with other data sources. They're used to answer ""why"" and ""what-if"" questions more than just ""what"" questions, if that makes sense.","","👍 (3)"
"766684226455207996","bright_hummingbird_31342","2025-01-14T12:46:20.1910000+08:00","You bring an interesting point about Ignition. I think Perspective is actual a very underrated tool for consuming this stuff. It strikes a nice balance between not having the limitations of a BI solution but without the complexity of full blown front end development. Additionally, it's not just read only and it can be tied to workflows and decisions. It can enable way more sophisticated interactions with data. It alway surprises me that more people don't run Ignition as an app platform in the cloud alongside the data services.","",""
"891563487241842699","jbonhage155","2025-01-17T04:51:45.0930000+08:00","I use Athena quiet a bit to analysis AWS load balancer logs for troubleshooting but the query gets cumbersome trying to parse the data. Plus it cost money per query depending on how much data is being pulled. I haven't used Kenesis like js referred to but that looks better as it might covert the s3 object data into some sort of time series DB that would be ideal for historian type work.","","👍 (1)"
"891563487241842699","jbonhage155","2025-01-17T04:54:17.9140000+08:00","I was just looking at s3 as a middleware storage for get events out of an MES database so we don't need to have 3rd party DB connect or develop an API. But this is slow frequency data to report status of the ERP transactions","",""
"343452320216121345","hanno23","2025-02-04T15:33:37.6940000+08:00","Thanks @John Patanian @js & @Joe Bonhage  for taking the time to answer my question. You gave me a lot of insight and things to think about!

@js it looks like you have a lot of exposure to cloud/data optimization/Ignition. Maybe a bit of background on why I am asking:

We have a client that sells proprietary containers that get placed all over the world on their client's sites. These containers need to be monitored continuously. Thus, they attempted to build an IIOT platform. Their edge devices are all linux based running scripts that read every single value, every single second. They then publish it to google pub/sub and use BigQuery to query the data and display it on a Angular website. Their data processing costs are quite high and their approach is definitely more from a cloud/IT perspective. Their containers also tend to be custom from site to site and tied to a lot of OT systems on site. So you cannot 100% take a product approach when building out the IIOT platform, you need to be able to be agile and flexible (in my view).

Eventually I am going to help them build out a new IIOT platform. So I am trying to stay ahead of the curve by already thinking about the architecture. Here is what I am thinking so far:

**__Edge (Ignition Edge)__**
The cost of Ignition Edge is nothing compared to the overall container, so no issues there.
Great ""Jack of all trades"" platform that can communicate with about anything (vs creating custom scripts for each OT protocol).
You can have a low-code (perspective) visualization on site
Use MQTT SpB between cloud/edge which allows for statefullness, Store and Forward, bi-directional control.
I like the idea that it is quick and easy to get someone up to speed with using ignition designer instead of custom scripts etc.
I still need to look into Ignition's  ""fleet managment"" capabilities (e.g. EAM)","",""
"343452320216121345","hanno23","2025-02-04T15:33:40.0140000+08:00","**__IIOT Cloud Platform (Ignition)__**
Exactly as you mentioned @js , Ignition strikes a nice balance. I think it speeds up development time for frontend and is easy to get someone up to speed (you don't need a full stack developer or need to know a bunch of web technologies). I think the only issue I have here is scalability. Just running one gateway might end up being slow. Thinking it might be a good idea to split it into multiple gateways (front end GWs/back end GWs)?
Maybe even have them run on someting like ECS/EKS etc. I just had issues with the licensing when testing containers out. Any ideas?

**__Historical Data__**
This is the area that I am the most unsure about. After the helpfull comments all of you gave I am thinking along the following lines:
- Maybe make use of a historian for operational/real-time charts. Maybe pruning data after a couple of months. Someting like TimescaleDB/InfluxDB/QuestDB/Ignition's new historian. What do you guys think? It will obviusly then also need to be setup in the cloud env (not as easy as s3 + Athena which are serverless).
- Have older data/ more advanced analytics be handled by a datalake of some type.

Like I said, at this stage I am just thinking of what this plaform would look like from a high level, any ideas/input is greatly appreciated!","",""
"890244048739270656","brianpribe","2025-02-04T22:22:48.6460000+08:00","If ur going to proveit! We should meet up","","💯 (1)"
"891563487241842699","jbonhage155","2025-02-04T22:28:42.4190000+08:00","No plans to go yet 😔","",""
"247530396252766208","krunk1222","2025-02-07T05:01:26.7060000+08:00","So I saw mention of fellow cloud-haters","",""
"247530396252766208","krunk1222","2025-02-07T05:01:50.3170000+08:00","for me it's not so much that I hate the cloud as that it introduces unacceptable failure points for most of what I work on","",""
"247530396252766208","krunk1222","2025-02-07T05:02:08.1450000+08:00","I was wondering if there was a channel better suited to on-prem first strategies?","","💯 (1)"
"890244048739270656","brianpribe","2025-02-07T05:03:46.6490000+08:00","Think of this channel as cloud technologies, not so much cloud providers, those they are encompassed.","",""
"890244048739270656","brianpribe","2025-02-07T05:09:43.0600000+08:00","Cost-wise: It's cheaper to go on-premise over time, but there is just a substantial upfront cost. With cloud, you have speed to develop and deploy, but over time you pay for it.

So it comes down to strategy and how and why you are using one over the other. For testing and development, go with cloud. It is more important to prove the value of the service than it is to instantiate an on-premise server. Now if you need long-term systems, you push them as close to where you need it as possible. That means pushing it to the device itself, if not then the edge, then lastly on-prem server.","",""
"247530396252766208","krunk1222","2025-02-07T05:14:22.2910000+08:00","Great points, thanks for sharing","",""
"247530396252766208","krunk1222","2025-02-07T05:14:39.3400000+08:00","Which cloud is least worst ?","",""
"247530396252766208","krunk1222","2025-02-07T05:14:47.3990000+08:00","😄","",""
"1073312001788477471","sparkylarks","2025-02-07T05:33:51.9510000+08:00","Consensus is Google.

I generally recommend cloud when you plan to scale.

If you know your traffic , functionality, tag count etc is pretty defined over you IT replacement lifecycle. On prem can make more sense.","",""
"247530396252766208","krunk1222","2025-02-07T05:53:54.7770000+08:00","I haven't messed with google much.","",""
"247530396252766208","krunk1222","2025-02-07T05:54:16.0890000+08:00","Lots of experience with AWS and Azure, I've been using Linode / Akamai for personal projects for ages","",""
"247530396252766208","krunk1222","2025-02-07T05:54:52.4960000+08:00","I think I have some intrinsic distrust of google from their graveyard of products.","",""
"247530396252766208","krunk1222","2025-02-07T05:55:01.7250000+08:00","they EOL'd so many things I liked 😦","",""
"247530396252766208","krunk1222","2025-02-07T05:55:29.6560000+08:00","Most of my background has dealt with onprem because of the application requirements.","",""
"247530396252766208","krunk1222","2025-02-07T05:55:43.6330000+08:00","I've primarly dealt with oil / gas automation and systems control","",""
"247530396252766208","krunk1222","2025-02-07T05:56:15.7260000+08:00","LEO / satellite data exfiltration, deeply remote mostly","",""
"247530396252766208","krunk1222","2025-02-07T05:56:23.6230000+08:00","https://www.onlogic.com","",""
"247530396252766208","krunk1222","2025-02-07T05:56:41.8560000+08:00","^ I buy a lot of stuff from these folks for on prem. Zero frowns so far","",""
"247530396252766208","krunk1222","2025-02-07T05:57:14.1950000+08:00","we do consulting so almost every time, we are dealing with whatever the client is using. I was just curious what people find to work best.","",""
"247530396252766208","krunk1222","2025-02-07T05:57:25.3330000+08:00","and fantasizing about having the luxury of choice 🙂","",""
"247530396252766208","krunk1222","2025-02-07T05:58:00.5150000+08:00","@Mark O'Donovan what about google cloud is the dominating factor in your preference?","",""
"1073312001788477471","sparkylarks","2025-02-07T06:01:15.2530000+08:00","https://tenor.com/view/excellent-breaking-bad-gus-fring-giancarlo-esposito-positive-word-of-mouth-gif-14049815246425714157","",""
"957775996856180737","evjakec","2025-02-07T06:09:50.3950000+08:00","Edge to cloud will pick up steam here. Hyperscalers are doing it and so are the MES vendors. As the edge hardware gets better, we could start to explore not having any data center at the plant and still do real time execution.","",""
"957775996856180737","evjakec","2025-02-07T06:10:36.8430000+08:00","AWS is also claiming that Aurora DSQL could fix the latency concern. Will be interesting if they can pull that off.","",""
"1073312001788477471","sparkylarks","2025-02-07T06:11:26.2650000+08:00","I don't do a lot at the cloud level.
but my understanding is the the Microsoft offering is still essentially being rebuild. and ends up costing more

AWS is pretty good, and have a lot of great partners,  HighByte, Snowflake Tulip.

Google from what I understand it is faster to get stuff done. Most of my impression apart from what people say, is based on my trip to Hannover. Google really got it, I talked to 3 people who really got the issues with manufacturing. To be fair, one of those worked for Litmus and I didn't realise until the end of out chat. and despite being a dabbler I love Litmus, and the fact that google were smart enough to have Litmus at their stand, speaks a lot for me.


I'd love to give you a better answer with hundreds of use cases and data point but, my basic summary is, 
Microsoft bet the farm on OPC and struggled to effectively connect to plants at Scale.
AWS is solid and has done a great job connecting with great partners.
Google seams to have a better set of tools and have the same partners, and I think is a big cheaper

So all very much vibes

Also Google is the fastest growing  and that is a good metric for me.","",""
"247530396252766208","krunk1222","2025-02-07T07:53:51.6800000+08:00","Awesome feedback, thank you! It’s wild that MS seems to suffer regular bouts of dementia with what had previously been well established competencies","",""
"890244048739270656","brianpribe","2025-02-07T08:19:21.3360000+08:00","What’s more important are the technologies being used. Containers, kubernetes, VMs all play an instrumental role in implementing systems (UNS, ERP, etc) and it would be wise to deploy and develop with them before investing millions.","",""
"247530396252766208","krunk1222","2025-02-07T10:21:23.1630000+08:00","I’ve been at it almost 30 years, I’m very comfortable with everything in the DevOps space to date.","",""
"247530396252766208","krunk1222","2025-02-07T10:22:05.1570000+08:00","When we do on-prem stuff we usually start with Proxmox as the host and put VMs and containers atop that","",""
"247530396252766208","krunk1222","2025-02-07T10:22:20.7400000+08:00","We try to keep the shape of things the same whether it’s in the cloud or on prem","",""
"247530396252766208","krunk1222","2025-02-07T10:22:53.3610000+08:00","We also like to be able to fully virtualize development and test environments locally in our lab if not on dev laptops","",""
"247530396252766208","krunk1222","2025-02-07T10:23:51.0130000+08:00","Lately we’ve been exploring WASM/WASI based apps which can be run as a container","",""
"247530396252766208","krunk1222","2025-02-07T10:24:23.0940000+08:00","Rust and Golang can both target WASM as a compiler output","","🔥 (2),👍 (1)"
"890244048739270656","brianpribe","2025-02-07T11:25:07.4680000+08:00","I like this mitten guy","","❤️ (1)"
"247530396252766208","krunk1222","2025-02-07T18:48:26.4960000+08:00","My lead engineer is a Rust dude, but I kinda haven’t been able to force myself to love it","",""
"247530396252766208","krunk1222","2025-02-07T18:48:49.6310000+08:00","I’ve been playing with Go and find it really pleasant to work in","",""
"247530396252766208","krunk1222","2025-02-07T18:49:18.7950000+08:00","No one lets me do any real work but I build a lot of proof of concept and algorithm implementations and hand them off","",""
"247530396252766208","krunk1222","2025-02-07T18:50:29.4330000+08:00","I got the luck of being the nominee for reading white papers and journal docs and translating them to nerd for the team, which is my main excuse to code lately","",""
"867075936054149191","rickbullotta","2025-02-09T12:17:42.7280000+08:00","I prefer languages/platforms that allow me to mix compiled core code with interpreted, application specific code.","",""
"891563487241842699","jbonhage155","2025-02-09T13:00:37.8690000+08:00","How’s reliability been running containers on-prem? We recently deployed an MES “self-hosted” on AWS — Kubernetes for app and MSSQL on EC2. Now 4 sites on production for a year we are starting to regret the decision to run MES in the cloud. Network latency is high especially sites from Mexico. 

OnPrem now seems like the better idea but reversing course at this point seems like a daunting task.","",""
"1003237589421137992","gregory.g.","2025-02-09T15:14:26.0980000+08:00","We are running now linux servers with portainer and docker containers in production on prem for almost 2years. No regrets.","",""
"247530396252766208","krunk1222","2025-02-09T18:59:53.8070000+08:00","Better than the cloud but its a function of your on-site equipment.","",""
"247530396252766208","krunk1222","2025-02-09T19:00:20.7380000+08:00","We put high end Dell servers and rackmount UPS / power conditioning systems","",""
"247530396252766208","krunk1222","2025-02-09T19:00:42.0020000+08:00","or we use OnLogic and address power issues with existing infra or add what we require.","",""
"247530396252766208","krunk1222","2025-02-09T19:01:43.1690000+08:00","Part of why we like this approach is that you can with a little maneuvering treat the on prem and the cloud pod as the same thing","",""
"247530396252766208","krunk1222","2025-02-09T19:02:04.8960000+08:00","Your use case is exactly the type of place I would do on prem and cloud as a hybrid.","",""
"247530396252766208","krunk1222","2025-02-09T19:07:42.9410000+08:00","","https://cdn.discordapp.com/attachments/740336311671586968/1338104035743633418/Screenshot_2025-02-09_at_6.07.37_AM.png?ex=68df05be&is=68ddb43e&hm=6d06364bcdcb91e5071af14a26b4141b481f16c0270d3be17dff32abffd21534&","👍 (1),🔥 (1)"
"247530396252766208","krunk1222","2025-02-09T19:07:52.1220000+08:00","something like this","",""
"247530396252766208","krunk1222","2025-02-09T19:08:43.8980000+08:00","We set up a VPC in the cloud, even if the only thing it's going to run is the VPN server.","",""
"247530396252766208","krunk1222","2025-02-09T19:09:16.9250000+08:00","On Prem servers are on this VPN, and it's used for management / maintenance / monitoring","",""
"247530396252766208","krunk1222","2025-02-09T19:11:06.7260000+08:00","Conceptually this is all just one network now, and if you _start_ in this shape, migrating backwards is much less difficult","",""
"247530396252766208","krunk1222","2025-02-09T19:11:26.5950000+08:00","URI / Paths are under your control in this configuration.","",""
"247530396252766208","krunk1222","2025-02-09T19:12:39.6380000+08:00","so is the DNS system, so no one has to know where `toluca.thisbiz.intranet` actually points just that it works","",""
"247530396252766208","krunk1222","2025-02-09T19:13:45.7570000+08:00","any external users that need to access the network get set up on a different subnet on the VPN","",""
"247530396252766208","krunk1222","2025-02-09T19:15:43.4150000+08:00","I wouldn't think of or discuss the idea of going ""on-prem"" as reversing course.","",""
"247530396252766208","krunk1222","2025-02-09T19:17:09.6630000+08:00","1. You are selling against yourself by presenting a message that it was a bad idea. It was a fine idea, it proved out the value of the system and you learned that latency issues were a pitfall. There was no mistake here, this was a cost effective science experiment with conclusive positive results.","",""
"247530396252766208","krunk1222","2025-02-09T19:18:26.5260000+08:00","2. On prem has it's own share of problems to manage. There's nothing that says they'd have gone any better than the approach you did take, and who knows if you'd have validated the important learnings anyway. On prem and it's complications only begin to make sense once the constraints of the cloud became apparent.","",""
"247530396252766208","krunk1222","2025-02-09T19:19:26.8140000+08:00","3. There's plenty of value in a hybrid solution. Generally the posture I try to take with these is that reporting / analysis happens on the cloud for the enterprise, and operational things happen on-prem at the plant level","",""
"247530396252766208","krunk1222","2025-02-09T19:19:58.7980000+08:00","The nice thing about this is it keeps the accounting department from dragging the DB down at the end of the month while they thrash the reporting system","",""
"247530396252766208","krunk1222","2025-02-09T19:20:33.7750000+08:00","conceptually the plant is where your Write operatins are, and the cloud is where your Read operations are.","","💯 (2)"
"891563487241842699","jbonhage155","2025-02-10T03:26:29.8420000+08:00","Yeah I think kubernetes is an over complication we had added when simple containerization system would have been adequate. Manufacturing production lines don’t see traffic surges like uber or amazon retail front would have during holiday seasons.","","💯 (6)"
"1003237589421137992","gregory.g.","2025-02-10T04:05:03.6180000+08:00","yeah we keep it as simple as possible. IaS: github to portainer, deploying simple containers for the applications. ignition, postgres, mqtt broker, etc. Fantastic time to live in. You could go for docker swarm if needed.","","👍 (2)"
"890244048739270656","brianpribe","2025-02-10T04:33:00.9990000+08:00","We find docker compose is a great solution for an intermediate step before Kubernetes.","",""
"1073312001788477471","sparkylarks","2025-02-10T06:00:13.9320000+08:00","Docker Compose is pretty Awesome.","","🔥 (1),💯 (2)"
"867035383509024778","mattmigchelbrink","2025-02-10T11:10:51.6160000+08:00","Can you share any of the details/specs on the latency issues?","",""
"891563487241842699","jbonhage155","2025-02-11T08:34:16.8300000+08:00","We are trying to nail down exactly were the largest variability comes in terms of performance of the MES but here's a few things we are finding:

 ------ Network ------
--> All traffic enterprise wide goes thru a central corporate datacenter proxy before existing outside. (or to another internal private link with AWS) For example for sites in Mexico data flow is:  site --> route to corporate data center in Minnesota --> route private link to AWS us-east
--> Ping times from plant floor to AWS load balancer (ingress) can vary depending if sites have an local network upgrades (SDWAN) Older site pings around ~600ms with newly upgraded network sites around ~200ms. These pings times are most impactful as our MES is based on a lot of API's calls  to load page - typically around 70 API calls per page load per user.
--> Other dependencies are calls DNS lookup, LDAP authentication and TLS handshake. DNS/LDAP reside in Minnesota, typically this is not an issue but we have had long latencies out of these services 
--> Traffic outbound hitting the main datacenter in Minnesota go thru a firewall, to then exiting corporate datacenter to AWS load balancer ingress, then to WAF (web application firewall) then to MES native application ingress control of Traefik, then to application host pods (core MES .net/C# logic) then to local DB","",""
"891563487241842699","jbonhage155","2025-02-11T08:34:29.2700000+08:00","------ Application------
--> Latency in the application is harder to pin down. Client API calls ultimately land in the application host pods (containerized in kubernetes, typically multiple replicas) Local host determines whether to reply to clients from cache or forward to database (still under investigation how this works )
--> Latency can happen in frequently when kubernetes decides to 'refresh' nodes or node groups, which scales up/down host pods. This normally isn't an issue but I don't not believe the app has session management to properly disconnect clients who are attached to the host pods (worker nodes) and handle off without clients seeing a 'blip' or a bunch of HTTP 500 errors before connection is re-established)
--> we see host pod resource overload (pod goes down on OOM 'out of memory') but other pods are underutilized. This maybe be due to the way traefik forwards requests to host/worker pods but still not ideal as a new pod spins up but clients connected to that host will see small outages as workload switches to other pods
--> currently work nodes/host  pod storage volumes are mapped via CIFS (SMB CSI driver) -- yes you read that correctly, windows SMB file share. gasp!. No idea why it was ever put in this way as volumes should be EFS elastic storage or ANYTHING else beside a windows file share. I think CIFS is like USB1.1 speeds. We investigating if there are bottlenecks here in terms of IOPs. Even if it's as simply as logs, if core app writes logs synchronously we would see slowness because we can't write stupid logs files in a timely matter","",""
"891563487241842699","jbonhage155","2025-02-11T08:35:05.6920000+08:00","------ Database ------
Background: This is the biggest point of contention and latency found for the end user. Most APIs are dependent on the database unless there are more simpler APIs call to which app can return in cache or it's C# scripting. It's not many. It is a MSQL database, always_on cluster spanned 2 large servers, 3 database (realtime, datastore and datawarehouse)
--> for single site, at beginning and end of shifts we can see about ~230k requests(APIs) / hour (~64/sec) The calls which performance database writes are logged in the DB with execution times and see a direct correlation of higher requests with longer execution times. DB calls with read-only we currently do not have observability / traceability on. 
--> DB's run on EC2 instances with gp3 storage (3000 IOPs, 125 Mb/s) -- we currently don't see any bottlenecks here so any other latencies would be around the bowels of MSSQL servers -- query plans, indexes, page swaps. Troubleshooting and getting stability from our SQL servers has been a challenge. We are starting to to implement SPC like alarm on common MES functions and stored procedure so we know if we are trending from baseline.","",""
"891563487241842699","jbonhage155","2025-02-11T08:35:16.9120000+08:00","------ Summary------
-- Unwinding some of these architecture decisions is no easy task being in a medical device manufacturer with 24x7 operations. Zooming out our biggest risk are site to AWS network path traversing 2,500 miles to the AWS with a pit stop at corporate datacenters. Being able to move the AWS workout closer to the source would make a big difference.
-- Getting an handle on database performance and optimization. Database grow each day, latency increases by increased workload by the sites and possible non-archival of data in the realtime database.","",""
"817835202746253344","IIoT#4707","2025-02-11T08:35:17.2140000+08:00","GG @Joe Bonhage, you just advanced to level 13!","",""
"957775996856180737","evjakec","2025-02-11T09:01:32.6260000+08:00","Do you happen to have start\end logging on your API calls? Can be traced of course, but wondering if it was just part of the logs. 70 per page load is interesting. Proper caching being done here?","",""
"894527802316046366","nickn5549","2025-02-11T18:58:54.2720000+08:00","Get some network monitoring tools to log latency spikes, packet loss and bottlenecks. Deploy DNS resolvers at sites to reduce DNS lookup time and use DNS caching to minimise repetitive DNS queries. You can configure/enable 'sticky sessions' to ensure that user sessions remain tied to specific host pods during scaling events. Set up DB read replicas to offload read-heavy operations and reduce the load on the primary database......","",""
"891563487241842699","jbonhage155","2025-02-12T03:43:14.3020000+08:00","we use Chrome DevTools so we can look at per API call where the latency is.. 99% of the time it falls in 'waiting for server response"" -- maybe I should look into Selinum framework monitoring which would give even more details into all the parts of the call.
Interesting you brought up caching because I think that is the weak spot here. Many of the calls are small like 'give me the path of where I should look for a material/resource' this should not need to go to the DB each time nor should there be any sort of long latency. We are finding this is not the case, the cache in the kubernetes containers are not processing fast enough. Need to look at possibly introducing some on-premise or local client caching.","https://cdn.discordapp.com/attachments/740336311671586968/1338958547094077471/image.png?ex=68df7e92&is=68de2d12&hm=b6cc1682c89e5a33909d72dd4fd41130cea6f34fbcb678d366af61f1113ecae8&",""
"891563487241842699","jbonhage155","2025-02-12T03:48:56.3810000+08:00","Good idea regarding DNS resolvers at the sites. I need to look into sticky session -- this where I think some of designs issues reside as we are using AWS load balancer for session management but then AWS hands off the traffic to the application ingress controller (Traefik) which I believe does session management as well. About 1% of all requests return a 400 or 500 HTTP (errors) back to the clients and maybe session management could be a reason.","","👍🏻 (1)"
"891563487241842699","jbonhage155","2025-02-12T09:48:45.9090000+08:00","Made it happen, see you there!","","🔥 (1),💯 (1)"
"890244048739270656","brianpribe","2025-02-12T09:50:23.0500000+08:00","See you there!","",""
"1203453953115693159","stephenbryant_89711","2025-02-12T17:09:09.3880000+08:00","You might also want to look at HTTP pipelining, which reduces DNS calls and TCP negotiation.  Both sides need to support it and actively use it though.  I've noticed that browsers often prefer a pool of parallel connections instead.

Another option - if you control both sides of the connection - is to use WebSockets.  This is especially useful if you are polling for changes, as the server can push notifications instead.  It is, however, a bit of a paradigm shift.  You can have parallel asynchronous communication streams over a single connection, but you need to handle the marshalling yourself at both ends.  I used JSON-RPC to help with that.","",""
"247530396252766208","krunk1222","2025-02-12T22:07:29.6180000+08:00","do you have control over the application stack / source code?","",""
"247530396252766208","krunk1222","2025-02-12T22:08:03.5730000+08:00","if you do, take a look at this https://newrelic.com","","👍 (1)"
"891563487241842699","jbonhage155","2025-02-12T22:15:46.9570000+08:00","We host the infrastructure, vendor controls source code. (.net app runnning in kubernetes) We have access to MSQL DB.","",""
"247530396252766208","krunk1222","2025-02-12T22:16:26.1060000+08:00","has anyone done any tuning of the MySQL DB?","",""
"247530396252766208","krunk1222","2025-02-12T22:16:33.1120000+08:00","bump up query cache sizes etc?","",""
"247530396252766208","krunk1222","2025-02-12T22:17:04.0770000+08:00","it's a bit tedius and you kinda need to instrument the system for a while to see what normal work loads look like for best results but usually you can juke the DB a good bit by just bumping the defaults","",""
"247530396252766208","krunk1222","2025-02-12T22:17:14.5610000+08:00","you'd be shocked how many times I find default db configs.","",""
"891563487241842699","jbonhage155","2025-02-12T22:17:34.5670000+08:00","When we first launched the app we were having slowness. Running wireshark on clients we noticed sessions would go into retransmission (renegotiate) and found aws load balancer max  session time was set to like 60 secs. We moved it to max 3600 secs but I think there are still issues with this","",""
"247530396252766208","krunk1222","2025-02-12T22:18:05.7360000+08:00","""first launched the app we were having slowness."" <- screams cold caches","",""
"247530396252766208","krunk1222","2025-02-12T22:18:15.8760000+08:00","does everything get smooth after it's run for a while?","",""
"891563487241842699","jbonhage155","2025-02-12T22:18:34.6090000+08:00","Yeah this is what we need to do. Started to look at it high level but we need a true DBA to deep dive in it. We bring the issues up to vendor but they just scratch their head","",""
"247530396252766208","krunk1222","2025-02-12T22:18:46.0400000+08:00","you can see it in the AWS load balancer timing out waiting for data to send back to the client and dropping requests","",""
"247530396252766208","krunk1222","2025-02-12T22:19:44.3220000+08:00","I run a consultancy, and would be happy to help you navigate this with the vendor if you have any interest.","",""
"891563487241842699","jbonhage155","2025-02-12T22:20:27.3340000+08:00","Yes. After adjusting load balancer session timeout we didn’t have that issue. That was during the first days after we installed the system. But I still think session management is an issue having both aws load balancer and traefik as session managers","",""
"247530396252766208","krunk1222","2025-02-12T22:20:31.1030000+08:00","a lot gets lost in translation, sometimes just being able to convert Business problems to geek speak is helpful","","👍 (1)"
"247530396252766208","krunk1222","2025-02-12T22:21:18.3840000+08:00","two competing session solutions would definitely be one of the first things I'd want to evaluate.","",""
"247530396252766208","krunk1222","2025-02-12T22:21:34.7000000+08:00","that gets hard to reason about fast when things behave weird","",""
"957775996856180737","evjakec","2025-02-12T22:25:51.5490000+08:00","If the vendor is not willing to share source, I might run a sql profiler on the GetMaterialBom…. Call. Clearly taking some time, yet not returning an overly large response. Wondering there is a lot of chatting with the DB in this method. Would be good to see how many DB calls are made, but then maybe there’s also some blocking/deadlocking going on.","",""
"247530396252766208","krunk1222","2025-02-12T22:26:11.4080000+08:00","can you connect with MySQL Admin to the db server?","",""
"247530396252766208","krunk1222","2025-02-12T22:26:20.1120000+08:00","turn on the slow query logging capabilities","",""
"247530396252766208","krunk1222","2025-02-12T22:26:48.9410000+08:00","and then see if there's any low hanging fruit that you can do without needing to prod the vendor","",""
"247530396252766208","krunk1222","2025-02-12T22:27:00.6850000+08:00","like adding some indexes on joined columns that lack them","",""
"891563487241842699","jbonhage155","2025-02-13T01:43:47.2500000+08:00","agreed on this for sql profiler, I need to figure out a way to trace the incoming API calls to DB activity. For anything that invokes a 'service' on the system (create, update, delete) those transactions are recorded with service start/stop time. We find a direct coorelation between number of calls being executed at a time with longer execution times. Something in the DB is stressed but when look at obvious things like server CPU, disk IOPs, throughput we don't see any pressure. But I think we need to look at hard vs soft page swap if SQL needs to reach to disk or stay in memory. Also we are running r6a.xlarge AWS EC2 types for the MSSQL server -- when looking at it, that size is advertised a mix of 'performance and value' --- at this point we don't need value, we need performance.. LOL. There are EC2 types which use NVME which we may consider switching to.

Back to the SQL profiler topic, it's easy to track the 'service' activity on the system but want we are finding is the small read stuff which should take ~100ms or less to execute can spike to 800ms +  --- when called 10 times during a single page load this still makes the difference. These type of reads are not recorded to the database so let you mentioned there might be some blocking/deadlocking going on.","",""
"891563487241842699","jbonhage155","2025-02-13T01:45:16.7060000+08:00","yeah I have admin rights to the MSSQL server so need to start doing some of this. Been starting to throw some of BrentOzar's monitoring SP's on it to try and get an idea of what to go after: https://www.brentozar.com/first-aid/","","👍 (1)"
"247530396252766208","krunk1222","2025-02-13T01:55:50.2700000+08:00","So depending on the _table type_, you might have either row or table level locking. It sounds like you're hitting a table that has full table locking happening so anything that writes to it blocks other IO until it completes.","",""
"247530396252766208","krunk1222","2025-02-13T01:56:31.7020000+08:00","I love diagnosing stuff like this. There's almost always a lot of profit to be had with some fine tuning.","",""
"891563487241842699","jbonhage155","2025-02-13T02:05:56.8630000+08:00","Love it. This is most likely our exact issue but company doesn't want to spend or bring a true DB expert to fix this kind of stuff so instead operations suffers for weeks/month getting used to a slow system. Both internal DBA and vendor finger pointing to where the issues resides.
I'm at the point of figuring it out myself --  knowing databases isn't the worst skill to have I don't think they are going away anytime soon 🤣","",""
"247530396252766208","krunk1222","2025-02-13T03:28:34.5970000+08:00","My day rates are surprisingly affordable! 😄","","👍 (1)"
"894527802316046366","nickn5549","2025-02-13T17:25:25.0070000+08:00","Ohhhh, yeah, spent some time playing with it","",""
"247530396252766208","krunk1222","2025-02-14T02:14:00.2060000+08:00","find any meaty bits?","",""
"894527802316046366","nickn5549","2025-02-15T07:44:44.9810000+08:00","many...innodb_buffer_pool_size, innodb_buffer_pool_instances, innodb_io_capacity, innodb_thread_concurrency, innodb_read_io_threads, innodb_write_io_threads.........","","🔥 (1)"
"247530396252766208","krunk1222","2025-02-15T08:22:14.7130000+08:00","Did you check query caching?","",""
"247530396252766208","krunk1222","2025-02-15T08:22:30.2770000+08:00","There’s usually profit in caching","",""
"894527802316046366","nickn5549","2025-02-15T08:25:50.9470000+08:00","query_cache_type, query_cache_size,query_cache_limit,  table_open_cache, table_definition_cache, thread_cache_size","",""
"894527802316046366","nickn5549","2025-02-15T08:29:49.0420000+08:00","query cache is deprecated in latest MySQL, need other tricks for speeding up queries","",""
"894527802316046366","nickn5549","2025-02-15T08:32:08.3170000+08:00","here is sample MySQL ini file that use, or start from","https://cdn.discordapp.com/attachments/740336311671586968/1340118414248771604/message.txt?ex=68df1988&is=68ddc808&hm=a6d28aa87c6aefd585a7722b129b7ea7b95b52193eb402c92fd0d67f9e4c91c7&",""
"247530396252766208","krunk1222","2025-02-18T00:11:03.4790000+08:00","did you turn on the slow query logging?","",""
"894527802316046366","nickn5549","2025-02-18T16:36:53.7480000+08:00","not always, only when needed: SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;","","❤️ (1)"
"217148552638365698","jared.comer35","2025-02-23T08:28:27.4680000+08:00","who here know's GraphQL? I'm struggling atm when trying to make a pie chart in Grafana to show the count of logs by Username. and it keeps returning a table with the count in one row (with nodekey count) and user in another row (with nodekey user)","",""
"817835202746253344","IIoT#4707","2025-02-23T08:28:27.7980000+08:00","GG @Jared Comer, you just advanced to level 2!","",""
"891563487241842699","jbonhage155","2025-02-24T12:54:00.6070000+08:00","ChatGPT","",""
"783917475128410112","geoffnunan","2025-02-24T14:38:40.7400000+08:00","What you can do in GraphQL depends completely on what you're using it to connect to.
What is the GraphQL API attached to?","",""
"217148552638365698","jared.comer35","2025-02-24T21:16:16.5530000+08:00","The data is stored in Cognite Data Fusion trying to show it in Grafana","",""
"217148552638365698","jared.comer35","2025-02-25T06:34:42.2590000+08:00","That was my first go to but it is not proving to be helpful unfortunately","",""
"1237180726299066482","vman1517","2025-02-25T11:01:53.6380000+08:00","I'm looking for a reference that shows the pros and cons of Google Cloud, AWS, Snowflake, and  Azure  or something similar. This is for a good opportunity to present options to internal stakeholders who are open to options.","",""
"783917475128410112","geoffnunan","2025-02-25T14:19:08.7900000+08:00","We use GraphQL a lot, but I'm not familiar with how the Cognite server works, so won't be much help.
Do Cognite provide much help in documentation, guides, or videos?","",""
"217148552638365698","jared.comer35","2025-02-25T16:41:03.0810000+08:00","Sadly no. But would you be able to provide some sample queries that return a table with group and count in the same row?","",""
"691362618681589860","keerthana7778","2025-04-22T02:12:37.1950000+08:00","Is it for a particular usecase or just in general? I work as a Data consultant and can probably help you out here","",""
"1195361146564263967","william_vanbus","2025-04-22T10:46:50.5890000+08:00","At that level, it gets a bit general. Is there a specific service you’re looking at?

Eg, data warehouse comparisons. AWS redshift vs. snowflake data cloud vs. google big query vs. Microsoft fabric data warehouse 

Or, by use case, you could also have some refined comparisons (eg, stream processing for maintenance condition monitoring)","",""
"817835202746253344","IIoT#4707","2025-04-22T10:46:50.9760000+08:00","GG @William VanBuskirk, you just advanced to level 2!","",""
"1214242167640424619","zack.scriven","2025-08-04T01:59:12.9160000+08:00","i found this interesting. around enterprise data modeling.","https://cdn.discordapp.com/attachments/740336311671586968/1401625469375479858/Screenshot_2025-08-03_at_1.58.01_PM.png?ex=68df6630&is=68de14b0&hm=1598ffd2b66fefa2d560300b7fda33e3653cf1ee67988141b9b0aa978a919e95&",""
